<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[保险常识]]></title>
    <url>%2F2022%2F12%2F04%2Flife-insurance%2F</url>
    <content type="text"><![CDATA[保险保险的作用：防患于未然，有力转移疾病和意外带来的经济风险，降低对家庭经济的压力。 保险分类： 重疾险：确诊大病后，一次性赔付钱，比如保额买 50W，就能赔付 50W。 医疗险：只有去医院产生的医疗费用才能进行报销； 意外险：比如猝死等 寿险 概念：社保：社会保险，社保即通常说的“五险”，内容有： 养老保险：退休工资 医疗保险：医疗报销，大病统筹。当我们买药、看病、报销，提到的社保一般指「医疗保险」，也就是「医保」 失业保险：失业时可拿一定时间的失业救济金 工伤保险：失业时可拿一定时间的失业救济金 生育保险：女人可以在生产期间费用报销、领取补贴，男人生育结扎、生殖健康等享受费用报销和津贴 医保：最基础的保障，”广覆盖、保基本“，报销额度和报销范围上有限制。社保目录范围内的药品才能报销，进口药、靶向药等高价药无法报销。 百万医疗险：对社保的补充，得了烧钱的大病，医保不报的特效药、高端器械及治疗手段，百万医疗险丢可以报销。 术语 免赔额：不进行赔付的额度，比如”1万免赔额“，表示 1 万元以下，是由个人承担。个人支付累计超过 1 万元部分可以保险报销。 保额 购买策略？ 保费：不要超过家庭收入的 10% 最后提醒大家，一定要做好健康告知，否则会影响后续理赔哦。 重疾险怎么挑选 保额：保额肯定越高越好，但是高保额的保费肯定就高，挑选自己能够负担的起的； 小公司的“长期重疾险”同样可靠——长期重疾险，在中国是强监管产品，保监会负责 建议优先投保定期重疾险 健康告知很重要：忽略健康告知，可能被拒赔 ”防坑指南“里给出的建议： 不建议购买境内的终身重疾险，也不建议购买返还型的重疾险 境内消费型重疾险，推荐相互宝、1年期不保证续保重疾险或只保20年的定期重疾险 健康福·重疾险推荐该产品的理由：婴幼儿的定期重疾险，而且是长期重疾险，年保费只有几百元。 购买建议：保额买足，长期 20 年。 这个产品仅是针对婴幼儿人群来推荐的，因为被投保人为成年人时，年保费就不仅仅是几百，而是上千了！ 婴幼儿闭坑指南: 不要被“少儿专属”重疾险忽悠 医疗险医保医疗保险：医疗报销，大病统筹。当我们买药、看病、报销，提到的社保一般指「医疗保险」，也就是「医保」，是社保”五险一金“中的一种保险。 医保使用记录查询：支付宝搜索框搜”医保“，进入之后，点击”使用记录“。参考 杭州医保消费记录查询教程. 浙里办（支付宝搜索”浙里办“或者下载浙里办 APP），进入之后，搜索”浙里医保“，点击”医保账号“，可以查询： 账户余额 参保状态 缴费记录 消费记录 此外，浙里办这里的”浙里医保“还可以进行报销、家庭共济绑定、定点医院查询、药品目录查询、缴费证明 百万医疗保险没有纳入医保的自费药、特效药、靶向药、进口药等，全额报销。 责任范围可以报销责任范围： 重疾（大病）：恶性肿瘤等 疾病（小病）：阑尾炎、胃溃疡等 意外：交通事故、烧烫伤、狂犬疫苗、 门诊 互联网购药 免责条款规定的情况不能报销，其他的病种均可申请报销。 不属于保障范围： 生孩子 牙齿矫正 视力矫正 整容整形 报销条件：不住院的门诊手术、特殊门诊、住院前后60 天的门急诊。 怎么挑选重点因素： 保证续保期间：保证续保20年的意思，保障的20年期间发生过理赔，也能续保，停售也不影响20年的续保权益。 包含”院外购药“ 院外靶向药是否可以报销 家庭单共享免赔额 家庭单折扣 投保年龄 费用垫付 报销门槛：选免赔额低或者能够家庭共享免赔额的 优选大公司的明星产品 投保注意点： 健康告知里没问到的既往症，可以不告知 保险合同的电子档保存好 一旦决定投保，建议长期续保 咨询阅读保险合同，尤其是责任免除部分 拉黑向你推荐投资功能保险的销售、经纪人或大V 太平洋保险 —— 医享无忧2022 年的明星产品。 泰康范围2 号多了： 意外门诊 传染门诊 使用渠道 APP：泰康在线 公众号：泰康在线保险 会员权益泰爱护·少儿百万医疗险： 凯叔讲故事 VIP 远程问诊、送药上门 意外险保障大小意外，看伤报销，身故/伤残拿一笔钱。 作用 保障大小意外，比如狗咬、烧烫伤、跌倒摔伤等 意外导致的身故、伤残，一次性赔付 报销意外导致的医疗费用 怎么挑选 保障期限：别买长期意外险，选 1 年期即可 加分项目：有疫苗接种意外保障、交通意外额外赔付]]></content>
      <categories>
        <category>Life</category>
      </categories>
      <tags>
        <tag>保险</tag>
        <tag>保障</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Notion使用教程笔记——标签tags功能]]></title>
    <url>%2F2021%2F10%2F31%2Fnote-notion-tags%2F</url>
    <content type="text"><![CDATA[前言在学习了一些基础功能之后，想要在 notion 中也找到印象笔记中的那种标签的功能。因为感觉很难给文章分一个具体的类别，尤其是有时候一篇文章可能属于多种分类的场景。如果将分类分的太细，那么，将来可能就比较痛苦了。 标签功能的使用，就比较好的解决了上面的问题。一篇文章，只要给它划分到一个大类下，然后再给它贴上多个标签，那么，在将来我既可以看到大类下的文章，也可以按照标签去筛选出相关的文章。从而实现可以在多个维度的去查找过往的笔记内容。 标签数据库输入 /database 然后选择 gallery inline ，在这个页面可以创建若干个 page，我将每个 page 设置好名字，比如 Java，这里的 page 名称就是后面供其他文章使用的 Tag。我将这个 page 页称为「标签 page」，机智如我 yeah~ 下面就是我创建的一个「标签 page」汇总的展示页 databse ： 通过 gallery inline 的 database，我提前创建好相应的「标签 page」以供后续文章使用，展示形式还很美观、直观。 链接标签 page使用 @ 或者 [[ 或者 + 都可以唤起输入框，这时候你输入已经建立好的 databse 中的标签就可以了。比如，我在我一篇文章中的属性里面，将 tags 类型设为 text，这样，我就可以在里面通过输入 @ 搜索 tech/java 找到我创建好的标签页。 经过上面的操作，这个文章就和之前创建好的「标签 page」关联好了。 效果阅读对应打了标签的文章时，可以看到 Tags 后面的标签，如果点击，则会跳转到对应的标签 page。 同时，在这个标签页中，也可以看到哪些文章与这个标签 page相关联的。 参考 Case4 - 打标签的两种用法]]></content>
      <categories>
        <category>ToolsDaily</category>
      </categories>
      <tags>
        <tag>效率工具</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式之——UML 类图学习]]></title>
    <url>%2F2021%2F10%2F20%2Fdesign-pattern-uml%2F</url>
    <content type="text"><![CDATA[前言UML 图有很多种，一般掌握类图、用例图、时序图的使用，就能完成大部分的工作。其中，类图主要显示系统中的类、接口以及它们之间的静态结构和关系的一种静态模型。 类的 UML 展示UML 类一般由三部分组成： 类名 类的属性 类的操作 一个具体类的示例： 抽象类、接口的表示法 抽象类：类名以及抽象方法都用斜体字表示 接口：在类图中的第一层顶端用构造型&lt;&lt;interface&gt;&gt;表示，下面是接口的名字。此外，还有一种表示方法，就是类上面的一根棒棒糖（圆圈+实线），圆圈旁为接口名称。 接口示例： 类的属性属性表示方式：1可见性 名称:类型[=默认值] 可见性 public : 用 + 表示 protected: 用 # 表示 defult : 无符号表示 private : 用 - 表示 类的操作/方法操作表示方式：1可见性 名称([参数列表])[:返回类型] 其中： 参数列表的表示，语法和属性的定义相似，参数个数是任意的，多个参数之间用 , 隔开 返回类型是一个可选项，可以是基本数据类型，也可以是用户自定义类型，还可以是空类型(void)。如果是构造方法，则无返回类型。 类之间的关系关联关系 associtaion用于表示一类对象与另一类对象之间有联系。在 Java 中，通常将一个类的对象作为另一个类的成员变量，比如汽车和轮胎。 在 UML 类图中，用直线连接有关联关系的对象所对应的类。 双向关联关联关系默认不强调方向，表示对象之间互相知道。—— 两个类中，互相有对方类型的成员变量。 单向关联如果特别强调方向，就加上箭头。比如是 A -&gt; B，则表示 A 知道 B，但 B 不知道 A。—— A 类中有 B 类型的成员变量，而 B 中则没有 A 类型的成员变量。 自关联类的属性对象类型为该类本身。比如。树节点的左右子节点的类型依然是树节点。 聚合关系(aggregation)has a 的关系，表示整体与部分的关系。成员对象是整体对象的一部分，但是成员对象可以脱离整体对象独立存在的。部分可以属于多个整体对象，也可以为多个整体对象共享，所以，聚合关系也称为共享关系。例如，公司部门与员工的关系，汽车和发动机的关系。在 UML 中，聚合关系用空心菱形的直线表示（空心菱形在整体的一方，箭头指向部分一方）。在代码实现聚合关系时，成员对象通常作为构造方法、Setter 方法或业务方法的参数注入到整体对象中。 代码示例：123456789101112public class Car &#123; private Engine e; // 构造注入 public Car(Engine e) &#123; this.e = e; &#125; // 设值注入 public void setEngine(Engine e) &#123; this.e = e; &#125;&#125; 组合关系(composition)contains a 的关系，它同样也表示整体与部分的关系，但是组合关系中，整体对象可以控制成员变量的生命周期（皮之不存毛将焉附）。例如人的头和嘴巴。在 UML 中，组合关系用实心菱形的直线表示（实心菱形在整体的一方，箭头指向部分一方）。在代码实现组合关系时，通常在整体类的构造方法中，直接实例化成员类。 `javapublic class Head { private Mouth mouth; public Head() { // 实例化成员类 mouth = new Mouth(); } …… } 依赖关系 dependency依赖关系是一种使用关系，在需要表示一个事物需要使用另一个事物时使用依赖关系。在大多数情况，依赖关系体现在某个类的方法使用另一个类的对象作为参数。 在 UML 中，依赖关系使用带箭头的虚线表示，由依赖的一方指向被依赖的一方。例如，驾驶员开车，在 Driver 类的 drive() 方法中，将 Car 类型的对象 car 作为一个参数传递，以便在 drive() 方法中能够调用 Car 类的 move()方法，且驾驶员的 drive() 方法依赖车的 move() 方法，因此类 Driver 依赖类 Car 实际系统开发阶段，依赖关系通常有 3 种方式来实现： 最常见的就是将一个类的对象作为另一个类中方法的参数 在一个类的方法中将另一个类的对象作为其局部变量 在一个类的方法中调用另一个类的静态方法 泛化关系 generalization泛化关系也就是继承关系，用于描述父类和子类之间的关系，其中，父类又被称为基类或超类。如果对象 A 和对象 B 之间的 is a 关系成立，那么二者之间就存在继承关系。例如，一个年薪制员工 is a 员工，那么，年薪制员工 Salary 对象和员工 Employee 对象之间存在继承关系，Employee 是父对象，Salary 对象是子对象。 在 UML 中，泛化关系用带空心三角形的直线来表示。 在代码实现时，使用面向对象的继承机制来实现泛化关系。Java 语言中使用 extends 关键字来实现继承。例如，Student 类和 Teacher 类都是 Person 的子类。 接口与实现关系 realization在接口中，通常没有属性，而且，所有的操作都是抽象的，只有操作的声明，没有操作的实现(Java 8 开始，接口里面可以使用 default 关键字给方法增加操作的实现)。 接口之间也可以有与类之间关系的继承关系和依赖关系，但是，接口和类之间还存在一种实现关系。 在 UML 中，类与接口之间的实现关系用空心三角形的虚线来表示。例如，定义了一个交通工具接口 Vehicle，包含一个抽象操作 move()，在类 Ship 和 Car 中，都实现了该 move() 操作。在 Java 语言中，使用 implements 关键字。 总结 参考 看懂UML类图和时序图 知乎/30分钟学会UML类图]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[儿童营养&喂养基础知识]]></title>
    <url>%2F2021%2F08%2F22%2Flife-jibao-yingyang%2F</url>
    <content type="text"><![CDATA[前言同事之前发我一个视频，是公司邀请的广州市妇女儿童医疗中心儿童营养科主任医师针对儿童营养&amp;喂养基础知识进行的分享。本文就是利用午休时间断断续续看完记录的笔记。 身高相关遗传靶向身高遗传靶身高有两种推算方式： 计算方式 CMH： 男孩=（父亲身高+母亲身高）/2+6.5cm 女孩=（父亲身高+母亲身高）/2-6.5cm 计算方式 FPH： 男孩=45.99+0.78*（父身高+母身高）/2±5.29cm 女孩=37.85+0.75*（父身高+母身高）/2±5.29cm 根据 CMH 方式推算，吉宝的遗传靶向身高在 165 cm，如果根据 FPH 方式进行推算，她的靶向身高将在 161.185~171.765 cm 范围。 骨龄骨龄（Bone age），即骨骼年龄，通常要拍摄人左手手腕部的X光片，医生通过X光片观察左手掌指骨、腕骨及桡尺骨下端的骨化中心的发育程度，来确定骨龄。相较于年龄，骨龄更能准确反映出孩子的骨成熟度，是评价儿童生长发育情况的核心指标。 骨龄检测建议1年1次，骨龄不要超前，也不要滞后太多，-1 &lt; 骨龄-生活年龄 &lt;= 1 属于一个正常范围。 骨龄 - 生活年龄 &gt; 2 岁：应该排查早熟等引起骨龄提前的遗传内分泌疾病的可能 骨龄 - 生活年龄 &gt; -2 岁：应排查生长激素缺乏、甲状腺问题等可能引起骨龄落后的遗传、内分泌疾病。 骨龄成熟比实际年龄大于1岁，就被认为是骨龄成熟较早，这些孩子身高比同龄孩子要高，但是骨骺将会提前闭合，长高潜力反而不大，最终身高可能不理想！ 举个例子，比如9岁的孩子，骨龄在8.5岁，他超过同龄孩子身高的机会就更大一些。而如果骨龄是在10岁，他的骨龄比实际年龄要大，后期超过其他孩子身高的可能性就较小。 如何监测骨龄骨龄的检查方法为：将左手手掌平放在检查台，照射低辐射剂量X光，取得清晰的手掌、手腕与远端尺骨、桡骨影像，再由儿童内分泌科医生做专业诊断。 手部属于肢体末端，避开了脑部、甲状腺和性腺等关键部位，一般拍骨龄片的照射时间很短，辐射量对人体的伤害可忽略不计。 骨龄检查的作用骨龄检查是初步诊断儿童生长发育相关疾患与特定内分泌疾患的一项重要依据，如：身材矮小、身高过高、生长迟缓、性早熟、性晚熟、生长激素缺乏等，所以儿童内分泌科医生常会用骨龄检查作为诊断参考。 骨龄超前或落后的原因引起孩子早发育的原因较多，个体遗传、疾病、环境中的污染物质、与性相关的药物或化妆品、反季节蔬果、过早接触成人媒体画面等都会引起早发育，导致骨龄超前。在日常生活中，家长应注意避免孩子过早接触易引起早发育的因素。 造成骨龄超前的常见原因有：青春期发育、肥胖、遗传、环境荷尔蒙的暴露、甲状腺亢进等。 导致骨龄落后的常见原因有：营养不良、体质性生长迟缓、甲状腺功能低下、特殊药物使用等。 骨龄超前不等于性早熟，关于性早熟，可以阅读三军总医院儿童内分泌科/卫教资讯-性早熟 建议 青春期前：身高水平良好，每年监测一次 青春期：身高水平良好，没半年监测一次 参考 天津医院/骨龄对于孩子的生长发育为何如此重要？ 体重 1~6个月：出生体重+月龄*0.7 —— 吉宝 6 月份目标体重：7.33 kg 7~24个月：出生体重+60.7+(月龄-6)0.5 —— 吉宝 2 岁时，体重 16.33 kg; 2~12岁：增长 2kg/年 营养指导身高促进 疾病预防 合理营养 适当运动 愉快心情 充足睡眠 营养不良原因坏的喂养习惯： 8个月添加糊状食物：辅食添加晚了，6个月就要开始添加糊状食物 边吃边玩 靠家长唱歌、跳舞吸引吃饭 一餐饭要 60 分钟 讨厌的喂养行为： 唱歌等 第一口还没吞下去又塞第二口 边喂边看手机 喂养过程吵闹 不用喊口号，“啊” 追着喂 有一个重要的点要注意：儿童肥胖/超重，70% 会转为成人肥胖，因此，孩子并不是越胖越好，要注意控制孩子的体重在一个健康的体重范围内！ 健康的喂养习惯喂养建议： 早餐：奶、肉/蛋+主食+适当蔬菜 多样化，三天不重复 餐前 1.5-2 小时内，禁止吃其他事物 这三个方面要注意： 营养气氛 营养行为 营养素 建议的喂养行为： 提供温馨和谐的就餐环境 进餐时避免分散注意力 适当限制就餐时间：争取 15-20 分钟 正餐前至少 1.5 ~ 2 小时内不要进食其他食物，不要剥夺孩子的饥饿感，适当的饥饿感，可以促进孩子的生长激素分泌 零食以水果为主，餐后 1 小时内给予 食物多样化，逐渐引入新食物 提高烹饪水平 培养与训练孩子自己进食的能力 自然食物、平衡膳食 要培养孩子自己吃饭的能力，比如 9 个月开始，这也是锻炼孩子能力的一个开始 养育：养+育，父母生养之后，也要注重学习专业的教育知识！ 最佳营养结局： 体格发育 免疫力/抵抗力 体能 智商 情商 睡眠 寿命]]></content>
      <categories>
        <category>孩子</category>
      </categories>
      <tags>
        <tag>营养</tag>
        <tag>育儿</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【转】如何高效地学习]]></title>
    <url>%2F2021%2F07%2F25%2Fsummary-how-to-learn-efficiently%2F</url>
    <content type="text"><![CDATA[本文转载自 博客园 编码砖家/如何高效的学习技术 我们相信努力学习一定会有收获，但是方法不当，既让人身心疲惫，也没有切实的回报。高中时代，我的同桌是个漂亮女同学。她的物理成绩很差，虽然她非常勤奋的学习，但成绩总是不理想。为了巩固纯洁的同学关系，我亲密无间地辅导她的物理，发现她不知道题目考什么。我们的教科书与试题都围绕着考试大纲展开，看到一道题，应该先想想它在考哪些定理和公式的运用。 不少朋友每天都阅读技术文章，但是第二天就忘干净了。工作中领导和同事都认可你的沟通和技术能力，但是跳槽面试却屡屡碰壁。面试官问技术方案，明明心里清楚，用嘴说出来却前言不搭后语。面试官再问底层算法，你说看过但是忘记了。他不在乎你看没看过，答不上就是零分。正如男女相亲，男方谈吐潇洒才能吸引姑娘。可是男方紧张了，平时挺能说，关键时候却支支吾吾，姑娘必然认为他不行。人生充满了许多考试，有形的和无形的，每次考试的机会只有一次。 工作五年十年后，别人成了架构师，自己还在基层打滚，原因是什么？职场上无法成功升迁的原因有很多，没有持续学习、学习效果不好、无法通过心仪公司的的面试，一定是很重要的原因。 把自己当成一台计算机，既有输入，也要有输出，用输出倒逼输入。 学什么基础与应用近些年诞生了许多新技术，比如最时髦的AI(目前还在智障阶段)，数学基础是初中就接触过的概率统计。万丈高楼从地起，不要被新工具或者中间件迷住双眼，一味地追新求快。基础知识是所有技术的基石，在未来很长的时间都不会变化，应该花费足够的时间巩固基础。 以数据结构和算法为例，大家阅读一下Java的BitSet的源码，里面有大量的移位操作，移位运算掌握的好，看这份源码就没问题。Java同步工具类AQS用到了双向链表，链表知识不过关，肯定搞不懂它的原理。互联网大厂都喜欢考算法，为了通过面试也要精通算法。 以Java工程师应该掌握的知识为例，按重要程度排出六个梯度： 第一梯度：计算机组成原理、数据结构和算法、网络通信原理、操作系统原理； 第二梯度：Java基础、JVM内存模型和GC算法、JVM性能调优、JDK工具、设计模式； 第三梯度：Spring系列、Mybatis、Dubbo等主流框架的运用和原理； 第四梯度：MySQL(含SQL编程)、Redis、RabbitMQ/RocketMQ/Kafka、ZooKeeper等数据库或者中间件的运用和原理； 第五梯度：CAP理论、BASE理论、Paxos和Raft算法等其他分布式理论； 第六梯度：容器化、大数据、AI、区块链等等前沿技术理论； 有同学认为第五梯度应该在移到第一梯度。其实很多小公司的日活犹如古天乐一样平平无奇，离大型分布式架构还远得很。学习框架和中间件的时候，顺手掌握分布式理论，效果更好。 广度与深度许多公司的招聘JD没有设定技术人员年龄门槛，但是会加上一句“具备与年龄相当的知识的广度与深度”。多广才算广，多深才算深？这是很主观的话题，这里不展开讨论。 如何变得更广更深呢？突破收入上升的瓶颈，发掘自己真正的兴趣。 大多数人只是公司的普通职员，收入上升的瓶颈就是升职加薪。许多IT公司会对技术人员有个评级，如果你的评级不高，那就依照晋级章程努力升级。如果你在一个小公司，收入一般，发展前景不明，准备大厂的面试就是最好的学习过程。在这些过程中，你必然学习更多知识，变得更广更深。 个人兴趣是前进的动力之一，许多知名开源项目都源于作者的兴趣。个人兴趣并不局限技术领域，可以是其他学科。我有个朋友喜欢玩山地自行车，还给一些做自行车话题的自媒体投稿。久而久之，居然能够写一手好文章了，我相信他也能写好技术文档。 哲学哲学不是故作高深的学科，它的现实意义就是解决问题。年轻小伙是怎么泡妞的？三天两头花不断，大庭广众跪求爱。这类套路为什么总是能成功呢？礼物满足女人的物欲，当众求爱满足女人的虚荣心，投其所好。食堂大妈打菜的手越来越抖，辣子鸡丁变成辣子辣丁，为什么呢？食堂要控制成本，直接提价会惹众怒。 科学上的哲学，一般指研究事物发展的规律，归纳终极的解决方案。软件行业充满哲学味道的作品非常多，比如《人月神话》。举个例子，当软件系统遇到性能问题，尝试下面两种哲学思想提升性能： 空间换时间：比如引入缓存，消耗额外的存储提高响应速度。 时间换空间：比如大文件的分片处理，分段处理后再汇总结果。 设计稳健高可用的系统，尝试从三个方面考虑问题： 存储：数据会丢失吗，数据一致性怎么解决。 计算：计算怎么扩容，应用允许任意增加节点吗。 传输：网络中断或拥塞怎么办。 从无数的失败或者成功的经验中，总结出高度概括性的方案，让我们下一步做的更好。 英语英语是极为重要的基础，学好英语与掌握编程语言一样重要。且不说外企对英语的要求，许多知名博客就是把英文翻译成中文，充当知识的搬运工。如果英语足够好，直接阅读一手英语资料，避免他人翻译存在的谬误。 怎么学知识体系体系化的知识比零散的更容易记忆和理解，这正如一部好的电视剧，剧情环环相扣才能吸引观众。建议大家使用思维导图罗列知识点，构建体系结构，如下图所示： 克服遗忘高中是我们知识的巅峰时刻，每周小考每月大考，教辅资料堆成山，地狱式的反复操练强化记忆。复习是对抗遗忘的唯一办法。大脑的遗忘是有规律的，先快后慢。一天后，学到的知识只剩下原来的25%，甚至更低。随着时间的推移，遗忘的速度减慢，遗忘的数量也就减少。 时间间隔 记忆量 刚看完 100% 20分钟后 60% 1小时后 40% 1天后 30% 2天后 27% 每个人的遗忘程度都不一样，建议第二天复习前一天的内容，七天后复习这段时间的所有内容。 碎片时间不少朋友利用碎片时间学习，比如在公交上看公众号的推送。其实我们都高估了自己的抗干扰能力，如果处在嘈杂的环境，注意力容易被打断，记忆留存度也很低。碎片时间适合学习简单孤立的知识点，比如链表的定义与实现。 学习复杂的知识，需要大段的连续时间。图书馆是个好地方，安静氛围好。手机放一边，不要理会QQ微信，最好阅读纸质书，泡上一整天。有些城市出现了付费自习室，提供格子间、茶水等等，也是非常好的选择。 用起来技术分享从下面这张图我们可以看到，教授他人是知识留存率最高的方式。 准备PPT和演讲内容，给同事来一场技术分享。不光复习知识，还锻炼口才。曾经有个同事说话又快又急，口头禅也多，比如”对吧、是不是”，别人经常听不清，但是他本人不以为然。领导让他做了几次技术分享，听众的反应可想而知，他才彻底认清缺点。 坚持写技术博客，别在意你写的东西在网上已经重复千百遍。当自己动手的时候，才会意识到眼高手低。让文章读起来流畅清晰，需要呕心沥血的删改。写作是对大脑的长期考验，想不到肯定写不出，想不清楚肯定写不清楚。 造个轮子我们经常说不要重复造轮子。为了开发效率，可以不造轮子，但是必须具备造轮子的能力。建议造一个简单的MQ，你能用到通信协议、设计模式、队列等许多知识。在造轮子的过程中，你会频繁的翻阅各种手册或者博客，这就是用输出倒逼输入。 感悟这一章节并不是原文中的内容，而是在阅读了这篇文章之后的触动。作为已经工作几年的程序员，缺乏系统性的学习以及职场的长久规划，竞争力明显会随着年纪的增长而变弱。做好职业的规划，并为此持续的准备，这样才能在未来维持竞争力，否则，危机四伏！警惕！]]></content>
      <categories>
        <category>思考</category>
      </categories>
      <tags>
        <tag>思考</tag>
        <tag>软技能</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[视频剪辑软件「剪映」的学习笔记]]></title>
    <url>%2F2021%2F07%2F24%2Flife-video-clip%2F</url>
    <content type="text"><![CDATA[介绍有了吉宝之后，最近偶尔会上传她的视频到抖音上，为了让视频更好玩儿，开始利用空闲时间学习视频剪辑。抖音官方有一个视频剪辑软件「剪映」，功能挺强大，因此，立个小目标，下半年持续学习输出它的使用笔记。 学习教程 胖姐的迷糊小生活 一位自媒体妈妈，出了很多关于剪映的视频剪辑教程。 B站/史上最精简最全的 剪映 教程【基础篇】 比较系统，但是介绍的比较基础，入门还可以 界面 可以在设置中关闭自动添加片尾 比例首页菜单下，调整视频的比例。 背景首页菜单下，用于填充比例的视频空余的部分，下面的选项是单选，不叠加的： 画布颜色 画布样式 画布模糊 设置画布的效果默认是给时间轴上那段视频片段设置，如果要将画布样式设置给所有的视频，那么，点击界面上的「应用到全部」按钮即可。 剪辑首页菜单下，剪辑中提供了很多功能，可以点击「剪辑」进入剪辑状态，此外，单击视频也会自动进入剪辑状态。 分割 变速 音量 变声 删除 降噪：对录制的视频中音频进行降噪处理 复制 倒放 定格：就是选取了视频中指定时间点画面持续几秒钟，类似于截图。 美化美化下提供了两个主要的功能：美颜和美体 美颜： 磨皮 瘦脸 美体： 瘦身 长腿 瘦腰 小头 音频首页菜单下 音乐 导入音乐：在音频-》音乐-》导入音乐下，支持输入一段音乐的链接地址进行导入。用这个功能就可以实现将网易云音乐的分享链接粘贴到这里，作为视频的背景音乐了。 音效这个菜单下提供了很多音效，例如： 综艺： 疑问-啊？：那种黑人问号的场景使用 震惊 “喂” 屏蔽脏话 土拨鼠大吼：啊！ 剧场欢呼 口哨 尴尬 无语 打嗝 放屁声 黑线 亲 悲伤长叹 笑声 多人大笑 观众笑声 机械声 打字声 机械键盘打字声 系统警告 时钟滴答 门铃 BGM Hello it’s me 小朋友你是否有很多问号 疑惑 人声 我太难了 什么？（日文） 游戏 一杀 美食 录音可以给视频通过自己录音的方式进行配音。 音频编辑当点击添加的音频时，会自动进入音频编辑的状态。 踩点提供了「自动踩点」的功能，能够在音频的时间轴上进行踩点标记，这样的话，就可以在一些音频点上进行照片的添加、转场等，这样会使视频效果更具有节奏感。 变声例如可以将自己录制的配音进行变声处理，提供了一些选项： 大叔 萝莉 女生 男生 怪物 文本新建文本给视频配上文本，充当字幕 识别字幕针对视频里的声音或者你给视频添加的录音进行识别，自动生成字幕。 文本编辑点击添加的文本，会自动进入文本编辑状态 文本朗读针对自己添加的文本，进入文本编辑状态，选择文本朗读，提供了很多特效声音来朗读你的文本： 动漫小新 说唱小哥 台湾女生 动漫海绵 小萝莉 东北老铁 贴纸首页菜单下，提供了贴纸的菜单。 点击添加的贴纸，四个角的功能有所不同，提供了缩放、编辑、删除、复制的功能。 选中贴纸，进入编辑状态，提供了若干动画效果的设置： 入场动画 出场动画 循环动画： 心跳：这个效果不错，比如结合一个手指，心跳效果可以起到引人注目效果。 旋转 滤镜首页菜单下，提供了滤镜的菜单。 调节首页菜单下，提供了调节的选项。在该菜单下提供了如下的功能： 亮度 对比度 饱和度 光感 锐化 高光 阴影 色温 色调 褪色 暗角 颗粒 特效人脸道具这个功能很赞，可以实现针对拍摄的视频自动识别人脸，然后用选择的道具替换，避免露脸了。 画面特效画面特效中提供了很多选择，例如： 基础-》开幕：这个在很多视频的开场可以使用一下 动感-》抖动：有种画面抖动效果 动感-》灵魂出窍：有种画面抖动效果 动感-》毛刺：有种画面抖动效果 边框-》录制边框：有种正在摄影的感觉 自然-》玫瑰花瓣：很唯美 复古-》复古DV：给画面一种老电影的感觉 分屏-》三屏 转场点击 2 个视频片段之间的分隔键，会弹出转场的选项： 基础转场 左移 右移 上移 下移 运镜转场 推近转场 拉远 特效转场 MG转场 幻灯片 遮罩转场]]></content>
      <categories>
        <category>兴趣</category>
      </categories>
      <tags>
        <tag>视频</tag>
        <tag>剪辑</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[小米电视大师 82 寸的使用心得]]></title>
    <url>%2F2021%2F06%2F12%2Fdigital-products-xiaomi-tv%2F</url>
    <content type="text"><![CDATA[前言 为了让已经拥有不错硬件的电视机发挥它应有的实力， 提高片源质量是非常关键的！ 提高片源质量是非常关键的！ 提高片源质量是非常关键的！ 因此，我购入了一款国外的 TV 盒子，它拥有原生的 Google Android 框架，可以支持安装 Youtube 和 Netflix，并且，该设备是经过 Netflix 认证的，可以看 4K 高清视频。关于这款盒子的使用，可以阅读 Tivo Stream TV 使用笔记 除了购入 TV 盒子之外，近期我还购入了 群晖 920+ NAS，可玩性也很高，可以阅读 群晖 NAS 920+ 使用笔记。 APP言归正传， aida64这个软件可以方便的查看电视机的系统信息、CPU 架构等。 下载地址：aida64官网 我的电视是小米电视大师 82 寸液晶版本的，架构信息： File Commander在 TV 盒子上安装好 File Commander，然后可以在局域网内从电脑端向盒子上传文件了。 悟空遥控当贝市场x-plorex-plore 真是个神器，不仅方便浏览目录结构，还有可以访问远端服务器上的资源，例如访问家里 NAS 中的共享文件夹、访问网盘中的文件……这样，就不用拿着 U 盘拷贝文件等琐碎的操作。 下载地址：X-plore File Manager 如果安装的 apk 在远端服务器上，直接安装时，它会先复制到电视机上的临时目录中，然后开始安装。 临时文件夹目录： 内部共享存储空间-》Android-》data-》com.lonelycatgames.Xplor-》cache-》temp vlc 对于一些新格式的视频，常见的播放器可能无法播放或者没有声音，而 VLC 这款开源播放器亲测兼容性很强！而且，功能非常丰富，各个平台都有对应客户端。通过它，可以直接播放 NAS 设备中共享的文件夹中的视频。 下载地址：VideLAN jellyfin Jellyfin 是一个开源的媒体库管理软件。我一开始是安装在 Tivo TV 盒子上的，后来想着这个 APP 也不依赖谷歌框架，因此，直接安装在了小米电视上。亲测，可用，这样，就少了一个切换信号源的操作了。 关于它的使用，我在 群晖 NAS 920+ 使用笔记 有详细的介绍。 下载地址：jellyfin/jellyfin-androidtv 目前，如果想要好看的海报墙，则在 TV 端打开 Jellyfin 客户端，如果图方便和稳定，则直接使用 TV 端的 VLC 播放器链接到 NAS 设备，然后播放视频文件。这两种方式，是目前我探索下来比较稳定、兼容性好的方案。 emby Emby 是一个家庭媒体库软件，包含服务端和客户端。服务端用于整理电影和剧集，客户端连上服务端后就能播放这些影片。这个软件真是一款神器！类似 Jellyfin~ Emby 公益服维护了数量庞大的视频资源，但是它的获取目前比较有门槛，需要经过考试等步骤才可以。网上有热心的网友汇总了题库语雀/Emby。 关于它的资料，可以阅读 Emby 公益服 油管 Bigdongdong/上万部电影和剧集免费来看！完全免费的EMBY公益媒体库分享 客户端下载：Emby 公益服 Mac 端：emby 官网 Mac 端的破解脚本：123bin/bash -c "$(curl -fsSL https://gitlab.com/iptv-org/embypublic/-/raw/master/Script/EmbyPremiere.sh)"# 备用/bin/bash -c "$(curl -fsSL https://git.io/EmbyPremiereUnlock.sh)" 脚本来自：emby mac emby 公益服的地址，可以访问 PLEX/EMBY交流群 回复「公益服」获取。 Youtube 油管 SmartYouTubeTV SmartTubeNext Netflix 奈菲影视 这个是国内的一个奈菲影视网站开发的 APP，可以免费看奈菲的视频，用于在一些非奈菲认证的设备上安装，例如投影仪、小米电视。 奈菲星影视 NFXHD kodi下载地址：kodi 软件下载地址 apkmirror aptoide，aptoide-tv apkpure uptodown]]></content>
      <categories>
        <category>数码</category>
      </categories>
      <tags>
        <tag>APP</tag>
        <tag>数码</tag>
        <tag>多媒体</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[群晖 NAS 920+ 使用笔记]]></title>
    <url>%2F2021%2F05%2F30%2Fdigital-products-nas-started%2F</url>
    <content type="text"><![CDATA[前言 很早之前就听说过 NAS 设备，但是苦于一直在租房的状态（其实是穷），一直没有入手。今年终于搬到新家了，加上近期老婆抱怨手机存储空间不够，已经塞满了吉宝的照片和视频了，因此，终于狠心剁手了一台群晖 920+ 的 NAS 设备。 本文主要就是围绕 NAS 到手后，我进行了哪些设置以及安装哪些好玩的套件。 DS video群晖安装套件：Video Station电视盒子、手机安装：DS Video 通过在 NAS 上安装好套件、添加好资源之后，可以在其他设备上安装 DS Video 来进行观看。会有视频的海报墙，比直接看文件夹或者视频文件更美观和直观。 经过测试发现，对于 DTS、EAC3 格式的视频，群晖的这个 DS Video 播放就没有声音了。只能在电视盒子安装一个 VLC 播放器，这样，DS Video 不支持的视频资源可以选择用第三方播放器打开。 网上有各种解决方案，比如 群晖 Video Station 支持 DTS 和 eac3 解决方案，但是在我群晖 920+ 上都没好使。 经过周末的折腾，利用 Jellyfin 搭建了家庭媒体服务中心，然后其他平台也都有 Jellyfin 的客户端，使用下来，效果也还可以，非常值得推荐！ 参考： 群晖 Video Station 支持 DTS 和 eac3 解决方案 kodikodi 就是个功能强大的播放器客户端，关于它的教程非常丰富，可玩性也非常高。由于我一开始是将 kodi 安装在电视盒子上，电视盒子性能不是很好，因此，kodi 播放一些视频时，卡顿感比较明显。 使用视频： B 站司波图/手把手教你组建家庭影院！（KODI+群晖+智能电视） 解决播放视频没有声音需要在设置-》系统-》音频里，勾选开启一些音频方面设置项的兼容性设置。设置要点： 系统-音频-声道数：2.0 系统-音频-允许直通输出 系统-音频-启用杜比数字（AC3）兼容功放 系统-音频-启用杜比数字（AC3）编码转换 参考： Would appreciate any insight into dealing with AAC 5.1 audio CSDN/安卓dts音频解码_【日常折腾】KODI的AC3音频转码设置 主菜单的添加与删除在设置/皮肤设置/主菜单选项中，可以开启剧集、电影等菜单项。 参考： Kodi主菜单功能介绍 主菜单如何添加删除 参考 KODI 中文网 这个网站提供了很多关于 kodi 的教程 Transmission 安装与汉化 Transmission 是一个开源的下载软件，可以用来下载 PT 站的资源。记得在大学时期使用六维空间时，经常为了做种需要将笔记本一直打开着。现在只需要在 NAS 中安装好这个 APP， 则可以使用 NAS 24 小时挂在后台进行资源的下载和上传。 安装 TR在套件中心添加套件源 http://packages.synocommunity.com： 常规中设置信任： 在社群中搜索 Transmission，按照提示安装，安装好之后的访问地址： 汉化汉化的安装，可以阅读 ronggang/transmission-web-control。以下简要介绍： 在群晖控制中心，开启 NAS SSH 登录的功能： 然后在终端命令行窗口即可登录 NAS： 1234# 登录账号名和 IP 得换成你自己的ssh 用户名@IP# 切换为 root，密码和你 admin 账户密码一样sudo -i 注意： 如果想要在下载时指定目录，需要对应目录需要添加群组： sc-transmission、sc-download 添加常用下载目录： 参考 君子不器/群晖安装Transmission 喵斯基俱乐部/群晖NAS安装及美化Transmission(PT)教程 新浪众测/最强下载工具，玩转NAS影音竟然如此简单！ 介绍了 Tr/万物下载、Plex/Kodi Jellfin Jellyfin 媒体中心介绍 Jellyfin 支持硬件转码，在使用硬件转码推流的时候可以大幅降低 CPU 占用率，支持实时转码。硬件转码功能在 emby 和 plex 都是付费功能。 Jellyfin 是在它的服务器上搭建影音资料库，这样，在任何客户端来访问资料库时，就不用再建立资料库。Kodi 在不同设备上需要重新建立存储在该设备上的资料库。观看的记录会保存在 Jellyfin 服务端，这样，在各个平台切换观看时，使用同一账户就可以方便继续观看了。 Kodi 播放方式类似电脑上的播放器播放。直接从共享文件夹读取文件流，而非播放视频流。Kodi 的这种方式，占用的网络资源则由具体的文件的码率决定。由于解码由播放设备进行，所以实际效果取决于设备的解码能力。如果播放设备解码能力弱，直接播放视频文件，有时候就会造成卡顿或无法播放。而 Jellyfin 的这种方式，可以理解为你自己在 NAS 上搭建了一个多媒体服务器，它可以进行视频的解码，客户端播放能够流畅很多。 安装通过打开 Docker 套件，在其中的注册表中搜索 jellyfin 镜像（映像）进行下载。 进入 jellyfin 服务器地址（NAS IP:8096），即可访问。 需要进行一些设置。可以参考 SMZDM阿文菌/使用群晖Docker 安装Jellyfin 家庭影院HTPC 比emby plex好用多了: 国家选项里没有 China，而是要选择 Peoples’s Republic of China 选择备用字体文件路径：控制台》播放》选择备用字体文件路径，提前在 config 下创建好 font 文件夹（可以自定义文件夹名），在其中放好下载的字体 noto.zip。这个主要为了解决 ASS/SSA 中文字幕会显示方块乱码。 安装的步骤，Jellyfin 官网可以看做是如下命令的等同：12345678docker run --name=jellyfin2 \--device=/dev/dri:/dev/dri \--device=/dev/dri/card0:/dev/dri/card0 \-p 8096:8096 \-v /volume1/docker/jellyfin/config:/config \-v /volume1/docker/jellyfin/cache:/cache \-v /volume1/video:/media \jellyfin/jellyfin:latest 之所以映射设备，是为了开启硬件加速 添加媒体库添加媒体库的步骤很简单，注意勾选： 将媒体图像保存到媒体所在文件夹：方便将下载的资源归档到视频文件夹中 插键字幕插键 Open Subtitles安装 Open Subtitles 插件，这样的话，可以使用字幕下载的功能。使用该插件 安装好插键之后，需要重启容器。 需要去 opensubtitles 注册账号，有了账号，需要去点击该插键进行配置。 参考： 92Nas/Jellyfin中电影外挂ass格式字幕无法显示的解决方法 All the Chinese plug-in subtitles in ASS format 中的解决方案进行配置 播放 查看播放数据： 播放信息：会显示播放方式，可以看出是转码播放还是直接播放的 媒体源信息：表示播放的视频源的信息，可以看到码率、音频编码 比特率：码率，视频文件 原本的码率，如果原本码率比较高，我们通过播放时设置低码率，那么，就会被自动转码 转码信息：看到这个表示正在进行硬件转码，方便播放设备播放。可以看到，源文件的音频是 EAC3，播放时被自动转码成 AAC 了。 硬件加速通过如下的设置开启硬件加速： 开启转码：控制台》播放，选择硬件加速Video Acceleration API(VAAPI) 注意，上面能够成功开启的前提是，勾选了「使用高权限执行容器」 通过 SSH 登录后台，htop 命令查看 CPU 占用率高的进程（jellyfin），查看是否开启验证加速： 此外，在 NAS 查看资源监控，播放视频时，CPU 如果没有飙升，一般也是开启硬件加速的效果。 参考： 分享一种简单得不能再简单的群晖DS918+下Jellyfin调用核显硬解的办法 客户端Jellyfin 的 APP 死机概率非常高，没有网页版本好用。可以使用手机浏览器直接访问网页。利用 Chrome 访问 Jellyfin 的地址，然后在浏览器页面的右上角的菜单项中，点击「添加到主屏幕」，这样即可在手机桌面创建快捷方式。 我的手机进行了权限管理，需要放开 Chrome 创建快捷方式的权限。 TV 端设置Jellyfin/Clients 官网有提供客户端的下载，其中，有安卓 TV 的客户端。 此外，也可以利用 kodi 来访问 Jellyfin 媒体中心。具体的使用方式，可以阅读 kodi ，简要步骤如下： 添加 jellyfin 源：进入插键菜单，插键浏览器，选择从 zip 文件安装，浏览服务器中已经下载好的压缩包 从库安装 jellyfin 插键 为了避免之前 kodi 中添加的媒体资源重复，可以使用使用 jellyfin 插键中的重置本地数据库的功能 利用 kodi + jellyfin 插键的方式播放资源，不会对视频进行转码，这可能就会导致播放高质量视频时会有卡顿。 具体的设置，可以阅读： B站司波图/Jellyfin的外网访问姿势，如何通过安卓，IOS，电视访问Jellyfin服务器 SMZDM/安卓TV端Kodi部署Jellyfin，使用Jellyfin打造最强媒体中心（篇二） 其他资源 字幕网站： opensubtitles a4k subhd 参考 喵斯基部落/群晖Docker安装Jellyfin媒体服务器 利用 Docker 部署 jellyfin 服务 SMZDM/使用群晖Docker 安装Jellyfin 家庭影院HTPC 比emby plex好用多了 B站司波图/免费开源影音服务器Jellyfin部署全攻略，含群晖，OMV系统下Docker安装并启动硬件转码 电影刮削器 TinyMediaManager参考 92NAS/群晖Docker里安装电影剧集刮削器TinyMediaManager KODI中文网/抛弃Kodi难用的刮削器 tinyMediaManager(TMM)刮削电影信息更方便 emby 免费版，服务器硬件解码是不支持的，通过 web 浏览器观看影片时，则会容易造成 NAS CPU 负载很高。但是，比如你使用 Mac 上的 infuse 客户端连接 emby 观看时，它是支持自己解码的，效果不错。 我尝试使用 docker 的方式安装 emby。 安装 emby 步骤查询核显：123456root@michael-nas:~# ll /dev/dritotal 0drwxr-xr-x 2 root root 80 Nov 21 17:35 .drwxr-xr-x 13 root root 13840 Nov 21 17:37 ..crw------- 1 root root 226, 0 Nov 21 17:35 card0crw-rw---- 1 root videodriver 226, 128 Nov 21 17:35 renderD128 看到有结果，则表示具有核显，支持硬件解码。 使用 docker 镜像来安装 emby server。 先在docker 套件中，下载好 emby server 的镜像，镜像地址：https://hub.docker.com/r/emby/embyserver 为了能够加载核显，支持硬件解码，需要通过 ssh 进入 nas 中进行相关操作： 12345chmod a+x /dev/dridocker create \ --name=emby \ --device /dev/dri:/dev/dri \ emby/embyserver:latest coker create 命令类似 docker run 命令，是创建一个容器，区别在于，后者会启动这个容器，前者不会启动这个容器。参考Docker create命令 在套件中心docker 套件中，设置容器配置 第一列「文件/文件夹」是选择 nas 中的路径，「装载路径」是指容器中的路径，二者是一个映射关系，要确保 nas 中的路径给与对应用户权限。这些路径，可以看镜像文档作为参考。 da265c1209c81d4e9e286cdef08f9191 设置 nas 实际端口和容器中的端口映射关系，如图，安装好之后，实际访问地址就是 &lt;nas ip 地址&gt;:8090。 通过 ssh 方式登录到 nas 后台，运行 id &lt;用户名&gt; 可以看到这些数据。gidlist 通过英文逗号配置 gid 的列表即可。 这个非常关键，填写错误，emby 中媒体库将无法正确选择 NAS 中的文件 媒体库设置 首选图像下载语言：English，这样图片会相对更丰富、准确 元数据读取器：Nfo 电影的元数据下载器：选择 TheMovieDb，并调整到第一位 元储存方式：勾选 Nfo 将媒体图像保存到媒体所在文件夹：勾选 Series 元数据下载器：选择 TheMovieDb，并调整到第一位 字幕下载：勾选 Chinese 相关的三个，不仅仅勾选了简体 字幕下载器：勾选 Open Subtitles 参考 群晖dsm7.0系统docker安装emby教程及解码测试 [群晖NAS]Docker安装&amp;使用EMBY全流程图文教程-长文 群晖dsm7.0系统docker安装emby教程及解码测试 Emby在群晖下开启核显硬解转码4K，黑裙6.2.3如何启用核显 PT下载客户端 Transmission Linux/MacOS uTorrent Azureus m-team馒头，通过捐赠即可获得账号+1 个月的 VIP： 账号保留规则 m-team 馒头捐赠页面 登录地址 M-Team 外站 Mac Time Machine 备份到 NAS参考群晖官网的设置，可以指定 NAS 的共享文件夹作为 Mac Time Machine 的备份文件存储磁盘，群晖官网的指导已经更新为 DSM 7.0，资料真是更新及时： 如何使用Time Machine将文件从Mac备份到Synology NAS？ NAS 教程 花王群晖教程 该]]></content>
      <categories>
        <category>数码</category>
      </categories>
      <tags>
        <tag>数码</tag>
        <tag>多媒体</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[sdkman 来管理多 JDK 版本的环境]]></title>
    <url>%2F2021%2F05%2F18%2Ftools-dev-sdkman%2F</url>
    <content type="text"><![CDATA[背景 [sdkman 官网]是这么介绍它的： SDKMAN! is a tool for managing parallel versions of multiple Software Development Kits on most Unix based systems. sdkman 是一个用来管理大多数类 Unix 系统（例如 Mac OSX、Linux、Cygwin等） SDK 多版本的。例如，现在个人机器上主要还是使用 JDK8 的版本，但是，突然有个项目（比如新版 Elasticsearch 7.10）需要更高版本的 JDK 版本，这时候怎么方便管理你机器上的 JDK 环境呢？ 看完下文的操作，你就会用 sdkman 来灵活切换你 SDK 的版本，真的方便！ 常用命令安装 sdkman：1curl -s &quot;https://get.sdkman.io&quot; | bash 打开新的终端窗口：1source &quot;$HOME/.sdkman/bin/sdkman-init.sh&quot; 验证安装：1sdk version sdkman 支持多达大约 29 个软件开发包管理，我们也可以使用 命令来查看支持的完整列表：1sdk list 这个内容比较多，可以使用例如 sdk list java 列出我感兴趣的 candidate 版本。 管理本地已经安装的 JDK 版本：1sdk install java 1.8.0_231 /Library/Java/JavaVirtualMachines/jdk1.8.0_231.jdk/Contents/Home 其实就是在 /Users/michael/.sdkman/candidates/java 路径下，创建一个软连接 1.8.0_231 指向了机器原本的 JDK 安装目录 安装指定的版本：1sdk install java 16.0.0.hs-adpt 临时使用指定版本（关闭终端之后失效）：1sdk use java 1.8.0_231 设置默认版本：1sdk default java 1.8.0_231 查看当前使用的版本：1234# 查看 java 当前版本sdk current java# 查看所有版本sdk current 卸载指定版本的包：1sdk uninstall java 16.0.0.hs-adpt 如果卸载之后想再次安装之前通过 sdkman 卸载的版本，此时不会再次重新下载，会提示 Found a previously downloaded java 11.0.7.hs-adpt archive. Not downloading it again...，因为之前删除操作并没有真正的从你计算机上删除源压缩包文件 清理：123456# 清理广播消息sdk flush broadcast# 清理下载的 sdk 二进制文件sdk flush archives# 清理临时文件内容sdk flush temp 升级 sdkman1sdk selfupdate 参考 sdkman/Usage segmentfault/如何在一台计算机上安装多个 JDK 版本 segmentfault/Java升级那么快，多个版本如何灵活切换和管理？]]></content>
      <categories>
        <category>ToolsDev</category>
      </categories>
      <tags>
        <tag>开发环境</tag>
        <tag>JDK</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基于 IDEA 针对 Elasticsearch 7.10 源码 Debug]]></title>
    <url>%2F2021%2F05%2F17%2Fes-code-debug%2F</url>
    <content type="text"><![CDATA[源码下载ES 仓库地址：https://github.com/elastic/elasticsearch 12git clone git@github.com:elastic/elasticsearch.gitgit checkout 7.10 看到其他人的经验，建议 fork 一下仓库，这样，在对源码进行阅读时，可以将注释等笔记，快速提交到自己的仓库中。 本机环境ES 运行和编译所需要的 JDK 版本是需要分开讨论的。 运行：只需要 Java 8 及以上版本即可 编译：如果是编译源码，对 JDK 的版本要求又高一点。一般在源码根目录下的 CONTRIBUTING.md 文件会有对于编译某个版本的 ES 需要的 JDK 的版本要求 在 ES 7.10 分支上，是有如下的描述： JDK 14 is required to build Elasticsearch. You must have a JDK 14 installation with the environment variable JAVA_HOME referencing the path to Java home for your JDK 14 installation. By default, tests use the same runtime as JAVA_HOME. However, since Elasticsearch supports JDK 8, the build supports compiling with JDK 14 and testing on a JDK 8 runtime; to do this, set RUNTIME_JAVA_HOME pointing to the Java home of a JDK 8 installation. Note that this mechanism can be used to test against other JDKs as well, this is not only limited to JDK 8. 简言之，ES 7.10 版本的编译需要 JDK 14 版本，必须有一个环境变量 JAVA_HOME 指向 JDK 14 的安装目录。默认情况，测试使用同样的 JAVA_HOME。同时，因为 ES 支持 JDK 8，构建支持用 JDK 14 编译，使用 JDK 8 测试。只需要设置一个 RUNTIME_JAVA_HOME 指向 JDK 8 的安装目录就行。 sdkman 管理不同的 JDK 版本，可以同时有多个 JDK 版本存在一台主机随时切换使用。 jdk 的最低版本，在项目中的 buildSrc/src/main/resources/minimumCompilerVersion 文件中可以看到 14，用命令 sdk install java 14.0.2.hs-adpt 安装 JDK 14。此外，JDK 可以在华为云镜像站下载，速度比较块快 gradle 的最低版本，可以在项目的 buildSrc/src/main/resources/minimumGradleVersion 文件下看到 6.6.1 源码编译，导入 IDEA 一些文章比较久，依然让进入 ES 项目的根目录，运行如下命令 ./gradlew idea，这个命令是为了配置 ES project 可以在 IDEA 中使用。目前，在 ES 7.10 版本的 CONTRIBUTING.md#importing-the-project-into-intellij-idea 中，已经略过了该步骤，可能是目前新版的 IDEA 已经自动支持了，不需要上面的步骤。 选择 File &gt; Open 在对话框中选择根目录下的 build.gradle 文件 在对话框中选择 Open as Project 设置 Project SDK 为：JDK 14，这个步骤同时也会将 Gradle JVM 也设为 14。 如果本机网络环境不好，使用默认的 maven 源，速度可能比较慢，可以参考 知乎/ElasticSearch-7.8.0 源码编译调试 (详细) 进行 Gradle 源等的设置。 点击侧边栏 Gradle 的 Reload All Gradle Projects 按钮，或者，打开根目录下的 build.gradle 文件，会有 Load Gradle Changes 按钮。这样会进行源码的构建（编译、下载依赖包等）。 看到上图，则表示源码构建成功。 关于 Roload All Gradle Projects，IDEA 是有相关文档介绍的。 调试远程调试当项目导入到 IDEA 之后，会看到有一个默认的 Remote JVM Debug 配置 Debug Elasticsearch，这个配置是无法修改的： 启动的第一步骤就是先启动这个这个，点击 Debug 按钮就好。 接着，在项目根目录下运行如下命令，启动一个 ES 实例：123./gradlew :run --debug-jvm# 如果是 Widows 平台，则运行如下命令./gradlew.bat :run --debug-jvm ES 实例启动完毕之后，用如下命令验证：1curl -u elastic:password localhost:9200 上面的 -u 是授权验证 user 的作用，如果你尝试在浏览器中直接访问 localhost:9200，将会弹出对话框让你输入用户名和密码。此外，如果在 Postman 中访问的话，也需要设置 Authorization。 之所有会需要授权认证，是因为开启了 xpack 的认证， 其实，除了上面的这种 Remote Debug 之外，还可以通过华为云镜像站点 下载源码对应的 ES 客户端，然后启动客户端之后，attach 到进程中开始调试。下面简要介绍一下步骤： 调整 ES 客户端的 config 目录下的 jvm.options 文件，加入 JVM 的配置参数：-agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=*:5005 启动 ES 客户端：./elasticsearch，Windows 客户端是：./elasticsearch.bat 创建一个 Remote 的远程启动配置： 源码调试源码调试的步骤比较繁琐，没有上面的方式方便。 提前在 华为云镜像站点 下载好源码对应版本的 ES 客户端安装包，解压好。 在 IDEA 中创建一个 Application 启动配置： VM options 如下：12345-Des.path.home=/Users/michael/opt/es/elasticsearch-7.10.2-Des.path.conf=/Users/michael/opt/es/elasticsearch-7.10.2/config-Dlog4j2.disable.jmx=true-Xmx4g-Xms4g Des.path.home 指刚刚 ES 客户端的解压根目录 Des.path.conf 指刚刚 ES 客户端解解压目录下的配置目录路径 需要打开你 Project SDK 设置的 JDK 目录中 conf/security/java.policy 的文件，例如我本机就是 /Users/michael/.sdkman/candidates/java/14.0.2.hs-adpt/conf/security/java.policy 文件，在 grant 括号中，添加如下内容： 12permission java.lang.RuntimePermission &quot;createClassLoader&quot;;permission java.lang.RuntimePermission &quot;setContextClassLoader&quot;; 上面的设置，是为了避免遇到 org.elasticsearch.bootstrap.StartupException: java.security.AccessControlException: access denied (&quot;java.lang.RuntimePermission&quot; &quot;createClassLoader&quot;)、和 java.security.AccessControlException: access denied (&quot;java.lang.RuntimePermission&quot; &quot;createClassLoader&quot;) 的报错 经过上面的设置，就可以通过启动主类的方式成功启动了。 断点断点加在 org/elasticsearch/rest/action/search/RestSearchAction.java 137 行，执行搜索就会进入断点。 FAQJDK 16 isn’t compatible with Gradle 6.6.1, Please fix JAVA_HOME environment variable这是因为 Gradle JVM 的版本与 Gradle 版本不兼容，可以在 IDEA 的 Build Tools -&gt; Gradle 中进行设置： 发现关于 JDK 的设置，当你设置了 Project SDK 的 JDK 版本，这里的 Gradle JVM 将会自动和前者保持保持一致。 参考： Found Invalid Gradle JVM configuration unsupported class file major version 60解决这个问题，还是采用上面描述的方法，设置正确 Gradle JVM 版本。 Stackoverflow/How to fix “unsupported class file major version 60” in IntelliJ? gradle 出现 Connection refused (Connection refused) 问题与网络有问题，检查 Proxy 是否联通，总之，要保证下载依赖的网络畅通。 参考 知乎/ElasticSearch-7.8.0 源码编译调试 (详细) 推荐 CBD Blog/IntelliJ debug elasticsearch 7.10 source code segmentfault/讲得最明白的Elasticsearch源码调试环境搭建教程 ES 7.1.0 版本的笔记 小旋锋/教你编译调试Elasticsearch 6.3.2源码 lanffy/ElasticSearch源码解读一：源码编译和Debug环境搭建 ES 6.7.0 的版本，该博主围绕 ES 写了不少总结 idea源码调试的问题/java.lang.NoClassDefFoundError: org/elasticsearch/plugins/ExtendedPluginsClassLoader]]></content>
      <categories>
        <category>ELK</category>
      </categories>
      <tags>
        <tag>DevOps</tag>
        <tag>Jenkins</tag>
        <tag>CICD</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Tivo Stream TV 使用笔记]]></title>
    <url>%2F2021%2F04%2F25%2Fdigital-products-tivo-tv%2F</url>
    <content type="text"><![CDATA[前言搬到新家之后，陆续购入了若干大件电器，其中，电视机作为家庭客厅的一个重要输出终端设备，经过综合比较，最后剁手了小米电视大师 82 寸 4K 的版本。同期，红米也新推出了一款 86 寸的电视。但是，硬件貌似并没有大师系列好，同时，红米的这款不支持远场语音功能，每次要呼叫小爱同学，还需要找到遥控器然后语音控制，不方便。 目前国产电视机的硬件性能其实都还 OK，个人觉得影响观看体验的重要因素反而是片源！国内「优爱腾」流媒体的质量还有待提高，2K/4K 的片源质量堪忧，甚至 1080P 的片源都不行。因为小米电视并不是 Netflix 认证的设备，是无法直接安装 Netflix 官方 APP 的。因此，决定购入一个国外的电视盒子——TiVo Stream TV 盒子，然后在它上面安装 Netflix、Youtube 等 APP 观看世界各地高质量的片源了。 上图就是效果图啦，美滋滋，顺带安利一部剧《纸钞屋》，西班牙剧真是给力！ 背景知识Netflix 在未进行 DRM（即 Digital Rights Management 数字版权管理） 认证的设备上无法提供高清播放。Netflix 官方帮助教程列出了支持 HD 以及 HDR 的 安卓设备。在 Netflix is available in HD on the Android phones below. 的页面，可以查看哪些安卓平板、安卓手机设备是可以播放 Netflix 高清视频的。 在播放 Netflix 的问题上，电视盒子的标准比上面的 DRM 认证更为严格。设备必须经过 Netflix 认证才能正常安装和播放 Netflix。在2020 Netflix Recommended TVs的页面，看到了 Netflix 推荐的热门电视设备。 哪些电视盒子是 Netflix 认证的设备呢？在这个网址查询：Both Netflix &amp; Prime Video Certified Android TV Streaming Players Tivo TV 激活Tivo TV 设置激活： 悟空/如何激活Tivo Stream 4K 悟空/Tivo Stream 4K 电视盒子开箱加9步长测评 ADB 工具为了解决盒子时间不正确以及提示网络不能联网的问题，需要用到 ADB 工具连接盒子进行设置。 ADB 各种客户端： 谷歌应用商店安装 Remote ADB Shell，可以通过手机来进行对 TV 盒子的设置 Windows 平台也有对应的 ADB 工具，查看 ADB Shell、悟空分享的网盘 Mac：brew install android-platform-tools 下载好 ADB 工具之后，怎么连接电视盒子？ 查看设置，查看系统版本，连续点击「内部版本号」，开启开发者选项 在开发者选项里，打开网络调试/USB调试开关 查看电视盒子连接的 WiFi 网络，获取电视盒子的链接 IP adb connect IP 电视盒子的ADB开关通常有以下几个名字，例如USB调试开关，远程调试开关、网络调试开关 可以正常访问奈菲，但是无法观看 youtube看一下你的 TV 盒子的系统时间，肯定于当前时间不一致，youtube 会有时间验证，临时的解决办法是打开“设置”-“设备偏好设置”，然后找到“日期和时间”，关闭“自动确定日期和时间”，然后手动更改的时间和日期为当前的正确时间。 一劳永逸的方法是去更改时间同步服务器。 修改时间服务器 安卓原生电视/盒子 出现已连接但无法访问 要怎么解决？根治请看这里！ 修复盒子时间不对的问题，因为时间不对，可能会影响证书验证：1234# 查看盒子 NTP Serveradb shell settings get global ntp_server# 设置 NTP Serveradb shell settings put global ntp_server ntp1.aliyun.com 此 WLAN 网络无法连接到互联网Tivo TV 盒子弹出：您所连接的 WLAN 网络无法访问互联网。 虽然弹出上面的提示，但是实际上有些 APP 是可以正常上网的，唯独 Youtube 就无法打开，显示”现在无法联网“！ 问题原因谷歌从 Android 5.0 开始就引入了 Captive Portal 机制，主要用来检测 WiFI 网络认证是否正常，默认检测访问的是谷歌服务器（gstatic.com/google.com）。通过HTTP返回的状态码是否是 204 来判断是否成功，如果访问得到了 200 带网页数据，那你就可能处在一个需要登录验证才能上网的环境里，比如说校园网，再比如说一些酒店提供的客户才能免费使用的WiFi(其实是通过DNS劫持实现的)，如果连接超时(根本就连接不上)就在 WiFi 图标和信号图标上加一个标志，安卓5和6是叹号，安卓7改成一个叉了。只不过默认访问的是谷歌自家的验证服务器，然而由于你懂的原因，就算你连接上了网络也连不上这个服务器。这就是所说的 generate_204 的问题。 国内安卓手机系统都会修改成自家的服务器地址或者高通中国的地址，以此来实现该功能。 解决步骤12345678910111213# 查看当前状态：adb shell settings get global captive_portal_mode# 关闭检测：adb shell settings put global captive_portal_mode 0# 查看机器已有的验证服务器，方便备份 adb shell settings get global captive_portal_http_urladb shell settings get global captive_portal_https_url# 删除验证服务器adb shell settings delete global captive_portal_http_urladb shell settings delete global captive_portal_https_url# 设置验证服务器adb shell settings put global captive_portal_http_url http://www.google.cn/generate_204adb shell settings put global captive_portal_https_url https://www.google.cn/generate_204 小米的验证服务器在国内应该是延迟最低的。12settings put global captive_portal_http_url http://connect.rom.miui.com/generate_204settings put global captive_portal_https_url https://connect.rom.miui.com/generate_204 验证服务器： 华为： http://connectivitycheck.platform.hicloud.com/generate_204 Vivo： http://wifi.vivo.com.cn/generate_204 小米：http://connect.rom.miui.com/generate_204 Google 大陆： www.google.cn/generate_204 给 captive_portal_https_url 赋值，改为 https 链接 以上设置了不一定能解决问题，可能还需要清理 play 数据和缓存，重启盒子。 其实上面步骤在我的软路由环境下不存在，因为很多科学插键的代理域名中已经包含了谷歌那个验证服务器的域名，因此，TV 盒子就不会报错误了。 参考 原生 Android 网络去叉／叹号 Android 5.0 - 10.0 摩西数码/shield tv无法访问互联网无法观看youtube/无线ADB教程 记录一次 Android TV 网络访问排障 油管悟空/Shield TV 出现已连接但无法访问 要怎么解决？Android TV的通用解决办法看这里！再说一遍~]]></content>
      <categories>
        <category>数码</category>
      </categories>
      <tags>
        <tag>数码</tag>
        <tag>多媒体</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[R4S 使用笔记]]></title>
    <url>%2F2021%2F04%2F24%2Fdigital-products-r4s%2F</url>
    <content type="text"><![CDATA[介绍为了让新家的网络可以自由访问各大流媒体资源，以及方便自己开发环境中下载各种国外资源依赖软件包等，购入了 R4S 软路由设备。 固件下载 官方固件/NanoPi R4S/zh 对应的网盘地址/5fd2 QiuSimons/R2S-R4S-X86-OpenWrt 404 大佬的 klever1988/nanopi-openwrt Star 数量比较高 SuLingGG/OpenWrt-Rpi Star 数量比较高，但是我的 R4S 每次安装完都无法联网 Dongdong/R4S第三方固件 骷髅头/DHDAXCW/NanoPi-R4S-2021 语雀上有个文章总结的挺好，推荐 NanoPi-R2S / NanoPi-R4S 常见第三方固件选择 如果想自己编译固件，可以看如下资源： coolsnowwolf/lede Lean的Openwrt源码仓库，高 Star 项目 固件格式说明 文件名带有 ext4 的固件，表示搭载 ext4 文件系统固件，适合熟悉 Linux 的用户使用 文件名带有 squashfs 的固件，表示搭载 squashfs 文件系统固件，适用于不折腾的用户，优点是方便系统还原 文件名带有 sysupgrade 的固件，表示是升级 OpenWRT 所用的固件，无需解压 gz 文件，可以在面板中升级 文件名带有 factory 的固件，表示全新安装 OpenWRT 所用的固件。 参考：bigdongdong-R4S第三方固件 刷固件 洋葱油管/R2S软路由销量之王！R2S安装openwrt攻略 openwrt软路由设置 DongDong/R2S 使用指南 刷固件的软件： balenaEtcher bigdongdong/R2S/R4S 使用指导 写盘工具：可以使用 Rufus 或者 balenaEtcher，其实，就和之前做 Linux 启动盘一样，就是拿着固件镜像文件做一个启动盘。 注意点：刷完固件的 TF 卡下次插入电脑，可能会弹出需要格式化，千万不要进行格式化，否则可能会丢失容量。下次刷固件，不用格式化就可以直接刷固件即可！ balenaEtcher 刷固件 select image：选择要刷入的固件 select dirve：选择 tf 卡，也就是要将固件刷入的存储介质 flash：开始刷入固件 刷好固件的 TF 卡插入 R4S，SYS 灯常亮之后，通过一根网线将 R4S 的 LAN 口和电脑连接。 接着就可以打开 R4S 的后台，浏览器访问 192.168.2.1（有的固件访问地址是 192.168.1.1，甚至 WAN 口 和 LAN 口都交换了，需要认证阅读文档）： 用户名 root 密码 password 至此， R4S 的系统已经安装启动完毕，接着开始配置网络。 网络配置要搞清楚是猫拨号还是路由器拨号。进入路由器后台观察它的上网方式设置，如果是 DHCP 的方式，则表示是光猫拨号上网的方式。 连接设备：光猫的线接入 R4S 的 WAN 口，然后用网线将 R4S 的 LAN 口和路由器的 WAN 口相连。 个人理解，WAN 口就是信号的入口，LAN 口就是信号的出口，这么理解，就知道上面为何这么连接了。 备注：路由器的上网方式其实就是对 WAN 口进行设置，局域网设置的就是对 LAN 口设置的。 图片来自 语雀/NanoPi R2S / R4S 软路由常见网络接线指引 将无线路由器改为无线交换机，有线中继模式所有设备都在一个局域网，没有路由功能，少一次转发 判断路由器是否支持场景二的设置：登录路由器后台，判断路由器是否支持无线接入点（AP）模式/有线中继模式，他们一样，只是叫法不同。 小米路由器在上网设置菜单下有工作模式的切换 后台管理地址一定要记住：重启之后，这台路由器就不是路由器了，就是一台无线交换机，以后，路由器的网口没有 WAN 口和 LAN 区分了。 如果是光猫拨号，网络接口的 WAN 协议就是 DHCP 客户端 如果是软路由拨号上网，就切成 PPPoE，配置宽带账号密码（填好重启光猫） 路由器设置 NanoPi R4S 上手体验 介绍了 OpenClash 的使用，简略 资料：悟空的日常 测速网站：https://fast.com/zh/cn/ 设置桥接模式如果为了让软路由的 IP 和家里联网设备都处于同一网段，那么，可以将路由器设为桥接模式，这样，路由器就相当于 AP，接入路由器的设备不会处于另外的网段。方便在软路由中针对具体的 IP 设备进行联网控制。 小米路由器进入后台：常用设置-》上网设置-》工作模式切换，选择「有线中继工作模式」： 要记住改为中继模式后的管理后台 IP Passwall 使用基本设置 UDP 一般选择与 TCP 节点一致 需要勾选「主开关」保存并应用才真正启用 模式 TCP 默认代理模式：一般选择「中国列表以外」 UDP 默认代理模式：默认是「游戏模式」 路由器自身 TCP 代理模式： 路由器自身 UDP 代理模式： 选项说明： 不代理：不启用代理 全局代理：全部网站走代理 GFW 列表：仅那些被屏蔽的网站走代理 中国列表以外：只要是外国的都走代理 中国列表：这个模式一般是国外的用于访问国内网站的，暂时用不到 访问控制控制连接到局域网中的设备，主要是控制他们使用什么节点或者什么模式来访问网络。 要能控制这些设备，有个前提，这些设备要和软路由在同一网段下。 一般家庭网络布置是如下的： 上面这种方式，路由器一般是 「DHCP 方式/动态 IP」。只能保证无线接入的设备和路由器在一个网段，但是，路由器和软路由并不在一个网段。这种情况，「访问控制」是无法使用的，因为对于软路由来说，只有路由器这个设备是它能控制的。除此以外，还多了一个缺点，多了一次转发。 上图是 UP 主推荐的模式，避免家中网段过多，光猫改为桥接模式，软路由负责拨号，路由器设为「AP模式/桥接模式/有线中继模式」。这样设置，设备就处于同一网段下了。此时，路由器就类似是一个交换机的角色，他不会像 DHCP 那样，产生一个新的网段。 有时候运宽带运营商是不推荐让光猫改为桥接模式，因为改为桥接模式他们没法直接后台操作网络，升级等。现在光猫的性能都不差，也没必要非要改为桥接模式，让其他设备拨号。上图的模式就比较方便，仅仅是将路由器的模式修改为「AP模式/桥接模式/有线中继模式」，路由器连接的设备也可以和软路由处在同一网段。 如下的设置，可以实现局域网内某些设备是否可以走代理： 比如我们使用的 NAS，一般都是国外厂商的，当我们模式选择「中国列表以外」时，一般他们的网站都会被代理，这时候想让他们不走代理或者为GFW 列表的方式，就可以使用访问控制的功能来设置了。 自动切换自动切换功能就是添加若干个备用节点，当其中一个节点不可用，会自动切换到备用节点，实现「高可用」。 直连/代理名单管理 直连列表：可以实现加入的 域名/IP 不走代理，这就可以让一些防火墙中的网址依然不能访问，对所有模式生效，优先级最高 代理列表：加入的 域名/IP 将走代理； 屏蔽列表：加入的 域名/IP 将屏蔽； 举例，https://www.speedtest.net/ 这个测速网站是国外网站，如果在使用代理的情况，默认会是在国外节点进行测速，如果我们将它加到「直连列表」中，则会测量我们家中实际运营商的网速，这才是我们关心的： 高级设置设置节点数量，可以使用多个 TCP 节点，然后配合上面介绍的访问控制，可以实现针对某个设备指定使用某个节点： 例如使用某些不限流量的节点给 NAS 云盘备份使用 分流实现让特定的网站使用指定的节点，比如奈菲使用新加坡节点，油管使用香港节点。 只需要在「节点列表」-》「添加」，按照如下示例选择： 当创建好这个「分流节点」之后，需要在「基本设置」中，选择我们刚刚创建的这个节点。这样，就可以实现分流了。 参考 油管/使用PassWALL 完美掌控内网科学上网 OpenClash全局配置模式设置 运行模式：选择混合模式 基本设置 绑定网络接口：选中系统默认接口 规则设置DNS 设置 本地 DNS 劫持：勾选 禁止 Dnsmasq 缓存 DNS：勾选 版本更新可以「一键检查更新」 配置文件订阅如果机场订阅地址仅有 SSR 的，则需要进行在线订阅转换. 订阅转换模板可以选择ACL4SSR 规则 Online Full 添加 Emoji：启用 UDP 支持：启用 勾选添加的规则，应用配置 OpenClash 的控制面板，里面的代理界面可以看到可以针对不同用途进行不同策略的配置，而且，策略的选择之间其实是一种指向关系。 比如，电报消息走的是「自动选择」，然后「自动选择」又指向了具体的某个节点。 参考 软路由设置重启在使用一周左右，发现网速降低比较明显，重启软路由之后正常了。因此，决定设置定时任务，让软路由每天清晨自动重启。 首先在系统》启动项中，检查 cron 服务是启用的状态 在系统》计划任务的输入框中，添加 0 4 * * * sleep 70 &amp;&amp; touch /etc/banner &amp;&amp; reboot，然后提交保存。计划每天凌晨 4 点重启 上面这个定时任务，其实，直接进入 TTYD 终端界面，crontab -e 也可以编辑保存 参考： 使用 Cron 定时重启 Openwrt 路由器 OpenWRT 设置设置主题进入 系统 》 系统》语言和界面，可以选择主题： 客户端客户端： Clash andriod smartyoutubetv 针对没有谷歌框架的设备可以安装的 Youtube 客户端]]></content>
      <categories>
        <category>数码</category>
      </categories>
      <tags>
        <tag>数码</tag>
        <tag>多媒体</tag>
        <tag>网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Elasticsearch常见API]]></title>
    <url>%2F2021%2F02%2F16%2Felk-es-operation-api%2F</url>
    <content type="text"><![CDATA[文档 CRUD Index API 示例 Index PUT my_index/_doc/1 {“user”:”mike”,”comment”:”You know,for search”} Create PUT my_index/_create/1{“user”:”mike”,”comment”:”You know,for search”}POST my_index/_doc （不指定 ID，则自动生成 ID）{“user”:”mike”,”comment”:”You know,for search”} Read GET my_index/_doc/1 Update POST my_index/_update/1{ “doc”: { “user”:”mike”, “comment”: “You know, Elasticsearch” }} Delete DELETE my_index/doc/1 示例中，my_index 是新建的索引名 Type 名，约定都用 _doc Create：创建新文档，如果 ID 已经存在，则会失败 Index：如果 ID 不存在，则新建文档；如果 ID 存在，则会先删除已有的文档，在创建新的文档，版本会增加 Update：文档必须已经存在，更新只会对相应字段做增量修改 Index 文档Index 和 Create 不一样的地方： index：如果文档不存在，就索引新的文档。否则现有文档会被删除，新的文档被索引。版本信息 +1 update：update 方法不会删除原来的文档，而是实现真正的数据更新，POST 方法请求体需要包含在 doc 中 1234567POST my_index/_update/1&#123; &quot;doc&quot;: &#123; &quot;user&quot;:&quot;mike&quot;, &quot;comment&quot;: &quot;You know, Elasticsearch&quot; &#125;&#125; Get 文档1234567891011121314GET my_index/_doc/1&#123; &quot;_index&quot; : &quot;my_index&quot;, &quot;_type&quot; : &quot;_doc&quot;, &quot;_id&quot; : &quot;1&quot;, &quot;_version&quot; : 6, &quot;_seq_no&quot; : 6, &quot;_primary_term&quot; : 1, &quot;found&quot; : true, &quot;_source&quot; : &#123; &quot;user&quot; : &quot;mike&quot;, &quot;comment&quot; : &quot;You know, Elasticsearch&quot; &#125;&#125; 找到文档，返回 HTTP 200 文档元信息 _index/_type 版本信息，同一个 ID 的文档，及时被删除，Version 号也会不断增加 _source 中默认包含了文档的所有原始信息 找不到文档，返回 HTTP 404 Bulk API 支持在一次 API 调用中，对不同的索引进行操作 支持四种类型操作 Index Create Update Delete 可以在 URI 中指定 Index，也可以在请求体中进行 操作中单条操作失败，并不影响其他操作 返回结果包含每一条操作执行的结果 12345678POST _bulk&#123;&quot;index&quot;: &#123;&quot;_index&quot;:&quot;test&quot;,&quot;_id&quot;:&quot;1&quot;&#125;&#125;&#123;&quot;field1&quot;: &quot;value1&quot;&#125;&#123;&quot;delete&quot;: &#123;&quot;_index&quot;: &quot;test&quot;,&quot;_id&quot;:&quot;2&quot;&#125;&#125;&#123;&quot;create&quot;: &#123;&quot;_index&quot;:&quot;test2&quot;,&quot;_id&quot;:&quot;3&quot;&#125;&#125;&#123;&quot;field1&quot;:&quot;value3&quot;&#125;&#123;&quot;update&quot;:&#123;&quot;_index&quot;:&quot;test&quot;,&quot;_id&quot;:1&#125;&#125;&#123;&quot;doc&quot;:&#123;&quot;field2&quot;:&quot;value2&quot;&#125;&#125; 说明： index 和 create 操作，需要在紧接着的下一行提供 source，以便添加文档或者更新 delete 不需要 source update 需要在下一行指定 doc，指明如何更新 返回体：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374&#123; &quot;took&quot; : 350, &quot;errors&quot; : false, &quot;items&quot; : [ &#123; &quot;index&quot; : &#123; &quot;_index&quot; : &quot;test&quot;, &quot;_type&quot; : &quot;_doc&quot;, &quot;_id&quot; : &quot;1&quot;, &quot;_version&quot; : 1, &quot;result&quot; : &quot;created&quot;, &quot;_shards&quot; : &#123; &quot;total&quot; : 2, &quot;successful&quot; : 2, &quot;failed&quot; : 0 &#125;, &quot;_seq_no&quot; : 0, &quot;_primary_term&quot; : 1, &quot;status&quot; : 201 &#125; &#125;, &#123; &quot;delete&quot; : &#123; &quot;_index&quot; : &quot;test&quot;, &quot;_type&quot; : &quot;_doc&quot;, &quot;_id&quot; : &quot;2&quot;, &quot;_version&quot; : 1, &quot;result&quot; : &quot;not_found&quot;, &quot;_shards&quot; : &#123; &quot;total&quot; : 2, &quot;successful&quot; : 2, &quot;failed&quot; : 0 &#125;, &quot;_seq_no&quot; : 1, &quot;_primary_term&quot; : 1, &quot;status&quot; : 404 &#125; &#125;, &#123; &quot;create&quot; : &#123; &quot;_index&quot; : &quot;test2&quot;, &quot;_type&quot; : &quot;_doc&quot;, &quot;_id&quot; : &quot;3&quot;, &quot;_version&quot; : 1, &quot;result&quot; : &quot;created&quot;, &quot;_shards&quot; : &#123; &quot;total&quot; : 2, &quot;successful&quot; : 2, &quot;failed&quot; : 0 &#125;, &quot;_seq_no&quot; : 0, &quot;_primary_term&quot; : 1, &quot;status&quot; : 201 &#125; &#125;, &#123; &quot;update&quot; : &#123; &quot;_index&quot; : &quot;test&quot;, &quot;_type&quot; : &quot;_doc&quot;, &quot;_id&quot; : &quot;1&quot;, &quot;_version&quot; : 2, &quot;result&quot; : &quot;updated&quot;, &quot;_shards&quot; : &#123; &quot;total&quot; : 2, &quot;successful&quot; : 2, &quot;failed&quot; : 0 &#125;, &quot;_seq_no&quot; : 2, &quot;_primary_term&quot; : 1, &quot;status&quot; : 200 &#125; &#125; ]&#125; 批量读取 mget批量操作，可以减少网络连接所产生的开销，提高性能。mget 是通过文档 ID 来查询文档信息。 12345678910111213GET _mget&#123; &quot;docs&quot;: [ &#123; &quot;_index&quot;: &quot;my_index&quot;, &quot;_id&quot;: 1 &#125;, &#123; &quot;_index&quot;: &quot;test&quot;, &quot;_id&quot;: 1 &#125; ]&#125; 返回体：12345678910111213141516171819202122232425262728293031&#123; &quot;docs&quot; : [ &#123; &quot;_index&quot; : &quot;my_index&quot;, &quot;_type&quot; : &quot;_doc&quot;, &quot;_id&quot; : &quot;1&quot;, &quot;_version&quot; : 10, &quot;_seq_no&quot; : 10, &quot;_primary_term&quot; : 1, &quot;found&quot; : true, &quot;_source&quot; : &#123; &quot;user&quot; : &quot;mike2&quot;, &quot;comment&quot; : &quot;You know, Elasticsearch&quot;, &quot;age&quot; : 28 &#125; &#125;, &#123; &quot;_index&quot; : &quot;test&quot;, &quot;_type&quot; : &quot;_doc&quot;, &quot;_id&quot; : &quot;1&quot;, &quot;_version&quot; : 2, &quot;_seq_no&quot; : 2, &quot;_primary_term&quot; : 1, &quot;found&quot; : true, &quot;_source&quot; : &#123; &quot;field1&quot; : &quot;value1&quot;, &quot;field2&quot; : &quot;value2&quot; &#125; &#125; ]&#125; 批量查询 msearchmsearch 是根据查询条件、搜索得到相应文档。 12345POST my_index/_msearch&#123;&#125;&#123;&quot;query&quot;: &#123;&quot;match_all&quot;: &#123;&#125;&#125;, &quot;from&quot;: 0, &quot;size&quot;: 10&#125;&#123;&quot;index&quot;:&quot;test&quot;&#125;&#123;&quot;query&quot;:&#123;&quot;match_all&quot;:&#123;&#125;&#125;&#125; 上面的查询涉及了 2 个索引，一个是 my_index 索引，还有一个是 test 索引 _analyzer API常见错误返回 问题 原因 无法连接 网络故障或集群挂了 连接无法关闭 网络故障或节点出错 429 集群过于繁忙 4xx 请求体格式有错 500 集群内部错误]]></content>
      <categories>
        <category>ELK</category>
      </categories>
      <tags>
        <tag>ELK</tag>
        <tag>Search</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Elasticsearch 学习笔记]]></title>
    <url>%2F2021%2F02%2F14%2Felk-es-basic-tutorial-note%2F</url>
    <content type="text"><![CDATA[基本概念文档 DocumentES 是面向文档的，文档是所有课搜索数据的最小单位。例如： 日志文件中的日志项 一本电影的具体信息 文档会被序列化为 JSON 格式，保存在 ES 中 JSON 对象由字段组成 每个字段都有对应的字段类型 每个文档都有一个 Unique ID 可以自定义 ID 或者 ES 自动生成 文档的元数据元数据，用于标准文档的相关信息 _id：一篇文档的唯一 ID _index：文档所属的索引名 _source：文档的原始 JSON 数据 _version：文档版本信息 _score：相关性打分 _all：整合所有字段内容到该字段，已被废除 索引Index 索引是文档的容器，是一类「文档」的集合 Index：体现了逻辑空间的概念：每个索引都有自己的 Mapping 定义，用于定义包含的文档的字段名和字段类型 Shard：体现了物理空间的概念：索引中的数据分散在 Shard 上 索引的 Mapping 与 Settings： Mapping 定义文档字段的类型 Setting 定义不同的数据分布 索引的不同语义索引这个词在不同的上下文中是有不同的含义的。 索引（动词）文档到 ES 的索引（名词）中。 名词：ES 集群中可以创建很多个不同的索引 动词：保存文档到 ES 的过程也叫索引（indexing），ES 中创建一个倒排索引的过程 Type 在 ES7 之前，一个 Index 可以设置成多个 Types 在 ES7 开始，一个 Index 仅可以创建一个 Type _doc 关系型数据库与 ES 的比较类比： RDMS ES Table Index Row Document Column Field Schema Mapping SQL DSL 传统关系型数据库与 ES 的区别： ES：相关性/高性能全文检索 RDMS：事务性/Join 分片（Primary Shard &amp; Replica Shard） 主分片，用以解决数据水平扩展的问题。通过主分片，可以将数据分不到集群内的所有节点之上 一个分片就是一个运行的 Lucene 的实例 主分片数在索引创建时指定，后续不允许修改，除非 Reindex 副本，用以解决数据高可用的问题。副本分片是主分片的拷贝。当主分片丢失，集群会选择对应的副本分片称为主分片 副本分片数是可以动态调整的 增加副本数，还可以在一定程度上提高服务的可用性（读取的吞吐 ）。 增删改属于写操作，增加副本只可能降低写入速度，但是会提高数据安全性。从写的角度看，会把请求分发到不同的副本，只要这些副本在不同的机器，机器资源又足够，那就实现了水平的扩展，提高了读取的并发性。 补充： 一个 ES node 对应一个 ES 实例 一个 ES node 可以有多个 index 一个 index 可以有多个 shard 一个 shard 是一个 Lucene index（这里的 index 是 Lucene 自己概念，和 ES 中的 index 不是一个概念） 分片的设定 对于生产环境中分片的设定，需要提前做好容量规划 分片数设置过小 导致后续无法实现增加节点实现水平扩展 单个分片的数据量太大，导致数据重新分配耗时 分片数设置过大，7.0 开始，默认主分片数设置成1，解决了 over-sharding 的问题 影响搜索结果的相关性打分，影响统计结果的准确性（因为 idf 是基于分片上的数据进行计算的，并不是基于所有分片计算，所以数据量少，容易出现不准的情况） 单个节点上过多的分片，会导致资源浪费，同时也会影响性能 从数据量、写入速度、是写为主还是查询为主等等，考虑分片的设置： 磁盘推荐 SSD JVM 最大 Xmx 不要超过 30G 副本分片至少设置为 1 主分片单个存储不要超过 30GB，按照这个推算出分片数 查看集群的健康状况：GET _cluster/health Green：主分片与副本都正常分配 Yellow：主分片全部正常分配，有副本分片未能正常分配 Red：有主分片未能分配 例如，当服务器磁盘容量超过 85%时，去创建了一个新的索引参考 极客时间- 倒排索引 正排索引指的是文档 ID 和文档内容的关联,索引号对应索引稳定的内容，比如：书的第一页有啥内容?第二页有啥内容? 倒排索引指的是单词到文档 ID的对应关系 倒排索引的核心组成倒排索引包含两个部分： 单词词典（Term Dictionary），记录所有文档的单词，记录单词到倒排列表的关联关系 单词词典一般比较大，可以通过 B+ 树或哈希拉链法实现，以满足高性能的插入与查询 倒排列表（Posting List），记录了单词对应的文档结合，由倒排索引项组成 倒排索引项（Posting） 文档 ID 词频 TF：该单词在文档中出现的次数，用于相关性评分 位置（Position）：单词在文档中分词的位置。用于语句搜索（pharse query） 偏移（Offset）：记录单词的开始结束位置，实现高亮显示 一个示例，针对 Elasticsearch 倒排索引： Elasticsearch 的倒排索引 Elasticsearch 的 JSON 文档中的每个字段，都有自己的倒排索引 可以指定对某些字段不做索引 优点：节省存储空间 缺点：字段无法被搜索 参考 简书/Elasticsearch是如何做到快速索引的 Analysis 与 Analyzer Analysis：文本分析是把全文本转换一系列单词（term/token）的过程，也叫分词 Analysis 是通过 Analyzer 来实现的 可以使用 Elasticsearch 内置的分析器或者按需定制化分析器 除了在数据写入时转换词条，匹配 Query 语句时也需要使用相同的分析器对查询语句进行分析 Analyzer 的组成分词器是专门处理分词的组件，Analyzer 由三部分组成： Character Filters 针对原始文本处理，例如去除 HTML 标签 Tokenier 按照规则切分为单词 Token Filter 将切分的单词进行 二次加工，小写，删除 stopwords，增加同义词 ES 的内置分词器Elasticsearch 内置了挺多分词器的： Standard Analyzer：默认分词器，按词切分，小写处理 Simple Analyzer：按照非字母切分（符号被过滤），小写处理 Stop Anlyzer：小写处理，停用词过滤（the,a,is） Whitespace Analyzer：按照空格切分，不转小写 Keyword Analyzer：不分词，直接将输入当做输出，★★★ Pattern Analyzer：正则表达式，默认 \W+（非字符） Language：提供 30 多种常见语言的分词器 Customer Analyzer：自定义分词器 Standar Analyzer默认分词器，按词切分，小写处理 停用词，例如 in 这些，也没有去除 12345GET _analyze&#123; &quot;analyzer&quot;: &quot;standard&quot;, &quot;text&quot;: [&quot;2 running Quick brown-foxes dogs in the summer&quot;]&#125; 返回体：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667&#123; &quot;tokens&quot; : [ &#123; &quot;token&quot; : &quot;2&quot;, &quot;start_offset&quot; : 0, &quot;end_offset&quot; : 1, &quot;type&quot; : &quot;&lt;NUM&gt;&quot;, &quot;position&quot; : 0 &#125;, &#123; &quot;token&quot; : &quot;running&quot;, &quot;start_offset&quot; : 2, &quot;end_offset&quot; : 9, &quot;type&quot; : &quot;&lt;ALPHANUM&gt;&quot;, &quot;position&quot; : 1 &#125;, &#123; &quot;token&quot; : &quot;quick&quot;, &quot;start_offset&quot; : 10, &quot;end_offset&quot; : 15, &quot;type&quot; : &quot;&lt;ALPHANUM&gt;&quot;, &quot;position&quot; : 2 &#125;, &#123; &quot;token&quot; : &quot;brown&quot;, &quot;start_offset&quot; : 16, &quot;end_offset&quot; : 21, &quot;type&quot; : &quot;&lt;ALPHANUM&gt;&quot;, &quot;position&quot; : 3 &#125;, &#123; &quot;token&quot; : &quot;foxes&quot;, &quot;start_offset&quot; : 22, &quot;end_offset&quot; : 27, &quot;type&quot; : &quot;&lt;ALPHANUM&gt;&quot;, &quot;position&quot; : 4 &#125;, &#123; &quot;token&quot; : &quot;dogs&quot;, &quot;start_offset&quot; : 28, &quot;end_offset&quot; : 32, &quot;type&quot; : &quot;&lt;ALPHANUM&gt;&quot;, &quot;position&quot; : 5 &#125;, &#123; &quot;token&quot; : &quot;in&quot;, &quot;start_offset&quot; : 33, &quot;end_offset&quot; : 35, &quot;type&quot; : &quot;&lt;ALPHANUM&gt;&quot;, &quot;position&quot; : 6 &#125;, &#123; &quot;token&quot; : &quot;the&quot;, &quot;start_offset&quot; : 36, &quot;end_offset&quot; : 39, &quot;type&quot; : &quot;&lt;ALPHANUM&gt;&quot;, &quot;position&quot; : 7 &#125;, &#123; &quot;token&quot; : &quot;summer&quot;, &quot;start_offset&quot; : 40, &quot;end_offset&quot; : 46, &quot;type&quot; : &quot;&lt;ALPHANUM&gt;&quot;, &quot;position&quot; : 8 &#125; ]&#125; Simple Analyzer 按照非字母切分（例如 空格啊、中划线 - 这样的），非字母的都被去除 小写处理 Stop Analyzer相比 Simpler Analyzer 多了 stop filter，会把 the/a/is 等词去除 Keyword Analyzer不分词，直接将输入当一个 term 输出 12345GET _analyze&#123; &quot;analyzer&quot;: &quot;keyword&quot;, &quot;text&quot;: [&quot;2 running Quick brown-foxes dogs in the summer&quot;]&#125; 返回体：1234567891011&#123; &quot;tokens&quot; : [ &#123; &quot;token&quot; : &quot;2 running Quick brown-foxes dogs in the summer&quot;, &quot;start_offset&quot; : 0, &quot;end_offset&quot; : 46, &quot;type&quot; : &quot;word&quot;, &quot;position&quot; : 0 &#125; ]&#125; _analyzer API直接指定 Analyzer 进行测试12345GET _analyze&#123; &quot;analyzer&quot;: &quot;standard&quot;, &quot;text&quot;: &quot;Mastering Elasticsearch, elasticsearch in Action&quot;&#125; 返回体：123456789101112131415161718192021222324252627282930313233343536373839&#123; &quot;tokens&quot; : [ &#123; &quot;token&quot; : &quot;mastering&quot;, &quot;start_offset&quot; : 0, &quot;end_offset&quot; : 9, &quot;type&quot; : &quot;&lt;ALPHANUM&gt;&quot;, &quot;position&quot; : 0 &#125;, &#123; &quot;token&quot; : &quot;elasticsearch&quot;, &quot;start_offset&quot; : 10, &quot;end_offset&quot; : 23, &quot;type&quot; : &quot;&lt;ALPHANUM&gt;&quot;, &quot;position&quot; : 1 &#125;, &#123; &quot;token&quot; : &quot;elasticsearch&quot;, &quot;start_offset&quot; : 25, &quot;end_offset&quot; : 38, &quot;type&quot; : &quot;&lt;ALPHANUM&gt;&quot;, &quot;position&quot; : 2 &#125;, &#123; &quot;token&quot; : &quot;in&quot;, &quot;start_offset&quot; : 39, &quot;end_offset&quot; : 41, &quot;type&quot; : &quot;&lt;ALPHANUM&gt;&quot;, &quot;position&quot; : 3 &#125;, &#123; &quot;token&quot; : &quot;action&quot;, &quot;start_offset&quot; : 42, &quot;end_offset&quot; : 48, &quot;type&quot; : &quot;&lt;ALPHANUM&gt;&quot;, &quot;position&quot; : 4 &#125; ]&#125; 指定索引的字段进行测试12345POST my_index/_analyze&#123; &quot;field&quot;:&quot;comment&quot;, &quot;text&quot;:&quot;Mastering Elasticsearch, elasticsearch in Action&quot;&#125; 返回体：123456789101112131415161718192021222324252627282930313233343536373839&#123; &quot;tokens&quot; : [ &#123; &quot;token&quot; : &quot;mastering&quot;, &quot;start_offset&quot; : 0, &quot;end_offset&quot; : 9, &quot;type&quot; : &quot;&lt;ALPHANUM&gt;&quot;, &quot;position&quot; : 0 &#125;, &#123; &quot;token&quot; : &quot;elasticsearch&quot;, &quot;start_offset&quot; : 10, &quot;end_offset&quot; : 23, &quot;type&quot; : &quot;&lt;ALPHANUM&gt;&quot;, &quot;position&quot; : 1 &#125;, &#123; &quot;token&quot; : &quot;elasticsearch&quot;, &quot;start_offset&quot; : 25, &quot;end_offset&quot; : 38, &quot;type&quot; : &quot;&lt;ALPHANUM&gt;&quot;, &quot;position&quot; : 2 &#125;, &#123; &quot;token&quot; : &quot;in&quot;, &quot;start_offset&quot; : 39, &quot;end_offset&quot; : 41, &quot;type&quot; : &quot;&lt;ALPHANUM&gt;&quot;, &quot;position&quot; : 3 &#125;, &#123; &quot;token&quot; : &quot;action&quot;, &quot;start_offset&quot; : 42, &quot;end_offset&quot; : 48, &quot;type&quot; : &quot;&lt;ALPHANUM&gt;&quot;, &quot;position&quot; : 4 &#125; ]&#125; 自定义分词器进行测试123456POST /_analyze&#123; &quot;tokenizer&quot;: &quot;standard&quot;, &quot;filter&quot;:[&quot;lowercase&quot;], &quot;text&quot;: &quot;Mastering Elasticsearch, elasticsearch in Action&quot;&#125; 返回体：123456789101112131415161718192021222324252627282930313233343536373839&#123; &quot;tokens&quot; : [ &#123; &quot;token&quot; : &quot;mastering&quot;, &quot;start_offset&quot; : 0, &quot;end_offset&quot; : 9, &quot;type&quot; : &quot;&lt;ALPHANUM&gt;&quot;, &quot;position&quot; : 0 &#125;, &#123; &quot;token&quot; : &quot;elasticsearch&quot;, &quot;start_offset&quot; : 10, &quot;end_offset&quot; : 23, &quot;type&quot; : &quot;&lt;ALPHANUM&gt;&quot;, &quot;position&quot; : 1 &#125;, &#123; &quot;token&quot; : &quot;elasticsearch&quot;, &quot;start_offset&quot; : 25, &quot;end_offset&quot; : 38, &quot;type&quot; : &quot;&lt;ALPHANUM&gt;&quot;, &quot;position&quot; : 2 &#125;, &#123; &quot;token&quot; : &quot;in&quot;, &quot;start_offset&quot; : 39, &quot;end_offset&quot; : 41, &quot;type&quot; : &quot;&lt;ALPHANUM&gt;&quot;, &quot;position&quot; : 3 &#125;, &#123; &quot;token&quot; : &quot;action&quot;, &quot;start_offset&quot; : 42, &quot;end_offset&quot; : 48, &quot;type&quot; : &quot;&lt;ALPHANUM&gt;&quot;, &quot;position&quot; : 4 &#125; ]&#125; 中文分词器中文分词的难点： 中文句子，需要切分成一个一个词（不是一个一个字）。英文中，单词有自然的空格作为分隔，而中文却没有。 一句中文，在不同的上下文，有不同的理解 这个苹果，不大好吃/这个苹果，不大，好吃 他说的确实在理/这事的确定不下来 ICU Analyzer 12345POST _analyze&#123; &quot;analyzer&quot;: &quot;icu_analyzer&quot;, &quot;text&quot;: &quot;他说的的确在理&quot;&#125; 返回体：123456789101112131415161718192021222324252627282930313233343536373839&#123; &quot;tokens&quot; : [ &#123; &quot;token&quot; : &quot;他&quot;, &quot;start_offset&quot; : 0, &quot;end_offset&quot; : 1, &quot;type&quot; : &quot;&lt;IDEOGRAPHIC&gt;&quot;, &quot;position&quot; : 0 &#125;, &#123; &quot;token&quot; : &quot;说的&quot;, &quot;start_offset&quot; : 1, &quot;end_offset&quot; : 3, &quot;type&quot; : &quot;&lt;IDEOGRAPHIC&gt;&quot;, &quot;position&quot; : 1 &#125;, &#123; &quot;token&quot; : &quot;的确&quot;, &quot;start_offset&quot; : 3, &quot;end_offset&quot; : 5, &quot;type&quot; : &quot;&lt;IDEOGRAPHIC&gt;&quot;, &quot;position&quot; : 2 &#125;, &#123; &quot;token&quot; : &quot;在&quot;, &quot;start_offset&quot; : 5, &quot;end_offset&quot; : 6, &quot;type&quot; : &quot;&lt;IDEOGRAPHIC&gt;&quot;, &quot;position&quot; : 3 &#125;, &#123; &quot;token&quot; : &quot;理&quot;, &quot;start_offset&quot; : 6, &quot;end_offset&quot; : 7, &quot;type&quot; : &quot;&lt;IDEOGRAPHIC&gt;&quot;, &quot;position&quot; : 4 &#125; ]&#125; 如果是默认的分词器呢？ 12345GET _analyze&#123; &quot;analyzer&quot;: &quot;standard&quot;, &quot;text&quot;: &quot;他说的的确在理&quot;&#125; 返回体：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253&#123; &quot;tokens&quot; : [ &#123; &quot;token&quot; : &quot;他&quot;, &quot;start_offset&quot; : 0, &quot;end_offset&quot; : 1, &quot;type&quot; : &quot;&lt;IDEOGRAPHIC&gt;&quot;, &quot;position&quot; : 0 &#125;, &#123; &quot;token&quot; : &quot;说&quot;, &quot;start_offset&quot; : 1, &quot;end_offset&quot; : 2, &quot;type&quot; : &quot;&lt;IDEOGRAPHIC&gt;&quot;, &quot;position&quot; : 1 &#125;, &#123; &quot;token&quot; : &quot;的&quot;, &quot;start_offset&quot; : 2, &quot;end_offset&quot; : 3, &quot;type&quot; : &quot;&lt;IDEOGRAPHIC&gt;&quot;, &quot;position&quot; : 2 &#125;, &#123; &quot;token&quot; : &quot;的&quot;, &quot;start_offset&quot; : 3, &quot;end_offset&quot; : 4, &quot;type&quot; : &quot;&lt;IDEOGRAPHIC&gt;&quot;, &quot;position&quot; : 3 &#125;, &#123; &quot;token&quot; : &quot;确&quot;, &quot;start_offset&quot; : 4, &quot;end_offset&quot; : 5, &quot;type&quot; : &quot;&lt;IDEOGRAPHIC&gt;&quot;, &quot;position&quot; : 4 &#125;, &#123; &quot;token&quot; : &quot;在&quot;, &quot;start_offset&quot; : 5, &quot;end_offset&quot; : 6, &quot;type&quot; : &quot;&lt;IDEOGRAPHIC&gt;&quot;, &quot;position&quot; : 5 &#125;, &#123; &quot;token&quot; : &quot;理&quot;, &quot;start_offset&quot; : 6, &quot;end_offset&quot; : 7, &quot;type&quot; : &quot;&lt;IDEOGRAPHIC&gt;&quot;, &quot;position&quot; : 6 &#125; ]&#125; IKIK Analysis for Elasticsearch 支持自定义词库，支持热更新分词词典 安装插键：1bin/elasticsearch-plugin install https://github.com/medcl/elasticsearch-analysis-ik/releases/download/v7.3.2/elasticsearch-analysis-ik-7.3.2.zip 测试：12345POST _analyze&#123; &quot;analyzer&quot;: &quot;ik_smart&quot;, &quot;text&quot;: &quot;他说的的确在理&quot;&#125; 返回体：123456789101112131415161718192021222324252627282930313233343536373839&#123; &quot;tokens&quot; : [ &#123; &quot;token&quot; : &quot;他&quot;, &quot;start_offset&quot; : 0, &quot;end_offset&quot; : 1, &quot;type&quot; : &quot;CN_CHAR&quot;, &quot;position&quot; : 0 &#125;, &#123; &quot;token&quot; : &quot;说&quot;, &quot;start_offset&quot; : 1, &quot;end_offset&quot; : 2, &quot;type&quot; : &quot;CN_CHAR&quot;, &quot;position&quot; : 1 &#125;, &#123; &quot;token&quot; : &quot;的&quot;, &quot;start_offset&quot; : 2, &quot;end_offset&quot; : 3, &quot;type&quot; : &quot;CN_CHAR&quot;, &quot;position&quot; : 2 &#125;, &#123; &quot;token&quot; : &quot;的确&quot;, &quot;start_offset&quot; : 3, &quot;end_offset&quot; : 5, &quot;type&quot; : &quot;CN_WORD&quot;, &quot;position&quot; : 3 &#125;, &#123; &quot;token&quot; : &quot;在理&quot;, &quot;start_offset&quot; : 5, &quot;end_offset&quot; : 7, &quot;type&quot; : &quot;CN_WORD&quot;, &quot;position&quot; : 4 &#125; ]&#125; ik_max_word 与 ik_smart 的区别： ik_max_word: 会将文本做最细粒度的拆分，比如会将“中华人民共和国国歌”拆分为“中华人民共和国,中华人民,中华,华人,人民共和国,人民,人,民,共和国,共和,和,国国,国歌”，会穷尽各种可能的组合，适合 Term Query； ik_smart: 会做最粗粒度的拆分，比如会将“中华人民共和国国歌”拆分为“中华人民共和国,国歌”，适合 Phrase Query。 Term Query 与 Phrase Query 的区别：Term Query，表示查询时，将查询的词分词之后，他们之间关系是 OR 的关系，例如请求为GET /movies/_search?q=title:(Beautiful Mind)，意思就是查询 title 中包括 Beautiful 或者 MindPhrase Query 表示查询时他们是一个整体短语，需要用引号包起来，例如请求为 GET /movies/_search?q=title:&quot;Beautiful Mind&quot; 综上，创建索引的时候可以使用 ik_max_word，查询的时候使用 ik_smart，例如： 1234567891011121314# 创建索引的同时指定 mappingPUT /ik_index&#123; &quot;mappings&quot;: &#123; &quot;properties&quot;: &#123; # 字段 &quot;content&quot;: &#123; &quot;type&quot;: &quot;text&quot;, &quot;analyzer&quot;: &quot;ik_max_word&quot;, &quot;search_analyzer&quot;: &quot;ik_smart&quot; &#125; &#125; &#125;&#125; 其他 THULAC 清华大学的一套中文分词器，官网主页 Search APIES 的搜索可以分为两大类： URI Search：在 URL 中使用查询参数 Request Body Search：使用 ES 提供的，基于 JSON 格式的更加完备的 Query Domain Specific Language（DSL） 指定查询的索引 语法 范围 /search 集群上所有的索引 /index1/_search 查询索引 index1 /index1,index2/_search 查询索引 index1 和index2 /index*/_search 查询以 index 开头的索引 URI 查询 使用 q 指定查询字符串 query string syntax KV 键值对 示例：1curl -XGET "http://localhost:9200/kibana_sample_data_ecommerce/_search?q=customer_first_name:Eddie" 说明：对索引 kibana_sample_data_ecommerce 中字段 customer_first_name 进行查询，查询的值是 Eddie Request Body 查询123456curl -XGET "http://localhost:9200/kibana_sample_data_ecommerce/_search" -H 'Content-Type:application/json' -d '&#123; "query":&#123; "match_all": &#123;&#125; &#125;&#125;' 说明： 支持 POST 和 GET _search 表明执行搜索的操作 查询返回所有的文档 搜索 Response搜索结果如何看懂，示例： took：表示花费的时间 total：表示符合条件的文档数 hits：表示结果集，默认前 10 个文档 _index：索引名 _id：文档 ID _score：相关度评分 _source：文档原始信息 搜索的相关性 Relevance用户关心的是搜索结果的相关性 是否可以找到所有相关的内容 有多少不相关的内容被返回了 文档的打分是否合理 结合业务需求，平衡结果排名 衡量相关性Information Retrieval Precision 查准率：召回的结果集中，正确结果的比例 Recall 查全率：召回结果中的正确结果数占实际全部的正确结果的比例 Ranking：是否能够按照相关度进行排序？ 比如搜索苹果，搜索出结果一共有 8 条，其中 6 条确实是和苹果有关的，但是实际上数据集中一共有 10 个苹果相关的文档，那么，查准率就是 6/8，查全率就是 6/10。很显然，查准率和查全率我们都希望越高越好！ 参考]]></content>
      <categories>
        <category>ELK</category>
      </categories>
      <tags>
        <tag>ELK</tag>
        <tag>Search</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Kibana 学习笔记]]></title>
    <url>%2F2021%2F02%2F14%2Felk-es-kibana%2F</url>
    <content type="text"><![CDATA[Kibana 安装官方文档 Installing Kibana 中提供了多种安装包对应的指导链接！本文就先选择 tar 包的方式安装。 下载 Kibana 安装包同样，Kibana 在我司镜像站上也有对应的软件包： 1234567https://mirrors.huaweicloud.com/kibana/7.3.2/wget https://mirrors.huaweicloud.com/kibana/7.3.2/kibana-7.3.2-linux-x86_64.tar.gzwget https://mirrors.huaweicloud.com/kibana/7.3.2/kibana-7.3.2-linux-x86_64.tar.gz.sha512shasum -a 512 -c elasticsearch-7.3.2-linux-x86_64.tar.gz.sha512tar xzf kibana-7.3.2-linux-x86_64.tar.gzchown -R michael kibana-7.3.2-linux-x86_64cd kibana-7.3.2-linux-x86_64 Mac 环境，下载的安装包是 kibana-7.3.2-darwin-x86_64.tar.gz。因为我是从华为镜像站下载的，直接运行可能会提示安全告警，运行这样的命令即可去除告警 xattr -d -r com.apple.quarantine kibana-7.3.2-darwin-x86_64 配置 Kibana12345egrep -v "^#|^$" config/kibana.yml # 如下内容是修改的配置server.port: 5601server.host: "0.0.0.0"elasticsearch.hosts: ["http://127.0.0.1:9200"]kibana.index: ".kibana" 更多配置内容，可以阅读 Configuring Kibana Kibana 链接 ES 以后，会把相关的数据写入 .kibana 开头的 index 中。 运行 Kibana如下方式可以实现后台运行，避免 Ctrl+C 终止了程序： 1nohup bin/kibana &amp; 访问：http://127.0.0.1:5601/ 这时候可以看到我们之前搭建的集群节点了： Dev ToolsKibana Console 可以执行一些 API 请求，Help 中有相关快捷键的操作说明： 快捷键： Ctrl/Cmd + / API 文档 Kibana Plugins安装命令和 ES 类似，提供了如下常用命令： bin/kibana-plugin install plugin_location bin/kibana-plugin list 补充Cerebro 可以用来管理查看 ES 除了上述安装方式之外，还有用 Docker 方式安装的，可以参考： onebirdrocks/geektime-ELK]]></content>
      <categories>
        <category>ELK</category>
      </categories>
      <tags>
        <tag>ELK</tag>
        <tag>Search</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[安卓手机必备 APP 清单]]></title>
    <url>%2F2021%2F02%2F11%2Fdigital-products-mobile-app-backup%2F</url>
    <content type="text"><![CDATA[前言APP 清单 效率 滴答清单 shadowsocks 阅读 Fasthub 多看 微信阅读 豆瓣阅读 开发者头条 Pocket 极客时间 西梅 译学馆 摄影 必剪 剪映 Vue Vlog 美图秀秀 黄油 一刻相册 MIX 视频 央视频 QQ 音乐 KMPlayer 办公 BOSS 拉钩 QQ 邮箱 扫描全能王 白描 WPS 个人所得税 QQ 浏览器 APP 酷安 应用宝 Play 商店 APKPure 笔记 印象笔记 智联 米家 Andpods 万能遥控器 小米 WiFi 唯乐 小爱音箱 乐播投屏 精臣云打印 金融 老虎证券 货币 Pro 兴业银行 动卡空间 掌上生活 招商银行 云闪付 购物 饿了么 拼多多 严选 苏宁易购 小米有品 悦拜 一淘 京粉 当当 盒马 瑞幸 生活 化妆品监管 食药云搜 贝壳 透明家 浙里办 丁香医生 美柚 网上国网 工具 百度网盘 手机营业厅 手机助手 倒数日 SpeedTest QQ同步助手 一键测速 QQ 输入法 AirDroid 身份验证器 v2rayNG 新闻 学习强国 出行 高德 嘀嗒出行 哈喽出行 滴滴出行 iAdmin 花小猪 T3 出行 携程 飞猪 巴士管家 慧通 马蜂窝 穷游 航旅纵横 铁路 12306 社交 QQ 订阅号助手 Telegram 脉脉 抖音 微博 兴趣 西窗烛 活动性 懂车帝 汽车之家 懒饭 好好住 ##]]></content>
      <categories>
        <category>数码</category>
      </categories>
      <tags>
        <tag>APP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[IT程序员的装修笔记——软装篇]]></title>
    <url>%2F2021%2F01%2F30%2Flife-shopping-soft-decoration%2F</url>
    <content type="text"><![CDATA[被子被子分类 棉花被：属于植物纤维，价格适中，性价比高。如果想更保暖，往往比较笨重。 化纤被：人造纤维（聚酯纤维）填充的被子。价格比棉花还便宜，其中最受欢迎的是七孔被。松软，保温效果也不错，比起自然纤维，坚固耐用、抗皱免烫，不像羽绒被一样老爱“掉毛” 羊毛被 羽绒被：羽绒取自鹅、鸭身上的绒毛。同样的体积，羽绒被重量只有棉被的三分之一 蚕丝被：讲究人专用 棉花被导热系数比较低低，所以相对来说比较保暖。但是它升温时间慢，我们需要用自己的体温先去捂热被子。羽绒被，轻盈的羽绒被的重量仅为同体积棉被的1/3、羊毛被的1/2，使用时不会对人体造成压迫感。 品牌 原装进口品牌：德国peter kohl，110年历史，是欧洲著名的羽绒供应厂家；德国obb royal bed 博登，成立于1900年，hanskruchen成立于1900年，billerbeck betten成立于1921年；奥地利kauffmann，日本西川 国外品牌+国内代工：澳大利亚的downia、日本的interlagos、英国downland、美国pacific coast、奥地利的SIDANDA 新国货品牌：网易严选、淘宝心选、京造，除此以外，以前和大型酒店供货的厂商也开始做自己的品牌，例如浙江三星羽绒厂的格兰贝恩 老牌国货：一类企业，在国内有比较长的历史了，集中分布在安徽、浙江羽绒生产基地。例如安徽鸿润、安徽霞珍、浙江雁皇 家纺品牌：一般都是跟江苏南通、浙江萧山、安徽等当地的企业进行OEM的定制，比如罗莱、水星、富安娜等家纺品牌 补充知识： OBM：A设计，A生产，A品牌，A销售==工厂自己设计自产自销 ODM：B设计，B生产，A品牌，A销售==俗称“贴牌”，就是工厂的产品，别人的品牌 OEM：A设计，B生产，A品牌，A销售==代工，代生产，别人的技术和品牌，工厂只生产如何选择羽绒 常见羽绒的品质排序如下：白鹅绒＞灰鹅绒＞白鸭绒＞灰鸭绒。 鹅绒比鸭绒的绒多更大、蓬松度也更好。关注常规绒与大朵绒的比列，大朵绒比例高比较好。 逆光看充绒是均匀整齐的、异色绒少、能看到朵朵绒。记住：真正的朵朵绒，在逆光下一定是点点状，而如果暗度差不多，说明里面的很充绒绒丝、碎羽毛多 核心参数指标： 清洁度：1000+，表示没有任何杂质、细菌的残留（国标是 450mm） 蓬松度：800+ 含绒量：95% 含绒量就算比较高的 填充量： 面料支数：60S，支数越高，不仅意味着面料越细腻光滑，还代表内容物能更好地包裹其中 数据编辑很容易，要有相关检验检疫证明才可靠！ 使用 羽绒和羊毛都可以干洗，但不可以在阳光下暴晒。羽绒和羊毛不需要频繁晾晒，也不可以直接让毒辣的阳光照射。因为高温会让羽毛、羊毛中的油分起变化，产生腐臭味。解决办法：可以选择通风干燥日，把杯子放在阳关直射不到的地方，晾一两个小时就能达到杀菌除湿的效果了。 羽绒被更不能使劲拍打，绒毛也容易断裂成细小的“羽尘”，羽绒保温性能会大幅降低。 参考 什么值得买/2019鹅绒被值得买 篇二：双十一最全的鹅绒被清单在这里！ 什么值得买/70款鹅绒被实力PK：2020双十一鹅绒被购买攻略 什么值得买/总抱怨没有深睡眠？可能是你盖错了被子！ ODM 和 OEM 分别是什么？两者有什么本质区别？ 什么值得买/鹅绒被什么值得买系列 篇八：关于羽绒行业，这次干脆跟你们交个底儿……（附双十二超值好价窗帘窗帘配色： 不知道选什么颜色，选纯色无脑灰肯定不会错 选择与墙面、地板相近或稍深的颜色，整体和谐统一 选择与软装点缀色相近或相似的颜色，掏钱可爱 窗帘配色原则： 同色系和谐不出错， 对比色系个性吸睛，红和绿、蓝和橙、黑和白 上浅下深显层高 根据墙面颜色：选择和家里大面积颜色同色系的，一般都不会出错，比如选择与墙面颜色相近或稍深的配色，显得整体和谐 根据地板的颜色：选择和地板颜色相近或稍深的窗帘也都没有问题（但要特别注意，如果你家连墙面带地面都是白色的，窗帘打死也别选白色） 根据软装的颜色：选择与软装色彩相近或相似的窗帘，整体感显而易见（参考物有沙发、茶几、地毯、床品、床头柜、保证、花瓶、绿植等） “白纱＋灰帘”这个神仙组合，一层白纱窗帘，搭配任何明度的灰色布帘，几乎能和所有空间风格完美融合 窗帘面料 纯棉布：褪色爱皱“洗一次缩一半”，求你打死别买 亚麻：窗帘全屋适用，但缩水爱皱又透光。亚麻窗帘适合选择困难星人，在窗帘款式上举棋不定的话，选亚麻一定不会出错 天鹅绒：卧室需要保护隐私或隔音，选厚一些的窗帘最佳，想低成本装出惊艳效果的，首选天鹅绒 亚麻或纱帘：客厅、阳台、书房等需要保证充足阳光的空间，选薄质的亚麻或纱帘 怕光星人追求颜值，可以选“薄帘+遮光帘”双层组合 高精密遮光布：想遮光又隔热，就买高精密遮光布 参考 家居搭配窗帘有什么技巧？ - 住范儿石乐天的回答 - 知乎 新房 Tips验房目前国内开发商都很强势，都会要求先签字收房再验房，先验后拿需要业主自己去争取。如果只能拿房后验房的话，大家不要着急，有问题也还是开发商的责任，提醒大家在拿房当天物业给你们的房屋确认书签字栏里写一句话：“以本人找的第三方检测公司出具的验房报告为准，房屋有待维修。”后期如果验出大问题，也可以起诉索赔。]]></content>
      <categories>
        <category>Life</category>
      </categories>
      <tags>
        <tag>装修</tag>
        <tag>购物</tag>
        <tag>软装</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[IT程序员的装修笔记——衣柜定制]]></title>
    <url>%2F2020%2F10%2F16%2Flife-shoppinmg-closet%2F</url>
    <content type="text"><![CDATA[前言最近在考虑家里衣柜定制的事情，发现这个行业真不像买电器那么容易……商家给板材门取的名字真是五花八门，比如生态板、无醛板、禾香板、康纯板、爱格板等等，听着一个比一个高大上！ 经过查阅各种文档、帖子、视频，将了解到的内容做个笔记，方便更多的业主熟悉一下这行业的基本情况，避免踩坑。 环保标准先来了解一下板材的环保标准： E0：目前国标只对强化复合地板有 E0 级的评定标准，其他木制品只有 E1 和 E2 两个标准 E1：国标用于室内的标准是 E1 级（0.124mg/m3） 商家宣传里的 E0 级一直是市场炒作并未写进国家标准的。2017年，中国发布《室内装饰装修材料人造板及其制品中甲醛释放限量》（GB18580——2017）中国家标准中无 E0 级标准。因此提个醒，如果最终签合同时，记得要明确是国标 E1。 GB18580——2017 标准链接：http://www.jianbiaoku.com/webarbs/book/11724/3216471.shtml 补充：所谓 F4 星标准，其实就是日本的 F☆☆☆☆ 认证标准。F4 星源于日本农林省的法律法规，是日本国土交通部颁发的证书，它是日本标准环保最高的健康等级，更被认为是国际上最健康的环保标准。如果按照平时的 E1、E0 级标准来看的话，那么 F3 星相当于国家 E0 级标准，建议限制使用面积，F4 星则远高于 F3 星，在使用面积上无限制。 参考： 百度百科：https://baike.baidu.com/item/F4%E6%98%9F%E6%A0%87%E5%87%86 板材介绍关于板材的讨论众说纷纭： 有人对颗粒板一棒子打死，认为它肯定没有常见的多层板、杉木芯板环保…… 有人就认为大品牌用的颗粒板（比如禾香板、康纯板）就一定比多层板更好…… 其实，个人觉得上面那些看法都太绝对！抛开基材品牌、封边工艺、贴面工艺直接就否定其他板材类型的做法，要么就是动机不纯、要么就是井底之蛙~ 现实生活中最常见的是，在不靠谱的渠道，消费者花了 E1 板材的价格，实际拿到的是 E2 级别的产品。 经过阅贴无数，总结一句话：只要确保是可靠品牌的板子，商家可信，封边、贴面工艺先进，合同里明确符合国标 E1 标准，那么，质量都不会差到哪里去！ 先说重点： 家具的核心不仅仅不在板材，五金也非常重要！ 封边和贴面的工艺水平也不能忽视！ 术语介绍板材种类之前，先熟悉一下相关名词： 素板/板芯：一般指从板材供应商直接拿到的基材，没有进行封边、贴面等处理 贴面：板式家具的贴面主要以贴纸皮、贴木皮、烤漆、水晶板、防火板、模压板为主 三聚氰胺纸：色彩丰富，经过了三聚氰胺树脂浸泡，它使得家具板材不易变形、耐腐蚀。缺点是只有平面造型，做不了凹凸效果 实木贴面：将天然木皮粘在基材的饰面板上，看起来像是实木家具。缺点是不易清洗，过于潮湿易变质 烤漆饰面：光泽好、防水性好、抗污能力强，易于造型。缺点是怕磕磕碰碰 防火板饰面：表面色彩丰富、方便加工，保温隔热，缺点是门板为平板，做不了凹凸造型 水晶板饰面：现代感强烈，其实是 PVC 透明软板，表面贴了游记玻璃板（类似常说的亚克力），成型后的板表面高光、亮丽透明，缺点是不耐磨、容易留下划痕、热胀冷缩易变形 模压板饰面：模压板表面有一定造型，可加工成各种形状，有高光和哑光两种选择，缺点是价格较贵，以进口品牌为主 封边：无起鼓无开裂。封边不好的有明显的交接线，不整齐。封边工艺是检验一个品牌做工好坏的细节点。激光封边是目前一种主流的高水准封边工艺 参考： 鲁班园/六大家具贴面材料：http://www.lubanyuan.cn/jishu/tmfm/3138.html 一兜糖/超详细橱柜选购攻略：http://www.yidoutang.com/guide-83034.html 接下来，是我从网上找到的一些关于各类板材的介绍。可能有些描述也不太精确，仅供参考。 密度板 材料：以木质纤维或其他植物纤维为原料、加热、加压压制 优点： 结构均匀、性能稳定，易加工 缺点： 密度太高，容易开裂，不适合做家具 不防潮，见水容易发胀 握钉力差 用途：一般密度板适合做室内装潢、墙板、隔板等 颗粒板/刨（bào）花板 材料：由木材或其他木质纤维材料制成的碎料+胶水粘剂+压力合成的人造板。 优点： 没有虫眼 稳定性好、材质均匀 防潮性能高于生态板 握钉力强 质轻 缺点： 环保性能比不过多层板（比较的是旧工艺的颗粒板，不绝对） 颗粒板也叫做刨花板。刨花板交叉错落结构，各方向力基本相同，尺寸稳定，厚度大，升级后的 OSB 工艺，甲醛释放更低。现在较火的 OSB 欧松板就是改进后的刨花板。 欧松板就是大片大片的刨花，所谓的定向刨花板，加的 MDI 胶也更加环保 爱格板爱格英文名叫 EGGER，是一家创建于 1961 年的奥地利企业。爱格板不是一种特殊的板材，它就是三聚氰胺刨花板！主要是因为它的环保性比较好，在国内才比较有名，称他们的板材为「爱格板」。 因为有名，所以模仿者众多！消费者花了爱格板的价格，不一定拿到的就是真的爱格板，需要仔细筛选、甄别！希望遇到的商家是一位有良心的商家，而不是只顾赚钱、不顾消费者家庭健康的无良商家。 W980 在爱格板里的存在更类似于柜体专用，是爱格板里唯一一个不是激光封边的色号，一般都会用来做柜体，非要做柜门也可以，但是可能效果没有那么好。W1000 就是很标准的门板，和 U702 等色号一样，大部分人用来做门板。 下面介绍一下如何查看爱格正规的授权商家：1.登录爱格官网，查看哪些是授权经销商 https://www.egger.com/shop/zh_MO/about-us/sources-of-supply： 2.访问对应经销商的官网，查看授权客户 http://www.vigour.net.cn/index.php?c=article&amp;a=type&amp;tid=101： 看到群主联系的爱格板厂家的 LOGO 了，可以确认他就是一个正规的爱格板授权方。 胶合板胶合板是一个统称，它有如下常见的几种板材种类。 大芯板/细木工板 材料：中间基材（板芯材）为拼接实木（如杉木、杨木等）组成，表面是三聚氰胺贴面 优点： 环保较好，因为生产使用的是杉木等密度较低的实木，加工过程用到胶水较少 防潮、耐高温 性价比高 缺点： 握钉力不太好 变形系数大 多层板 材料：多层实木加热、加压粘合，表面以实木贴皮等工序制作而成 优点： 环保性能高于颗粒板，低于生态板 变形小、强度大、结构稳定性好 握钉力高于颗粒板和生态板 缺点： 价格比颗粒板贵 行业背景： 胶合板九成以上用脲醛树脂，用酚醛树脂是安全，但是贵啊！ 生态板/免漆板生态板其实就是饰面板，也叫免漆板，是将带有不同颜色或纹理的纸放入三聚氰胺树脂胶粘剂中浸泡，然后干燥到一定固化程度再贴在人造板材（细木工、刨花板、颗粒板）表面装饰的装饰面板。细木工板表层为树皮（装饰面板）。 在毒奶粉事件中三聚氰胺出名了，但它在板材里其实是很成熟的工艺，不要被它吓退 然而，我们去市场上去买的生态板大多是指大芯板贴三聚氰胺的板，其内芯是用杉木条平铺两面各贴一层薄板而成，板的质量好坏在于杉木条铺的是否密实，两面薄板的材质和厚度。 为什么市场上买的生态板主要是这种呢？因为只有这种板才适合家装现场木工使用，木工现场使用的大多是小圆盘锯，只有这种板才能锯的动，不会有锯齿痕，不会有大的崩边，像多层板是小锯很难锯动根本锯不直的，颗粒板又会崩边很厉害，密度板是不能用来做柜体的。 实木指接板 胶水常见的如脲醛树脂、酚醛、三聚氰胺—甲醛胶粘剂等都是含有可游离的甲醛。还有一种胶黏剂原材料，叫异氰酸酯，英文名 MDI。它与前面说过的脲醛树脂相比，最大的优点就是没有游离甲醛，而且高温下也不会产生甲醛；缺点就是比较贵。 万华集团是中国唯一拥有 MDI 生产技术与能力的企业。他们官网是有提供合作品牌的列表的，可以访问查询： 万华官网：https://www.whchem.com/ 万华禾香板官网：http://www.whstby.cn/customer/?page=7 板材供应商 看了 GB18580——2017 标准的文件，发现了这个起草单位列表，我看觉得这应该都是行业龙头吧，应该都是比较可靠的品牌了！ 参考 小红书/为大家介绍一下衣柜通用的四种板材如下 知乎/实木颗粒板与多层实木板做柜体如何选择？ 石榴家/实木板？颗粒板？生态板？眼花缭乱分不清？看完选家具有谱了 五金五金是个值得关注的地方，每天开合柜门等，如果阻尼有问题、生锈、变形等，都会影响使用体验！ 五金小件 滑轨 铰链 轨道 拉手 五金品牌 海蒂诗/Hettich：德国品牌，官网 https://web.hettich.com/zh-cn/%E4%B8%BB%E9%A1%B5.jsp 百隆/Blum：奥地利品牌，官网 https://www.blum.com/cn/zh/ 顶固：广东，https://www.dinggu.net/ 东泰 DTC 固特：广东 斯力高：广州 市面上很多百隆铰链用的都是山寨的阻尼器，需要谨防商家使用山寨货！！！ 细节 国产铰链的固定位常见是 4 个螺丝位，而进口的则是 2 个（因为国外常见颗粒板，握钉力强，而国内常用多层板、大芯板等，因此要多用几个螺丝位） 重量也是评价铰链好坏的一个细节 参考 什么值得买/铰链都不懂，还瞎选啥家具：https://post.smzdm.com/p/a83dm9l0/ 合同签署注意事项 环保等级签署在合同里 板材用料、五金品牌，明确签署在合同里 比如明确注明「材料品牌、环保等级符合合同说明，假一赔十」 设计虽然各花入各眼，但是向优秀的设计学习是有效提升审美的途径。 设计避免踩坑定制衣柜我们要避免如下的设计： 1.框门不同色 2.门板线条错缝 3.白色木纹：要么选纯白色、要么选原木色 4.有花纹樱花、有腰线装饰带 建议：定制衣柜越低调越好，选择纯白色、纯平门板，百搭。柜子低调，家具高调~ 参考： 住范儿/定制柜这6种设计，劝你千万不要做！ 一言在做笔记的同时发现一些品牌的官网就很与时俱进，比如爱格、百隆、海蒂诗、顶固、兔宝宝，他们官网都启用了 HTTPS 协议，而大多数品牌的官网则还是老旧的 HTTP 协议，比如知名的千年舟……当然，并不是他官网没有与时俱进，就代表它产品就不好。只是想说，细节决定成败，用心维护官网，让我觉得更放心！ 最后采用了爱格的板材，一是他们官网确实很可靠，各级经销商都能查到，二是他们板材的口碑确实都挺好~ 衣柜定制篇就总结到这儿啦，祝愿小伙伴们都能装修不踩坑！Peace~]]></content>
      <categories>
        <category>Life</category>
      </categories>
      <tags>
        <tag>装修</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【转】程序员如何把控自己的职业]]></title>
    <url>%2F2020%2F10%2F08%2Flife-cook-tools%2F</url>
    <content type="text"><![CDATA[炒锅B站/【小高姐】炒锅选购-3 铸铁锅 碳钢锅 中式炒锅 铁锅也可以无油煎鸡蛋 这个视频中介绍了常见铁锅的选择，简要笔记： 铸铁炒锅（生铁）：一般厚度比较厚，适合煎的烹饪方式 碳钢炒锅（熟铁）：贴皮薄，适合中式爆炒的方式 因此，决定先选购一款熟铁炒锅，在以下品牌选购： 陈枝记 苏泊尔 珍珠生活 鉴于以前家里用的铁锅不是知名品牌，也依旧好用，选了性价比高的陈枝记的熟铁炒锅。 铁锅的开锅及保养： 【小高姐】铁锅翻新与开锅 介绍一个秘密武器 解决你的厨房烦恼 其实，今后的铁锅使用过程，关键的过程是洗完铁锅要用厨房纸擦干锅的表面，不留水分，因为由高中化学可以知道，铁+水+氧气，就会发生化学反应的。 铁锅炒菜、煎蛋🍳怎么做到不粘锅呢？ 科学防粘锅（上）炒什么都不粘 科学防粘锅（下）不锈钢锅、不粘锅 简要笔记就是： 热锅到冒烟，高温下的铁锅，它的内部空隙已经打开 倒油滑锅，油脂将填满铁锅内部空隙，在铁锅表面形成一层膜 如果需要低温烹饪，则将滑锅的热油倒出，重新导入冷油，否则，无需倒出滑锅的热油 上面的方法对于不粘锅不适用，因为不粘锅本身有特氟龙的隔离层起到不沾的作用。此外，不粘锅不能高温干烧，因为不沾涂层在高温下会散发有害物质。]]></content>
      <categories>
        <category>思考</category>
      </categories>
      <tags>
        <tag>思考</tag>
        <tag>软技能</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[杭州民生信息相关笔记]]></title>
    <url>%2F2020%2F10%2F08%2Flife-info-navigate%2F</url>
    <content type="text"><![CDATA[教育幼儿园杭州省一级幼儿园名单信息，最官方的查询网站还是 浙江省人民政府/全省政府网站信息统一搜索网站 2020年浙江省一级幼儿园认定结果公示 可以看到，萧山区截止 2020 年，经过认定的省一级幼儿园就下面的 5 所：]]></content>
      <categories>
        <category>孩子</category>
      </categories>
      <tags>
        <tag>民生</tag>
        <tag>教育</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【转】程序员如何把控自己的职业]]></title>
    <url>%2F2020%2F10%2F08%2Fsoft-skills-IT%2F</url>
    <content type="text"><![CDATA[本文转载自 酷 壳 – CoolShell 。 这篇文章的主要内容主要是我今年3月份在腾讯做的直播，主要是想让一些技术人员对世界有一个大体的认识，并且在这个认识下能够有一个好的方法成就自己。而不是在一脸蒙圈的状态下随波逐流，而日益迷茫和焦虑。直播完后，腾讯方面把我的直播形成文字的形式发了出来，我觉得我可以再做一个精编版。所以，有了这篇文章，希望对大家有帮助。 对我来说，在我二十多年的工作经历来看，期间经历了很多技术的更新换代，整个技术模式、业务模式也是一直变来变去，我们这群老程序员成长中所经历的技术比今天的程序员玩的还更杂更多。我罗列一下我学过的，而且还被淘汰掉的技术，大家先感受一下。 MIS应用开发：FoxPro，PowerBuilder，Delphi OA：Lotus Notes，VBScripts 微软：ODBC/ADO，COM/DCOM，MFC/ATL，J++ 服务器：AIX，HP-UX，SCO Unix Web：CGI，ISAPI，SOAP RPC：CICS，Tuxedo J2EE：Websphere，Weblogic DB：Sybase，Informix 我想说的是，无论过去还是今天，我们这些前浪和你们后浪所面对的技术的挑战和对技术的焦虑感是相似的，我们那个时候不但玩996，还玩封闭开发（就是一周只能回家一天）。当然，唯一好的东西，就是比起今天的程序员来说，我们那个年代没有像微信、微博、知乎，抖音这些巨大消耗你人生的东西，所以，我们的工作、生活和成长都有很效率，不会被打断、喜欢看书、Google还没有被封……当然，那时代没有StackOverlow和Github这样的东西，所以，能完成的东西或质量都一般。 当然，这里并不是想做一个比较，只是想让大家了解一下两代程序员间的一些问题各有千秋，大同小异。在整个成长过程中，其实有很多东西是相通的，基本上来说，就是下面的三件事—— 第一，如果想要把控技术，应对这个世界的一些变化，需要大致知道这个世界的一些规律和发展趋势，另外还得认识自己，自己到底适合做什么？在这个趋势和规律下属于自己的发挥领域到底是什么？这是我们每个人都需要了解的。 第二，打牢基础，以不变应万变，不管世界怎样变化，我都能很快适应它。基础的重要程度对于你能够飞多高是相当有影响的，懂原理的人比不懂原理的人能做出来的事情或是能解决的问题完全是两个层级的。 第三，提升成长的效率，因为现在社会的节奏实在太快了，比二十年前快得太多，技术层出不穷，所以我们的成长也要更有效率。效率并不单指的快，效率是怎么样更有效，是有用功除以总功（参看《加班与效率》），怎么学到更有效的东西，或者怎么更有效学习，是我们需要掌握的另一关键。 下面是我这多年来的一些认识，希望对你有帮助。 世界发展趋势我个人经历的信息化革命应该分成三个阶段： 1990年代到2000年，这个时代MB时代，是雅虎、新浪、搜狐、网易门户网站的时代，这个时代就是ISP/ICP互联网提供商，把一些资讯数字化，然后发布到网络上。 2000年到2010年，这个时代叫GB时代，或是叫多媒体或UGC时代，上网开始变得普遍了，每个人手里的数码设备开始变得多了起来，可以上传照片，可以上传视频，甚至可以在网上做社交。 2010年到2020年，这个时代叫TB时代，这过去的十年是移动互联网时代，移动互联网只需要手机在线，不需要依靠电脑。因为手机随时在线，所以个人的各种各样的数据始终在被收集，只要用户上网就会产生数据，所以人的行为最终也被数字化了。 所有的硬件和软件都是跟着需要处理的数据而演进的，我们需要更大的带宽，更大的硬盘，更多的处理器……大到一定时候就只能进入分布式化的技术架构了，再大，数据中心也顶不住了，就会要引入更为分布式的边缘计算了。 另一方面，从业务上来看，我们可以看到整个世界就在不断地进行数字化，因为，只要数字化了，就可以进行复制传播和计算，只要可以进行计算了，就可以进行数学建模，就可以自动化，只要可以自动化了就可以规模化，只要可能规模化了，就可以改变整个行业。人类的近代史的大趋势基本上都是在解决能源和自动化的事，源源不断的能源是让机器不知疲倦的前提条件，用机器代替牲口，代替人类进行工作是规模化的前提条件。 所以，技术的演进规律基本是自动化加规模化，从而降低成本，提升效率。这就是为什么世界变得越来越快，人类都快跟不上节奏的原因，主要是整个社会不断被机器、数据所驱动。 人才需求在这个过程中，需要什么样的人？下面是我的一些认识—— 技工，在机器和自动化面前，肯定是需要能够操作机器的技术工人了，这类人是有技术的劳动力。在编程的圈子里俗称“码农”，他们并不是真正的工程师，他们只是电脑程序的操作员，所以，随着技术门槛的下降或是技术形式的变更他可能就会变得越来越不值钱，直到被淘汰掉。 特种工，这种人是必须了解原理和解决难题的一类人，他们是解决比较难的、特定的一些技术问题。当一种技术被淘汰，他并不容易被淘汰，因为他懂原理，原理就是解决问题的能力，是解决问题的套路和方法。 工程师，不但是使用技术，还可以把活儿做好，他们认为代码更多的时间是在维护，这些人使用各种各样的手段和各种技术，精益求精地持续不断地提高代码的易读性、扩展性、可维护性和重用性，这个过程似乎永无止境。对于这些有“洁癖”，有“工匠精神”，有“修养”的技术人员，我们称他们为工程师。这种人做事又稳又快，而且可以做出很多称手的工具和方法论。 再往上是设计师和架构人员，这些人主要是开发一些工具，框架，模式，提升软件开发和维护效率，同时也提升用户体验，和提升稳定性、性能、代码重用等，总的来说就是为了降本增效。这类人的工作降低了技术得到门槛，他们把技术门槛降低了以后，就可以把这个技术普及开来，就可以由广大劳工、技工、特殊工人使用了。 还有一类人是经理，经理主要是组织团队、完成项目、创造利润。这类人中，即有身先士卒的leader，也有高高在上的boss，但无论怎么样，这些人只不过是为了让一个公司或是一个团队更好组织在一起的“粘合剂”，这类人只有在大公司中才会变成更有价值。 这就是我总结的世界需要哪些人才，我们了解这些东西以后大概就明白我们现在所处的位置有什么样的问题，我们应该去什么样的地方。 Google评分卡接下来，我们再来看看Google的SRE的自我评分卡： 对于相关的技术领域还不熟悉 可以读懂这个领域的基础知识 可以实现一些小的改动，清楚基本的原理，并能够在简单的指导下自己找到更多的细节。 基本精通这个技术领域，完全不需要别人的帮助 对这个技术领域非常的熟悉和舒适，可以应对和完成所有的日常工作。 对于软件领域 – 有能力开发中等规模的程序，能够熟练和掌握并使用所有的语言特性，而不是需要翻书，并且能够找到所有的冷知识。 对于系统领域 – 掌握网络和系统管理的很多基础知识，并能够掌握一些内核知识以运维一个小型的网络系统，包括恢复、调试和能解决一些不常见的故障。 对于该技术领域有非常底层的了解和深入的技能。 能够从零开发大规模的程序和系统，掌握底层和内在原理，能够设计和部署大规模的分布式系统架构 理解并能利用高级技术，以及相关的内在原理，并可以从根本上自动化大量的系统管理和运维工作。 对于一些边角和晦涩的技术、协议和系统工作原理有很深入的理解和经验。能够设计，部署并负责非常关键以及规模很大的基础设施，并能够构建相应的自动化设施 能够在该技术领域出一本经典的书。并和标准委员会的人一起工作制定相关的技术标准和方法。 在该领域写过一本书，被业内尊为专家，并是该技术的发明人。 SRE需要自评如下这些技术或技能： TCP/IP Networking (OSI stack, DNS etc) Unix/Linux internals Unix/Linux Systems administration Algorithms and Data Structures C/C++ Python Java Perl Go Shell Scripting (sh, Bash, ksh, csh) SQL and/or Database Admin Scripting language of your choice (not already mentioned) _ People Management Project Management 这个评分卡是面试 Google 前需要候选人对自己的各种技术进行自评，也算是一种技术人员的等级的度量尺，其把技术的能分成 11 个等级，我用颜色把其它成四大层级，希望这个评分卡能够给你一个能力提升的参考标准。 认识自己认识了世界是怎么发展的，也知道技术人员的种类和层级，那么还要了解一下自己，因为如果不了解自己，那么你也无法找到自己的路和适合自己的地方。 我觉得，一个人要认识自己就需要认识自己的特长、兴趣、热情、擅长等，下面是一个认识自己的标准方法： 特长。首先你要找得到自己特长。你要认识自己的特长，找到自己的天赋，找到你在DNA里比别人强的东西，就拿你的 DNA 跟别人竞争就好了。所以你要找到自己可以干成的事，找到别人找你请教的事，你身边人找你请教就是说明你有特长。这是找到自己特长非常非常重要，扬长避短。 兴趣。如果你没有找到自己特长，就找自己有兴趣有热情的东西。什么叫兴趣？兴趣是再难再累都不会放弃的事。如果你遇到困难就会放弃不叫兴趣，那叫叶公好龙。不怕困难，痴迷其中，就算你没有特长，有了这种特质，你也是头部的人才。 方法。如果你没有特长，没有兴趣和热情就要学方法。这种方法就是要有时间观念，要会做计划，要懂统筹、规划对于做过的事情，犯过的错误多总结，举一反三，喜欢自己找答案，自己探究因果关系，这是一些方法，自己总结一些套路。 勤奋。如果你没有特长，没有兴趣，也没有方法，你还能做的事就是勤奋，勤奋注定会让你成为一个比较劳累的人，也是很有可能被淘汰的人随着你的年纪越来越大，你的勤奋也会越来越不值钱。因为年轻人会比你更勤奋，比你更勤奋、比你斗志更强，比你能力更强，比你要钱更少的人会出现。勤奋最不值钱，但是只要你勤奋至少能够自食其力。 以上就是为了应对未来技术变化，作为个人必须要从特长、兴趣、方法一层一层筛选挖掘，如果没有这些你就要努力和勤奋。就只能接受“福报”了。 从我个人而言，我不算是特别聪明的人，但自认为对技术还是比较感兴趣的，难的我不怕。有很多比较难啃的技术，聪明点的人啃一个月就懂了，我不行，我可能啃半年。但是没有关系，知识都是死的，只要不怕困难总有一天会懂的。最可怕是畏难，为自己找借口，这样就不太好了。 打好基础最前面提到我学的各式各样的被淘汰的技术，会让你感觉很迷茫，或是迷失。但前面也提到了“谷歌评分卡”，在这个评分卡中，我们看到了许多基础原理方面的内容，其实要应对未来的变化，很重要的一点就是无招胜有招，以不变应万变。 变化都是表面的东西，内在的东西其实并没有太多的变化。理论层面上变得不多，反而形式上的东西今天一个花样，明天一个花样，所以如果要去应对这种变化，就一定要打牢自己的基础，提升内功修养。比如像编程的一些方式和套路，修饰模式原理本质，解耦，提升代码的重用度等。提升代码重用度必须解耦，要跟现实解耦，提升抽象，这些都是一些技术基础。无论用什么语言，都是这么做的。 打牢基础就可以突破瓶颈，不打牢基础没有办法突破瓶颈。在技术世界不要觉得量变会造成质变，这是不可能的。技术这个东西就像搞建筑砌砖头，砌砖头砌的再多也不可能让你能成为一个架构师的，因为你不懂原理，不懂科学方法，你就不可能成长上去的，就像学数学一样，当你掌握了微积分这种大杀器后，你解题的能力是无所披靡，而微积分这种方式绝对不是你能“量变”出来的。 所以你必须学习基础的理论知识，如果不学这些基础理论知识，还要学习解题思路和方法，如果你只学在表面，那么当这个技术的形式有变化，就会发现以前学的都没用了，要重头学一遍。掌握技术基础可以让自己找到答案和知识，基础是抽象和归纳，很容易形成进一步的推论。我们学的很多技术实现都逃不脱基础原理，不管是Java，还是其他语言，只要用TCP用的都是相同的原理，逃不出范围，只要抓住原理，举一反三，时间一长了，甚至还可以自己推导答案。对于技术的基础，我会把其它成四类： 程序语言：语言的原理，类库的实现，编程技术（并发、异步等），编程范式，设计模式…… 系统原理：计算机系统，操作系统，网络协议，数据库原理…… 中间件：消息队列，缓存系统，网关代理，调度系统 …… 理论知识：算法和数据结构，数据库范式，网络七层模型，分布式系统…… 这些知识其实就是一个计算机科学专业的学生他所要学习的原理，但可惜的是，我们的一些学校教得也很糟糕，不但老师能力不足，而且放着世界上最优秀的教课书不用了，一定要自己写一本。讲也讲不全，还有各种错误，哎……总之，如果你学习用用到的教材不行，那么可以肯定的是你的学习效率一定是很糟糕的。这就是为什么我们大学上完了，还是跟个傻瓜一样，还要在工作中再重新自学。 不过，就算自学，这些基础技术大概需要四五年的时间堆叠。我工作二十年了，这二十年来基本还是这些原理没变，无论形式怎么变，但是核心永远还是这些，理论创新很难，这是以不变应万变。 学习效率 谈到学习效率，就需要拿出这张学习金字塔的图来了。从图可以看到学习方法分布两层，一种是被动学习，也是浅度学习，听讲，阅读，视听，演示都是在被动学习，而与人讨论，自己动手实践，教授给别人是主动学习。主动学习我们称之为深度学习，如果你不能深度学习，你就不能真正学到东西。这也是你会经常有“学那么多干什么，不用就忘了”，这就是浅度学习的症状了。 下面，我给出一些我自己觉得不错的学习经验： 挑选一手知识和信息源。对于学习方法：第一我们一定要到知识源去挑选知识，知识信息源非常关键，二手信息丢失太大了，谭浩强写的书就丢失太多信息了。目前计算机一手知识基本都是国外的，所以英文非常重要。我鼓励大家一定读第一手的资料。如果你英语有问题，至少要看翻译过来，最好是原汁原味翻译的，不要我理解了给你讲那种，那种也是被别人嚼一遍再讲给你你没有体会，是别人带着你，别人的体会会影响你，也许你的体会会比他更好，因为是你自己总结出来的东西，所以知识源很重要。 注意原理和基础第二要注重基础原理。虽然可以忘记这个技术，但是原理记在心里，我可以徒手实现出来，而且通过原理可以更快学习其他类似的技术。所以原理很重要！当你学会C、C++要学Java和GO都很快。 使用知识图谱一定要学会使用知识图，把知识结构化。从一个技术关键点开始不断地关联和细化下去，比如：关于TCP协议，首先第一个要记住状态图，怎么建立连接，怎么断连接，状态怎么变迁。TCP没有连接，是靠状态维护连接的。其次，要了解TCP怎么保证可靠性，就是丢包以后怎么重传，重传有哪些技术点。然后，重传会让你联想到拥塞控制，拥塞控制到滑动窗口……。这基本就是TCP的所有东西了，找到关键点，然后顺着这个脉络一点点往下想，通过知识图关联就可以进行顺藤摸瓜。我们不需要记所有知识，那些手册的知识不需要记，你知道在哪里能找到就可以了。你脑子里面要有地图，学一个东西就跟在城市生活一样，闭上眼睛就知道地图，A点到B点怎么去大概方向要知道。我在北京我去广州，广州在南边，我大概坐飞机还是火车要心里有数。。 学会举一反三。就是用不同方法学一个东西，比如说学TCP协议，看书是一种方法，编程是另外一种方法，还有用做Debug去看的，用不同方法学一个东西会让你更加熟悉，你学一个知识的同时把周边也学了。比如说学前端能不能把HTTP学一下，比如说长连接、短连接，包括hp1、hp2有一些不一样的东西。 总结和归纳。只有学会总结和归纳，才能形成自己的思维框架、自己的套路、自己的方法论，以后学这个东西应该怎么学。就像学一门新的语言，不管GO语言，还是Rust语言，第一件事情就是了解内存是怎么管理的，数据类型什么样，第二是泛型怎么搞，第三是并发怎么弄。还有一些抽象怎么弄，比如说怎么解耦，怎么实现多态？套路这种东西只有学的多了以后才能形成套路，如果你只学会一门语言不会有套路，你要每年学门语言，不用学多精，你思考这个语言有什么不一样，为什么这个这种有玩法，那个有那种玩法，这些东西思考多了套路方法论就出来了。比如说Windows和Linux有什么不同，Linux和Unix又有什么不同？只有总结自己的框架、套路和方法，这些才永远不会被淘汰。 实践和坚持。剩下就是多做多练，多坚持，只有实践才会有经验，只有锻炼了才能够把自己的脂肪变没，所以，要把知识变成技能必须练，就像小学生学会加减乘除，还是要演练，必须多做题，题目做得多了，自然掌握得好。要挑选好的知识源，注重原理技术，有一些原理的基础的书太枯燥，但是我告诉你学习这些基础太值得投入时间，搬砖赚几十元不值得，因为赚的是辛苦钱，老了就赚不了，必须要赚更有能力的钱，这是学习投资。 小结好了，该到这篇文章收尾的时候了，小结一下，如果你想更好的把握时代，提升自己，你需要知道这个时代的趋势是什么，需要什么样的人，这些人需要什么样的能力，这些能力是怎么获得的，投入到基础知识的学习就像“基建”一样，如果基础不好，不能长高，学习能力也是需要适应这个快速时代的重要的基础能力，没有好的学习能力，很快就会掉队被淘汰。 这些东西，是我从业二十年来的总结和体会，希望对你有用。]]></content>
      <categories>
        <category>思考</category>
      </categories>
      <tags>
        <tag>思考</tag>
        <tag>软技能</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mac 效率工具必备神器 —— Alfred]]></title>
    <url>%2F2020%2F09%2F23%2Ftools-dev-mac-alfred%2F</url>
    <content type="text"><![CDATA[前言alfred 这款软件称为「神器」真是当之无愧。今天专门总结一下，作为之前 Mac 配置教程-开发篇 的补充。 需要说明的是，如果你发现我介绍的功能无法使用，则代表需要花钱购买它的 Powerpack。麦哥是从淘宝购买的正版永久激活码搞定的，百十块大洋~如果你囊中羞涩，也有一些网站提供了破解版本。关注公众号[Coder魔法院]，回复 Alfred，会提供对应的下载网站（注意：破解版软件往往会有安全风险）。 General 通用设置 Startup：勾选上，这样就能在登录系统时自动启动 Alfred； Alfred Hotkey： 启动 Alfred 的快捷键，我设置的是双击 Command 键； Alfred 基本功能 /：输入 /，会跳转到系统根目录； ~：输入 ~，会进入当前用户的用户目录； 输入搜索内容后，Enter 按键是直接打开文件，Command + Enter表示打开文件所在文件夹； Command + L 居中放大显示结果； 搜索应用 文件搜索 Find + 文件名：搜索文件，Enter 确认之后，直接跳转到 Finder 中文件所在位置； Open + 文件名：搜索文件，Enter 确认之后，直接打开该文件； 内容搜索输入 in 命令加空格，以及待搜索的文本，列出磁盘中包含该文本的相关文件： Features 特性功能Features 功能很多，这里仅介绍目前个人发现的常用设置。 Default Results 默认结果这个菜单项主要是设置 Alfred 搜索结果时，默认从哪些目录搜索出结果。 Essentials：搜索系统偏好设置和联系人信息； Extras：指定搜索对象，比如文件夹、文档、图片等。如果格式不全，可以点击 Advanced 按钮自定义； Search Scope：指定搜索范围，哪些路径可以搜； Web Search 文件搜索该功能非常方便，快捷键启动 Alfred 之后，输入指定网站的关键字，然后输入要搜索的内容，按下 Enter 键之后自动跳转到浏览器对应网站的搜搜结果，一气呵成的搜索体验！ 只需要点击右下角的 Add Custom Search 按钮，即可添加你经常搜索的网站的快捷方式： 日常网站： 百度：https://www.baidu.com/s?ie=utf-8&amp;f=8&amp;wd={query} 淘宝：https://s.taobao.com/search?q={query} 豆瓣电影：http://movie.douban.com/subject_search?search_text={query}&amp;cat=1002 B 站：http://search.bilibili.com/all?keyword={query} 知乎：https://www.zhihu.com/search?type=content&amp;q={query} 什么值得买：https://search.smzdm.com/?s={query}&amp;v=b 技术网站： DuckDuckGo：https://duckduckgo.com/?q={query} Stackoverflow：http://www.stackoverflow.com/search?q={query} Github Search：https://github.com/search?utf8=%E2%9C%93&amp;q={query} MDN：https://developer.mozilla.org/zh-CN/search?q={query} Web Bookmarks又是一个非常赞的功能！虽然我浏览器中已经安装了插键可以快速搜索我的书签，但是 Alfred 的作用就是，当浏览器没有打开、你正在做其他工作时想要快速打开你浏览器中的某个书签，这时候你只需要快速启动 Alfred-&gt;搜索书签的关键字-&gt;Enter 打开该书签。又是一气呵成的操作！ 我设置了一个关键字 bm，寓意 bookmarks，用来表示我目的是搜索书签： 如果遇到权限问题，需要在系统偏好设置中安全性与隐私-&gt;隐私-&gt;完全磁盘访问权限，勾选 Alfred 4.app。接着在 Alfred 中输入 Reload Alfred Cache 后回车，Alfred 重新加载缓存就可以搜索书签 Clipboard History 剪贴板历史这个功能其实是我掏钱购买它的主要原因之一！在 Windows 上有 Ditto，但是在 Mac 上没有体验足够好的剪贴板历史工具。之前也使用了几个开源免费的剪贴板工具，但是他们有一些细节功能缺失，比如没法搜索剪贴板的历史。 有了 Alfred 的剪贴板增强，两个场景最常用： 当你需要大段编辑文字、敲代码时，不需要反复在两个页面复制、切换页面、粘贴……只需要在一个页面将想要复制的内容复制好，然后切换页面，刚刚你复制的历史片段都可以看到，大大提高了文本编辑的效率！ 当你需要快速找到某一天你复制过的片段时，只需要输入关键字在剪贴板历史中搜索即可~ 这里我把它们都设置为存储 1 个月，同时把打开剪贴板的默认快捷键为 Command + Shift + V： Clear Now：表示立即清空剪贴板的历史 Snippets 文本片段有一些文本是需要反复输入的，比如你的邮箱、QQ号、地址、手机号码、某个网址等信息，亦或者聊天常用语句、表情等等，这些都可以通过 Alfred 来管理，节省输入时间。 这个功能很强大，不止描述的那么简单。 Alfred 官网 Snippets 提供了集合片段集合，下载后双击文件即可导入到 Alfred 中。 Emoji Pack Mac Symbols 例如，我们有时候编辑文本时经常需要输入 Mac 上的一些按键符号⌘： Calculator 计算器直接在输入框中输入计算的表达式，例如 15*3，Alfred 会自动计算出结果： Advanced 增强计算的功能，支持一些高级计算的表达式，使用时以 = 开头，然后输入表达式即可，例如：=sqrt(9)+abs(-2)。 支持这些函数： 1sin, cos, tan, log, log2, ln, exp, abs, sqrt, asin, acos, atan, sinh, cosh, tanh, asinh, acosh, atanh, ceil, floor, round, trunc, rint, near, dtor, rtod等 Dictionary 字典输入 define 开头，然后输入查询的单词； Define a word：可以自定义一个关键词来标记你要查询单词了，例如 df。 System 系统这个设置也很实用，通过在 Alfred 中输入一些命令来实现系统的操作，比如输入 Empty Trash 就是清空垃圾箱。不用担心记不住命令，因为 Alfred 是支持联想的。 常用的有： emptytrash：清空垃圾箱 lock：锁定屏幕 slppe：休眠 restart：重启 shutdown：关机 eject：快速推出一些外界设备，比如 U 盘、挂载的镜像 Terminal 终端可以直接在 Alfred 中输入 &gt; 之后，指定 shell 命令在 Terminal 中执行。 操作示例： 默认情况是在 Mac 自带的 Terminal 中执行命令，如果你想在 Alfred 中执行，则需要通过如下命令自定义： 1234567891011121314151617181920212223242526on alfred_script(q) tell application "iTerm" set _length to count window if _length = 0 then create window with default profile end if set aa to (get miniaturized of current window) if aa then set miniaturized of current window to false end if set bb to (get visible of current window) if bb is false then set visible of current window to true end if set cc to frontmost if cc is false then activate end if (*if _length = 0 then*) set theResult to current tab of current window (*else set theResult to (create tab with default profile) of current window end if*) write session of theResult text qend tellend alfred_script Previews 预览Mac 预览功能也叫 Quick Look。当我们在 Finder 中选中一些文件之后，按住 Space/空格键 键，可以预览文件内容。Alfred 中这个预览功能叫 Preview。当我们在 Alfred 搜到一些文件之后，按一下 Shift 按键，就可以预览对应文件内容。同时，在 Finder 中，也可以通过 Alfred 提供的预览功能预览文件，对应快捷键是 Command+y。 workflowworkflow 是什么 上面截图是 Alfred 官网对 Workflow 的一个描述，简单描述就是，workflow 是一个类似工作流的功能，它可以根据你预设的流程进行一系列的操作来帮你实现一个功能。 日用推荐NumToCNY：转换数字为人民币金额，cny 然后输入数字即可 YoudaoDict 有道翻译 mpco/AlfredWorkflow-Recent-Documents 快速打开最近访问的文档、文件夹、应用 输入 rr，列出当前激活应用的最近文档 输入 rf，列出最近访问的文件夹 输入 rd，列出最近打开的各种文件 输入 ra，列出最近打开的应用 开发推荐ip address：查看本机 IP http_status_code：显示 HTTP 状态码含义 输入 httpcode + 状态码，按下 Enter 键会跳到对应网站 encode 字符编码（encode）、解码（decode），例如有时候一些密码、URL 中有特殊字符则可以使用它 下载源 Alfred官宣/workflows：https://www.alfredapp.com/workflows/ alfredworkflow：http://www.alfredworkflow.com/ packal/workflow-list：http://www.packal.org/workflow-list zenorocha/alfred-workflows：https://github.com/zenorocha/alfred-workflows github/awesome-alfred-workflows：https://github.com/alfred-workflows/awesome-alfred-workflows 由于网络原因，workflow 可能下载比较慢，麦哥已经将本文提到的一些 workflow 文件打包好了，公众号后台回复 「Alfred」即可获取相关的安装文件。 Usage 使用统计 参考 总是在 Mac 「装机必备」看到的搜索利器 Alfred，究竟是怎么用的？| 新手问号 效率神器 Alfred workflow 插件推荐 Alfred神器使用手册 掘金-Mac 提升开发效率的小工具 iHTCboy/程序员的macOS系列：高效Alfred进阶 博主总结很详细，推荐]]></content>
      <categories>
        <category>ToolsDev</category>
      </categories>
      <tags>
        <tag>Tools</tag>
        <tag>Mac</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java 定时任务框架 Quartz 入门篇]]></title>
    <url>%2F2020%2F09%2F06%2Fjava-middleware-quartz-basic%2F</url>
    <content type="text"><![CDATA[Quartz 概念Quartz 是任务调度的开源项目。Quartz 就是基于 Java 实现的任务调度框架。 Quartz 官网地址：http://www.quartz-scheduler.org Quartz 官网 - Examples：http://www.quartz-scheduler.org/documentation/quartz-2.3.0/tutorials/ Quartz 运行环境 Quartz 可以运行嵌入在两一个独立式应用程序 Quartz 可以在应用程序服务器（或 Sevelet 容器） 内被实例化，并参与事务 Quartz 可以作为独立的程序运行（其自己的 Java 虚拟机内），可以通过 RMI 使用 Quartz 可以被实例化，作为独立的项目集群（负载平衡和故障转移功能），用于作业的执行 Quartz 设计模式 Buider 模式 Factory 模式 组件模式 链式编程 这里说的设计模式，其实主要是针对 Quartz 使用过程中涉及的一些有用法。比如，通过 Factory 模式，生成调度器。比如，使用 Quartz 涉及了调度器、Job、触发器等组件。比如可通过 Build 方法创建出组件。 Quartz 核心概念任务 Job 和 JobDetailJob 指的是你想要执行的任务类，每一个 Job 必须实现 org.quartz.job 接口，且只需要实现接口定义的 execute() 方法。在 execute 方法内编写任务的业务逻辑。 Job 实例在 Quartz 中的生命周期：每次调度器执行 Job 时，它在调用 execute 方法前会创建一个新的 Job 实例，当调用完成之后，关联的 Job 对象实例会被释放，释放的实例会被垃圾回收机制回收。 JobDetail: JobDetail 为 Job 实例提供许多设置属性，以及 jobDataMap 成员变量属性，它用来存储特定 Job 实例的状态信息，调度器需要借助 JobDetail 对象来添加 Job 实例。 触发器 TriggerTrigger 为你执行任务的触发器，比如你想每天定时 3 点发送一份统计邮件，Trigger 将会设置 3 点进行执行该任务。 Trigger 主要包含两种： SimpleTrigger CronTrigger 调度器 SchedulerScheduler 为任务的调度器，它将任务 Job 及 触发器 Trigger 整合起来，负责基于 Trigger 设定的时间来执行 Job。 Quartz 的体系结构 Quartz 几个常用 API以下是 Quartz 编程 API 几个重要接口，也是 Quartz 的重要组件。 Scheduler 用于与调度程序交互的主程序接口 Scheduler 调度程序-任务执行计划表，只有安排进执行计划的任务 Job（通过 schduler.scheduleJob 方法安排进执行计划），当它预先定义的执行时间到了（任务触发器 trigger），该任务才会执行。 Job 我们预先定义的希望在未来时间能够被调度程序执行的任务类，我们可以自定义。 JobDetail 使用 jobDetail 来定义定时任务的实例，jobDetail 实例是通过 JobBuilder 类创建的。 JobDataMap 可以包含不限量的（序列化）的数据对象，在 job 实例执行的时候，可以使用其中的数据。JobDataMap 是 Java Map 接口的一个实现，额外增加了一些便于存取基本类型的数据方法。 Trigger 触发器，Trigger 对象是用来触发执行 Job 的。当调度一个 Job 时，我们实例触发器然后调整它的属性来满足 Job 执行的条件。表明任务在什么时候会执行。定义了一个已经被安排的任务将会在什么时候执行的时间条件，比如每 2 秒执行一次。 JobBuilder 用于声明一个任务实例，也可以定义关于该任务的详情，比如任务名、组名等。这个声明的实例将会作为一个实际执行的任务。 TriggerBuilder 触发器创造器，用于创建触发器 trigger 实例。 JobListener、TriggerListener、SchedulerListener 监听器，用于对组件的监听。 注意 Job 和 JobDetail 的区分，Job 是指我们具体的「任务类」。JobDetail 指通过 JobBuilder 类创建出的一个实例，它和 Job 类进行了绑定。 贴一个官网示例片段： 12345678910111213141516// define the job and tie it to our HelloJob classJobDetail job = newJob(HelloJob.class) .withIdentity("job1", "group1") .build();// Trigger the job to run now, and then repeat every 40 secondsTrigger trigger = newTrigger() .withIdentity("trigger1", "group1") .startNow() .withSchedule(simpleSchedule() .withIntervalInSeconds(40) .repeatForever()) .build();// Tell quartz to schedule the job using our triggerscheduler.scheduleJob(job, trigger); 入门案例引入 Maven 依赖在 https://mvnrepository.com 官网搜索 quartz，选择了最新版本 2.3.2 12345678910111213141516&lt;dependencies&gt; &lt;!-- 核心包 --&gt; &lt;!-- https://mvnrepository.com/artifact/org.quartz-scheduler/quartz --&gt; &lt;dependency&gt; &lt;groupId&gt;org.quartz-scheduler&lt;/groupId&gt; &lt;artifactId&gt;quartz&lt;/artifactId&gt; &lt;version&gt;2.3.2&lt;/version&gt; &lt;/dependency&gt; &lt;!-- 工具包 --&gt; &lt;!-- https://mvnrepository.com/artifact/org.quartz-scheduler/quartz-jobs --&gt; &lt;dependency&gt; &lt;groupId&gt;org.quartz-scheduler&lt;/groupId&gt; &lt;artifactId&gt;quartz-jobs&lt;/artifactId&gt; &lt;version&gt;2.3.2&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 说明：核心依赖是 quartz，而 quartz-jobs 是一个可选依赖，它主要放置了一些 quartz 的工具代码、一些预定义的 job。 任务类1234567891011public class QuartzHelloJob implements Job &#123; @Override public void execute(JobExecutionContext jobExecutionContext) throws JobExecutionException &#123; // 当前时间 Date date = new Date(); DateFormat dateFormat = new SimpleDateFormat("yyyy-MM-dd:HH:mm:ss"); String dateStr = dateFormat.format(date); // 工作内容 System.out.println("正在进行数据备份任务的定时执行，执行时间：" + dateStr); &#125;&#125; 主类1234567891011121314151617181920212223242526public class QuartzHelloScheduler &#123; public static void main(String[] args) throws Exception &#123; // 1. 调度器 Schduler，从工厂中获取调度器实例 Scheduler stdScheduler = StdSchedulerFactory.getDefaultScheduler(); // 2. 任务实例 JobDetail // 参数 1：任务的名称；参数 2：任务组的名称 JobDetail jobDetail = JobBuilder.newJob(QuartzHelloJob.class) .withIdentity("job1", "jobGroup1") .build(); // 3. 触发器 Trigger // 参数 1：触发器的名称；参数 2：触发器组的名称 Trigger trigger = TriggerBuilder.newTrigger() .withIdentity("trigger1", "triggerGroup1") .withSchedule(SimpleScheduleBuilder.simpleSchedule().repeatSecondlyForever(5)) .startNow() .build(); // 4. 通过调度器将触发器与任务实例关联，保证按照触发器定义的条件执行任务 stdScheduler.scheduleJob(jobDetail, trigger); // 5. 启动 stdScheduler.start(); &#125;&#125; 运行主类，结果如下： 1234正在进行数据备份任务的定时执行，执行时间：2020-09-06:17:45:56正在进行数据备份任务的定时执行，执行时间：2020-09-06:17:46:01正在进行数据备份任务的定时执行，执行时间：2020-09-06:17:46:06正在进行数据备份任务的定时执行，执行时间：2020-09-06:17:46:11 可以看到控制台果然每隔 5 秒就会有输出内容。 概念扩展上面介绍过一些核心概念，还有一些概念也比较重要。 JobExecutionContext 介绍当 Scheduler 调用一个 Job 时，会将 JobExecutionContext 传递给 Job 的 execute() 方法。Job 能通过 JobExecutionContext 对象访问到 Quartz 运行时的环境以及 Job 本身的详细数据。 JobDataMap 介绍 在进行任务调度时，JobDataMap 存储在 JobExecutionContext 中，非常方便获取； JobDataMap 可以用来装载任何可序列化的数据对象，当 Job 实例对象执行时，这些参数对象会传递给它； JobDataMap 实现了 JDK 的 Map 接口，并且添加了非常方便的方法用来存取基本数据类型； 主类： 123456// 2. 任务实例 JobDetail// 参数 1：任务的名称；参数 2：任务组的名称JobDetail jobDetail = JobBuilder.newJob(QuartzHelloJob.class) .withIdentity("job1", "jobGroup1") .usingJobData("message", "job message") // 传参 .build(); Job 实现类： 123// JobDataMap 传值JobDataMap jobDataMap1 = jobExecutionContext.getJobDetail().getJobDataMap();System.out.println("任务数据的参数值：" + jobDataMap1.get("message")); 还有一个用法，在 Job 实现类中添加 setter 方法对应 JobDataMap 的键，Quartz 框架默认的 jobFactory 实现类在初始化 Job 实例对象时会自动地调用这些 setter 方法。这样的好处是，你可以在 Job 实现类中方便地使用成员变量，而不用像上面那种方式去取值。 注意点：如果遇到同名的 key，Trigger 中的 key 对应的值会覆盖 JobDetail 中的值。 有状态 Job 和无状态的 Job 有状态 Job 可以理解为，多次 Job 调用期间可以持有一些状态信息，这些状态信息存储在 JobDataMap 中。 默认的无状态的 Job 每次调用时都会创建一个新的 JobDataMap。 @PersisJobDataAfterExecution 注解的使用在 Job 任务类上，多次 Job 实例被调用期间，可以持有一些状态信息，比如可以实现 count 的累加。 Trigger 介绍Quartz 有一些不同的触发器类型，使用最多的是 SimpleTrigger 和 CronTrigger jobKey：表示 job 实例的标识，触发器被触发时，该指定的 job 实例被执行（也就是说，除了通过 JobDetail 获取到 job 实例的内容，Trigger 对象也提供了方法获取）； startTime：表示触发器的时间表，第一次开始被触发的时间，数据类型是 java.util.Date； endTime：表示触发器终止被触发的时间，数据类型也是 java.util.Date； SimpleTrigger 触发器5 秒重复执行，只执行 3 次，设置结束时间：123456789Trigger trigger = TriggerBuilder.newTrigger() .withIdentity("trigger1", "triggerGroup1") .withSchedule(SimpleScheduleBuilder.simpleSchedule() .repeatSecondlyForever(5) .withRepeatCount(2)) .usingJobData("message", "simple 触发器") .startNow() .endAt(endDate) .build(); SimpleTrigger 属性有开始时间、结束时间、重复次数和重复时间间隔等 重复次数的属性值从 0 开始计数 重复时间间隔属性值必须是长整型的正整数 如果指定了结束时间属性值，那么，结束时间属性权重优于重复次数属性 CronTrigger 触发器CronTriggers 通常比 SimpleTrigger 更有用，因为它是基于日历的作业触发器。使用 CronTrigger，你可以指定诸如“每周五中午”或者“每个工作日的 9:30”这样的日程来触发 Job 执行。像 SimpleTrigger 一样，CronTrigger 也有一个 startTime 以指定日程从什么时候开始，也有一个（可选） endTime 以指定何时日程不再继续。 Cron Expressions —— Cron 表达式Cron 表达式被用来配置 CronTrigger 实例。Cron 表达式是一个由 7 个表达式组成的字符串。每个子表达式描述一个单独的日程细节。这些表达式用空格分隔： Seconds 秒 Minutes 分 Hours 小时 Day-Of-Month 月中的天，日 Month 月 Day-Of-Week 周中的天，周几 Year 年（可选） 字段 是否必填 允许值 可以出现的运算符 秒 必填 0 - 59 / * , - 分 必填 0 - 59 / * , - 时 必填 0 - 23 / * , - 月中的天 必填 1 - 31 / * , - ? L W C 月 必填 1 - 12， 也可以用JAN这些缩写 / * , - 星期中的天 必填 1 - 7 或者 SUN-SAT，7是星期六， 可以用 WED 这些缩写 / * , - ? L C # 年份 非必填 1970 - 2099 / * , - 1 表示周日 运算符的含义： 运算符 含义 * 表示这个字段的每一个值， 可以出现在所有字段中。 如” ？”表示每一秒钟。 / 表示值的增量，从一个值开始，每间隔多少时间后再次执行，可以出现在所有的字段。如在分钟字段上， 0/15表示从0分开始， 间隔15分钟执行一次， 相当于0,15,30,45 , 表示多个值， 可以出现在所有的字段。 如周一周三周五可表示为MON,WED,FRI。 - 表示一个区间。如周一到周三可表示为MON-WED。 ? 表示放弃这个字段设置， 可以出现在月中的天和周中的天这两个字段。如” ？”表示每一秒钟。 L L是 Last 的缩写， 可以出现在月中的天和周中的天这两个字段, 当时含义不一样。 在月中的天这个字段中， L表示这个月的最后一天。 而在周中的天中， 如果L单独出现， 那么就表示7或者SAT即星期六， 如果出现在一个数字的后面， 那么就表示这个月的周几， 如“6L”, 表示这个月的最后一个周五 W W是 week 的缩写， 可以出现在月中的天这个字段， 可以用来指定距离这个时间最近的周几， 周的天在Day of Week字段中指定。 # 表示这个月的第几个星期，可以出现在周中的天这个字段。 如 1#3 或 SUN#3， 表示这个月的第 3 个星期日。 月中的天和周中的天互斥，只能出现一个问号，例如，不能保证每周二都是 1 号！ / 这个符号还是挺常用的，比如在秒的位置，如果你直接 5，那么，就表示第 5 秒执行，但是如果是 0/5 则表示从 0 秒开始，每隔 5 秒！注意不要搞错！L 和 W 可以一起使用，比如每隔月最后一个周五结算工资周字段的英文字母缩写不区分大小写，例如 MON 等价于 mon在线 Cron 表达式生成器：https://www.matools.com/cron Cron 表达式示例：12345"0 0 10,14,16 * * ?" 每天 10 点、14 点、16 点执行"0 0/30 9-17 * * ?" 每天 9-17 点，每隔 30 分钟执行一次"0 0 12 ? * WED" 每周三的 12 点执行"0 15 10 L * ?" 每月的最后一天的 10 点 15 分执行"0 15 10 ? * 6#3" 每月的第三个周五 10 点 15 分执行 CronTrigger 示例123456JobDetail jobDetail = JobBuilder.newJob(QuartzHelloJob.class) .withIdentity("job1", "jobGroup1") .usingJobData("message", "job message") .usingJobData("param", "setter 传参") .usingJobData("count", 1) .build(); SchedulerFactory 对于 Job 来说，Trigger 就类似于驱动器，没有触发器来定时驱动作业 Job，Job 就无法运行； 对于 Job 而言，一个 Job 可以对应多个 Trigger； 对于 Trigger 而言，一个 Trigger 只能对应一个 Job； Trigger 和 Job 因此就是「多对一」的关系 Scheduler 的创建方式：（1） StdSchdulerFactory：Quartz 默认的 SchdulerFactory 使用一组参数（java.util.Properties）来创建和初始化 Quartz 调度器； 配置参数一般存储在 quartz.properties 文件中； 调用 getScheduler 方法就能创建和初始化调度器； 1234StdSchedulerFactory stdSchedulerFactory = new StdSchedulerFactory();Scheduler stdScheduler = stdSchedulerFactory.getScheduler();// 等价于Scheduler stdScheduler = StdSchedulerFactory.getDefaultScheduler(); 将任务和触发器关联1stdScheduler.scheduleJob(jobDetail, trigger); 其他用法 启动任务调度 stdScheduler.start(); 调度挂起，即暂停（暂停后，需要再次调用 start() 方法才能启动）: stdSchduler.standby(); 调度关闭（关闭之后，重新启动也不行）：stdSchduler.shutdown(); shutdown() 方法可以传入一个布尔值，boolean waitForJobsToComplete，用于表示是否等待 Job 执行完毕再结束！ture 表示等待所有正在执行的 Job 执行完毕之后，再关闭 Scheduler。false 表示直接关闭 Scheduler。 quartz.properties 配置在项目中搜索该文件，可以在依赖的 Quartz 包下看到默认的配置文件：1234567891011121314151617181920212223# Default Properties file for use by StdSchedulerFactory# to create a Quartz Scheduler Instance, if a different# properties file is not explicitly specified.## 调度器属性## instanceName 用来区分特定调度器实例，可以按照功能用途来给调度器起名org.quartz.scheduler.instanceName: DefaultQuartzSchedulerorg.quartz.scheduler.rmi.export: falseorg.quartz.scheduler.rmi.proxy: falseorg.quartz.scheduler.wrapJobExecutionInUserTransaction: false# 线程池属性org.quartz.threadPool.class: org.quartz.simpl.SimpleThreadPool## 处理 Job 的线程数，至少为 1，并不是越大越好org.quartz.threadPool.threadCount: 10## 线程的优先级，优先级别高的线程比级别低的线程优先得到执行。最小为 1，最大为 10，默认 5org.quartz.threadPool.threadPriority: 5org.quartz.threadPool.threadsInheritContextClassLoaderOfInitializingThread: true# 作业存储设置org.quartz.jobStore.misfireThreshold: 60000org.quartz.jobStore.class: org.quartz.simpl.RAMJobStore 扩充： org.quartz.scheduler.instanceId: AUTO 这个值必须所有调度器实例中唯一，作为集群的唯一 key。 org.quartz.spi.ThreadPool.class 一个实现了 org.quartz.spi.ThreadPool 接口的类，Quartz 自带的线程池实现类是 org.quartz.smpl.SimpleThreadPool 如果想自定义配置，那么只需要拷贝上面内容放在项目的 resources 目录下即可。也可以通过编写程序代码操作 quartz.properties 文件的内容： 12345678910// 通过代码方式配置 quartzProperties properties = new Properties();// 可以用工厂类中的常量properties.put(StdSchedulerFactory.PROP_THREAD_POOL_CLASS, &quot;org.quartz.simpl.SimpleThreadPool&quot;);properties.put(&quot;org.quartz.threadPool.threadCount&quot;, &quot;10&quot;);// 1. 调度器 Schduler，从工厂中获取调度器实例StdSchedulerFactory stdSchedulerFactory = new StdSchedulerFactory();stdSchedulerFactory.initialize(properties);Scheduler stdScheduler = stdSchedulerFactory.getScheduler(); 通过 Properties 设置工厂属性的缺点在用硬编码，例如需要修改线程数量，将不得不修改代码，然后又重新编译。因此，不推荐使用。还是使用 quartz.properties 的配置方式方便。 Quartz 监听器概念Quartz 监听器用于当任务调度你所关注的事件发生时，能够及时获取这一事件的通知。 Quartz 监听器主要有 JobListener、TriggerListener、SchedulerListener 三种。先明确两个概念：全局监听器与非全局监听器。二者区别在于： 全局监听器能够接收到所有的 Job/Trigger 的事件通知 非全局监听器只能接收到在其上注册的 Job 或 Trigger 事件，不在其上注册的 Job 或 Trigger 则不会进行监听。 监听器的用法步骤大致如下： 新建一个类，实现监听器接口 xxxListener； 通过监听管理器创建并注册监听器 JobListener任务调度过程中，与任务 Job 相关事件包括： Job 开始要执行的提示； Job 执行完成的提示； JobListener 接口包含几个重要的方法声明： getName：用于获取 JobListener 的名称； jobToBeExecuted 方法：Scheduler 在 JobDetail 将要被执行时调用该方法； jobExecutedVetoed 方法：Scheduler 在 JobDetail 即将被执行，但又被 TriggerListener 否决时调用该方法； jobWasExecuted 方法：Scheduler 在 JobDetail 被执行之后调用该方法； TriggerListenerTriggerListener 包含几个方法： getName：获取触发器的名称 triggerFired 方法：当与监听器相关联的 Trigger 被触发，Job 上的 execute() 方法将被执行时，Scheduler 就调用该方法； vetoJobExecution 方法：在 Trigger 触发后，Job 将要被执行时由 Scheduler 调用这个方法。TriggerListener 给了一个选择去否决 Job 的执行。假如这个方法返回 true，这个 Job 将不会被此次 Trigger 触发而得到执行； triggerMisfired 方法：Scheduler 调用这个方法是在 Trigger 错过触发时。 triggerComplete 方法：Trigger 被触发并且完成了 Job 的执行时，Scheduler 调用这个方法； SchedulerListenerSchedulerListener 会在 Scheduler 的生命周期中关键事件发生时被调用。与 Scheduler 有关的时间包括： 增加一个 Job/Trigger 删除一个 Job/Trigger Scheduler 发生错误 关闭 Scheduler 等 示例代码完整示例代码：https://github.com/Michael728/java-middleware-demos/tree/master/quartz-demos 参考 B 站/任务调度 Quartz 视频教程全集（21P）| 3 小时从入门到精通 博客园/Quartz的基本使用之入门（2.3.0版本）]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>定时任务</tag>
        <tag>Quartz</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[IT程序员的装修笔记——家电选购之冰箱篇]]></title>
    <url>%2F2020%2F08%2F21%2Flife-shopping-applicances-fridge%2F</url>
    <content type="text"><![CDATA[冰箱冰箱可谓是现代家庭必不可少的一件电器，最近花时间了解了一下现在冰箱的常见卖点功能。这里总结分享出来，方便其他有需要的同学作参考。重点不是推荐具体型号的冰箱，而是方便大家选购适合自己需求的产品~ 不了解不知道，一了解吓一跳。小时候电视剧里出现的高大上的对开门大冰箱，如今二三千也可以入手！ 箱门形式按照冰箱门类型设计进行划分： 双门冰箱：一般上冷藏，下冷冻，通常无变温室 三门冰箱：比双门冰箱多了一个中间的变温室，可以调节不同温度使用 对开门冰箱：体积大、性价比高，缺少变温室 十字对开门冰箱：对开门冰箱的进阶版，分区更为合理，一般也有独立变温室 多门冰箱：有时也称法式多门，一般 4 门起 假设倾向大容量冰箱，食材管理比较精细化的可以选择多门和十字对开门，粗放式的同学可以选择对开门 变温空间就是指有一块空间，你可以独立指定它的温度模式，适配存储鲜肉、冰镇啤酒、干燥坚果。 容量在空间允许的前提下，建议参考 100~150L/人 的标准，结合家庭食材购买频率，确定容积需求。 正常家庭 250~500L 即可, 500L 以上适合多口之家。毕竟食物还是新鲜的好，没必要囤积太多食品。 放置冰箱会要求上、左、右都要留有一定的间隙用于散热，在保证箱门正常开启的前提下，两侧各预留 5cm 左右即可。 制冷模式 直冷：通过蒸发器直接直冷，对于蔬果保鲜有利，但是易结冰 风冷：蒸发器增加风机，有自动除霜效果，现在主流技术，也就是常看见的「风冷无霜」宣传语 混冷：冷藏直冷（防止蔬果风干）、冷冻风冷（无霜）。高端冰箱会采用，因为其结构稍复杂、成本较高 压缩机美芝、加西贝拉、恩布拉科、扎努西、华意等品牌 当我在京东咨询客服试图了解一款冰箱的具体压缩机型号时，下面是客服给我的答复： 因根据产品批次不同，选配的压缩机不同，多品牌更利于确保供货，所以具体品牌查询不到哦~ 看京东经常也会有核心部件、质保十年的赠品，因此压缩机这块应该不用太在意。 循环模式 单循环，就是一个蒸发器，冷风在冰箱里冷藏变温冷冻转一圈再回去。 双循环，则是两个蒸发器，冷藏和冷冻分别冷风循环，制冷更快，也缓解了串味问题。常常带有「双系统制冷」描述字眼。 多循环：常见于三开门或多门冰箱，除了冷藏和冷冻各有蒸发器之外，零度区可能也也有单独调节温度。 确认是不是双系统，得向客服咨询！！！因为从描述很难判断，双循环≠双系统！小心被坑~ 单循环只有一套制冷系统，即一个蒸发器，制冷剂的流向压缩机-冷凝器-过滤器-毛细管-蒸发器-压机。冷藏室与冷冻室不可单独控制，任何一个间室的制冷都会让另一个间室被迫制冷。 双系统制冷的优点： 食材不串味 控温更精确，不同于单循环的“牵一发而动全身” 品牌 欧美：博士、西门子 日系：松下、东芝 国产：海尔、美的、海信、容声、美菱 海信、容声目前是一家了，博士西门子合称博西，因为西门子家用电器业务据说被博士收购了 价格记录 此处不是推荐！仅是做一个价格记录的快照，方便日后对比！ 品牌 型号 容量 长宽高/mm 上市时间 价格 好评度 质保 能效（度/天） 款式 特点 海尔 BCD-545WFPB 单系统 545L 648*908*1905 2020-4 4499（20200816） 99% 赠品赠送 10 年核心部件质保 1 级（0.93） 十字对开门 变温箱（母婴模式、零度模式、珍品模式）、90°悬停门 美的 BCD-503WSPZM(E) 双系统 503L 648*833*1898 202006 5749（20200816） 99% 赠品赠送 10 年核心部件质保 1 级（0.89） 十字对开门 母婴保鲜智能、不容易留指纹、果润保鲜 总结本文的目的不是推荐冰箱，而是梳理选购冰箱时涉及到的一些基本概念，有助于帮助大家选择到合适的产品！有些功能不是必选，而是可选。抛开预算、推荐产品就是耍流氓，根据自己的需要、选择适合自己的才是理智的行为！ 一言在和京东客服咨询时，发现国产品牌的客服都很热心，周末都提供在线咨询服务到深夜！国产家电的质量和国外品牌的差距并没那么大，有时候没必要盲从，同样的功能，因为品牌溢价，你可能就要多付很多智商税~ 2020 魔幻的一年，国外的月亮不一定就更圆，国货加油！ 参考 一兜糖家居APP/拜托，挑冰箱真没那么难！ 什么值得买/装修系列专题｜2020年冰箱选购推荐（6.29更新） 知乎/出木衫同学/家电选购终极指南——冰箱篇 海尔官网/冰箱双循环制冷，食材新鲜不串味]]></content>
      <categories>
        <category>Life</category>
      </categories>
      <tags>
        <tag>装修</tag>
        <tag>购物</tag>
        <tag>家电</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[IT程序员的装修笔记——家电选购之冰箱篇]]></title>
    <url>%2F2020%2F08%2F21%2Flife-shopping-network%2F</url>
    <content type="text"><![CDATA[概念5G &amp; 2.4Gwifi 路由器目前主要分为 2.4G 和 5G 两种频率的型号。5G 信号频率高、波长短，而 2.4G 信号频率低、波长长，所以 5G 信号穿过障碍物时衰减更大，穿墙能力比 2.4G 信号弱。那么5G信号有什么优点呢？5G 信号频宽较宽，无线环境比较干净，干扰少，网速稳定，且 5G 可以支持更高的无线速率。 电磁波的物理特性：频率低，则波长越长，衰减越少，也更容易绕过障碍物继续传播。 因此，如果能够配置全屋 WiFi，则理想情况是多覆盖 5G 信号。 带宽与下载速率运营商通常给出的套餐中，经常会听到百兆宽带，但是我们实际使用时的下载速率却到不到百兆，这是为为什么呢？因为二者的单位不一致。 运营商的单位是 Mbps，下载速率的单位通常是 MBps。 1 Byte = 8 bit，即 1 字节 = 8 位。因此，100兆宽带大约最大的下载速率在 12.5兆/秒左右。 网线 五类线（Cat5）的速度最高能达到 100Mb/s，频率能达到100Mhz，所以说五类线可以支持百兆以下的网 超五类线（Cat5e）的速度最高能达到 1Gb/s（1000Mb/s），频率也是 100Mhz，超五类线可以支持千兆以下的网。在一般的家庭中，传输距离有限，因此，超五类网线也够用了。 六类线（Cat6）的速度最高能达到 10Gb/s，频率是 250Mhz，六类线可以支持万兆网，主要用于万兆局域网等 需要注意网线水晶头接了几根芯，详情阅读 网线的四芯接法以及八芯接法 POEPOE(Power Over Ethernet)也被称为基于局域网的供电系统(POL, Power over LAN )或有源以太网( Active Ethernet)，有时也被简称为以太网供电，这是利用现存标准以太网传输电缆的同时传送数据和电功率的最新标准规范 不需要为每个AP专门再拉一条电线供电，直接通过网线就可以实现供电，但是这边还有个注意点就是每个AP都是有额定功率的，所以在后期POE供电功率要大于等于所有AP的功率之和。 AC接入控制器（Access Controller或Wireless Access Point Controller），即无线控制器，是一种网络设备，负责管理某个区域内无线网络中的 AP AP无线访问接入点(WirelessAccessPoint)，即无线接入点，它用于无线网络的无线交换机，也是无线网络的核心。无线AP是移动计算机用户进入有线网络的接入点，主要用于宽带家庭、大楼内部以及园区内部，可以覆盖几十米至上百米。无线AP（又称会话点或存取桥接器）是一个包含很广的名称，它不仅包含单纯性无线接入点（无线AP），同样也是无线路由器（含无线网关、无线网桥）等类设备的统称。 无线协议第一代的 802.11 演变到了 802.11ax。目前主流的 802.11ac 已经重新被命名为 WiFi 5，最新的 802.11ax 为WiFi 6 路由器 路由器不能取代AC，要不就无法控制下面的AP,最重要的是没有POE的功能了，需要加POE的设备，多余； 如果是需要路由器的使用功能，如DDNS,挂硬盘，去广告等，建议把 AC 挂在路由器下面，路由器作为核心来拨号，AC 控制其他的WIFI,路由器的WIFI关闭（原因是路由器的WIFI在面积很大的基础上没有AP的范围广） 如果是需要路由器的网络信号，就直接找个合适的位置挂在 AC 下面即可，建议放客厅，但是部分功能就用不了了，因为这样配置路由器就相当于家里的一个AP面板。 https://www.acwifi.net/category/mesh 参考 知乎/家庭组网AP+AC，是否需要一个强力路由器？ 知乎/小怪的装修笔记-设计篇五（无线网络方案 全屋wifi ap+ac） 「五类网线」 和 「六类网线」 有什么区别? 四芯网线与八芯网线的区别 四芯双绞线怎么接,四芯网线接法,4根网线如何接]]></content>
      <categories>
        <category>Life</category>
      </categories>
      <tags>
        <tag>装修</tag>
        <tag>购物</tag>
        <tag>家电</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[IT程序员的装修笔记——家电选购之电视机篇]]></title>
    <url>%2F2020%2F08%2F16%2Flife-shopping-appliances-TV%2F</url>
    <content type="text"><![CDATA[前言2018 年五月购买的房子，等了 2 年多多了，预计今年年底就要交付了。今天在家看看家电有关的内容，做好笔记。 电视机电视机的诉求就是画质好、用的久、接口齐全、与相关的设备兼容性好，比如和游戏主机的互联等。 分辨率市面上很多假 4K，要注意分辨率要达到 3840*2160 或 4096*2160 真 4K 是 RGB 三色面板，则为，假 4K 是 RGBW 四色面板。 面板 VA 面板：对比度更好，适合观看影片电视剧 IPS 面板：可视度更好，看比赛、玩游戏 HDR光影对比更加真实。一个画面中，亮的的地方可以亮，同时，暗的地方可以依然保持暗。 要明确是支持 HDR 解码还是支持 HDR 显示效果。 HDR电视标准： 液晶电视屏幕峰值亮度 1000 Nit以上； 广色域，大于等于 90%DCI-P3色域； 支持动态区域背光控制； 杜比视界/HDR10/HLG至少支持一种； 市售低于5K的电视机支持的HDR自然只是HDR解码，并无太多实际意义 画质芯片 索尼 X1、XR 三星 8K 的 AI 芯片 LG 的 α9、α7 海信的 Hi-View Pro 色域色域又叫色彩空间，是衡量电视画质的重要标准之一。一般来说色域越广越好，广色域包含更多的色彩表现，能够更好的呈现视频的画质。 色域标准众多，常用的主要包括 NTSC、sRGB、BT.709、BT.2020 和 DCI-P3，不同标准覆盖的色域范围不同。考虑到NTSC标准相对通用，习惯性会将其他色域标准转化成 NTSC（考虑到不同色域之间并不能完全互相覆盖，这里的转换只是近似）。 100% sRGB≈72% NTSC； 100% BT.709≈72% NTSC； 100% BT.2020≈150% NTSC； 100% DCI-P3≈96% NTSC。 关注厂商广告中色域标准采用的是哪个。100%色域。可能是采用的 BT.709 标准，它只是近似为72% NTSC标准的色域表现 关键其实是色彩管理系统！这才是厂家核心技术的护城河~ 背光方式 直下式 运动补偿运动补偿功能（多数厂家叫MEMC，SONY的叫Motion Flow） 屏幕刷新率屏幕刷新率表示电视在一秒钟能刷新的图片数量。刷新率越高刷新的照片越多，电视画面就越流畅。目前大多数电视屏幕刷新率都是 60Hz，高端电视屏幕刷新率可以达到 120Hz。高刷新率配合 MEMC 技术，可以带来更加流畅的画面体验。 接口 HDMI 1.4 = 10.2 Gbps HDMI 2.0 = 18 Gbps 如果没有上面这种接口，大概率无法播放 4K 片源 蓝牙智能电视蓝牙功能有用，搭配游戏手柄、蓝牙音箱使用十分方便，同时看电视无法外放声音的时候可以使用蓝牙耳机。 视频格式 H.265+ 视频格式，为 4K 而生的编码格式 选购索尼索尼： OLED 有 A9、A8 两个系列； 液晶电视 9000 系列高端、8000 系列中端、7000 系列入门级； 每个系列后面有字幕代表年份，比如 Z9G，G 代表 2019 年；F 表示去年机型; 关注型号： X9000H 65 寸，8000，202005 上市，安卓 9.0，二级能效，蓝牙耳机、4K HDR、4G16G、4 核、x1 芯片、2 个 USB 接口 2.0/3.0，HDMI 2.1 接口、耳机接口、可屏幕发声、特丽魅彩技术、精锐光控、杜比音效、线上线下同款，整机一年，主要部件三年，好评率 99%，官网参数 8000H 入门级 4K，刷新率 60HZ 的面板，扬声器也有区别；9500H 芯片是 X1 加强版，精锐光控增加强版、支持远程语音，9500 G 是 2019 年旗舰机型； 三星三星主打 QLED 量子点技术，色域很广 芯片： UA 系列，7 系以上，三星自研芯片； 5-7 系，芯片主频比较低 5 系以下，使用太长新芯片 海信 E 系列是线上型号，线下没有； A 系列，线下款； U 系列是 ULED 电视； 带 E 的型号，带远场语音； 选择海信电视，关注是否有 AI 画境芯片或者 ULED 量子点技术或者「信芯」芯片 关注型号： E8D 5669 ULED/140%色域/3+ 32G/CPU A73✖️2核+A53✖️2核数/刷新率 60HZ/支持蓝牙耳机 尺寸在国外这个网站 rtings/size-to-distance-relationship 有提供关于根据观影距离和视频分别率推荐电视尺寸的工具，非常值得推荐！ 海尔官网/你真的会选电视尺寸吗? 参考 B站/知电晓春哥/液晶电视选择的坑你踩了几个？屏好不等于电视好，液晶电视选购必看 提到了关注芯片、接口、视频格式等关键因素 科技狗/油管/【選購指南】2020年4K 電視怎麼選？ 更专业的评测，提供很多专业讲解 什么值得买/从参数到推荐：2020年电视机选购指南 B站 Wayne的生活/索尼电视2020新品又挤牙膏？快去抢X9500G！SONY 85寸9500G评测 上集]]></content>
      <categories>
        <category>Life</category>
      </categories>
      <tags>
        <tag>装修</tag>
        <tag>购物</tag>
        <tag>家电</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java 基础 —— 反射]]></title>
    <url>%2F2020%2F08%2F09%2Fjava-basic-class-reflect%2F</url>
    <content type="text"><![CDATA[通过反射查看类信息Java 程序中的许多对象在运行时会出现两种类型：编译时类型和运行时类型。例如：Person p = new Student();，代码会生成一个 p 变量，编译时类型是 Person，运行时类型为 Student。除此之外，有时程序在运行时接收到外部传入的一个编译类型为 Object，但程序又需要调用该对象运行时类型的方法。 未解决这些问题，程序需要运行时发现对象和类的真实信息。有下面两种做法： 先试用 instanceOf 运算符进行判断，再利用强制类型转换将其转换成运行时类型的变量； 程序只依靠运行时信息来发现该对象和类的真实信息，这就必须使用「反射」； 本文就主要是来介绍反射知识点的。 获得 Class 对象之前文章已经介绍过类加载了，每个类被加载之后，系统会为该类生成一个对应的 Class 对象，通过该 Class 对象就可以访问 JVM 中的这个类。Java 程序中获得 Class 对象有如下三种方式： 使用 Class 类的 forName(String clazzName) 静态方法。该方法需要传入字符串参数，该字符串参数的值是某个类的「全限定名」（必须是完成包名）。 调用某个类的 class 属性来获取该类对应的 Class 对象。例如 Person.class 将会返回 Person 类对应的 Class 对象。 调用某个实例对象的 getClass() 方法。该方法是 java.lang.Object 类中的方法，因此所有 Java 对象都可以调用该方法。 方式 1 和方式 2 都是直接根据类来获得该类的 Class 对象。大部分时候，应该使用方式 2 来获取指定类的 Class 对象。因为方式 2 有如下优势： 代码更安全。编译阶段就可以检查需要访问的 Class 对象是否存在； 程序性能更好。 获取了 Class 对象之后可以进行的操作就多了，程序可以调用 Class 对象的方法来获得该对对象和对应类的真实信息了。 从 Class 中获取信息Class 类提供了大量的实例方法来获取该 Class 对象所对应类的相关信息。下面的方法都可能提供了多个重载的版本。 获取 Class 对象的对应类的构造器 Constructor&lt;T&gt; getConstructor(Class&lt;?&gt; ... parameterTypes)：返回此 Class 对象对应类的、带指定形参列表 的 public 构造器； Constructor&lt;T&gt;[] getConstructors()：返回此 Class 对象对应类的所有 public 构造器； Constructor&lt;T&gt; getDeclaredConstructor(Class&lt;?&gt; ... parameterTypes)：返回此 Class 对象对应类的、带指定形参列表 的构造器，与构造器的访问权限无关！ Constructor&lt;T&gt;[] getDeclaredConstructors()：返回此 Class 对象对应类的所有构造器，与构造器的访问权限无关！ 获取 Class 对象的对应类所包含的方法 Method getMethod(String name, Class&lt;?&gt; ... parameterTypes)：返回此 Class 对象对应类的、带指定形参列表的 public 方法 Method[] getMethods()：返回此 Class 对象对应类的所有 public 方法； Method getDeclaredMethod(String name, Class&lt;?&gt; ... parameterTypes)：返回 Class 对象对应类的、带指定形参列表的方法，与方法的访问权限无关！ Method[] getDeclaredMethods()：返回 Class 对象对应类的全部方法，与方法的访问权限无关！ 获取 Class 对象的对应类所包含的成员变量 Field getField(String name)：返回此 Class 对象对应类的、指定名称的public 成员变量； Fields[] getFileds()：返回此 Class 对象对应类的所有 public 成员变量； Field getDeclaredField(String name)：返回此 Class 对象对应类的、指定名称的成员变量，与成员变量的访问权限无关！ Fields[] getDeclaredFields()：返回此 Class 对象对应类的全部成员变量，与成员变量的访问权限无关！ 还有很多其他的功能呢： 访问 Class 对象对应类上所包含的 Annotation； 访问 Class 对象对应类包含的内部类（Class&lt;?&gt;[] getDeclaredClasses()）； 访问 Class 对象对应类的所在的外部类（Class&lt;?&gt; getDeclaringClass()）； 获取 Class 对象对应类的修饰符、所在包、类名等基本信息 方法就不一一介绍了，详细可阅读 Java Class API。 观察上面方法的描述，其实大体可以总结出来，带 Declared 字眼的方法呢，返回的内容就不受访问权限的控制！ 方法理解上面介绍了一群方法，怎么调用呢？传参是怎样的呢？看个栗子就明白了！ 假设某个类包含如下三个 info 方法签名： public void info() public void info(String str) public void info(String str, Integer num) 这三个同名方法属于重载，参数列表不同。假如想要指定第 2 个 info 方法，那么形参列表为 String.class，因此程序中获取该方法应该使用如下代码： 12// clazz 是 Class 对象，第一个参数是方法名，后面的个数可变的 Class 参数形参类型列表clazz.getMethod("info", String.class); 看了上面的例子，应该可以看懂 Method getMethod(String name, Class&lt;?&gt; ... parameterTypes) 这个方法如何使用了吧。这里仅是概览一下方法，下文会有更详细的示例。 使用反射生成并操作对象Class 对象通过上面介绍的方法，可以获得该类里的方法（由 Method 对象表示）、构造器（由 Constructor 对象表示）、成员变量（由 Field 对象表示），这三个类都位于 java.lang.reflect 包下，并实现了 java.lang.reflect.Member 接口。 程序可以通过 Method 对象来执行对应的方法，通过 Constructor 对象来调用对应的构造器创建实例，能通过 Field 对象直接访问并修改对象的成员变量值。 创建对象先使用 Class 对象获取指定的 Constructor 对象，再调用 Constructor 对象的 newInstance() 方法来创建该 Class 对象对应类的实例！ 看个栗子： Student.java:123456789101112131415public class Student&#123; String name; public Student() &#123; &#125; private Student(String name) &#123; System.out.println("My name is: " + name); &#125; public void hello(String content) &#123; System.out.println("name: " + name + " say :" + content); &#125;&#125; CreateObjectTest.java: 12345678910111213public class CreateObjectTest &#123; static Object createObject(String clazzName) throws Exception &#123; // 根据全限定的类名获取对应的 Class 对象 Class&lt;?&gt; clazz = Class.forName(clazzName); // 使用 clazz 对应类的无参构造器创建实例 return clazz.getConstructor().newInstance(); &#125; public static void main(String[] args) throws Exception &#123; Object s = createObject("reflect.Student"); &#125;&#125; 其实，如果想调用有参的构造器创建对象，只要用上面介绍过的方法去获取有参的 Contructor 对象即可。然后调用 newInstance 方法时，传入对应的实参就行。 Spring 框架就采用读取配置文件的内容，然后通过反射来创建对象。 通常没有必要使用反射来创建对象，因为反射创建对象时性能要稍低。实际上，只有当程序需要动态创建某个类的对象时才会考虑使用反射。通常在开发通用性比较广的框架、基础平台时可能会大量使用反射。 调用方法通过反射调用方法其实和上面的步骤差不多：获得某个类的 Class 对象，通过该对象的 getMethods() 方法或者 getMethod() 方法获取全部方法或指定方法。具体语法在上面介绍过。方法返回值是 Method 数组或者 Method 对象。 每个 Method 对象对应一个方法，程序通过该 Method 调用它对应的方法。Method 包含一个 invoke() 方法，方法签名如下： Object invoke(Object obj,Object ... args)：obj 是执行该方法的主调，args 是执行该方法时传入的实参。 接上面的示例继续完善，CreateObjectTest.java： 123456789101112131415161718192021public class CreateObjectTest &#123; static Object createObject(String clazzName) throws Exception &#123; Class&lt;?&gt; clazz = Class.forName(clazzName); return clazz.getConstructor().newInstance(); &#125; static void methodTest(Object target) throws Exception &#123; // 通过实例的 `getClass` 方法获取 Class 对象 Class&lt;?&gt; clazz = target.getClass(); // 通过 Class 对象获取对应类的 Method 对象 Method mtd = clazz.getMethod("hello", String.class); // 调用 Method 对象的 invoke 方法，传入方法实参 mtd.invoke(target, "测试"); &#125; public static void main(String[] args) throws Exception &#123; Object s = createObject("reflect.Student"); methodTest(s); &#125;&#125; 输出：1name: null say :测试 这里因为调用的是 Student 无参构造器，因此 name 为空。 Method 的 invoke() 方法来调用对应方法时，Java 会要求程序具有调用该方法的权限。默认情况，private 方法是无权调用的。可以通过先调用 Method 对象的 setAccessible(boolean flag) 方法取消 Java 语言的访问权限检查（设为 false 时，不检查）。 Spring 框架将成员变量的值以及依赖对象等都放在配置文件中，然后采用上面方式进行创建对象、赋值成员变量的。这也是 Spring 框架 IoC 的秘密。 上面这个是《疯狂 Java 讲义》中的提示，从这提示里可以看到，反射的重点意义其实不在于它能够创建对象、赋值变量，因为这通过构造器等也能做，我觉得它存在的主要意义在于能够在运行时动态地执行创建对象、赋值变量等操作。 访问成员变量值通过 Class 对象的 getFields() 或 getField() 方法可以获取该类所包括的全部成员变量或指定成员变量。Field 提供了下面两组方法来读取或设置成员变量值。 getXxx(Object obj) 获取 obj 对象的该成员的变量值。此处 Xxx 对应 8 中基本类型，如果该成员变量类型是引用类型，则取消 get 后面的 Xxx setXxx(Object obj, Xxx val) 将 obj 对象的该成员变量设置成 val 值。如果该成员变量类型是引用类型，则取消 set 后面的 Xxx 栗子：123456789101112131415161718192021222324252627282930313233343536373839404142class Person &#123; private String name; private Integer age; public Person() &#123; &#125; public Person(String name, Integer age) &#123; this.name = name; this.age = age; &#125; @Override public String toString() &#123; return "Person&#123;" + "name='" + name + '\'' + ", age=" + age + '&#125;'; &#125;&#125;public class FieldTest &#123; public static void main(String[] args) throws Exception &#123; // 创建一个 Person 对象 Person p = new Person(); // 获取 Class 对象 Class&lt;Person&gt; personClazz = Person.class; // 使用 getDeclaredField() 方法获取 private 类型的成员变量 Field nameFiled = personClazz.getDeclaredField("name"); // 能够获取到并不代表能够访问成员变量，需要设置可访问才行，否则会报错： // Class reflect.FieldTest can not access a member of class reflect.Person with modifiers "private" nameFiled.setAccessible(true); nameFiled.set(p, "Michael"); Field ageFiled = personClazz.getDeclaredField("age"); ageFiled.setAccessible(true); // 调用 setInt() 方法为 p 对象的 age 成员变量设置值 // ageFiled.setInt(p, 30); ageFiled.set(p, 30); System.out.println(p); &#125;&#125; 上面代码中，如果使用 ageFiled.setInt(p,30) 则会报如下错误：123456Exception in thread&quot;main&quot;java.lang.IllegalArgumentException:Can not set java.lang.Integer field reflect.Person.age to(int)30at sun.reflect.UnsafeFieldAccessorImpl.throwSetIllegalArgumentException(UnsafeFieldAccessorImpl.java:167)at sun.reflect.UnsafeFieldAccessorImpl.throwSetIllegalArgumentException(UnsafeFieldAccessorImpl.java:191)at sun.reflect.UnsafeObjectFieldAccessorImpl.setInt(UnsafeObjectFieldAccessorImpl.java:114)at java.lang.reflect.Field.setInt(Field.java:949)at reflect.FieldTest.main(FieldTest.java:50) 因为 age 不是基本类型，要用上面那种写法才会 OK。 操作数组在 java.lang.reflect 包下提供了一个 Array 类，Array 对象可以代表所有的数组。可以通过 Array 动态地创建数组、操作数组元素。 static Object newInstance(Class&lt;?&gt; componentType,int ... length)：创建一个具有指定的元素类型、指定维度的新数组 static xxx getXxx(Object array, int index)：返回 array 数组中第 index 个元素。其中，xxx 是各种基本数据类型，如果数据元素时引用类型，则方法为 get(Object array, int index) static setXxx(Object array, int index, xxx value)：设置 array 数组中第 index 个元素值为 value。xxx 表示基本类型，如果是引用引用类型，则方法为 set(Object array, int index, Object value)。 具体的用法，可以阅读 java.lang.reflect.Array 栗子： 123456789101112131415public class ArrayTest &#123; public static void main(String[] args) &#123; try &#123; Object arr = Array.newInstance(String.class, 10); Array.set(arr, 5, "反射测试"); Array.set(arr, 6, "数组学习"); Object c1 = Array.get(arr, 5); Object c2 = Array.get(arr, 6); System.out.println(c1); System.out.println(c2); &#125; catch (Exception e) &#123; System.out.println(e); &#125; &#125;&#125; 其他 java.lang.reflect 包下还有 Proxy 类和一个 InvocationHandler 接口，通过他们可以生成 JDK 动态代理或动态代理对象。代理对象具有原本对象的执行方法之外，还增加了可以增加以下额外的行为（AOP 里方法在执行目标前、之后插入一些通用处理的效果）。 参考 腾讯云社区/深入理解 Java 反射：Field （成员变量） 《疯狂 Java 讲义》第四版，18 章 生命不息，折腾不止！关注 「Coder 魔法院」，祝你 Niubilitiy ！🐂🍺]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java 基础 —— 类加载]]></title>
    <url>%2F2020%2F08%2F07%2Fjava-basic-class-load%2F</url>
    <content type="text"><![CDATA[JVM 和类当使用 java 命令运行 Java 程序时，会启动一个 Java 虚拟机进程。同一个 JVM 的所有线程、所有变量都处于同一个进程里，他们都使用该 JVM 进程的内存区。当系统出现如下情况时，JVM 进程将被终止。 程序运行到最后正常结束 程序使用了 System.exit() 或 Runtime.getRuntime().exit() 程序遇到未捕获的异常或错误 程序所在平台强制结束了 JVM 进程 两个运行的 Java 程序处于两个不同的 JVM 进程中，两个 JVM 之间并不会共享数据。 类的加载当程序主动使用某个类时，如果该类还未被加载到内存中，则系统会通过加载、连接、初始化三个步骤来进行该类的初始化。这三个步骤统称为「类加载」或「类初始化」。 「类加载」指的是将类的 class 文件读入内存，并为之创建一个 java.lang.Class 对象。换言之，程序中使用任何类时，系统都会为之建立一个 java.lang.Class 对象。 系统中所有的类实际上也是实例，它们都是 java.lang.Class 的实例。 类的加载由类加载器完成，类加载器由 JVM 提供。除此之外，开发者可以通过集成 ClassLoader 基类来自定义类加载。**类加载器通常无须等到”首次使用“该类时才加载它，Java 虚拟机规范允许系统预先加载某些类。 类的连接类被加载后，系统会为之生成对应的 Class 对象，接着就会进入连接阶段。连接阶段负责把类的二进制数据合并到 JRE 中。类接连分为如下三个阶段： 验证：验证阶段用于检验被加载的类是否有正确的内部结构 准备：类准备阶段则负责为类的类变量分配内存，并设置默认初始值 解析：将类的二进制数据中的符号引用替换成直接引用 类的初始化类初始化阶段主要就是虚拟机堆类变量进行初始化。在 Java 类中堆类变量指定初始值有两种方法： 声明类变量时指定初始值 使用静态初始化块为类变量指定初始值 如果类变量没有指定初始值，则采用默认初始值 静态初始化块只会被执行一次（第一次加载该类时），静态初始化块先于构造器执行。类初始化块和类变量所指定的初始值都是该类的初始化代码，它们的执行顺序与源程序中的排列顺序相同。 JVM 初始化一个类包含如下几个步骤： 加入该类未被加载和连接，则程序先加载并连接该类 假如该类的直接父类还没有被初始化，则先初始化其直接父类 假如类中有初始化语句，则系统依次执行这些初始化语句 第 2 个步骤中，如果直接父类又有父类，会再次重复这三个步骤 实例初始化块负责对象执行初始化，而类初始化块是类相关的，系统在类初始化阶段执行，而不是在创建对象时才执行。因此，类初始化块总是比实例初始化块先执行。只有当类初始化完成之后，才可以在系统中使用这个类，包括访问类的类方法、类变量或者用这个类来创建实例。 栗子 Root.java: 1234567891011121314public class Root &#123; static &#123; int root = 1; System.out.println("Root 的类初始化块"); &#125; &#123; System.out.println("Root 的实例初始化块"); &#125; public Root() &#123; System.out.println("Root 的无参构造器"); &#125;&#125; Mid.java: 12345678910111213141516171819public class Mid extends Root &#123; static &#123; int mid = 2; System.out.println("Mid 的类初始化块"); &#125; &#123; System.out.println("Mid 的实例初始化块"); &#125; public Mid() &#123; System.out.println("Mid 的无参构造器"); &#125; public Mid(String msg) &#123; this(); System.out.println("Mid 的有参构造器，其参数值：" + msg); &#125;&#125; Leaf.java: 123456789101112131415public class Leaf extends Mid &#123; static &#123; int leaf = 3; System.out.println("Leaf 的类初始化块"); &#125; &#123; System.out.println("Leaf 的实例初始化块"); &#125; public Leaf() &#123; super("初始化测试"); System.out.println("执行Leaf的构造器"); &#125;&#125; Test.java: 123456public class Test &#123; public static void main(String[] args) &#123; new Leaf(); new Leaf(); &#125;&#125; 运行结果会是怎样的呢？停下来想一想。 输出结果：123456789101112131415Root 的类初始化块Mid 的类初始化块Leaf 的类初始化块Root 的实例初始化块Root 的无参构造器Mid 的实例初始化块Mid 的有参构造器，其参数值：初始化测试Leaf 的实例初始化块执行Leaf的构造器Root 的实例初始化块Root 的无参构造器Mid 的实例初始化块Mid 的有参构造器，其参数值：初始化测试Leaf 的实例初始化块执行Leaf的构造器 说明： 优先进行类初始化块（类静态块）的初始化，如果有父类，那么就先进行父类的的类初始化块运行； 类初始化块执行完成之后，会进行实例初始化块和构造器，如果有父类，则也需要先进行父类的实例初始化块、构造器执行； 实例初始化块就是指没有 static 修饰的初始化块。当创建该类的 Java 对象时，系统总是先调用该类定义的实例初始化块（当然，类初始化要已经先完成）。实例初始化是在创建 Java 对象时隐式执行的，而且，在构造器执行之前自动执行。 实例初始化栗子 123456789101112public class InstanceTest &#123; &#123; a = 1; &#125; int a = 2; public static void main(String[] args) &#123; // 输出 2 System.out.println(new InstanceTest().a); &#125;&#125; 如果上面例子，将实例初始化块和实例变量声明顺序调换，输出就会变为 1。 创建 Java 对象时，系统先为该对象的所有实例变量分配内存（前提是该类已被加载过），接着程序对这些实例变量进行初始化：先执行实例初始化块或声明实例变量时指定的初始值（按照它们在源码中的先后顺序赋值），然后再执行构造器里指定的初始值。 实际上实例初始化块是一个假象，使用 javac 命令编译 Java 类后，该 Java 类中的实例初始化块会消失—实例初始化块中代码会被“还原”到每个构造器中，且位于构造器所有代码的前面。 类初始化的时机Java 程序首次通过下面 6 种方式使用某个类或接口时，系统就会初始化该类或接口： 创建类的实例。包括使用 new 操作符来创建实例、通过反射创建实例、通过反序列化创建实例 调用某个类的类方法（静态方法） 调用某个类的类变量，或为该类变量赋值 使用反射方式来强制创建某个类或接口对应的 java.lang.Class 对象。例如 Class.forName(&quot;Person&quot;) 初始化某个类的子类。（就是前面介绍过的，该子类的所有父类都会被初始化） 直接使用 java.exe 命令运行某个主类 对于 final 型的类变量，如果该类变量的值在编译时就确定了，那么，这个类变量相当于「宏变量」。Java 编译器会在编译时直接将该类变量出现的地方替换为它实际的值。因此，程序使用这种静态变量不会导致该类的初始化。 栗子：12345678910111213class MyTest &#123; static &#123; System.out.println("静态初始化块"); &#125; static final String compileConstant = "类初始化 demo";&#125;public class ComileConstantTest &#123; public static void main(String[] args) &#123; System.out.println(MyTest.compileConstant); &#125;&#125; 输出：1类初始化 demo 由此可见，的确没有初始化 MyTest 类。 当类变量使用了 final 修饰，并且，它的值在编译时就能确定，那么它的值在编译时就确定了，程序中使用它的地方相当于使用了常量。 如果上面栗子中代码改为如下：1static final String compileConstant = System.currentTimeMillis() + ""; 这时候输出就是：12静态初始化块1596804413248 因为上面 compileConstant 修改之后，它的值必须在运行时才能确定，因此，触发了 MyTestg 类的初始化。 此外，ClassLoader 类的 loadClass() 方法来加载某个类时，该方法只是加载类，并不会执行类的初始化。使用 Class.forName() 静态方法再回强制初始化类。 栗子： 1234567891011121314151617181920212223package class_load;/** * description: * * @author Michael * @date 2020/8/7 * @time 8:54 下午 */class Tester &#123; static &#123; System.out.println("Tester 类的静态初始化块"); &#125;&#125;public class ClassLoadTest &#123; public static void main(String[] args) throws ClassNotFoundException &#123; ClassLoader cl = ClassLoader.getSystemClassLoader(); cl.loadClass("class_load.Tester"); System.out.println("系统加载 Tester 类"); Class.forName("class_load.Tester"); &#125;&#125; 输出：12系统加载 Tester 类Tester 类的静态初始化块 经测试可以发现，loadClass 方法确实没有触发类的初始化，而 Class.forName 则会初始化 Tester 类。 类加载器类加载器负责将 .class 文件（可能在磁盘上，也可能在网络上）加载到内存中，并为之生成 java.lang.Class 对象。 类加载机制类加载器负责加载所有的类，系统为所有被载入内存中的类生成一个 java.lang.Class 对象/实例。一旦一个类被载入 JVM 中，同一个类就不会再次被载入。正是因为有这样的缓存机制存在，所以 Class 修改之后，必须重启 JVM 修改才会生效。 类加载器加载 Class 大致经过如下步骤： 开发者也可以通过继承 ClassLoader 来自定义类加载器。因为暂时未涉及这块，本文暂且略过。 总结本文重点是了解了类初始化的流程，同时，也结合栗子比较了与实例初始化的区别。类初始化块、实例初始化块、构造器的执行顺序也是面试题常考的内容。最后补充了类加载机制的内容，暂时仅是了解。 绘图采用的 ProcessOn 在线绘制，安利~ 生命不息，折腾不止！关注 「Coder 魔法院」，祝你 Niubilitiy ！🐂🍺 参考 《疯狂 Java 讲义》第四版，18 章]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>类</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ubuntu 开发环境备忘]]></title>
    <url>%2F2020%2F08%2F01%2Ftools-linux-ubuntu%2F</url>
    <content type="text"><![CDATA[常用开发环境安装123456# npmsudo apt install npm# gitbooksudo npm install gitbook-cli -g# jdksudo apt install openjdk-8-jdk]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>ENV</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[中国婴幼儿身高体重参照表]]></title>
    <url>%2F2020%2F07%2F31%2Fbaby-weight-height%2F</url>
    <content type="text"><![CDATA[今天在一位技术博主的网站看到了他整理的这个表格，我也存过来备用一下吧。 男孩体重标准表 月龄 -3SD（轻） -2SD（偏轻） -1SD（正常） 中位数（正常） +1SD（正常） +2SD（偏重） +3SD（重） 0 2.26 2.58 2.93 3.32 3.73 4.18 4.66 1 3.09 3.52 3.99 4.51 5.07 5.67 6.33 2 3.94 4.47 5.05 5.68 6.38 7.14 7.97 3 4.69 5.29 5.97 6.7 7.51 8.4 9.37 4 5.25 5.91 6.64 7.45 8.34 9.32 10.39 5 5.66 6.36 7.14 8 8.95 9.99 11.15 6 5.97 6.7 7.51 8.41 9.41 10.5 11.72 7 6.24 6.99 7.83 8.76 9.79 10.93 12.2 8 6.46 7.23 8.09 9.05 10.11 11.29 12.6 9 6.67 7.46 8.35 9.33 10.42 11.64 12.99 10 6.86 7.67 8.53 9.53 10.71 11.95 13.34 11 7.04 7.87 8.8 9.83 10.98 12.26 13.68 12 7.21 8.06 9 10.05 11.23 12.54 14 15 7.63 8.57 9.57 10.68 11.93 13.32 14.88 18 8.13 9.07 10.12 11.29 12.61 14.09 15.75 21 8.61 9.59 10.69 11.93 13.33 14.9 16.66 24 9.06 10.09 11.24 12.54 14.01 15.67 17.54 27 9.47 10.54 11.75 13.11 14.64 16.38 18.36 30 9.86 10.97 12.22 13.64 15.24 17.06 19.13 33 10.24 11.39 12.68 14.15 15.32 17.72 19.39 36 10.61 11.79 13.13 14.65 16.39 18.37 20.64 39 10.97 12.19 13.57 15.15 16.95 19.02 21.39 42 11.31 12.57 14 15.63 17.5 19.65 22.13 45 11.66 12.96 14.44 16.13 18.07 20.32 22.91 48 12.01 13.35 14.88 16.64 18.67 21.01 23.73 51 12.37 13.76 15.35 17.18 19.3 21.76 24.63 54 12.74 14.18 15.84 17.75 19.98 22.57 25.61 57 13.12 14.61 16.34 13.35 20.69 23.43 26.68 60 13.5 15.06 16.87 18.98 21.46 24.38 27.85 63 13.36 15.48 17.33 19.6 22.21 25.32 29.04 66 14.18 15.87 17.85 20.13 22.94 26.24 30.22 69 14.43 16.24 18.31 20.75 23.66 27.17 31.43 72 14.74 16.56 18.71 21.26 24.32 28.03 32.57 75 15.01 16.9 19.14 21.32 25.06 29.01 33.39 78 15.3 17.27 19.62 22.45 25.89 30.13 35.41 81 15.66 17.73 20.22 23.24 26.95 31.56 37.39 男孩身高标准表 月龄 -3SD（矮） -2SD（偏矮） -1SD（正常） 中位数（正常） +1SD（正常） +2SD（偏高） +3SD（高） 0 45.2 46.9 48.6 50.4 52.2 54 55.3 1 43.7 50.7 52.7 54.8 56.9 59 61.2 2 52.2 54.3 56.5 58.7 61 63.3 65.7 3 55.3 57.5 59.7 62 64.3 66.6 69 4 57.9 60.1 62.3 64.6 66.9 69.3 71.7 5 59.9 62.1 64.4 66.7 69.1 71.5 73.9 6 61.4 63.7 66 68.4 70.8 73.3 75.8 7 62.7 65 67.4 69.3 72.3 74.8 77.4 8 63.9 66.3 68.7 71.2 73.7 76.3 78.9 9 65.2 67.6 70.1 72.6 75.2 77.8 80.5 10 66.4 68.9 71.4 74 76.6 79.3 82.1 11 67.5 70.1 72.7 75.3 78 80.8 83.6 12 68.6 71.2 73.8 76.5 79.3 82.1 85 15 71.2 74 76.9 79.8 82.3 85.8 83.9 18 73.6 76.6 79.6 82.7 85.8 89.1 92.4 21 76 79.1 82.3 85.6 89 92.4 95.9 24 78.3 81.6 85.1 83.5 92.1 95.3 99.5 27 30.5 83.9 87.5 91.1 94.3 93.6 102.5 30 82.4 85.9 39.6 93.3 97.1 101 105 33 84.4 83 91.6 95.4 99.3 103.2 107.2 36 86.3 90 93.7 97.5 101.4 105.3 109.4 39 37.5 91.2 94.9 98.8 102.7 106.7 110.7 42 89.3 93 96.7 100.6 104.5 108.6 112.7 45 90.9 94.6 93.5 102.4 106.4 110.4 114.6 48 92.5 96.3 100.2 104.1 108.2 112.3 116.5 51 94 97.9 101.9 105.9 110 114.2 113.5 54 95.6 99.5 103.6 107.7 111.9 116.2 120.6 57 97.1 101.1 105.3 109.5 113.8 113.2 122.6 60 98.7 102.8 107 111.3 115.7 120.1 124.7 63 100.2 104.4 108.7 113 117.5 122 126.7 66 101.6 105.9 110.2 114.7 119.2 123.8 128.6 69 103 107.3 111.7 116.3 120.9 125.6 130.4 72 104.1 103.6 113.1 117.7 122.4 127.2 132.1 75 105.3 109.3 114.4 119.2 124 128.8 133.3 78 106.5 111.1 115.8 120.7 125.6 130.5 135.6 81 107.9 112.6 117.4 122.3 127.3 132.4 137.6 女孩体重标准表 月龄 -3SD（轻） -2SD（偏轻） -1SD（正常） 中位数（正常） +1SD（正常） +2SD（偏重） +3SD（重） 0 2.26 2.54 2.85 3.21 3.63 4.1 4.65 1 2.98 3.33 3.74 4.2 4.74 5.35 6.05 2 3.72 4.15 4.65 5.21 5.86 6.6 7.46 3 4.4 4.9 5.47 6.13 6.87 7.73 8.71 4 4.93 5.48 6.11 6.83 7.65 8.59 9.66 5 5.33 5.92 6.59 7.36 8.23 9.23 10.38 6 5.64 6.26 6.96 7.77 8.68 9.73 10.93 7 5.9 6.55 7.28 8.11 9.06 10.15 11.4 8 6.13 6.79 7.55 8.41 9.39 10.51 11.8 9 6.34 7.03 7.81 8.69 9.7 10.86 12.18 10 6.53 7.23 8.03 8.94 9.98 11.16 12.52 11 6.71 7.43 8.25 9.18 10.24 11.46 12.85 12 6.87 7.61 8.45 9.4 10.48 11.73 13.15 15 7.34 8.12 9.01 10.02 11.18 12.5 14.02 18 7.79 8.63 9.57 10.65 11.88 13.29 14.9 21 8.26 9.15 10.15 11.3 12.61 14.12 15.85 24 8.7 9.64 10.7 11.92 13.31 14.92 16.77 27 9.1 10.09 11.21 12.5 13.97 15.67 17.63 30 9.48 10.52 11.7 13.05 14.6 16.39 18.47 33 9.86 10.94 12.18 13.59 15.22 17.11 19.29 36 10.23 11.36 12.65 14.13 15.83 17.81 20.1 39 10.6 11.77 13.11 14.65 16.43 18.5 20.9 42 10.95 12.16 13.55 15.16 17.01 19.17 21.69 45 11.29 12.55 14 15.67 17.6 19.85 22.49 48 11.62 12.93 14.44 16.17 18.19 20.54 23.3 51 11.96 13.32 14.88 16.69 18.79 21.25 24.14 54 12.3 13.71 15.33 17.22 19.42 22 25.04 57 12.62 14.08 15.78 17.75 20.05 22.75 25.96 60 12.93 14.44 16.2 18.26 20.66 23.5 26.87 63 13.23 14.8 16.64 18.78 21.3 24.28 27.84 66 13.54 15.18 17.09 19.33 21.98 25.12 28.89 69 13.84 15.54 17.53 19.88 22.65 25.96 29.95 72 14.11 15.87 17.94 20.37 23.27 26.74 30.94 75 14.38 16.21 18.35 20.89 23.92 27.57 32 78 14.66 16.55 18.78 21.44 24.61 28.46 33.14 81 14.96 16.92 19.25 22.03 25.37 29.42 34.4 女孩身高标准表 月龄 -3SD（矮） -2SD（偏矮） -1SD（正常） 中位数（正常） +1SD（正常） +2SD（偏高） +3SD（高） 0 44.7 46.4 48 49.7 51.4 53.2 55 1 47.9 49.8 51.7 53.7 55.7 57.8 59.9 2 51.1 53.2 55.3 57.4 59.6 61.8 64.1 3 54.2 56.3 58.4 60.6 62.8 65.1 67.5 4 56.7 58.8 61 63.1 65.4 67.7 70 5 58.6 60.8 62.9 65.2 67.4 69.8 72.1 6 60.1 62.3 64.5 66.8 69.1 71.5 74 7 61.3 63.6 65.9 68.2 70.6 73.1 75.6 8 62.5 64.8 67.2 69.6 72.1 74.7 77.3 9 63.7 66.1 68.5 71 73.6 76.2 78.9 10 64.9 67.3 69.8 72.4 75 77.7 80.5 11 66.1 68.6 71.1 73.7 76.4 79.2 82 12 67.2 69.7 72.3 75 77.7 80.5 83.4 15 70.2 72.9 75.6 78.5 81.4 84.3 87.4 18 72.8 75.6 78.5 81.5 84.6 87.7 91 21 75.1 78.1 81.2 84.4 87.7 91.1 94.5 24 77.3 80.5 83.8 87.2 90.7 94.3 98 27 79.3 82.7 86.2 89.8 93.5 97.3 101.2 30 81.4 84.8 88.4 92.1 95.9 99.8 103.8 33 83.4 86.9 90.5 94.3 98.1 102 106.1 36 85.4 88.9 92.5 96.3 100.1 104.1 108.1 39 86.6 90.1 93.8 97.5 101.4 105.4 109.4 42 88.4 91.9 95.6 99.4 103.3 107.2 111.3 45 90.1 93.7 97.4 101.2 105.1 109.2 113.3 48 91.7 95.4 99.2 103.1 107 111.1 115.3 51 93.2 97 100.9 104.9 109 113.1 117.4 54 94.8 98.7 102.7 106.7 110.9 115.2 119.5 57 96.4 100.3 104.4 108.5 112.8 117.1 121.6 60 97.8 101.8 106 110.2 114.5 118.9 123.4 63 99.3 103.4 107.6 111.9 116.2 120.7 125.3 66 100.7 104.9 109.2 113.5 118 122.6 127.2 69 102 106.3 110.7 115.2 119.7 124.4 129.1 72 103.2 107.6 112 116.6 121.2 126 130.8 75 104.4 108.8 113.4 118 122.7 127.6 132.5 78 105.5 110.1 114.7 119.4 124.3 129.2 134.2 81 106.7 111.4 116.1 121 125.9 130.9 136.1 参考 中国婴幼儿身高体重参照表]]></content>
      <categories>
        <category>孩子</category>
      </categories>
      <tags>
        <tag>资源</tag>
        <tag>Blog</tag>
        <tag>博客</tag>
        <tag>List</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java 泛型知识笔记]]></title>
    <url>%2F2020%2F07%2F13%2Fjava-basic-generic%2F</url>
    <content type="text"><![CDATA[泛型概念泛型（ Generic）是一种编译器机制，您可通过该机制获取通用的代码并参数化（或模板化）剩余部分，从而以一种一般化方式创建（和使用）一些类型的实体（比如类或接口和方法）。这种编程方法被称为泛型编程。 所谓泛型，就是允许在定义类、接口、方法时使用类型形参，这个类型形参(或叫泛型)将在声明变量、创建对象、调用方法时动态地指定(即传入实际的类型参数，也可以称为「类型实参」)。 JDK 5.0（2004 年发布）向 Java 语言中引入了泛型类型（泛型）和关联的语法。增加泛型支持，很大程度上都是为了让集合能记住其元素的数据类型。在没有泛型之前，一旦把一个对象「丢进」 Java 集合中，集合就会忘记对象的类型，把所有的对象当成 Object 类型处理。当程序从集合中取出对象后，就需要进行强制类型的转换。这种强制类型转换不仅使代码臃肿，还很容器引起 ClassCastException 错误。 示例先通过一个简单的示例了解一下泛型是什么样的。 123456789List strList = new ArrayList();strList.add("Name");strList.add("Aget");// 不小心存入一个 Integer 对象strList.add(new Integer(1));//ArrayList可以存放任意类型，所以，下一行执行，并不会报错System.out.println(strList);//这一行强转就出错了String str = (String)strList.get(2); 输出： 12345[Name, Aget, 1]Exception in thread "main" java.lang.ClassCastException: java.lang.Integer cannot be cast to java.lang.String at main.main(main.java:14)Process finished with exit code 1 可以看到，我们 在给 List 中元素包含了两种类型：String 和 Interger 类型。 在 JDK 5.0 之前，Java 语言对此行为没有任何约束，这导致了许多编码错误。因为不知道 List 中包含的内容，则必须检查想要访问的元素，查看是否能处理这种类型的元素，否则可能会遇到 ClassCastException。 借助泛型，可以事先指定 List 中的元素类型，这样编译器在编译阶段就能够发现上面的问题： 1234567List&lt;String&gt; strList = new ArrayList();strList.add("Name");strList.add("Aget");// 下面这一行编辑器就会提示错误，编译就不会通过strList.add(new Integer(1));System.out.println(strList);String str = (String)strList.get(2); 从 Java 5 之后，Java 引入了「参数化类型」(parameterized type)的概念。允许程序在创建集合时指定集合元素的类型。Java 的参数化类型被称为「泛型」(Generic)。 上面的 List&lt;String&gt;，可以称 List 是带一个类型参数的泛型接口，类型参数（类型实参）是 Sting。集合记住了所有元素的数据类型，从而无须对集合元素进行数据类型转换。 在 Java 7 之前，如果使用带有泛型的接口、类定义变量，那么调用构造器创建对象时，构造器的构面也要带上泛型： 1List&lt;String&gt; strList = new ArrayList&lt;String&gt;(); 从 Java7 开始， Java 允许在构造器后不需要带完整的泛型信息，只需要给出尖括号即可，Java 可以自动推断出尖括号里的是什么泛型信息： 1List&lt;String&gt; strList = new ArrayList&lt;&gt;(); 常见的 T，E，K，V，？本质上这些个都是通配符，没啥区别，只不过是编码时的一种约定俗成的东西。比如上述代码中的 T ，我们可以换成 A-Z 之间的任何一个 字母都可以，并不会影响程序的正常运行，但是如果换成其他的字母代替 T ，在可读性上可能会弱一些。通常情况下，T，E，K，V，？ 是这样约定的： ？ 表示不确定的 java 类型 T (type) 表示具体的一个java类型 K V (key value) 分别代表java键值中的Key Value E (element) 代表Element 泛型的应用泛型有三种使用方式： 泛型类 泛型接口 泛型方法 泛型类泛型类型用于类的定义中，这个类称为「泛型类」。最典型的泛型类就是各种容器类，例如：List、Set、Map。 泛型类的定义语法： 1234class 类名称&lt;泛型标识&gt;&#123; private 泛型标识 成员变量； ……&#125; 泛型标识：可以随便写任意标识号，标识指定的泛型的类型，比如常用的 T 举个栗子： 1234567891011121314151617181920212223242526// 泛型类class Card&lt;T&gt; &#123; private T id; public T getId() &#123; return id; &#125; public void setId(T id) &#123; this.id = id; &#125; public Card(T id)&#123; setId(id); &#125;&#125;// main 函数Card&lt;String&gt; card1 = new Card&lt;&gt;("One");System.out.println("card1 id is: "+card1.getId());Card&lt;Integer&gt; card2 = new Card&lt;&gt;(2);System.out.println("card2 id is: "+card2.getId());// 输出card1 id is: Onecard2 id is: 2 怎么样，看到区别了吗？同样一个类创建的两个实例，成员变量名都是 id，但是二者的类型却可以不同。T 感觉有种 template 的意思，模板嘛，占坑渲染即可。 定义的泛型类实例化对象时并不一定要春如泛型类型实参。比如一开始的例子 ArrayList，当不传入泛型类型实参时，默认的就是 Object 类型。这时候，就不会起到限制类型的作用了。 注意点： 泛型的类型参数只能是「类类型」，不能是原始类型（Primitive Type）——byte/short/ int/long/float/ double/ boolean/char 定义泛型类中的构造器时，构造器名还是原来的类型，不需要增加泛型声明。 不能对确切的泛型类型使用 instanceof操作，比如 card1 instanceof Card&lt;String&gt;，会报 instanceof 的泛型类型不合法 错误，但是 card1 instance Card 是不会报错的，并返回 true。因为不管泛型的实际类型参数是什么，他们在运行时总有同样的类，对于 Java 来说，它们依然被当成同一个类处理，在内存中也只占用一块内存空间。 List&lt;Integer&gt; 并不是 List&lt;Number&gt; 的子类！List&lt;Integer&gt; 并不是 List&lt;Number&gt; 的子类！List&lt;Integer&gt; 并不是 List&lt;Number&gt; 的子类！ 泛型接口泛型接口和泛型类的定义语法差不多。泛型接口经常被用在各种类的生成器中。 1234//定义泛型接口public interface Generaotr&lt;T&gt; &#123; public T next();&#125; 泛型接口实现类，未传入泛型实参时： 1234567public class FruitGenerator&lt;T&gt; implements Generaotr&lt;T&gt; &#123; // 这个 Override 可不能少 @Override public T next()&#123; return null; &#125;&#125; 接口实现类定义时，也需要将泛型的声明加上。如果不加，例如public class FruitGenerator implements Generaotr&lt;T&gt;，这样就会报错，cannot resolve symbol T。 泛型接口实现类，传入泛型实参，比如 String： 123456789public class FruitGenerator implements Generaotr&lt;String&gt; &#123; private String[] fruits = new String[]&#123;"Apple", "Banana", "Pear"&#125;; @Override public String next()&#123; Random rand = new Random(); return fruits[rand.nextInt(3)]; &#125;&#125; 这里我们传入了泛型实参，接口实现类中的泛型都改为了这个传入的实参。并且，此时，接口实行类就不用加上泛型声明了，加入的话，反而会提示 attempting to use incompatible return type错误。 泛型通配符Integer 是 Number 的一个子类。那么，在使用 Card&lt;Numer&gt; 作为方法形参的方法中，是否可以传入 Card&lt;Interger&gt; 的实参呢？ 123456789private static void showKeyValue1(Card&lt;Number&gt; card)&#123; System.out.println(card.getId());&#125;// 测试Card&lt;Integer&gt; card2 = new Card&lt;&gt;(2);System.out.println("card2 id is: " + card2.getId());showKeyValue1(card2); 编译器会报错 ： 1Generic&lt;java.lang.Integer&gt; cannot be applied to Card&lt;java.lang.Number&gt; 通过提示信息我们可以看到 Card&lt;Integer&gt; 不能被看作为 Card&lt;Number&gt; 的子类。 如果 Apple 是 Fruit 的一个子类型（子类或者子接口），G 是一个具有泛型声明的类或接口，G&lt;Apple&gt; 并不是 G&lt;Fruit&gt; 的子类型！这一点值得注意，因为与大部分人第一感觉是不同的。 如何解决上面的问题呢？ 我们需要在逻辑上引入一个同时是 Card&lt;Number&gt; 和 Card&lt;Interger 父类的引用类型。由此，「类型通配符」产生了： 1234// 其实，这里不用通配符，直接是 Card 也会 OKprivate static void showKeyValue1(Card&lt;?&gt; card)&#123; System.out.println(card.getId());&#125; 类型通配符一般是使用 ? 代替具体的类型实参。注意，? 是类型实参，不是类型形参。简单理解，这里的 ? 就和 Number、String 一样，都是一种实际的类型。可以把 ? 看成所有类型的父亲，是一种真实的类型，当成 Object 来处理。 通配符上界为了表示限制类型，泛型提供了被限制的通配符。通配符上界使用 &lt;? extends T&gt; 的格式，意思是需要一个 T 类型或者 T 类型的子类，一般T 类型都是一个具体的类型。示例如下： 12345public void printIntValue(List&lt;? extends Number&gt; list) &#123; for (Number number : list) &#123; System.out.print(number.intValue()+" "); &#125;&#125; 此处，未知类型一定是 Number 的子类型，因此，可以把 Number 称为这个通配符的上界(upper bnound)。 写入操作过以上给定的赋值语句，你能把一个什么类型的元素合法地插入到 list 中呢？ 你不能插入一个 Integer 元素，因为 list 可能指向 List&lt;Double&gt;。 你不能插入一个 Double 元素，因为 list 可能指向 List&lt;Integer&gt;。 你不能插入一个 Number 元素，因为 list 可能指向 List&lt;Integer&gt;。 你不能往 List&lt;? extends T&gt; 中插入任何类型的对象，因为你不能保证列表实际指向的类型是什么，你并不能保证列表中实际存储什么类型的对象。唯一可以保证的是，你可以从中读取到 T 或者 T 的子类。 通配符下界除了可以指定通配符的上限之外，Java 还允许指定通配符的下限。通配符下界使用 &lt;? super T&gt; 的格式，意思是需要一个T类型或者 T 类型的父类，一般 T 类型都是一个具体的类型。示例如下： 12345public void fillNumberList(List&lt;? super Number&gt; list) &#123; // Number 及它子类的实例就可以加入 list 中 list.add(new Integer(0)); list.add(new Float(1.0));&#125; 其实，Java 泛型不仅允许在使用通配符形参时设定上限，还可以在定义泛型形参时设定上限，用以表示传给泛型形参的实际参数类型要么是该上限类型，要么是该上限类型的子类。 12345678910public class Apple&lt;T extends Number&gt; &#123; T col; public static void main(String[] args) &#123; Apple&lt;Integer&gt; ai = new Apple&lt;&gt;(); Apple&lt;Double&gt; ad = new Apple&lt;&gt;(); // 下面编译就会出错，因为设置了上限是 Number Apple&lt;String&gt; as = new Apple&lt;&gt;(); &#125;&#125; 总结 PECS 上面的知识点可以概括为 PECS 原则，方便记忆。Producer 生产者，则用 extends。因为你想从列表中获取 T 类型的的元素。看着就像是「生产」元素的效果。不能明确存入元素的类型，因此它的主要总用不在「存」。Conumer 消费者，则用 super。想把 T 类型的子元素放入到列表中。不能保证明确读取到的元素的类型，因此它的主要作用不在于「读」。 详细理解这里的 PECS 原则，还可以阅读： 知乎/Java 泛型 &lt;? super T&gt; 中 super 怎么 理解？与 extends 有何不同？。 并发编程网/泛型中? super T和? extends T的区别 原文 URL 泛型方法在一些情况下，定义类、接口时没有使用泛型形参，但定义方法时想自己定义泛型形参，这也是可以的。Java 5 提供了对泛型方法的支持。 判断一个方法是否是泛型方法关键看方法返回值前面有没有使用 &lt;&gt; 标记的类型，有就是，没有就不是。 假设需要实现这样一个方法：将一个 Object 数组所有的元素添加到一个 Collection 集合中。 12345static void fromArrayToCollection(Object[] a, Collection&lt;Object&gt; c) &#123; for (Object o : a) &#123; c.add(o); &#125;&#125; 下面这么写将会引起编译错误： 12345String[] strArr = &#123;"a","b"&#125;;List&lt;String&gt; strList = new ArrayList&lt;&gt;();// Collection&lt;String&gt;对象不能当成 Collection&lt;Oject&gt;使用fromArrayToCollection(strArr, strList);System.out.println(strList); Collection&lt;String&gt; 并不是 Collection&lt;Object&gt; 的子类型，所以上面这个方法只能将 Object[] 数组中的元素复制到元素为 Object 的 Collection 集合中。 Collection&lt;Object&gt; c 改为通配符 Collection&lt;?&gt; c 是否可行呢？也不行。 为了解决上面这个问题，可以使用泛型方法(Generic Method)。所谓泛型方法，就是在声明方法时，定义一个或多个泛型形参。多个泛型形参声明放在方法修饰符和方法返回值类型之间。泛型方法语法格式如下： 123修饰符 &lt;T,S,...&gt; 返回值类型 方法名(形参列表)&#123; // 方法体&#125; 上面的方法改进如下： 12345static &lt;T&gt; void fromArrayToCollection(T[] a, Collection&lt;T&gt; c) &#123; for (T o : a) &#123; c.add(o); &#125;&#125; 与泛型类和泛型接口的使用不同，泛型方法中的泛型形参不需要显示传入实际参数类型。编译器会根据实参推断泛型所代表的类型。但是小心，避免制造迷惑。比如下面的栗子： 12345678910111213141516public class Main &#123; public static void main(String[] args) &#123; List&lt;String&gt; as = new ArrayList&lt;&gt;(); List&lt;Object&gt; ao = new ArrayList&lt;&gt;(); // 下面会编译错误 test(as, ao); &#125; static &lt;T&gt; void test(Collection&lt;T&gt; from, Collection&lt;T&gt; to) &#123; for (T ele : from) &#123; to.add(ele); &#125; &#125;&#125; test 方法传入两个实参，ao 的数据类型是 List&lt;Object&gt;，而 as 的数据类型是 List&lt;String&gt;。与泛型方法签名进行对比，test(Collection&lt;T&gt; from, Collection&lt;T&gt; to)，编译器无法正确识别 T 所代表的实际类型。为了避免这种错误，可以改为如下形式： 12345static &lt;T&gt; void test(Collection&lt;? extends T&gt; from, Collection&lt;T&gt; to) &#123; for (T ele : from) &#123; to.add(ele); &#125;&#125; Collection&lt;? extends T&gt; 这种采用类型通配符并设置通配符上限的表示方式，只要 test 方法的第一个 Collection 集合里的元素类型是后一个 Collection 集合里元素类型的子类即可。 补充对于类中变量的类型，绘制了一个简单的图： 作图工具：ProcessOn，强烈安利 总结经过上面的学习，我对泛型(Generic)有了初步的认识。类似于一个「模板」的概念，「占坑」等着渲染，提供了对类、接口、方法定义的灵活性，使用起来具有了「动态性」。当然，这只是我的个人理解，方便记忆的，可能表述并不是很准确。在实际的生产代码中，也有应用泛型类、泛型方法的，能够想到去使用它，无疑需要对泛型有比较好的理解。 参考 Oracle-Generics Documentation CSDN-java 泛型详解-绝对是对泛型方法讲解最详细的，没有之一 CSDN-ShuSheng007-秒懂Java泛型 掘金-深入理解Java泛型 重新认识Java——泛型（基础、使用和实现原理） glmapper—聊一聊-JAVA 泛型中的通配符 T，E，K，V，？]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>基础</tag>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2020 疫情年一次说走就走的端午重庆游]]></title>
    <url>%2F2020%2F07%2F05%2Flife-travel-chongqing%2F</url>
    <content type="text"><![CDATA[前言前阵子趁着端午放假，媳妇儿张罗了一次去重庆的三天游的计划！确实属于一次说走就走的旅行了，因为我们提前 5 天才买好了机票、订好了住宿……虽然订票仓促，但是媳妇儿还是做了很详细的攻略！👏 年轻人嘛，就是得「浪」~ 1189年，宋光宗赵惇先封恭王再即帝位，自诩“双重喜庆”，重庆由此得名（摘自百度百科）。因古代流经重庆的嘉陵江称为渝水，故重庆古名为渝州。重庆还有很多简称，巴或渝，既以江城、雾都著称，又以山城扬名。 Day 1期盼了几天之后，终于等到了端午假！第一天一大早，我们便从杭州出发前往重庆啦。那一天杭州大暴雨，但是重庆确实大晴天。前面的小哥拿着他的 ipad 还在抓紧时间看下载的 IT 教程视频呢，不得不感慨这位程序员小哥有点拼！ 不过这不太符合我的理念，玩的时候就放开尽情的玩吧！ 在前往重庆之前，机智的媳妇儿就让我们提前在 Huawei Pay 中申请好了重庆的交通卡，因此，全程我俩都省去了排队买车票的麻烦，so 方便~ 到了重庆，第一顿是在一家叫「月半（解放碑总店）」的川菜馆吃的，可谓是实惠又美味！下面这顿 98 元就搞定了！老板还热情的赠送了我们粽子和红枣，临走又送了 2 盒红枣，重庆人的火辣热情立马就赢得了我俩的好感！ 坐轻轨前往了网红打卡地「李子坝」，其实就是因为轻轨穿过居民楼而显得有些新奇。楼上的居民是否住的开心呢？个人感觉有条件的话，应该不会选择这样的居住环境吧，毕竟过于「热闹」了些~ 在「鹅岭公园」的最高处「瞰胜楼」，可以看到一个不错的重庆城的全貌。可惜的是，这个「瞰胜楼」造的相对比较简陋，不过可以理解，毕竟是个免费的公园观景楼。 「鹅岭公园」和「二厂文创园」离得比较近，紧接着我们就前往了这个网红地。确实是个网红地，很多小年轻在那里拍照，不过个人认为是个 IDEA 大于美景的去处，老楼弄点涂鸦、开了一些创意文化礼品店。 累了一天，晚上在「八一美食街」上吃了传说中的「玫瑰冰粉」，真是巴适啊…… 晚上我俩沿着「千厮门大桥」走到了江对面远观了一下「洪崖洞」。很可惜的是，当我们走回对面时，因为过了 22:30 了，洪崖洞的灯关了……不过订的住宿就在洪崖洞的上方，因此，第二天晚上弥补了这个小遗憾。 作为名副其实的吃货，我俩又打包了两份好吃的带回去当夜宵了。🤣 Day 2酒店提供的自助早餐真是丰富，重庆小面都有，真是赞！ 一位拎着年代感十足的箱子的老人。 本打算去四川美院逛逛的，可惜受疫情影响，学校没有开发。在涂鸦一条街随便走了走，便打算离开了。重庆的出租车是黄色的，有点与众不同，很亮眼有活力啊。 在等公交车的时候，也观察到一些老人在打扑克，懂得享受生活也是一种幸福！ 「磁器口」就是一个商业古镇，街边都是做生意的小商贩，挺热闹的。 下午的太阳很强烈，偶然发现了一个茶楼「转运楼」，于是我们买票进去歇息了会儿。真是有惊喜的一个选择，在里面避暑的同时，还看到了很多表演！ 人生有时候也一样，不经意的选择，并未充分考虑好，或许反而会带来一些意料之外的收获。 来了重庆，怎能不坐一次「长江索道」呢？本应被长江大桥替代的旧交通工具，如今演变成了旅游景点的项目。果然，「物以稀为贵」。 在「南山一棵树观景台」可以俯视整个山城，夜景确实相当赞！ 城市和城市之间的差异其实正越来越小，繁华的夜景和上海滩、钱塘江夜景好像也差不多……这算不算「城市同质化」？ Day 3第三天重庆大暴雨，约了本科同宿舍的兄弟见见，属于「怀旧」的一天。 四年的舍友，当初我们都还是懵懂少年，如今他有了自己的小家，也成为了一位父亲。恭喜 &amp; 祝福，期待杭州再聚！ 重庆的火锅魅力就是大，平日对牛肉不感冒的媳妇儿也吃了挺多，吃撑的节奏~😋 一言「一方水土养育一方人」，重庆一游，感受到了不同的风土人情。不像江浙沪这边的含蓄、小家碧玉，重庆人的豪爽、热情给我们留下了深刻的印象。我觉得这股子乐观的精神要多多学习，人生短短几十载，在我们能够快活的岁月里，应该珍惜时光！希望余生可以和媳妇儿一起探索更多的风景~ 旅行的意义是什么？回来后和小辉聊到了这个话题。他的一些观点还是给了我一些启发的。比如我们经常看到一些贫困区的新闻，但是，当我们亲眼见证了这些生活时，这种带来的震撼不是书本和新闻能够给与的。 「体验」生活，增加生命的「厚度」。辛勤工作的同时，别忘记了工作赚钱的目的是为了更好的生活！「旅行」对于你的意义是什么呢？欢迎交流~]]></content>
      <categories>
        <category>Life</category>
      </categories>
      <tags>
        <tag>Life</tag>
        <tag>游记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java 基础 —— 注解 Annotation]]></title>
    <url>%2F2020%2F07%2F04%2Fjava-basic-annotation%2F</url>
    <content type="text"><![CDATA[简介 Annotation 是从 JDK 5.0 引入的。 注解使得我们可以以编译器验证的格式存储程序的额外信息。注解可以生成描述符文件，甚至是新的类定义，并且有助于减轻编写“样板”代码的负担。 比如，我们项目中常常使用的 lombok 包中的注解，@Data、@NoArgsConstructor、@AllArgsConstructor 等注解，大大简化了代码，省了很多操作。 基本注解Java 提供了几个基本注解，这些内置注解它们都位于 java.lang 包下。 @Override 作用于子类中的方法，表示该方法一定要重写父类中的方法，可以有效避免子类方法名误写错误； @Deprecated表示某类、方法等已过时，当它们被使用时，编译器将会给出警告； @SuppressWarnings 镇压警告，被修饰的程序元素及其子元素取消显示指定的编译器警告，supress 有抑制、废止的含义； @SafeVarags Java 7 新增的，抑制堆污染警告； @FunctionalInterface：Java 8 中加入用于表示类型声明为函数式接口 注解示例123456789@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)public @interface TestAnnotation &#123; public int id() default -1; public String msg() default "Hi";&#125; 说明： 通过关键字 @interface 定义，并不是接口； 注解的属性也叫做成员变量。注解只有成员变量，没有方法。注解的成员变量在注解的定义中以“无形参的方法”形式来声明，其方法名定义了该成员变量的名字； 这里的示例上使用了一些注解，称为「元注解」，后面会详细介绍，稍安勿躁，这里仅仅是 show 一下自定义的注解长什么样； 注意点： 如果一个注解内仅仅只有一个名字为 value 的属性时，应用这个注解时可以直接接属性值填写到括号内； 有一种情况是一个注解没有任何属性，在应用这个注解的时候，括号都可以省略，不包含任何元素的注解称为标记注解（marker annotation）； 在注解中定义属性时它的类型必须是 8 种基本数据类型外加 类、接口、注解及它们的数组； 元注解JDK 除了在 java.lang 下提供了 4 个基本的 Annotation 之外，还在 java.lang.annotation 包下提供了4个 Meta Annotation——元注解。这 4 个注解用于修饰其他的注解。元注解是可以注解到注解上的注解，或者说元注解是一种基本注解，但是它能够应用到其它的注解上面。 @RetentionRetention 的英文意为保留期的意思。当 @Retention 应用到一个注解上的时候，它解释说明了这个注解的的存活时间。 RetentionPolicy.SOURCE 注解只在源码阶段保留，在编译器进行编译时它将被丢弃忽视； RetentionPolicy.CLASS 注解只被保留到编译进行的时候，它并不会被加载到 JVM 中； RetentionPolicy.RUNTIME 注解可以保留到程序运行的时候，它会被加载进入到 JVM 中，所以在程序运行时可以获取到它们； @Documented它的作用是能够将注解中的元素包含到 Javadoc 中去。 @Target@Target 指定了注解运用的地方，规定了只能张贴到方法上、类上、方法参数上等等。@Target 有下面的取值： ElementType.TYPE 可以给一个类型进行注解，比如类、接口、枚举 ElementType.METHOD 可以给方法进行注解 ElementType.FIELD 可以给属性进行注解 ElementType.CONSTRUCTOR 可以给构造方法进行注解 ElementType.LOCAL_VARIABLE 可以给局部变量进行注解 ElementType.PACKAGE 可以给一个包进行注解 ElementType.PARAMETER 可以给一个方法内的参数进行注解 ElementType.ANNOTATION_TYPE 可以给一个注解进行注解 @InheritedInherited 是继承的意思，但是它并不是说注解本身可以继承，而是说如果一个超类被 @Inherited 注解过的注解进行注解的话，那么如果它的子类没有被任何注解应用的话，那么这个子类就继承了超类的注解。 自定义注解使用 @interface 自定义注解时，自动继承了 java.lang.annotation.Annotation 接口。 一般我们使用注解，常常和验证器配合着使用。另外一种就是利用 AOP 结合使用。下面我们结合具体的示例来加深一下注解的使用。 @Length 注解下面，我们自定义一个注解，用来实现限制字段的长度。 123456789101112131415161718@Target(&#123;ElementType.FIELD, ElementType.CONSTRUCTOR, ElementType.PARAMETER&#125;)@Retention(RetentionPolicy.RUNTIME)@Documented@Constraint(validatedBy = &#123;LengthValidator.class&#125;) // 与约束注解关联的验证器public @interface Length &#123; // 约束注解验证时的输出消息 String message() default "限制字段值的范围"; // 约束注解在验证时所属的组别 Class&lt;?&gt;[] groups() default &#123;&#125;; // 约束注解的有效负载 Class&lt;? extends Payload&gt;[] payload() default &#123;&#125;; int min() default 0; int max() default 100;&#125; 接着，我们定义对应的验证器： 123456789101112131415161718192021public class LengthValidator implements ConstraintValidator&lt;Length, Integer&gt; &#123; private Integer min; private Integer max; @Override public void initialize(Length constraintAnnotation) &#123; this.min = constraintAnnotation.min(); this.max = constraintAnnotation.max(); &#125; @Override public boolean isValid(Integer value, ConstraintValidatorContext context) &#123; if (value == null) &#123; return true; &#125; if (value &gt;= min &amp;&amp; value &lt;= max) &#123; return true; &#125; return false; &#125;&#125; 注意点： 只有当注解中有 value 成员变量时，才可以不传 key，因为它默认是将值赋给 value 成员变量的； 成员变量没有使用 default 定义默认值，在使用注解时，就必须要对它进行赋值，有默认值则可以不必赋值； 如果只有一个参数成员，一般参数名为 value； but does not contain a groups parameter 注解需要定义成员变量 groups xxx contains Constraint annotation, but does not contain a payload parameter. 注解需要定义成员变量 Payload 提取注解信息AnnotatedElement 接口是所有程序元素（如Class、Method、Constructor等）的父接口，所以程序通过反射获取了某个类的 AnnotatedElement 对象（如Class、Method、Constructor等）之后，程序就可以调用该对象的如下3个方法来访问Annotation信息： getAnnotation(Class&lt;T&gt; annotationClass) 返回该程序元素上指定类型的注释，如果不存在，则返回 null，比如 Length length = field.getAnnotation(Length.class); 通过反射获取到该字段上使用的 @Length 注解的详细信息； Annotation[] getAnnotations() 返回该程序元素上的所有注释，例如 Annotation annotations = Class.forName(&quot;Test&quot;).getMethod(&quot;info&quot;).getAnnotations(); 表示获取 Test 类中 info 方法上的注释； boolean isAnnotatinPresent(Class&lt;?extends Annotation&gt; annotationClass) 判断该元素上是否存在指定类型的注释，如果存在则返回 true，否则返回 false，例如 methodA.isAnnotationPresent(Length.class)，表示判断方法 methodA 上是否用了 @Length注释； 为了获得程序中的程序元素（如 Class 、Method等），必须使用反射知识。 1234// 获取某个对象的类Class cl = obj.getClass();// 获取某个类中定义的所有属性Fields[] fields = cl.getDeclaredFields(); 编译时处理 Annotation如果希望让程序中的 Annotation 在运行时起一定的作用，只有通过某种配套的工具对Annotation中的信息进行访问和处理，访问和处理 Annotation 的工具统称 APT（Annotation ProcessingTool）。 Annotation 处理器在处理 Annotation 时可以根据源文件中的Annotation生成额外的源文件和其他的文件（文件的具体内容由 Annotation 处理器的编写者决定），APT 还会编译生成的源代码文件和原来的源文件，将它们一起生成 class 文件。 我们可以在Java源文件中放置一些Annotation，然后使用APT工具就可以根据该 Annotation 生成另一份 XML 文件，这就是 Annotation 的作用。 参考 On Java8 —— 第二十三章 注解 csdn-frank909-秒懂，Java 注解 （Annotation）你可以这样学 啥？听说你还在手写复杂的参数校验？ 使用 spring validation 完成数据后端校验 csdn-Bean Validation——自定义注解 生命不息，折腾不止！关注 「Coder 魔法院」，祝你 Niubilitiy ！🐂🍺]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>注解</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java 基础 —— Lambda 表达式]]></title>
    <url>%2F2020%2F07%2F04%2Fjava-basic-lambda%2F</url>
    <content type="text"><![CDATA[概述阅读项目代码时，尤其是阅读一些源码时，经常会遇到 Lambda 表达式。对此之前看过相关文章，但是停留在模模糊糊的印象上。今天趁着有时间，通过一些 demo 示例，梳理一下它的用法，以备后期遗忘的时候快速查询它的用法！ Lambda 表达式是 Java 8 的重要更新，它支持将代码块作为方法参数、允许使用更简洁的代码来创建只有一个抽象方法的接口的实例。 描述中提到的接口称为函数式接口 语法Lambda 表达式的主要作用就是可以用于简化创建匿名内部类对象，Lambda 表达式的代码块将会用于实现抽象方法的方法体，Lambda 表达式就相当于一个匿名方法。 Lambda 表达式由三部分组成： 形参列表：形参列表允许省略类型，如果形参列表中只有一个参数，形参列表的圆括号也可以省略； 箭头（-&gt;）：通过英文画线和大于符号组成； 代码块：如果代码块只有一条语句，花括号可以省略。Lambda 代码块只有一条 return 语句，可以省略 return 关键字，Lambda 表达式会自动返回这条语句的值作为返回值。 示例12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152interface Eatable &#123; void taste();&#125;interface Flyable &#123; void fly(String weather);&#125;interface Addable &#123; int add(int a, int b);&#125;public class LambdaQs &#123; // 调用该方法需要传入一个 Eatable 类型的对象 public void eat(Eatable e) &#123; System.out.println(e); e.taste(); &#125; // 调用该方法需要传入 Flyable 类型的对象 public void drive(Flyable f) &#123; System.out.println("我正在驾驶：" + f); f.fly("「夏日晴天」"); &#125; // 调用该方法需要 Addable 类型的对象 public void calc(Addable add) &#123; System.out.println("5 + 3 = " + add.add(5, 3)); &#125; public static void main(String[] args) &#123; LambdaQs lq = new LambdaQs(); // Lambda 表达式的代码块只有一句，因此省略了花括号 lq.eat(() -&gt; System.out.println("雪糕的味道不错！")); // Lambda 表达式的形参只有一个参数，因此省略了圆括号 lq.drive(weather -&gt; &#123; // 对接口中抽象方法 fly 的重写 System.out.println("今天天气是：" + weather); System.out.println("飞机平稳飞行！"); &#125;); // Lambda 表达式只有一条语句，即使该表达式需要返回值，也可以省略 return lq.calc((a, b) -&gt; a + b); // 如果不用 Lambda 表达式，就需要如下匿名类的方式去重写抽象方法 lq.calc(new Addable() &#123; @Override public int add(int a, int b) &#123; return a + b; &#125; &#125;); &#125;&#125; 输出结果：1234567oop.lambda.LambdaQs$$Lambda$1/1607521710@7ef20235雪糕的味道不错！我正在驾驶：oop.lambda.LambdaQs$$Lambda$2/1329552164@15aeb7ab今天天气是：「夏日晴天」飞机平稳飞行！5 + 3 = 85 + 3 = 8 以上示例可以说明，Lambda 表达式实际上可以被当做一个具体的对象。 Lambda 表达式与函数式接口 Lambda 表达式的类型，也被称为「目标类型（target type）」。Lambda 表达式的目标类型必须是「函数式接口（functional interface）」。函数式接口代表只包含一个抽象方法的接口。函数式接口可以包含多个默认方法、类方法，但仅能声明一个抽象方法。 查询 Java 8 的 API 文档，可以发现大量的函数式接口，例如：Runnable、ActionListener 等接口都是函数式接口。 Java 8 专门为函数式接口提供了 @FunctionalInterface 注解。该注解就是用于告诉编译器校验接口必须是函数式接口，否则就报错。 由于 Lambda 表达式的结果就是被当做对象/实例，因此，可以使用 Lambda 表达式进行赋值，示例： 12345Runnable r = () -&gt; &#123; for (int i = 0; i &lt; 100; i++) &#123; System.out.println(i); &#125;&#125;; 我们看一下 Runnable 接口的定义：1234@FunctionalInterfacepublic interface Runnable &#123; public abstract void run();&#125; 看一个错误示例：12345Object obj = () -&gt; &#123; for (int i = 0; i &lt; 100; i++) &#123; System.out.println(i); &#125;&#125;; 上面这段代码会报错：Target type of a lambda conversion must be an interface。Lambda 表达式的目标类型必须是明确的函数式接口！将 Lambda 表达式赋值给 Object 类型的变量，编译器只能推断出它的表达类型为 Object，而 Object 并不是函数式接口，因此就报错了！ 为了保证 Lambda 表达式的目标类型是明确的函数式接口，有如下三种常见方式： 将 Lambda 表达式赋值给函数式接口类型的变量； 将 Lambda 表达式作为函数式接口类型的参数传给某个方法； 使用函数式接口对 Lambda 表达式进行强制类型转换； 将上面出错的代码可以进行如下的改写： 12345Object obj1 = (Runnable)() -&gt; &#123; for (int i = 0; i &lt; 100; i++) &#123; System.out.println(i); &#125;&#125;; 综上，Lambda 表达式的本质很简单，就是使用简单的语法来创建函数式接口的实例，避免匿名内部类的繁琐。 方法引用与构造器引用如果 Lambda 表达式的代码块只有一条代码，还可以在代码中使用方法引用和构造器引用。 方法引用和构造器引用的好处是使 Lambda 表达式的代码块更加简洁。方法引用和构造器引用都需要使用两个英文冒号 ::。 种类 示例 说明 对应的 Lambda 表达式 引用类方法 类名::类方法 函数式接口中被实现的方法的全部参数传给该类方法作为参数 (a,b,...) -&gt; 类名.类方法(a,b,...) 引用特定对象的实例方法 特定对象::实例方法 函数式接口中被实现的方法的全部参数传给该方法作为参数 (a,b,...) -&gt; 特定对象.实例方法(a,b,...) 引用某类对象的实例方法 类名::实例方法 函数式接口中被实现的方法的第一个参数作为调用者，后面的参数全部传给该方法作为参数 (a,b,...)-&gt;a.实例方法(b,...) 引用构造器 类名::new 函数式接口中被实现方法的全部参数传给该构造器作为参数 (a,b,...)-&gt;new 类名(a,b,...) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657@FunctionalInterfaceinterface Converter &#123; Integer convert(String from);&#125;@FunctionalInterfaceinterface MyTest &#123; String test(String a, int b, int c);&#125;@FunctionalInterfaceinterface YourTest &#123; // 抽象方法负责根据 String 参数生成一个 JFrame 返回值 JFrame win(String title);&#125;public class LambdaRef &#123; public static void main(String[] args) &#123; // 1 引用类方法 // 下面使用 Lambda 表达式创建 Converter 对象 Converter converter1 = from -&gt; Integer.valueOf(from); Integer val = converter1.convert("99"); // 函数式接口中被实现方法的全部参数传给该类方法作为参数 Converter converter2 = Integer::valueOf; Integer val2 = converter2.convert("100"); // 2 引用特定对象的实例方法 // 使用 Lmabda 表达式创建 Converter 对象 Converter converter3 = from -&gt; "hello michael翔".indexOf(from); // 调用 "hello michael翔"的indexOf()实例方法 // 函数式接口中被实现的全部参数传给该方法作为参数 Converter converter4 = "hello michael翔"::indexOf; // 3 引用某类对象的实例方法 // 使用 Lambda 表达式创建 MyTest 对象 MyTest mt = (a, b, c) -&gt; a.substring(b, c); String str = mt.test("Hello World, Hello Michael翔", 2,9); // 上面 Lambda 表达式只有一行，因此可以使用如下引用进行替换 // 函数式接口中被实现方法的第一个参数作为调用者 // 后面的参数全部传给该方法作为参数 MyTest str2 = String::substring; // 4 引用构造器 // 使用 Lambda 表达式创建 YourTest 对象 YourTest yt = a -&gt; new JFrame(a); JFrame jf = yt.win("窗口"); // 使用构造器引用进行替换 // 函数式接口中被实现方法的全部参数传给该构造器作为参数 YourTest yt2 = JFrame::new; JFrame jf2 = yt.win("窗口2"); &#125;&#125; Lambda 表达式与匿名内部类的联系与区别Lambda 表达式与匿名内部类存在如下相同点： Lambda 表达式与匿名内部类一样，都可以直接访问 effectively final 的局部变量，以及外部类的成员变量（包括示例变量和类变量）； Lambda 表达式创建的对象与匿名内部类生成的对象一样，都可以直接调用从接口中继承的默认方法； Lambda 表达式与匿名内部类的区别： 匿名内部类可以为任意接口创建实例，不管接口包含多少个抽象方法，只要匿名内部类实现所有抽象方法即可；但是 Lambda 表达式只能为函数式接口创建实例； 匿名内部类可以为抽象类甚至普通类创建实例，但是 Lambda 表达式只能为函数式接口创建实例； 匿名内部类实现的抽象方法体允许调用接口中定义的默认方法，但是 Lambda 表达式的代码块不允许调用接口中定义的默认方法； 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657@FunctionalInterfaceinterface Converter &#123; Integer convert(String from);&#125;@FunctionalInterfaceinterface MyTest &#123; String test(String a, int b, int c);&#125;@FunctionalInterfaceinterface YourTest &#123; // 抽象方法负责根据 String 参数生成一个 JFrame 返回值 JFrame win(String title);&#125;public class LambdaRef &#123; public static void main(String[] args) &#123; // 1 引用类方法 // 下面使用 Lambda 表达式创建 Converter 对象 Converter converter1 = from -&gt; Integer.valueOf(from); Integer val = converter1.convert("99"); // 函数式接口中被实现方法的全部参数传给该类方法作为参数 Converter converter2 = Integer::valueOf; Integer val2 = converter2.convert("100"); // 2 引用特定对象的实例方法 // 使用 Lmabda 表达式创建 Converter 对象 Converter converter3 = from -&gt; "hello michael翔".indexOf(from); // 调用 "hello michael翔"的indexOf()实例方法 // 函数式接口中被实现的全部参数传给该方法作为参数 Converter converter4 = "hello michael翔"::indexOf; // 3 引用某类对象的实例方法 // 使用 Lambda 表达式创建 MyTest 对象 MyTest mt = (a, b, c) -&gt; a.substring(b, c); String str = mt.test("Hello World, Hello Michael翔", 2,9); // 上面 Lambda 表达式只有一行，因此可以使用如下引用进行替换 // 函数式接口中被实现方法的第一个参数作为调用者 // 后面的参数全部传给该方法作为参数 MyTest str2 = String::substring; // 4 引用构造器 // 使用 Lambda 表达式创建 YourTest 对象 YourTest yt = a -&gt; new JFrame(a); JFrame jf = yt.win("窗口"); // 使用构造器引用进行替换 // 函数式接口中被实现方法的全部参数传给该构造器作为参数 YourTest yt2 = JFrame::new; JFrame jf2 = yt.win("窗口2"); &#125;&#125; Lambda 表达式调用 Arrays 的类方法Arrays 类的有些方法需要 Comparator、XxxOperator、XxxFunction 等接口的实例，这些接口都是函数式接口。因此，可以使用 Lambda 表达式来调用 Arrays 的方法。 12345678910111213141516171819202122232425public class LambdaArrays &#123; public static void main(String[] args) &#123; String[] arr1 = new String[]&#123;"java", "python", "rust", "go"&#125;; Arrays.parallelSort(arr1, (o1, o2) -&gt; o1.length() - o2.length()); System.out.println(Arrays.toString(arr1)); int[] arr2 = &#123;3, -4, 25, 16, 30, 18&#125;; // left 代表数组中前一个索引处的元素，计算第一个元素时，left 为 1； // right 代表数组中的当前索引处的元素 Arrays.parallelPrefix(arr2, (left, right) -&gt; left * right); System.out.println(Arrays.toString(arr2)); long[] arr3 = new long[5]; // a 代表正在计算的元素索引 Arrays.parallelSetAll(arr3, a -&gt; a * 5); System.out.println(Arrays.toString(arr3)); // 等价于用匿名内部类重写 applyAsLong 抽象方法 Arrays.parallelSetAll(arr3, new IntToLongFunction() &#123; @Override public long applyAsLong(int value) &#123; return value * 5; &#125; &#125;); System.out.println(Arrays.toString(arr3)); &#125;&#125; 输出：1234[go, java, rust, python][3, -12, -300, -4800, -144000, -2592000][0, 5, 10, 15, 20][0, 5, 10, 15, 20] 因为这些要出入 Comparator、XxxOperator、XxxFunction 等接口的实例往往都是一次性的，使用 Lambda 表达式也不用考虑重用等，反而让程序更加简洁了。 总结本文主要参考的是 《疯狂 Java 讲义第 5 版》的第 6 章的面向对象下，通过实际的示例 demo 应该可以将 Lambda 的常用场景和用法掌握了。这样，看项目代码或者源码的话，会更加易于理解！基本功扎实，才能走得更快！ 参考 To Be Top Javaer/糖块十二、Lambda表达式]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Lambda</tag>
        <tag>面向对象</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[初识 Git 基本命令 merge 和 rebase]]></title>
    <url>%2F2020%2F06%2F21%2Fgit-merge-rebase%2F</url>
    <content type="text"><![CDATA[前言Git 中的分支合并是一个常见的使用场景。 仓库的 bugfix 分支修复完 bug 之后，要回合到主干分支，这时候两个分支需要合并； 远端仓库的分支 A 有其他小伙伴合入了代码，这时候，你需要和远端仓库的分支 A 进行合并； 以上只是列举了分支合并的一些常见场景，关于 merge 和 rebase 命令你足够了解吗？ HEAD 的理解在介绍本文的主要内容之前，我们先理解一下 HEAD 。 HEAD 指向当前所在的分支，类似一个活动的指针，表示一个「引用」。例如当前在 develop 分支，HEAD 内容就是 ref: refs/heads/develop。 HEAD 既可以指向「当前分支」的最新 commit，也可以指向历史中的某一次 commit (「分离头指针」的情况)。归根结底，HEAD 指向的就是某个提交点。 当我们做分支切换时，HEAD 会跟着切换到对应分支。 fast-forward 与 –no-ff 的区别假如有一个场景：有两个分支，master 分支和 feature 分支。现在，feautre 分支需要合并回 master 分支。 fast-forward 合并方式是条件允许的情况，通过将 master 分支的 HEAD 位置移动到 feature 分支的最新提交点上，这样就实现了快速合并。这种情况，是不会新生成 commit 的。 --no-ff 的方式进行合并，master 分支就会新生成一次提交记录。 如果条件满足时，merge 默认采用的 fast-forward 方式进行合并，除非你显示的加上 --no-ff 选项；而条件不满足时，merge 也是无法使用 fast-forward 合并成功的！ merge 操作上面用图解的方式介绍了 fast-forward 和 --no-ff 的区别。下面，结合实际的代码仓进行合并操作，举几个栗子理解一下。 git merge 操作是区分上下文的。当前分支始终是目标分支，其他一个或多个分支始终合并到当前分支。这个注意点记住了，方便记忆！所以，当需要将某个分支合并到目标分支时，需要先切到目标分支上。 fast-forward 合并刚刚一直在强调条件允许的时候，fast-forward 才能合并成功。条件指的是什么呢？ 其实指的是源分支和目标分支之间没有分叉（单词 diverge），这种情况才可以进行快速合并。如果是下图中的场景，无法通过 HEAD 的快速移动实现分支的合并！ 下面进行一个不分叉的场景的示例： 现在需要将 feature 分支合入到 master 分支，默认使用 fast-forward 方式： 123# 切到目标分支git checkout mastergit merge feature 命令行里显示了 Fast-forward 的提示： 看一眼 master 分支合入的前后对比（注意 HEAD 的位置）： no-ff 合并不分叉的场景是否可以强制采用 --no-ff 方式合并呢？可以！ 123# master 回到合入前的状态git reset --hard d2fa1aegit merge feature --no-ff 这次命令行没有 Fast-forward 的提示了。 看一眼 master 分支图： 这个图和上面讲解 no-ff 命令时的示意图一致，果然会有新 commit 生成。 分叉场景的合并 上面的图展示了我们经常遇到的一个场景，特性分支创建之后，源分支也会有新的提交。这就是形成分叉了。 这时候如果我们进行合并呢？ 1git merge feautre 可以看到，虽然默认会尝试 fast-forward 的方式进行合并，但是因为分叉了，所以此时会采用 no-ff 的方式进行合并！有新的 commit 生成了！ fast-forward 方式对应的合并参数是 --ff 我们试试这个参数 --ff-only，顾名思义，就是强制只使用 ff 方式进行合并： 123# 回到合并前git reset --hard 3793081git merge feature --ff-only 经过测试，当分叉时，因为无法使用 ff 方式合并，即使你强制指定使用该方式合并也不行，会提示终止！ 附上 Git 官方文档中的解释，方便理解： 1With --ff, when possible resolve the merge as a fast-forward (only update the branch pointer to match the merged branch; do not create a merge commit). When not possible (when the merged-in history is not a descendant of the current history), create a merge commit. rebase 操作rebase 命令是一个经常听到，但是大多数人掌握又不太好的一个命令。rebase 合并往往又被称为 「变基」，我称为 「基化」🤣。「基」的理解很重要，理解了它，其实 rebase 命令你就掌握了。 我的描述可能并不准确，只是为了能够帮助你理解。这里的「基」就是一个「基点」、「起点」的意思。「变基」就是改变当前分支的起点。注意，是当前分支！ rebase 命令后面紧接着的就是「基分支」。 变基前： git reabse master feature 变基后： git rebase 命令通常称为向前移植（forward porting）。 变基提交示例我们接下来进行实际的测试，将代码库状态构造成分叉的状态，状态图如下： 以 master 分支为基，对 feautre 分支进行变基： 12git checout featuregit rebase master 以上两行命令，其实可以简写为：git rebase master feature 特性分支 feature 向前移植到了 master 分支。经常使用 git rebase 操作把本地开发分支移植到远端的 origin/&lt;branch&gt; 追踪分支上。也就是经常说的，「把你的补丁变基到 xxx 分支的头」 可以发现，在 master 分支的最新节点（576cb7b）后面多了 2 个提交（生成了新的提交记录，仅仅提交信息保持一致），而这两个提交内容就是来自变基前 feature 分支，feature 分支的提交历史发生了改变。 观察上图还可以发现，变基后，改变的只是 feature 分支，基分支（master 分支）的 HEAD 指针依然在之前的 commit （576cb7b）处。这时候要将 feature 分支合入到 master 分支上，就满足 fast-forward 的条件了，master 分支执行快速合并，将 HEAD 指针指向刚刚最新合入的提交点： 12git checkout mastergit merge feature 看下图 master 分支图，观察 HEAD 指针的位置： rebase 变基操作最适合的是本地分支和远端对应跟踪分支之间的合并。这样理解可能会更清晰一点。比如，远端仓库里有一个特性分支 feature，除了你开发之外，还有其他人往这个分支进行合入。当你每次准备提交到远端之前，其实可以尝试变基，这时候基分支就是远端的追踪分支。 下图是仓库的分支图： 12git fetchgit rebase origin/feature feature 观察上图，我们本地的提交以远端分支的最新提交为「基」，将差异提交重新进行了提交！远端分支的提交记录依然是一条直线~如果分叉的情况，不采用这种「变基操作」，而直接采用 merge 的方式合并，就会有如下这种分支提交图： 因为分叉了，采用 git pull 时默认也没法 fast-forward 合并，只能采用 no-ff 方式合并，最后的提交历史就会像上图那样。会产生一个合并提交。同时，分支图也显得稍微杂乱了一点，因为 feature 分支不是一条直线了。但是，其实也有好处，可以实际的看出来合并的提交历史。该选择哪个，往往取决于团队的选择策略。 养成习惯，使用 git pull --rebase 方式同步远端分支也是一个不错的习惯，这样，就不会多出多余的 commit 记录了。具体可以看这篇文章 博客园/聊下git pull –rebase rebase 总结rebase 命令其实关键在于理解「基」，git rebase &lt;基分支&gt;，就是将当前基分支与当前分支的差异提交获取到，然后在「基分支」最新提交点后面将差异提交逐个再次提交，最后将当前分支的 HEAD 指针指向最新的提交点。 「基分支」的 HEAD 位置是不变的。要想完成分支合并，完成变基之后，需要再进行分支间的合并等操作。 rebase 命令的用法也不止于此，计划后期会专门写一篇介绍她的文章。本文本来是计划介绍 merge 命令的，但是合并的方式中，其实也经常涉及变基操作之后的合并，因此，干脆就放一起比较好了，这样易于理解记忆。 补充 git merge --abort 当合并的过程中，由于冲突难解决，你想放弃合并，回到未合并之前的状态； git log --graph --pretty=oneline --abbrev-commit 可以在命令行方便地查看提交图 一言在 Git 这个专辑里有一篇介绍 cherry-pick 的文章，有个小伙伴给了如下的留言，说明自己分享的内容获得了肯定，欣慰啊！ 今天肝的这篇文章，介绍了 Git 中的 merge 和 rebase 的基本概念和用法，同时，又自己手动绘制了图！俗话说，一图胜千言，但写完才发现，是真的耗时啊……不过，总结绘图的过程，自己也加深了理解，有些概念也变得更加清晰了！希望，我的总结也能让其他人读懂~ 之前我经常会开启文章的「赞赏」，但发现收效甚微，很少有小伙伴会打赏。后来我就每次发文就关闭了这个选项。本文应该是 6 月份的「月末总结」了，就开启一次「月末赞赏」吧！期待小伙伴的支持与鼓励！ 参考我将本文的参考文章也都注明了，他们也都很有阅读的价值。但由于微信外链的缘故，可以点击右下角的「阅读原文」浏览！ StackoverFlow-What is the difference between git merge and git merge --no-ff? git-scm-git-merge 分支的合并 Gitlab-Fast-forward merge requests 颜海镜-图解4种git合并分支方法 Sync with a remote Git repository (fetch, pull, update) IDEA 的帮助文档 生命不息，折腾不止！关注 「Coder 魔法院」，祝你 Niubilitiy ！🐂🍺]]></content>
      <categories>
        <category>ToolsDev</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git 基本命令 -- 你用过 git diff 吗？补习一下吧]]></title>
    <url>%2F2020%2F06%2F14%2Fgit-diff-patch%2F</url>
    <content type="text"><![CDATA[前言上周介绍过一篇 Git cherry-pick 的文章，阅读数比之前有明显的增加。本周再接再厉，总结了 Git 的 diff 相关的用法。经过自己的学习，弥补了一些知识盲区。通过本文总结一下吧，以便日后查阅，也希望对你也有所帮助。 工作区和版本库的概念在介绍 diff 命令之前，我们先认识一下 Git 的工作目录。在一个 GIt 工作区文件夹下，有一个 .git 隐藏目录。它其实不算是工作区内容，它是 Git 的版本库。 当我们使用 git add 命令时，会将文件添加到暂存区（也称索引区）。需要使用 git commit 命令才能将修改提交到对象库中，这里的 「提交」对应的英文也就是 commit。 git diff 命令的 4 种比较git diff比较「暂存区」与「工作区」之间的差异。 当我们直接修改了工作区中的文件之后，在添加到暂存区之前，想要看看修改了那些内容，保证修改正确性。这时候运行 git diff 即可，将会显示暂存区与工作区文件的差异。例如下图就是一个示例： 可以看到工作区的 test.txt 文件比暂存区 test.txt 文件新增了一行内容。 git diff commit比较「给定提交 ID」与「工作区」的差异。 有时候你需要将工作区的改动和历史中某个提交点的内容进行对比，这个命令就有用了。例如，我要将目前工作区的内容和当前分支的最新一次的提交进行比较，运行 git diff 3f0c1b 或者 git diff HEAD 即可： git diff --cached commit比较「暂存区」与「给定提交 ID」的差异。 因为已经将修改内容添加到暂存区了，这时候直接运行 git diff 就看不到差异了。因为我们手速快，已经将工作区修改的文件通过 git add 命令添加到暂存区了，这时候，又想要知道暂存区的变更和给定提交点的差异。只需要加上 --cached 选项即可。 例如，我现在将上面的修改已经添加到了暂存区，运行 git diff --cached HEAD 即可将暂存区内容与最新一次提交进行比较： 如果省略 commit，那么，就是默认指 HEAD。 git diff commit1 commit2比较指定的两次提交 「commit1」与 「commit2」的差异。 运行 git log --pretty=oneline --abbrev-commit 命令看一下当前分支的提交记录，选择两个进行比较。 运行 git diff 3f0c1 41312 比较这两个 commit 的差异： 好奇宝宝附体，咱们颠倒一下 commit 之间的顺序，看看差异效果： 可以看到，比较对象的先后顺序决定了 diff 的差异结果的「增删」。上面几个命令的的描述，我其实都有注意顺序的表达。按照该顺序显示的效果，就是「后者」-「前者」的差异。这里需要你自己意会一下啦。可能我的总结并不是很精准。 比较有用的选项 --stat 显示有多少行发生变化，简洁的展示差异； 限制路径 如果只要显示 src 文件夹下的差异，指定文件夹名即可， git diff --stat HEAD~ HEAD src 如果质押显示 test.txt 文件的差异，指定文件即可， git diff HEAD~ HEAD src/test.txt 补丁 patch补丁名是自定义的，通常带有 patch 命名，这样命名比较通俗易懂。 前面介绍的 4 中比较差异的场景，我们可以通过比较差异的命令加上 &gt; patch 这样的方式导出补丁文件。这里的 patch 就是自定义的补丁名。 我们来进行一个示例。使用 git diff HEAD~ HEAD &gt; patch 导出上一次提交和这一次提交差异的补丁。 运行上述命令之后，会生成一个叫 patch 补丁文件。现在来看看差异文件到底表示的什么含义吧： - 表示第 1 个文件 + 表示第 2 个文件 @@ -1 +1,2@@ 表示比较的区块，第 1 个文件的第 1 行，第 2 个文件的第 1 行起的连续 2 行 +new line in work dir 新增的内容 总结起来就是表示当前分支的倒数第 2 个提交与最后 1 个提交之间的差异是，最后一个提交在 test.txt 的第 2 行新增了一行。 怎么用这个补丁呢？示例： 1234# 切换至倒数第 2 个提交git reset --hard HEAD~# 应用一下补丁git apply patch 这时候刚刚差异的内容就会在相应的文件夹进行修改了，但是并不会生成提交。 补丁文件可以发给其他人，只需执行 git apply patch 就可以实现打补丁的效果喽。 在打补丁之前，可以先检验补丁能否应用，执行 git apply --check patch 即可。如果没有任何输出，那么表示可以顺利打补丁。 IDEA 中的 diff 使用 IDEA 的右键菜单 Git 中提供了一些 Compare 的命令： Compare with the Same Repository version 与 Git 仓库的相同版本进行对比 Compare with 选择当前分支的两个提交进行对比 Compare with Branch 选择指定的分支进行对比 一言本周在园区进行了 5 KM 的跑步，因为是和同事一起跑的，速度也被他带上来了，竟然跑进了 30 min。想起来上一任老大当时和我的聊天，「如果不知道前进的方向的话，不妨从周围同事身上学习那些优秀的习惯。」 本周还发生了一件让我震惊的事，进公司的第一任老大竟然短短一周内突然「走了」，前同事告诉我之后，真是感觉人生无常啊，太遗憾了……希望大家在搬砖的同时，别忘记身体健康才是最重要的。珍惜当下，peace~ 参考 卖逗搞 IT —— 聊聊 git diff 命令]]></content>
      <categories>
        <category>ToolsDev</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git 的 cherry-pick 命令还没用过？快来看看它的厉害！]]></title>
    <url>%2F2020%2F06%2F06%2Fgit-cherry-pick%2F</url>
    <content type="text"><![CDATA[前言最近一周在对项目的代码做一些构建工程的整改，一些通用的代码往往经常需要在代码库中的各个分支进行提交。没接触过 cherry-pick 功能时，往往需要你反复切换分支，在各个分支上进行相关内容的修改。这样的操作不仅繁琐，而且修改的地方一多，极易出错！ cherry-pick 的理解Git 提供了 cherry-pick 的命令可以很好的解决上面场景的问题，高效、快捷！同样的适配，会该用法之后，比其他同事能够提前不少时间完成整改！ 我们代码库中的一个个 commit 可以看做一个个 cherry。同一个代码库中的 commit-id 往往是唯一的，当你在分支 B 上也需要在分支 A 上的提交内容时，就可以将它们 cherry-pick 过来！ 语法123git cherry-pick [--edit] [-n] [-m parent-number] [-s] [-x] [--ff] [-S[&lt;keyid&gt;]] &lt;commit&gt;…git cherry-pick (--continue | --skip | --abort | --quit) 稍安勿躁，上面是该命令的语法，下面我们将通过如下的这个仓库进行示例演示： 代码库有三个分支：master、feature-a、feature-b master 分支处于 d3113d5 feature-a基于 master 分支创建后，进行了三次提交，commit-id 分别是： b09a488c011cb954e0de0df7e4a03622daeefc8d 9517fc12ecfb81ecc6379dc7cc62368e239c4542 6b95b589152a6e54a6a7c945d9de97eb3ecc147a feature-b 特性分支b，当前处于 967181，这里是为了测试的时候方便恢复 从 feature-a 分支选择 2 个提交合入 feature-b首先解决一个疑问，可能有同学会说，为何不采用 merge 进行分支的合并呢？ 因为，并不是每个场景都是可以进行分支的合并的。比如，这两个分支就是不同的发布分支，一个是版本 1.0.0 的分支，一个是版本 2.0.0 的分支，这两个版本分支是需要独立保存的。这时候将它们进行合并就不合适。但是这时候有一个 bug 是它俩都有的，需要修复。使用 cherry-pick 就可以仅仅将你在一个分支上修复的内容筛选出来，提交到另一个分支上！ 看🌰：我现在需要将我在feature-a 分支上的两次提交 b09a488 和 6b95b5 改动的内容也在 feature-b 上进行修改提交： 1234# 切换到 feature-b 分支git checkout feature-b# 挑选 commitgit cherry-pick 6b95b5 b09a488 这时候，如果没有冲突的话， git log 就可以看到 feature-b 分支上会多出 2 次新的提交。 注意点：虽然表面上看似是将那两次提交拿过来再用一遍，但其实 Git 只是拿到修改生成了新的提交，因此，这里会看到这 2 个新的提交，commit-id 和我们挑选commit-id 并不一致。 从 feature-a 分支选择连续的提交合入到 feature-b如果需要挑选 feature-a 上那 3 次连续的 commit 进行合入，那么，有种简单的写法进行这种操作： 1234# 切换到 feature-b 分支git checkout feature-b# 语法：git cherry-pick &lt;start-commit-id&gt;...&lt;end-commit-id&gt;git cherry-pick d3113d5...b09a488c01 细心的读者应该发现了，为何 start-commit-id 选用的是 6b95b58 的上一次提交呢？因为上面这种写法，是「左开右闭」的！下面介绍另外一个写法，它是「左闭右闭」的： 1234# 切换到 feature-b 分支git checkout feature-b# 语法：git cherry-pick &lt;start-commit-id&gt;^...&lt;end-commit-id&gt;git cherry-pick 6b95b58^...b09a488c01 如果要合并的多个提交修改的文件有先后依赖关系，建议要按照这几个提交的时间顺序进行 cherry-pick，否则可能会有冲突等问题 如何不自动提交-n/--no-commit 选项可以在进行 cherry-pick 时不进行自动提交，而且，经过测试发现，当你选择多个 commit-id 时，它会将这些 commit-id 对应的修改在当前分支生效而不进行提交，实现了多个 commit-id 修改进行合并的效果。 看🌰： 12345678# 切换到 feature-b 分支git checkout feature-b# 在 feature-b 分支，恢复到初始状态git reset --hard 967181# 选择 feature-a 上的连续三个提交修改的内容，但是不进行自动提交git cherry-pick 6b95b58^...b09a488c01 -n# 查看一下状态git status 注意点：会将多个 commit-id 的修改合并为一个修改，只是修改，并不会生成新的提交，你需要手动进行提交，提交信息可以自定义 其他有用的选项 -e/--edit：进行 cherry-pick 时，会在进行新的提交之前，重新编辑提交的信息 x：在记录提交时，会在原始提交消息后添加一行cherry picked from commit …，以表明此更改是从哪个提交中挑选出来的。 这仅适用于没有冲突的 cherry-pick -s/--signoff：在提交信息的末尾追加一行操作者的签名，表示是谁进行了这个操作 樱桃摘的时候有冲突怎么办其实和 rebase 命令时有冲突的解决步骤差不多： 解决有冲突的文件 git add -u 标记有冲突的文件已经解决好冲突了 git cherry-pick --ontinue 除此以外，如果你过程中不想 cherry-pick了，只需执行：git cherry-pick --abort 再来一段难道介绍到这里就结束了吗？No~ 麦哥再介绍一下我们日常使用的宇宙最强 IDEA 编辑器中集成的 cherry-pick 功能吧！ 通过这个动图中的信息可以看到，虽然挑选的 commit 在分支 feature-b 上也进行了提交，提交信息没变，但是其实 commit-id 是新的了，证明是新的提交！ 总结Github 作为知名的程序员交友网站，Git 就是其后面的基石。作为程序员，我们应该对一些基本的 Git 命令有所了解，这在日常开发中将大大提高开发效率！ 一言最近一周，我是亲眼看到一些同事由于对 Git 不熟悉，白白浪费了一些时间在提交入库的操作上。后期，我也会陆续在总结一些 Git 的基础知识，争取用通俗易懂的 demo 将它们讲明白，希望感兴趣的小伙伴持续关注起来吧~ 生命不息，折腾不止！关注 「Coder 魔法院」，祝你 Niubilitiy ！🐂🍺 参考 https://git-scm.com/docs/git-cherry-pick https://juejin.im/post/5925a2d9a22b9d0058b0fd9b http://www.ruanyifeng.com/blog/2020/04/git-cherry-pick.html]]></content>
      <categories>
        <category>ToolsDev</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Windows 开发环境必备终端工具 Cmder]]></title>
    <url>%2F2020%2F05%2F16%2Ftools-win-cmder%2F</url>
    <content type="text"><![CDATA[概述Windows 的命令终端确实不太好用，这也是很多人吐槽 Windows 的一个槽点。今天安利一款叫 Cmder(http://cmder.net/) 的神器，希望它能让你在 Windows 上的开发体验提升一点！Cmder 现在确实也成为了我工作中的一款必备软件。 Cmder 的优势主要有： 它提供了 portable 的版本，也就是移动版，一次配置之后，方便在其他环境再使用； 颜值比 Windows 默认的高，可以安装相关主题、设置背景图片等，自定义比较丰富； 支持一些常用命令的自定义（设置一些 alias）； 提供了一些 Linux 命令，比如 ls、pwd、curl 等； 支持多窗口，这对于开发确实方便； 操作方便，比如命令行的复制、粘贴等； 基于以上的原因，推荐还在 Windows 平台工作的小伙伴可以安装试用一下，不会后悔的！ 安装官网主页上提供下载，有两个版本 mini 与 full 版，full 版本自带了 msysgit 工具，推荐下载。 默认会跳转至 Github(https://github.com/cmderdev/cmder/releases/tag/v1.3.14)。国内下载速度比较慢，如果有需要，可以在公众号后台回复 cmder 即可获得百度云的下载链接。 安装： 解压下载下来的压缩包至你一般安装软件的文件夹，比如 C:\Program Files 配置系统的环境变量，在 Path 中新增：C:\Program Files\cmder Win+R 输入 cmder 即可打开 cmder 客户端了，可以将快捷方式固定至任务栏； 配置将 cmder 添加至右键菜单添加 cmder 到右键菜单，需要先以管理员权限打开 Windows 自带 cmd，然后运行如下命令: 1Cmder.exe /REGISTER ALL 经过上面的设置，在需要打开终端的文件夹下，你就可以在右键菜单中看到 Cmder Here，免去原来还需要在终端中输入路径进行跳转的繁琐步骤！ 避免中文乱码在使用 ls 等命令时，如果文件夹下有中文名乱码的问题，需要进行如下的设置解决（settings-&gt;Startup-&gt;Environmen）： 1set LANG=zh_CN.UTF-8 Win+Alt+P 是打开设置的快捷键，或者在顶部/底部右击点击 settings, 也可以进入设置页面 默认终端设置、默认目录设置选择默认的终端，比如设置 Cmder As Admin 作为默认选项； 更改默认开启 cmder 时默认的目录，选择对应终端，增加-new_console:d:D: 即可，默认在 D 盘根目录： 别名（alias）设置在 Cmder 终端，输入 alias 可以看到默认的一些别名设置。可以根据个人需要，自定义常用命令行操作的别名，提升开发效率！ 依次进入 Cmder 安装目录-&gt;config，user-aliases.cmd 文件中定义了命令的别名，如下是我的一些示例，你也可以根据你的需要进行自定义： 123456782c=cd /d "D:\020-Code"2dl=cd /d "C:\Users\xiang\Downloads"ga=git addgst=git statusci=commitco=checkout 快速切换至一些常用的目录； git 常用命令的缩写； 系统默认的有一个别名设置比较有用，e. 可以快速打开文件夹。 背景的透明度、背景图片的设置打开 settings-&gt;Feature-&gt;Transparency，可以进行终端透明度的设置，看起来效果比较酷炫。 背景图片的设置： 主题主题，我使用的是 Dracula 吸血鬼主题（https://draculatheme.com/cmder）。 顺便安利这款主题，它也提供了 VSCode/IDEA/Pycharm 等一系列 IDE 软件对应的主题！ Win+Alt+P 点击 Import 选择 Dracula.xml 设置分屏的快捷键 进入 Settings-&gt;Keys&amp;Macro，搜索 Split: Duplicate 设置。我的分屏快捷键设置为： ctrl+shift+→：左右分屏 ctrl+shift+↓：上下分屏 快速复制/粘贴下面这两个功能很常用，比 Windows 终端的复制和粘贴好用太多： 鼠标左键选中需要复制的内容，即可将终端的内容快速复制至剪贴板； 鼠标右键即可将剪贴板的内容快速粘贴； Cmder 窗口放大/缩小快捷键默认的快捷键是 ctrl+~，这个和 VSCode 中终端启动的快捷键冲突了，因此，我修改了 Cmder 的这个快捷键，改为了 Alt+~ 快捷键 Tab：路径的自动补全； Ctrl+T：建立新页签； Ctrl+W：关闭页签; Ctrl+Tab：切换页签; Ctrl+1：快速切换到第 1 个页签，Ctrl+n 快速切换到第 n 个页签； Ctr+R：历史命令搜索; Ctrl+滑鼠滚轮：字体的快速放大/缩写； Alt+F4：关闭所有页签 Alt+enter：切换到全屏状态； Win+Alt+P：进入cmder设置菜单； 参考 Win下必备神器之Cmder 简书-cmder 一个比cmd强n倍的神器]]></content>
      <categories>
        <category>ToolsDev</category>
      </categories>
      <tags>
        <tag>Tools</tag>
        <tag>Win</tag>
        <tag>Terminal</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JetBrains PyCharm/IDEA 常用插键总结]]></title>
    <url>%2F2020%2F05%2F05%2Ftools-dev-pycharm-idea-plugins%2F</url>
    <content type="text"><![CDATA[工欲善其事必先利其器 前言IDEA 有用一套非常强大的插件市场，提供了丰富的插键帮助开发者提升开发效率。之前总结过一篇博文，渐渐觉得有必要写一篇文章单独罗列一下 IDEA 常用的插键！ 主题IDEA主题- Settings-&gt;Editor-&gt;Color Scheme-&gt;Import Scheme，导入 jar 包即可。这种方式安装主题略微麻烦，其实在应用市场里提供了很多主题可以直接安装的。Dracula 在 IDEA 中，可以像安装插键一样搜索该主题进行安装。吸血鬼主题插件，各 IDE 都有适配的主题，非常推荐！Material Theme 主题插键 安装说明Install JetBrains plugin：弹出IntelliJ IDEA 公司自行开发的插件仓库列表，供下载安装。Browse repositories：弹出插键仓库中所有插键列表供下载安装。Install plugin from disk：浏览本地的插键文件进行安装。 插键列表Lombok 当你使用 lombok 包进行开发时，要同时安装该插键才行！笔者近期就因为升级 IDEA 重装之后忘记安装该插键，导致代码报红问题，半天才发现因为该插键忘记重新安装了。 TestMe Junit 等测试工具的生成插件,支持 Junit4/5,TestNG,Spock 等测试框架代码的生成 数据库相关Free MyBatis plugin 快速从代码跳转到 mapper 及从 mapper 返回代码 Mybatis Log 在控制台打印mybatis的脚本日志，需要配置才能在控制台输出，参考 Mongo Codota可以搜索知名开源项目中该类或者方法的使用案例.写代码的时候，某个类不熟悉用法，右键选择”Get relevant examples“ 比如我们想了解：SerializationUtils 工具类的用法，也可以直接在网址上搜索即可，网址：https://www.codota.com/code，选择对应的包名 CamelCaseCamelCase （https://plugins.jetbrains.com/plugin/7160-camelcase）：是一个日常开发中常用的一款插键。可以辅助你将变量名方便的进行转换。 我们先简单看一下变量常见的命名方式有哪些： kebab-case：烤肉串式命名，单词之间用中划线 - 隔开，例如 user-name，还确实挺形象; 蛇形命名法，蛇在地上爬，因此，蛇形命名法单词之前是下划线 _ 隔开的。 蛇形命名具体又分为如下两种： snake_case：小蛇形命名法，例如 user_name； SNAKE_CASE：大蛇形命名法，例如 USER_NAME； 驼峰命名法，单词首字母大写，看上去像驼峰 驼峰命名具体分为如下两种： camelCase：驼峰命名法，也称小驼峰命名法，首字母小写，例如 userName； PascalCase：帕斯卡命名法，也称大驼峰命名法，首字母大写，例如 UserName 除以上命名方式之外，匈牙利命名法也比较常见，它的基本命名原则是：属性+类型+对象描述，例如 getListUsers。 铺垫到此结束，上今天的主角！看看 CamelCase 插键主页上是如何介绍它的： Switch easily between kebab-case, SNAKE_CASE, PascalCase, camelCase, snake_case or space case. See Edit menu or use ⇧ + ⌥ + U / Shift + Alt + U. Allows to disable some conversions or change their order in the preferences. 该插键使得我们能够方便的在各种命名方式的变量名之间转换。 Windows 上的快捷键是：Shift+Alt+U Mac 上的快捷键是：Shift+Option+U 下面上个动图演示一把： 不要小看这个插键噢，在变量名挺长的情况下，如果手写经常会发生敲错变量名的情况，转换命名方式就不那么方便了，这时候这款插键就能很好的提高你的开发效率了！ String Manipulation：字符串转换工具，安装好插件后，选中需要处理的内容后，按快捷键 Alt+m，即可弹出工具功能列表 anyrule：该插键在 VSCode 也有提供，可以用来搜索适合场景的正则表达式 新建一个文件（因为 anyrule 一定要在文本环境下才能生成正则表达式），然后按下快捷键 Alt+a 功能键，这时候就会弹出 anyrule 正则表达式搜索框（anyrule 生成的是 javascript 的正则表达式，如果需要用到 Java 中。需要将最前面和最后面的”/“去掉） 理解这个表达式的运行原理，点击右下角的”图解正则”。（就是将刚才any-rule生成的正则表达式填入 https://regexper.com/ GsonFormatPlus给你一段 Json 格式数据，除了手写之外，利用该插键可以快速生成一个和该Json数据对应的Java对象： 比如一段Json格式数据如下： 12345&#123; "status": 0, "msg": "操作成功", "data": 1&#125; GsonFormat则是一个JSON格式数据 → 对象的快速代码自动生成插件 saveAction格式化、serialVersionUID生成等，很有用的插键 参考： 嗨：VSCode和IDEA都请安装上这个神奇的插件 编码规范 概述今天介绍的插件主要是围绕编码规范的。有追求的程序员，往往都有代码洁癖，要尽量减少代码的「坏味道」。 代码静态检查是有很多种类，例如圈复杂度、重复率等。业界提供了很多静态检查的插件来识别这些不合规的代码，帮助提高项目的质量。比较知名的一个产品是 SonarQube，它提供了一个「门禁」平台，集成了很多静态检查检查。下次有机会介绍一下该平台的搭建。 本文主要介绍 IDEA 中对于 Java 语言静态检查的好插件： Alibaba Java Coding Guidelines 阿里基于他们 Java 规范提供的插件 CheckStyle-IDEA 检查代码的格式是否符合规范 FindBugs-IDEA 检查代码是否有常见的一些 Bug Alibaba Java Coding Guidelines阿里巴巴 Java 编码指南插件支持。 首先说说阿里的 p3c 项目，它的 Github 主页地址是：https://github.com/alibaba/p3c 阿里之前开源过一份 Java 开发手册。手册从编程规约、异常日志、单元测试、MySQL 数据库、工程结构、设计规约等角度，介绍了阿里的 Java 开发规范，这个对于 Java 新手帮助挺大的，能够学到不少东西。有一些坑可能老司机也会翻车。 开发人员 Coding 时，可能就忘记规范了，写出来的代码还是会有『坏味道』。这时候Alibaba Java Coding Guidelines 插件就派上用场了。它会根据上面的 Java 开发规范对你的代码进行检查，不符合规范的代码会有提示，并给出修改建议。阿里作为国内 Java 大厂，基于成千上万的工程师总结出来的踩坑经验，我相信给出的规范建议还是比较可靠的。 上个栗子： 1234String str = "hello";for (int i = 0; i &lt; 100; i++) &#123; str = str + "world!";&#125; 先不要往下看，试着分析一下这段代码哪里可以优化？ 其实，插键扫描的结果不仅有这个问题，还有『魔法数字』的问题。插件的用法，见下面的截图。 除此以外，建议在 IDEA 进行代码提交时，勾选上它提供的检查项按钮，这样如果有不合规的代码进行提交，就会提醒你修改： CheckStyle-IDEA 项目主页：https://github.com/jshiell/checkstyle-idea 安装好之后，进入设置，勾选上你要选用的默认检查规范： 大厂往往都有自己的语言规范，可以导入选用： 右键菜单，选择 Check Current File 即可检查当前文件是否符合编码规范： 检查结果： 如果不符合规范的写法有点多，整改起来就会很痛苦了，这时候该怎么办？有一个功能叫格式化代码（Reformat Code），快捷键是： Mac：Command+Option+L Win：Ctrl+Shift+L 如果想按照你指定的规则进行格式化，可以按照如下方式进行自定义： FindBugs-IDEAFindBugs 是一款老牌 Java 静态检查插件了。它的功能和阿里 p3c 那个插件很像，只不过它历史悠久、国际化一点。它同样的可以扫描代码，发现一些可能会引入 Bug 的代码段，给出参考建议。 启动 FindBugs 的方式，右键菜单中，Findbugs 提供了好几个选项： Analyze Current File：检查当前文件 Analyze Class uner Cursor：检查光标处的类 Analyze Package Files：检查包文件 Analyze Modul Files：检查 Module 文件 Analyze Project Files：检查项目文件 Analyze Scope Files：检查指定范围内的文件 Analyze All Modified Files：检查所有修改过的文件 Analyze changelist files：检查变更列表中的文件 检查结果： 检查结果分为如下类别： Bad practice：不好的做法，代码违反了公认的最佳实践标准； Malicious code vulnerbility：恶意的代码漏洞； Correctness：可能不正确，比如错误的强制类型转换； Performance：潜在的性能问题； Security：安全性； Dodgy code：糟糕的代码，FindBugs团队认为该类型下的问题代码导 Bug 的可能性很高； Experimental：实验； Multithreaded correctness：关注于同步和多线程问题； Internationalization：国际化 扫描出来的结果怎么看懂，官网有专门的一页介绍 FindBugs Bug Description http://findbugs.sourceforge.net/bugDescriptions.html 除了上面右键菜单启动检查之外，还可以在相应文件夹右键菜单中启动： 针对检查的严格程度，其实是可以调节的，建议修改为 low，这样会尽可能的扫描出有潜在 Bug 的代码片段： 总结以上是目前工作中经常用到的静态代码检查插键，虽然不是用了它们就真的能写出好代码，但是这些工具的确能够让你能够在前人的肩膀上少踩一些坑。比如阿里的那个检查插键，你可以按照它的提示，对照着他们的 Java 开发手册查看，分析一下，为何他们会有如此的规约。高楼大厦不都是一砖一瓦砌成的嘛？小知识点的基础打扎实了，才能走得更高！ 由于国内网络问题，我提前将最新版的《阿里巴巴 Java 开发手册（泰山版）.pdf》上传至云盘了，有需要的小伙伴公众号后台回复 泰山版 即可获得下载链接。 一言上周的写的一篇文章分享到微信群里，群友有人指出来标题有错别字，真是有点尴尬！其实，我写文章也比较随意，也是最近才开始坚持每周至少输出一篇分享的。但想想既然写了，就要尽量保证质量。引以为戒，以后要认真点才行！ 目前分享的内容主要是开发环境、效率工具等。自己一直对这方面的文章比较感兴趣，因此之前就有相关积累。今后希望能通过阅读带来一些读书总结的分享，也希望关注的同学后台多留言，给出你的建议，感谢~ 生命不息，折腾不止！关注 「Coder魔法院」，祝你 Niubilitiy ！ 参考 代码缺陷扫描神器——FindBugs：https://juejin.im/entry/591ad01ba22b9d005833903e 调试Java Stream Debugger 可以查看stream中间操作的数据状态 jclasslib IDEA 如何使用jclasslib 插件查看 Java 字节码 VisualVM Launcher 对于经常实用 visualvm 进行性能调优和 debug 的场景，这个快速启动 visualvm 并打开正在调试的应用的按钮。 使用技巧Key Promoter X 快捷键提示 IDE Feature Trainer 安装之后，可以在 View &gt; Tool Windows &gt; Learn 里打开练习页面，了解 IDEA 的快捷键。 界面优化Rainbow Brackets 彩虹括号，这个插件方便查看括号的匹配 ctrl+鼠标右键点击 所在区域高亮 alt+鼠标右键点击 非所选区域外不高亮 CodeGlance 可以在编辑区的右边增加一个类似 VSCode 的缩略图的效果，拖动比较方便。 辅助功能Statistic 代码统计 Maven Helper：安装之后，直接打开pom文件，即可查看依赖数，还能自动分析是否存在 jar 包冲突，查看idea 中解决maven 包冲突的问题 GitToolBox Git 功能增强，比如可以在状态栏显示当前光标所在行的修改者 Restful Tookit：编写 RESTful 接口必不可少的插件，编写完接口当然还需要调试，可以搭配HTTP Client 一起使用 Dash: ctrl+shift+h 语言支持BashSupport 花里胡哨activate-power-mode：写代码的时候，就会附加一些狂拽炫酷屌炸天的效果 AceJump：允许您快速将光标导航到编辑器中可见的任何位置，只需点击ctrl +;，然后输入一个你想要跳转到的字符，之后键入匹配的字符就跳转到你想要挑战的地方了 参考那些提高效率的Idea插件]]></content>
      <categories>
        <category>ToolsDev</category>
      </categories>
      <tags>
        <tag>IDE IDEA Pycharm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[202016周 菜谱 辣子鸡 & 辣炒蚬子肉]]></title>
    <url>%2F2020%2F04%2F19%2Ffood-spicy-chicken-clams%2F</url>
    <content type="text"><![CDATA[辣子鸡 辣子鸡，又名辣子鸡丁，起源于重庆，所以也有人称之为重庆辣子鸡或歌乐山辣子鸡。一道经典的川菜。食客吃这道菜就是在享受辣椒中寻找鸡块的感觉 鸡块切小，入味 腌制鸡肉： 食用盐 胡椒粉 料酒 生抽 酱油 鸡蛋黄 菜品颜色金黄 淀粉 植物油 辅料： 生姜切姜末 大蒜，蒜末 香葱头 干辣椒（七星椒、子探头、灯笼椒） 青花椒 撒料： 花生米 芝麻 花椒油、芝麻香油 步骤： 油温七成热，炸鸡肉 1 分钟定型 鸡肉捞出 油温八成肉，复炸 20 秒 捞出鸡肉 辅料用热油爆香 鸡肉下锅，慢炒2分钟 调味，味精、白糖、香醋、加入撒料，小火翻炒均匀 装盘 辣炒花蚬子肉辅料： 香葱 姜 蒜 郫县豆瓣酱（家里没有豆瓣酱，用的黄豆酱替代，味道也OK） 淀粉 耗油 生抽 糖 步骤： 蚬子肉热水烧开，放点葱、料酒去腥 蚬子肉捞出沥水 热油爆炒香葱头、姜片、蒜、干辣椒 放入适量豆瓣酱炒出红油 放入蚬子肉翻炒均匀 放入调料：料酒、生抽、耗油、盐、少量清水 烧开后放入淀粉、香葱，翻炒均匀 装盘]]></content>
      <categories>
        <category>风味人间</category>
      </categories>
      <tags>
        <tag>川菜</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Elasticsearch安装及集群的配置]]></title>
    <url>%2F2020%2F04%2F12%2Felk-es-install%2F</url>
    <content type="text"><![CDATA[简介首先引用 Elasticsearch （下文简称 ES）官网的一段描述： Elasticsearch 是一个分布式、RESTful 风格的搜索和数据分析引擎，能够解决不断涌现出的各种用例。 作为 Elastic Stack 的核心，它集中存储您的数据，帮助您发现意料之中以及意料之外的情况。 本文主要介绍 Elasticsearch 集群的搭建。通过在一台服务器上创建 3 个 ES 实例来创建一个建议的 ES 集群。 Elasticsearch/ES官方的Elasticsearch Reference 提供了不同版本的文档连接，真是赞！ 如果英文的不想看，还提供了中文版的 Elasticsearch 2.x: 权威指南，版本不是最新的，但是了解基本概念也是有帮助的。 Elasticsearch 7.x 包里自包含了 OpenJDK 的包。如果你想要使用你自己配置好的 Java 版本，需要设置 JAVA_HOME 环境变量 —— 参考 官方文档 Set up Elasticsearch 有各个 OS 的安装指导，页面 Installing Elasticsearch 中提供了多种安装包对应的指导链接！ 本文选择绿色安装包的的方式（tar.gz）安装。 由于实验机器有限，可以在同一台机器上模拟出 3 个节点，安装 ES 集群。 安装 ES准备工作 不能使用 root 用户启动 es，否则会报错：Caused by: java.lang.RuntimeException: can not run elasticsearch as root 如果需要新建用户的话可以运行 sudo adduser es，修改 es 用户的密码：sudo passwd es。 下载 ES 安装包安装包下载地址： 官方-Past Releases 官网的下载速度龟速 华为镜像站 下载速度不错，推荐 下面的步骤参考 Set up Elasticsearch » Installing Elasticsearch » Install Elasticsearch from archive on Linux or MacOS，选择的安装包是 elasticsearch-7.3.0 版本。 123456789101112# 下载安装包wget https://mirrors.huaweicloud.com/elasticsearch/7.3.0/elasticsearch-7.3.0-linux-x86_64.tar.gzwget https://mirrors.huaweicloud.com/elasticsearch/7.3.0/elasticsearch-7.3.0-linux-x86_64.tar.gz.sha512# 验证安装包的完整性，如果没问题，会输出 OKshasum -a 512 -c elasticsearch-7.3.0-linux-x86_64.tar.gz.sha512tar -xzf elasticsearch-7.3.0-linux-x86_64.tar.gz# 将目录复制三份，作为三个节点，后面配置 ES 集群时，对应了三个 ES 实例cp -R elasticsearch-7.3.0 es-7.3.0-node-1cp -R elasticsearch-7.3.0 es-7.3.0-node-2mv elasticsearch-7.3.0 es-7.3.0-node-3# 因为以 root 用户启动不了 ESchown -R es es-7.3.0* 如果是 Mac 平台，则下载包 elasticsearch-{version}-darwin-x86_64.tar.gz。MacOS Catalina 在你第一次运行 ES 时，会弹出对话框阻止运行，你需要到设置-》安全隐私中允许才行。为了阻止这种告警，可以运行如下的命令：xattr -d -r com.apple.quarantine &lt;$ES_HOME or archive-or-directory&gt; $ES_HOME 是指 ES 的安装包 tar 包解压后的文件夹目录。 解压后的目录组成： 1234567891011.├── bin # 二进制脚本存放目录，包括 elasticsearch 来指定运行一个 node，包括 elasticsearch-plugin 来安装 plugins├── config # 包含了 elasticsearch.yml 配置文件├── data # 节点上分配的每个 index/分片 的数据文件├── lib├── LICENSE.txt├── logs├── modules├── NOTICE.txt├── plugins # 插键文件存放的位置└── README.textile 运行 Elasticsearch我们先运行一个节点，创建 ES 单机版实例： 1./bin/elasticsearch 如果要将 ES 作为守护程序运行，请在命令行中指定 -d，指定 -p 参数，将进程 ID 记录到 pid 文件： 1./bin/elasticsearch -d -p pid 日志在 $ES_HOME/logs 目录中。 如果要停止 ES，运行如下的命令： 1pkill -F pid 检查一下运行状态1curl -X GET "localhost:9200/?pretty" 或者在浏览器中访问 localhost:9200 都可以，会返回： 1234567891011121314151617&#123; "name": "node-1", "cluster_name": "appsearch-7.3.2", "cluster_uuid": "GlzI_v__QJ2s9ewAgomOqg", "version": &#123; "number": "7.3.0", "build_flavor": "default", "build_type": "tar", "build_hash": "de777fa", "build_date": "2019-07-24T18:30:11.767338Z", "build_snapshot": false, "lucene_version": "8.1.0", "minimum_wire_compatibility_version": "6.8.0", "minimum_index_compatibility_version": "6.0.0-beta1" &#125;, "tagline": "You Know, for Search"&#125; 如果你是在远端服务器上部署的 ES，那么，此时在你本地的工作机上还无法调通 &lt;IP&gt;:9200，需要对 ES 进行相关配置才能访问，下文会介绍。 ES 配置相关官网关于配置的内容主要有两处： Configuraing Elasticsearch Important Elasticsearch configuration Elasticsearch 主要有三个配置文件： elasticsearch.yml ES 的配置，more jvm.options ES JVM 配置，more log4j2.properties ES 日志配置，more 配置文件主要位于 $ES_HOME/config 目录下，也可以通过 ES_PATH_CONF 环境变量来修改 YAML 的配置形式参考：123path: data: /var/lib/elasticsearch logs: /var/log/elasticsearch 设置也可以按如下方式展平：12path.data: /var/lib/elasticsearchpath.logs: /var/log/elasticsearch JVM 配置JVM 参数设置可以通过 jvm.options 文件（推荐方式）或者 ES_JAVA_OPTS 环境变量来修改。 jvm.options 位于 $ES_HOME/config/jvm.options 当通过 tar or zip 包安装 /etc/elasticsearch/jvm.options 当通过 Debian or RPM packages 官网也介绍了如何设置堆大小。 默认情况，ES 告诉 JVM 使用一个最小和最大都为 1GB 的堆。但是到了生产环境，这个配置就比较重要了，确保 ES 有足够堆空间可用。 ES 使用 Xms(minimum heap size) 和 Xmx(maxmimum heap size) 设置堆大小。你应该将这两个值设为同样的大小。 Xms 和 Xmx 不能大于你物理机内存的 50%。 设置的示例：12-Xms2g -Xmx2g elasticsearch.yml 配置ES 默认会加载位于 $ES_HOME/config/elasticsearch.yml 的配置文件。 备注：任何能够通过配置文件设置的内容，都可以通过命令行使用 -E 的语法进行指定，例如： 1./bin/elasticsearch -d -Ecluster.name=my_cluster -Enode.name=node_1 通过 -E 会覆盖掉 elasticsearch.yml 中的配置。 cluster.namecluster.name 设置集群名称。一个节点只能加入一个集群中，默认的集群名称是 elasticsearch。 1cluster.name: search-7.3.2 确保节点的集群名称要设置正确，这样才能加入到同一个集群中。上面示例就自定义了集群名称为 appsearch-7.3.2。 node.namenode.name：可以配置每个节点的名称。用来提供可读性高的 ES 实例名称，它默认名称是机器的 hostname，可以自定义： 1node.name: node-1 同一集群中的节点名称不能相同 network.hostnetwork.host：设置访问的地址。默认仅绑定在回环地址 127.0.0.1 和 [::1]。如果需要从其他服务器上访问以及多态机器搭建集群，我们需要设定 ES 运行绑定的 Host，节点需要绑定非回环的地址。建议设置为主机的公网 IP 或 0.0.0.0： 1network.host: 0.0.0.0 更多的网络设置可以阅读 Network Settings http.porthttp.port 默认端口是 9200 ： 1http.port: 9200 注意：这是指 http 端口，如果采用 REST API 对接 ES，那么就是采用的 http 协议 transport.portREST 客户端通过 HTTP 将请求发送到您的 Elasticsearch 集群，但是接收到客户端请求的节点不能总是单独处理它，通常必须将其传递给其他节点以进行进一步处理。它使用传输网络层（transport networking layer）执行此操作。传输层用于集群中节点之间的所有内部通信，与远程集群节点的所有通信，以及 Elasticsearch Java API 中的 TransportClient。 transport.port 绑定端口范围。默认为 9300-9400 1transport.port: 9300 因为要在一台机器上创建是三个 ES 实例，这里明确指定每个实例的端口。 discovery.seed_hostsdiscovery.seed_hosts：发现设置。有两种重要的发现和集群形成配置，以便集群中的节点能够彼此发现并且选择一个主节点。官网/Important discovery and cluster formation settings discovery.seed_hosts 是组件集群时比较重要的配置，用于启动当前节点时，发现其他节点的初始列表。 开箱即用，无需任何网络配置， ES 将绑定到可用的环回地址，并将扫描本地端口 9300 - 9305，以尝试连接到同一服务器上运行的其他节点。 这无需任何配置即可提供自动群集的体验。 如果要与其他主机上的节点组成集群，则必须设置 discovery.seed_hosts，用来提供集群中的其他主机列表（它们是符合主机资格要求的master-eligible并且可能处于活动状态的且可达的，以便寻址发现过程）。此设置应该是群集中所有符合主机资格的节点的地址的列表。 每个地址可以是 IP 地址，也可以是通过 DNS 解析为一个或多个 IP 地址的主机名（hostname）。 当一个已经加入过集群的节点重启时，如果他无法与之前集群中的节点通信，很可能就会报这个错误 master not discovered or elected yet, an election requires at least 2 nodes with ids from。因此，我在一台服务器上模拟三个 ES 实例时，这个配置我明确指定了端口号。 配置集群的主机地址，配置之后集群的主机之间可以自动发现（可以带上端口，例如 127.0.0.1:9300）： 1discovery.seed_hosts: ["127.0.0.1:9300","127.0.0.1:9301"] the default discovery settings are unsuitable for production use; at least one of [discovery.seed_hosts, discovery.seed_providers, cluster.initial_master_nodes] must be configured 必须至少配置 [discovery.seed_hosts，discovery.seed_providers，cluster.initial_master_nodes] 中的一个。 cluster.initial_master_nodescluster.initial_master_nodes: 初始的候选 master 节点列表。初始主节点应通过其 node.name 标识，默认为其主机名。确保 cluster.initial_master_nodes 中的值与 node.name 完全匹配。 首次启动全新的 ES 集群时，会出现一个集群引导/集群选举/cluster bootstrapping步骤，该步骤确定了在第一次选举中的符合主节点资格的节点集合。在开发模式下，如果没有进行发现设置，此步骤由节点本身自动执行。由于这种自动引导从本质上讲是不安全的，因此当您在生产模式下第一次启动全新的群集时，你必须显式列出符合资格的主节点。也就是说，需要使用 cluster.initial_master_nodes 设置来设置该主节点列表。重新启动集群或将新节点添加到现有集群时，你不应使用此设置 在新版 7.x 的 ES 中，对 ES 的集群发现系统做了调整，不再有 discovery.zen.minimum_master_nodes 这个控制集群脑裂的配置，转而由集群自主控制，并且新版在启动一个新的集群的时候需要有 cluster.initial_master_nodes 初始化集群主节点列表。如果一个集群一旦形成，你不该再设置该配置项，应该移除它。该配置项仅仅是集群第一次创建时设置的！集群形成之后，这个配置也会被忽略的！ cluster.initial_master_nodes 该配置项并不是需要每个节点设置保持一致，设置需谨慎，如果其中的主节点关闭了，可能会导致其他主节点也会关闭。因为一旦节点初始启动时设置了这个参数，它下次启动时还是会尝试和当初指定的主节点链接，当链接失败时，自己也会关闭！因此，为了保证可用性，预备做主节点的节点不用每个上面都配置该配置项！保证有的主节点上就不设置该配置项，这样当有主节点故障时，还有可用的主节点不会一定要去寻找初始节点中的主节点！ 关于 cluster.initial_master_nodes 可以查看如下资料： Bootstrapping a cluster Discovery and cluster formation settings 其他集群的主要配置项上面已经介绍的差不多了，同时也给出了一些文档拓展阅读。实际的生产环境中，配置稍微会复杂点，下面补充一些配置项的介绍。需要说明的是，下面的一些配置即使不配置，ES 的集群也可以成功启动的。 下文节点角色会对上文中的 node.master 等配置做了介绍。如果本地仅是简单测试使用，上文中的 node.master/node.data/node.ingest 不用配置也没影响。 节点角色Node默认情况，一个节点 Node 包含下面所有的角色：master-eligible, data, ingest, and machine learning (if available)。 节点类型 配置参数 默认值 master eligible node.master true data node.data true ingest node.ingest true coodrinating only 无 设置上面三个参数全部为 false machine learning node.ml true (需要 enable x-pack) 随着群集的增长，尤其是如果您有大量机器学习工作，需要考虑将具有主机资格（master-eligible）的节点专用，将它与专用数据的节点（data nodes）和专用机器学习的节点（machine learning nodes）分开。我理解，这里的专用（dedicated）一词就是表示，将一个节点的角色不要设置那么多，主节点资格的节点就是用于当主节点，而不是同时设置数据节点的角色！ 开发环境中，一个节点可以承担多种角色 生产环境中，应该设置单一的角色的节点（dedicated node） 本文 ES 是 7.3.0 版本，查看官方文档，发现 ES 7.9.0 的配置和它是有点区别的。 master-eligible nodemaster-eligible node：默认值就是 true，意味着每个节点启动后，默认就是一个 Master eligible 节点。具有该角色的节点表示它有资格被选举为 mater node。备注：eligible 一词表示符合条件的含义。 主节点负责维护集群的状态，集群范围内的轻量级操作（只有 Master 节点才能修改集群的状态信息），例如： 创建或删除索引， 跟踪哪些节点是集群的一部分 确定将哪些分片分配给哪些节点 分片的路由信息 任意节点都能修改信息，会导致数据的不一致性 拥有稳定的主节点对于群集健康非常重要。 在主节点选举过程中，任何一个非 voting-only 的 master-eligible 节点都可能被选为主节点。 很好理解，如果已经是「仅是选举」用途的节点，它怎么能称为主节点呢？ 索引和搜索数据是占用大量CPU，内存和 I/O 的工作，这可能给节点的资源带来压力。为了确保主节点稳定且不受压力，在较大的群集中，最好将符合角色的专用主节点和专用数据节点分开。 尽管主节点还可以充当协调节点（coordinating nodes），将搜索和索引请求从客户端路由到数据节点，但最好不要为此目的使用专用的主节点。对于符合主节点要求的节点，其工作量应尽可能少，这对于群集的稳定性很重要。 概括来讲就是，主节点的机器不要身兼数职，不要给主节点配置其他节点角色，以免影响主节点的稳定性！ 1234567891011121314# 可选为主节点（默认是 true）node.master: true# voting_only 角色不启用（默认也是 false） node.voting_only: false# data 角色不启用 （默认是 true） node.data: false # inges 角色不启用（默认是 true）node.ingest: false # ml 角色不启用（默认是 true）node.ml: false # xpack.ml.enabled 默认是启用的xpack.ml.enabled: true # 默认是 truecluster.remote.connect: false xpack 功能时付费功能，因此，一般情况下，可以忽略 xpack 的设置。 一个集群中可以有多个 master 节点，active 的 master 节点只有一个！ Voting-only master-eligible node一个具有 voting-only master-eligible 两种角色的节点，它是参与主节点的选举但不会充当主节点的节点。特别指出，voting-only 可以在选举中为决胜局服务。 要配置一个具有主机资格的节点为 voting-only 节点，需要如下配置 12# 默认是 falsenode.voting_only: true 注意：OSS-only 分布式版本不支持 voting-only 角色。只有 master-eligible 的节点才能标记为 voting-only 角色！这里虽然有点难理解，但是由于历史原因造成的。 一个高可用的集群（HA —— High Avaliablity clusters）至少需要 3 个 master-eligible 角色的节点、至少 2 个不是 voting-only 节点。这样的集群将能够在一个主节点故障时选出一个主节点。 一个具有 voting-only master-eligible 两种角色的节点同样也可以赋予其他的角色。例如，一个节点可以同时赋予 voting-only master-eligible data 3 种角色。专用于 voting-only master-eligible 的节点配置如下： 12345678node.master: true# 默认不启用，需要设置为 false node.voting_only: true node.data: false node.ingest: false node.ml: false xpack.ml.enabled: true cluster.remote.connect: false Data Node数据节点包含您已建立索引的文档的分片。数据节点处理与数据相关的操作，例如： CRUD， 搜索和聚合。 数据节点在数据扩展上起到了至关重要的作用 这些操作是 I/O，内存和 CPU 密集型的。监视这些资源并在过载时添加更多数据节点非常重要。 具有专用数据节点的主要好处是将主节点角色和数据节点角色分开。 参考如下配置：123456789101112# 默认是 truenode.master: false # 默认是 falsenode.voting_only: false # 默认是 truenode.data: true # 默认是 truenode.ingest: false # 默认是 truenode.ml: false # 默认是 truecluster.remote.connect: false Ingest Node接收节点（Ingest nodes）可以执行由一个或多个接收处理器组成的预处理管道。根据摄取处理器执行的操作类型和所需的资源，拥有专用的摄取节点可能会很有意义，这些节点仅会执行此特定任务。 Ingest 节点也称为预处理节点。 123456node.master: false node.voting_only: false node.data: false node.ingest: true node.ml: false cluster.remote.connect: false Ingest Node，可以用来承担一些数据管道的数据转换工作，例如，为你的文档增加一个新的字段，例如帮转换文档中的字段。 Coordinating only nodes如果您不具备处理主节点职责、保存数据和预处理文档的能力，那么你就剩下一个仅可路由请求的协调节点角色（coordinating only nodes），处理搜索缩减阶段、分配批量索引的。本质上，coordinating only nodes 可充当智能负载平衡器。 负责接受 Client 的请求，将请求分发到合适的节点，最终把结果汇集到一起。 每个节点默认都起到了 Coordinating Node 的职责 仅协调节点也称为负载均衡节点或 Client 节点 在集群中添加过多的仅协调节点可能会增加整个集群的负担，因为选择的主节点必须等待每个节点的集群状态更新确认！仅协调节点的好处不应被夸大 —— 数据节点可以很好地达到相同的目的。 为了创建一个仅协调节点（coordinating only node），可以如下配置： 123456node.master: false node.voting_only: false node.data: false node.ingest: false node.ml: false cluster.remote.connect: false 其他节点类型 Hot &amp; Warm Node 不同硬件配置的 Data Node，用来实现 Hot &amp; Warm 架构，降低集群部署的成本 Machine Learning Node 负责跑机器学习的 Job，用来做异常检测 单一职责节点一个节点只承担一个角色，总结图： 参考 官宣-Elasticsearch Reference [7.3] » Modules » Node learnku-笔记五十二：集常见的集群部署方式 Elasticsearch集群规划求助 创建集群实验机器有限，我们在同一台机器上创建三个 ES 实例来创建集群，分别明确指定了这些实例的 http.port 和 transport.port。discovery.seed_hosts明确指定实例的端口对测试集群的高可用性很关键。 如果后期有新节点加入，新节点的 discovery.seed_hosts 没必要包含所有的节点，只要它里面包含集群中已有的节点信息，新节点就能发现整个集群了。 集群配置预览分别进入es-7.3.0-node-1、es-7.3.0-node-2 和 es-7.3.0-node-3 的文件夹，config/elasticsearch.yml 设置如下： 123456789101112131415161718192021222324252627282930313233# es-7.3.0-node-1cluster.name: search-7.3.2node.name: node-1node.master: truenode.data: falsenode.ingest: falsenetwork.host: 0.0.0.0http.port: 9200transport.port: 9300discovery.seed_hosts: ["127.0.0.1:9300","127.0.0.1:9301","127.0.0.1:9302"]cluster.initial_master_nodes: ["node-1"]# es-7.3.0-node-2cluster.name: search-7.3.2node.name: node-2node.master: truenode.data: truenode.ingest: falsenetwork.host: 0.0.0.0http.port: 9201transport.port: 9301discovery.seed_hosts: ["127.0.0.1:9300","127.0.0.1:9301","127.0.0.1:9302"]# es-7.3.0-node-3cluster.name: search-7.3.2node.name: node-3node.master: truenode.data: truenode.ingest: falsenetwork.host: 0.0.0.0http.port: 9202transport.port: 9302discovery.seed_hosts: ["127.0.0.1:9300","127.0.0.1:9301","127.0.0.1:9302"] node-1 节点仅仅是一个 master 节点，它不是一个数据节点。 经过上面的配置，可以通过命令 egrep -v &quot;^#|^$&quot; config/elasticsearch.yml 检查配置项。 先启动 node-1 节点，因为它设置了初始主节点的列表。这时候就可以使用 http://&lt;host IP&gt;:9200/ 看到结果了。然后逐一启动 node-2 和 node-3。通过访问 http://127.0.0.1:9200/_cat/nodes 查看集群是否 OK： 123192.168.3.112 25 87 13 4.29 dm - node-3192.168.3.112 26 87 16 4.29 dm - node-2192.168.3.112 35 87 16 4.29 m * node-1 http://127.0.0.1:9200/_nodes 将会显示节点更多的详情信息 插键显示结果： 五角星表示该节点是主节点，圆圈表示该节点是数据节点 有没有发现，我并没有给 node-2 和 node-3 明确指定端口，为什么在一台机器上也成功启动了这两个节点？ 因为 Elasticsearch 会取用 9200~9299 这个范围内的端口，如果 9200 被占用，就选择 9201，依次类推。 补充：其实，还有一个简单的方法模拟创建集群（该方法我未测试，仅供参考）。 我们首先将上面运行的三个节点停止掉，然后进入 es-7.3.0-node-1 文件夹下： 1234mkdir -p data/data&#123;1,2,3&#125;./bin/elasticsearch -E node.name=node-1 -E cluster.name=appsearch-7.3.2 -E path.data=data/data1 -E path.logs=logs/logs1 -d -p pid1./bin/elasticsearch -E node.name=node-2 -E cluster.name=appsearch-7.3.2 -E path.data=data/data2 -E path.logs=logs/logs2 -E http.port=9201 -d -p pid2./bin/elasticsearch -E node.name=node-3 -E cluster.name=appsearch-7.3.2 -E path.data=data/data3 -E path.logs=logs/logs3 -E http.port=9202 -d -p pid3 安装插键1234# 查看已经安装的插键列表bin/elasticsearch-plugin list# 安装一个国际化分词插键bin/elasticsearch-plugin install analysis-icu 如果插键安装慢，可以先下载下来，再安装： 12wget https://artifacts.elastic.co/downloads/elasticsearch-plugins/analysis-icu/analysis-icu-7.3.0.zip./bin/elasticsearch-plugin install file://file path Of analysis-icu-7.1.0.zip 如下 API 也可以查看 ES 插键列表：1http://127.0.0.1:9200/_cat/plugins 一个三个节点的 ES 集群，如果安装插件则需要三个节点都安装 ES-FAQQ1：[1]: max virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144]12echo "vm.max_map_count=262144" &gt; /etc/sysctl.confsysctl -p Q2：max file descriptors [4096] for elasticsearch process is too low, increase to at least [65536]1234567sudo vim /etc/security/limits.conf# 加入以下内容* soft nofile 300000* hard nofile 300000* soft nproc 102400* soft memlock unlimited* hard memlock unlimited Q3：master_not_discovered_exception主节点指定的名字要保证存在，别指定了不存在的节点名。 总结本文是通过 tar 包方式安装的，安装目录相对集中、配置方便。用 RPM 包安装的话，可以直接用 systemctl 的命令查看 ES 状态、对其重启等。 参考 learnku/Elasticsearch中文文档-7.3版本 推荐 ES-CN 官网/Elasticsearch 集群协调迎来新时代 对于 ES7 的集群发现机制介绍较为详细，推荐 程序羊-CentOS7上ElasticSearch安装填坑记 FAQ 有帮助 搭建ELFK日志采集系统 静觅—Ubuntu 搭建 Elasticsearch 6 集群流程 ELK 架构之 Elasticsearch 和 Kibana 安装配置 使用 ELK(Elasticsearch + Logstash + Kibana) 搭建日志集中分析平台实践 手把手教你，在CentOS上安装ELK，进行服务器日志收集]]></content>
      <categories>
        <category>ELK</category>
      </categories>
      <tags>
        <tag>ELK</tag>
        <tag>Search</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mac 10.15 Catalina 开机登录壁纸图片修改]]></title>
    <url>%2F2020%2F03%2F04%2Ftools-mac-change-wallpaper-login%2F</url>
    <content type="text"><![CDATA[前言为了修改 macOS 10.15 Catalina 系统开机时的登录界面的壁纸，折腾了好一会儿才搞定，没想到这么麻烦，记录一贴，方便有需求的小伙伴借鉴 步骤 关闭 SIP：重启 Mac，在开机时立马按住 Command+R 键，直到看到苹果的logo-》选择语言-》选择账户-》下一步进入macOS实用工具的界面，然后点击上方菜单栏的「实用工具」下的「终端」，输入下面的命令： 1csrutil disable 将准备好的壁纸下载到「下载」目录下，当然，你也可以放到其他目录下，但是本文以该目录下的壁纸文件作为操作路径。将壁纸重命名为 Catalina.heic 打开访达，在菜单栏上点击「前往 - 前往文件夹」，或者使用快捷键 Command+Shift+G 打开「前往文件夹」，路径地址 /System/Library/Desktop Pictures。默认的登录时的壁纸就位于该文件夹下。使用命令行操作比较简单： 12345678# 这个命令是把分区 mount 成可写模式。这个命令在系统重启后失效sudo mount -uw /# 备份原来的默认壁纸sudo cp /System/Library/Desktop\ Pictures/Catalina.heic ~/Downloads/Catalina.old.heic# 将下载后重命名好的壁纸替换掉默认路径下的壁纸sudo cp -f ~/Downloads/Catalina.heic /System/Library/Desktop\ Pictures/Catalina.heic# 执行了下面这行关键操作之后，开机壁纸才最最终生效！查了很多资料都没提到这个diskutil apfs updatePreboot / 注意点： 现在网上很多 Mojave 系统的教程，路径说的是 /Library/Desktop Pictures/，其实已经不适用了。 diskutil apfs updatePreboot / 这个命令执行之后，开机壁纸才最终成功修改成功，很多旧教程中没有提到 修改完毕之后，建议按照步骤一的方式开启 SIP，命令行是：csrutil enable 参考 CSDN——MMac OS 10.15 修改登录壁纸 CSDN——MAC：Read-only file system问题 少数派——macOS 开启或关闭 SIP]]></content>
      <categories>
        <category>ToolsDaily</category>
      </categories>
      <tags>
        <tag>Tools</tag>
        <tag>Mac</tag>
        <tag>壁纸</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 必备命令利器 —— sed]]></title>
    <url>%2F2020%2F02%2F18%2Flinux-command-sed%2F</url>
    <content type="text"><![CDATA[虽然之前对常用的 Linux 命令有过一个总结 工作中常用的 Linux 命令，但是有一些命令的用法确实值得为她单独写一篇总结。今天我们就来认识一下 sed。 概述sed 是一个流编辑器（stream editor，或许，sed 缩写的含义就是这个）。流编辑器用于对输入流（文件或来自管道的输入）执行基本的文本转换。 sed在管道中过滤文本的能力，这使其与其他类型的编辑器特别有区别。 地址定界符今天看到一个 sed 的写法，sed &#39;s#^key##&#39;，一开始没看明白，因为之前都是类似 sed &#39;s/^//&#39; 这样写的。后来查了资料才发现，/、#、@ 都是地址定界符，效果是一样的。 增加12345678910111213141516171819202122[root@607bac0e5f20 demo]# sed -i '1i demo learn' demo.txt[root@607bac0e5f20 demo]# cat demo.txtdemo learnhello michaelhello qq[root@607bac0e5f20 demo]# sed -i '2a sunny smile' demo.txt[root@607bac0e5f20 demo]# cat demo.txtsed demo learnhello michaelsunny smilehello qq[root@607bac0e5f20 demo]# sed '$a end' demo.txtsed demo learnhello michaelsunny smilehello qqend[root@607bac0e5f20 demo]# cat demo.txtsed demo learnhello michaelsunny smilehello qq 说明： -i 参数加上之后，会去「就地」修改 demo.txt 这个文件，不加的话，demo.txt 的内容不会被修改； 1i 表示文件第1行内容加上内容，i 效果是读取第一行之前增加 include 记录。有点 VIM 的 i 的效果； 2a 表示文件第2行捏偶人后面加上内容，a 效果就是读取此行之后增加 append 记录。优点 VIM 的 a 的效果； $ 表示文件尾，在最后一行增加，则可用 $a 表示； 如果需要在匹配的地方增加一行，可以：1234567[root@607bac0e5f20 demo]# sed -i '/michael/i michael is michael' demo.txt[root@607bac0e5f20 demo]# cat demo.txtsed demo learnmichael is michaelhello michaelsunny smilehello qq 说明： 上面这里的 /michael/i 这里的 i 当然也可以换成 a，那么，插入的位置会有不同； 如果插入的行以空格开头，可用 \ 来转义这个空格 如果多行都满足匹配条件，那么就会多出插入内容； 如果插入的内容要换行，可用 \n 表示换行符，可以实现插入2行的效果 删删除和增加差不多，只需要把 i 或 a 替换为 d。 示例文本内容如下：123456[root@607bac0e5f20 demo]# cat -n demo.txt 1 sed demo learn 2 michael is michael 3 hello michael 4 sunny smile 5 hello qq 把第1行删除：12345[root@607bac0e5f20 demo]# sed '1d' demo.txtmichael is michaelhello michaelsunny smilehello qq 将和 michael 匹配的行删除：1234[root@607bac0e5f20 demo]# sed '/michael/d' demo.txtsed demo learnsunny smilehello qq 将 smile 匹配行和其下一行内容删除：1234[root@607bac0e5f20 demo]# sed '/smile/&#123;N;d&#125;' demo.txtsed demo learnmichael is michaelhello michael 说明： 这里的 N 表示 next line 的意思。 如果不想删除 smile 这行，仅仅是删除 smile 匹配行的下一行呢？ 12345[root@607bac0e5f20 demo]# sed '/smile/&#123;N;s/\n.*//&#125;' demo.txtsed demo learnmichael is michaelhello michaelsunny smile 说明： s/\n.*// 这里表示匹配了下一行的内容，然后用空字符替换掉了这一行，即实现了删除下一行的效果 改、替换示例文本内容如下：123456[root@607bac0e5f20 demo]# cat -n demo.txt 1 sed demo learn 2 michael is michael 3 hello michael 4 sunny smile 5 hello wheel 每行开头增加 China, 的内容：123456[root@607bac0e5f20 demo]# sed 's/^/China,/' demo.txtChina,sed demo learnChina,michael is michaelChina,hello michaelChina,sunny smileChina,hello wheel 说明： s 表示 substitute，替换的意思； ^ 表示一行的开头，行尾用 $ 表示，又和 VIM 的操作一样； 扩展： 12345\&lt; 表示词首。 如：\&lt;abc 表示以 abc 为首的詞。\&gt; 表示词尾。 如：abc\&gt; 表示以 abc 結尾的詞。. 表示任何单个字符。* 表示某个字符出现了0次或多次。[ ] 字符集合。 如：[abc] 表示匹配a或b或c，还有 [a-zA-Z] 表示匹配所有的26个字符。如果其中有^表示反，如 [^a] 表示非a的字符 将所有的 michael 替换为 `Michael：123456[root@607bac0e5f20 demo]# sed 's/michael/Michael/g' demo.txtsed demo learnMichael is Michaelhello Michaelsunny smilehello wheel 说明： g 代表整行范围内的所有匹配全部替换，如果不加，那么只会匹配每一行第一个匹配的内容，比如，文本第二行，有两个 michael，如果不加 g，那么，第二个 michael 将不会 -&gt; Michael。如果用 2 的话，则表示只替换第 2 个匹配项。还可以用 i 忽略大小写 如果想让匹配的内容后面加上指定字符呢，比如，上面文本中， el 匹配的后面加上 -dev 的字符：123456789101112[root@607bac0e5f20 demo]# sed 's/el/&amp;-dev/g' demo.txtsed demo learnmichael-dev is michael-devhel-devlo michael-devsunny smilehel-devlo wheel-dev[root@607bac0e5f20 demo]# sed -r 's/(el)/\1-dev/g' demo.txtsed demo learnmichael-dev is michael-devhel-devlo michael-devsunny smilehel-devlo wheel-dev 说明： 第一种方法中，&amp; 表示匹配上的内容； 第二种方法，-r 表示扩展的正则表达式，圆括号表示分组，第一个圆括号是第一组，替换的时候则用 \1 表示，一次类推； 将2-3行的 michael 替换为 xiang： 123456[root@607bac0e5f20 demo]# sed '2,3s/michael/xiang/g' demo.txtsed demo learnxiang is xianghello xiangsunny smilehello wheel 将第2行的内容替换为 hello mike：123456[root@607bac0e5f20 demo]# sed '2s/.*/hello mike/g' demo.txtsed demo learnhello mikehello michaelsunny smilehello wheel 使用变量的值用于替换的表达式中，需要用双引号：123456789[root@607bac0e5f20 demo]# name=Michael[root@607bac0e5f20 demo]# echo $nameMichael[root@607bac0e5f20 demo]# sed "s/wheel/$&#123;name&#125;/g" demo.txtsed demo learnmichael is michaelhello michaelsunny smilehello Michael 说明： 如果不用双引号，那么，文本最后一行将会是这样的 hello ${name}; 删除所有的符号： 123456789101112[root@607bac0e5f20 demo]# cat demo.txtFirst, sed demo learnSecond, michael is michaelThird, hello michaelFourth, sunny smileFifth, hello wheel[root@607bac0e5f20 demo]# sed 's/[[:punct:]]//g' demo.txtFirst sed demo learnSecond michael is michaelThird hello michaelFourth sunny smileFifth hello wheel 说明： [[:punct:]] 是正则表达式中预先定义的子字符类（character classes），代表所有的标点符号。sed 支持的子字符类如下： 123456789101112:alnum:]：[0-9A-Za-z][:alpha:]：[A-Za-z][:blank:]：空格和TAB[:cntrl:]：控制字符（Control characters），ASCII码为000~037和177 (DEL)[:digit:]：[0-9][:graph:]：[:alnum:]和[:punct:][:lower:]：[a-z][:print:]：[:alnum:]、[:punct:]和空格[:punct:]：符号 ! “ # $ % &amp; ‘ ( ) * + , - . / : ; &lt; = &gt; ? @ [ \ ] ^ _ ` &#123; | &#125; ~[:space:]：[:blank:]和回车、换行等[:upper:]：[A-Z][:xdigit:]：16进制 [0-9A-Fa-f] 参考 官宣-sed, a stream editor 权威文档 CoolShell-SED 简明教程 看例子学sed growing-up/doc/三十分钟学会SED.md]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>command</tag>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2020 规划]]></title>
    <url>%2F2020%2F01%2F05%2Fplan-2020%2F</url>
    <content type="text"><![CDATA[Reading Great Code 文章中提到了，要想变成更优秀的程序员，需要去阅读、理解和欣赏优秀的代码。可见，阅读的重要性。 回顾2019 工作上：转型 2019 年，由部门内的构建小组进入到了部署小组，真是 CICD 全流程体验了。技术栈也由 Python 变为了 Java。『转型』的难点其实往往不是技术的困扰，更多的是业务类型的差异，一切都要从零开始！很庆幸，自己适应过来了…… 2019 生活：今年的国庆和媳妇儿一起去日本关西地区玩了一周。印象深刻，不虚此行。深深地感觉到，国内一二线城市虽然可能硬件设施、基建上面已经追赶上了发达国家，但是素质、职业精神等『看不见』的地方还有很长一条道路要走。 展望 OKR 的核心：制定一个较长期的目标，并且将目标分解成为一些关键的结果 O：Objective 目标 KR：Key Result 关键结果 参考： OKR 工作法简介 PS：规划的脑图采用 ProcessOn]]></content>
      <categories>
        <category>规划</category>
      </categories>
      <tags>
        <tag>总结</tag>
        <tag>规划</tag>
        <tag>阅读</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Maven 基础知识]]></title>
    <url>%2F2020%2F01%2F05%2Fjava-tools-maven%2F</url>
    <content type="text"><![CDATA[简介Maven是Java项目构建工具，可以用于管理Java依赖，还可以用于编译、打包以及发布Java项目，类似于JavaScript生态系统中的NPM。 构建环节：清理-编译-测试-报告-打包-部署 清理：将编译代码前生成的内容删除 编译：将源代码编译为字节码 测试：运行单元测试用例 报告：测试程序的结果 打包：将 java 项目打成 java 包；将 Web 项目达成 war 包； 安装：将 jar 或 war 生成到 Maven 仓库中； 部署：将 jar 或 war 从 Maven 仓库中部署到 Web 服务器上运行； 安装maven官方安装包，直接下载二进制包，我使用的是 apach-maven-3.6.2-bin.tar.gz 1234weget http://mirrors.tuna.tsinghua.edu.cn/apache/maven/maven-3/3.6.2/binaries/apache-maven-3.6.2-bin.tar.gztar xvf apache-maven-3.6.2-bin.tar.gz -C ~/optecho &quot;export PATH=$PATH:/Users/michael/opt/apache-maven-3.6.2/bin&quot; &gt;&gt; ~/.zshrcsource ~/.zshrc 到此，Mac 环境的 maven 的就已经安装好了，检测： 1mvn --version 来源 my-config-files/maven/ 配置相关settings.xml文件可以定义本地仓库的实际路径： 1&lt;localRepository&gt;/path/to/local/repo&lt;/localRepository&gt; Maven 镜像源设置，第一个 mirror 才会生效，其他的只是放这儿，后期可以将某个调整至第一个，使其生效，提高下载速度和稳定性： 123456789101112131415161718192021 &lt;!-- https://blog.csdn.net/sayyy/article/details/80447757 --&gt; &lt;mirror&gt; &lt;!--This sends everything else to /public --&gt; &lt;id&gt;nexus&lt;/id&gt; &lt;mirrorOf&gt;*&lt;/mirrorOf&gt; &lt;url&gt;https://maven.aliyun.com/nexus/content/groups/public/&lt;/url&gt; &lt;/mirror&gt; &lt;mirror&gt; &lt;!--This is used to direct the public snapshots repo in the profile below over to a different nexus group --&gt; &lt;id&gt;nexus-public-snapshots&lt;/id&gt; &lt;mirrorOf&gt;public-snapshots&lt;/mirrorOf&gt; &lt;url&gt;https://maven.aliyun.com/nexus/content/repositories/snapshots/&lt;/url&gt; &lt;/mirror&gt;&lt;!-- https://mirrors.huaweicloud.com/ --&gt;&lt;!-- https://bbs.huaweicloud.com/forum/forum.php?mod=viewthread&amp;tid=1779 --&gt; &lt;mirror&gt; &lt;id&gt;huaweicloud&lt;/id&gt; &lt;mirrorOf&gt;*&lt;/mirrorOf&gt; &lt;url&gt;https://mirrors.huaweicloud.com/repository/maven/&lt;/url&gt; &lt;/mirror&gt; 注：&lt; mirrorOf&gt;可以设置为哪个中央仓库做镜像，为名为“central”的中央仓库做镜像，写作&lt; mirrorOf&gt;central&lt; /mirrorOf&gt;;为所有中央仓库做镜像，写作&lt; mirrorOf&gt;*&lt; /mirrorOf&gt;。Maven默认中央仓库的id 为 central。id是唯一的。 重要：除非你有把握，否则不建议使用&lt; mirrorOf&gt;*&lt; /mirrorOf&gt;的方式。 参考： IntellJ IDEA配置Maven以及修改默认Repository pom.xmlpom.xml中，&lt;project&gt;&lt;/project&gt;为最外层的标签； &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;定义了所使用的POM版本。这2个标签基本上是不变的。 groupId、artifactId 与 version 一起则定义了模块的坐标( Coordinates )，每个公共模块的坐标应该是唯一的： groupId：组织名称，通常是把域名反过来，例如 com.fundebug artifactId：模块名称，比如一个微服务的项目名称，例如 fundebug-java version：模块版本，例如 0.2.0 通常项目版本号分为 3 段，主版本号.次版本号.修订版本号 SNAPSHORT 表示开发中的版本； RELEASE 表示一个正式发布版本，也可能没有任何后缀也表示正式版 M1 M2 ... M 表示里程碑，即将发布； RC( Release Candicate) 发布候选 GA(General availability) 基本可用版本 SNAPSHORT&lt;M1&lt;M2&lt;...&lt;RC&lt;GA&lt;RELEASE SpringBoot Star 中可以看到版本的一个示例： &lt;dependencies&gt;&lt;/dependencies&gt;定义了当前项目所依赖的模块。Maven 可以根据 &lt;dependency&gt;&lt;/dependency&gt; 中定义的坐标，自动下载所依赖的模块。在 MacBook 上，Maven 将下载的模块缓存在 $HOME/.m2/ 目录。 参考： fundebug-Maven入门教程 推荐 Maven 常用命令 mvn compile 编译 Maven 工程，生成一些 class 文件和配置文件； mvn package 编译并打包，根据 pom.xml 中元素 packaging 是 jar 还是 war 进行打包。 mvn install 打包并安装到本地仓库。比如 env-service 服务可以安装到本地，deploy-service 服务可以通过项目在本地引用到； mvn deploy 同 install，但打包并安装到远程仓库； mvn clean 删除 target 目录； 最近项目中用来打包生成 jar 包的命令： 1mvn clean package 会在同目录下生成一个 target 目录，jar 包就在该子目录下； 同时，另外一个项目是 gradle 写的，类似命令： 1gradle -x test build 跳过测试阶段，生成的 jar 包在 build 的子目录中； Gradle vs Maven 推荐]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Maven</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[用英语做 Presentation 的常用词汇和句型]]></title>
    <url>%2F2019%2F11%2F24%2Fenglish-presentation-words%2F</url>
    <content type="text"><![CDATA[开场 hello everyone I&#39;m zhangxiang and I&#39;m very happy to be here It&#39;s an honor to have the opportunity to address such a distinguished audience. Good morning, eyeryone. I appreciate the opportunity to present of making this presentation I&#39;m very glad to have a chance here to make a speech on the subject---Health 引出主题 The subject of my presentation is …… I shall be speaking today about …… My presentaion conserns …… 发言说明 My presentation will last for about ten minutes... I know that time is short, so I intend to keep this brief. Please feel free to interrupt me if you have questions. There will be time for questions at the end of the presentation. 概要 My presentation is divided into three main sections. My presentation is in three parts. Firstly, secondly, thirdly, finally… 主体部分 As I said at the beginning… 总结 in summary in conclusion, I&#39;d like to… To summarise, I… I hope you have found this useful That brings me to the end of my presentation. I&#39;ve talked about… 观众提问重述一下问题是个聪明的办法，可以确认你是否理解了问题，同时，给自己一些时间来思考 That&#39;s an interesting question. How are we going to get voluntary redundancy? Thank you. So you would like further clarification on our strategy? 回答完毕后，确认提问者是否满意。 Does this answer your question? I hope this explains the situation for you. 如果你不知道如何作答，就说不知道。承认无知总比妄自猜测要好 I&#39;m afraid I&#39;m unable to answer that at the moment. Perhaps I can get back to you later. That&#39;s a very good question. However, we don&#39;t have any figures on that, so I can&#39;t give you an accurate answer. Unfortunately, I&#39;m not the best person to answer that. 各种状况观众没听懂？ Let me just say that in another way. Put it another way, this means… 过渡词 transitions表递进 moreover besides furthermore what is more in addition in other words 确保观众跟上你的思路，转到下一个话题： The next topic/point I&#39;d like to talk about is how to …… now we are going to talk about this point OK/Right, I&#39;d now like to move on to… I&#39;d like to turn to… 我要转移到 表顺序 first, second, third then/next finally to begin with first of all 表可能 probably perhaps 展示例子 I&#39;ve prepared a demonstration to show how this work Let&#39;s see a demonstration which applies waht we&#39;ve learned As you can see… This clearly shows … 返回之前的观点 Let&#39;s return Let&#39;s go back to ... 表比较 相似 similarly likewise in the same way 表转折 however on the other side on the other hand on the contrary 因果关系 therefore as a result consequently for that reason 表举例 in a word 参考 Presentation实用表达总结]]></content>
      <categories>
        <category>Soft Skills</category>
      </categories>
      <tags>
        <tag>English</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mac 免费支持 Windows 可用的移动硬盘/U盘]]></title>
    <url>%2F2019%2F11%2F17%2Ftools-mac-support-ntfs%2F</url>
    <content type="text"><![CDATA[图片链接 前言Windows 上的磁盘格式，默认一般都是 NTFS 格式。Mac 能够直接从 NTFS 格式的磁盘拷贝文件，但是不支持直接从 Mac 上拷贝文件到 NTFS 磁盘。 最早在 OSX 10.5的时候，OSX 其实原生就支持直接写入 NTFS 的盘的，后来由于微软的限制，把这个功能给屏蔽了，我们可以通过命令行手动打开这个选项。 这时候一般上网查到的都是推荐去购买软件. Paragon NTFS for Mac(¥139) Tuxera NTFS for Mac(¥99) 开源免费的 mounty-brew cask install mounty，但是這個免費的好像更新不頻繁了，最近一次还是 2018年9月份，现在都是2019年11月份了，最新的系統测试不OK。 偶然发现有办法可以通过设置，让 Mac 免费支持 NTFS，在最新的系统 macOS Catalina(10.15.1) 测试 OK 🤡 这时候有两个场景： 1.你的移动硬盘或者U盘可以格式化位 ExFAT 格式，因为 Windows 和 Mac 都支持这种格式。 2.移动硬盘或者U盘上的内容比较多，不方便转移后，进行格式化，这时候，就需要通过如下的方法进行设置了。 配置1.查看磁盘的 Volume Name 1diskutil list 可以看到的这个磁盘名叫做 Seagate翔。 如果 Volume Name 有空格，用 \040 表示空格。 2.更新 /etc/fstab 文件 1sudo vi /etc/fstab 添加： 1LABEL=Seagate翔 none ntfs rw,auto,nobrowse rw 表示把这个分区挂载为可读写的 ntfs 格式 nobrowse 这个代表了在 finder 里不显示这个分区，这个选项非常重要，如果不打开的话挂载是不会成功的 3.将移动硬盘/USB拔出重插，然后在 Finder-&gt;前往-&gt;前往文件夹，输入：/Volumes，这时候可以看到我的移动硬盘，拖动它至Finder的边栏『个人收藏』，后面就可以方便打开和推出。 4.将磁盘快捷方式添加到桌面： 1sudo ln -s /Volumes/Seagate翔 ~/Desktop/Seagate翔 缺点如果后面有其他便携硬盘设置使用，需要按照上面步骤再操作适配一下。因此，本文需要收藏好，以后还要查阅参考。 参考 CSDN——Mac OSX 打开原生自带读写NTFS功能 chad——Mac开启原生NTFS读写功能 最后 本文地址 Mac 免费支持 Windows 可用的移动硬盘/U盘]]></content>
      <categories>
        <category>ToolsDaily</category>
      </categories>
      <tags>
        <tag>Tools</tag>
        <tag>Mac</tag>
        <tag>NTFS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[neovim 安装及插键配置]]></title>
    <url>%2F2019%2F11%2F17%2Ftools-vim-plugin-neovim-plug%2F</url>
    <content type="text"><![CDATA[Vim 学习系列： Vim 基础 Vim 插件及配置 neovim 安装及插键配置 安装 NeoVimVim 主要开发目前就一个人，开发效率低，年久失修。为了让 Vim 有一个快速的迭代速度，neovim 应运而生。 安装： 1brew install neovim neovim 的官方配置文件在 /Users/michael/.config/nvim/init.vim 123# edit ~/.zshrcalias vim=&apos;nvim&apos;alias vi=&apos;nvim&apos; 检查：1nvim +checkhealth 支持 Python 语言： 1pip install neovim --upgrade 插键 vim-plug安装 vim-plug插键没使用 Vundle，而是采用 vim-plug Vundle是之前Vim插件管理比较流行的工具。转向使用Vim-Plug，最大的原因还在于相比Vundle，所有的插件更新和安装都是并行的，这样比Vundle效率提升了不是一点半点。 此外，最令人心动的，是Vim-Plug的杀手级特性：按需加载控件，可以让你根据不同的需求，决定某些插件在什么时机开始加载，从而大大提升Vim/NeoVim的启动速度。 安装 vim-plug 的脚本： 12curl -fLo ~/.vim/autoload/plug.vim --create-dirs \ https://raw.githubusercontent.com/junegunn/vim-plug/master/plug.vim 配置 vim-plug1234# 将已有的 Vim 配置，用于 nvim# .vim 文件夹会存放插键相关内容，比如 vim-plug 的内容ln -s ~/.vim ~/.config/nvimln -s ~/.vimrc ~/.config/nvim/init.vim 常用命令：12345678910# 安装插键:PlugInstall# 检查状态:PlugStatus# 删除插键（需要先将 ~/.config/nvim/init.vim 中注释掉相关插键）:PlugClean# 更新插键: PlugUpdate# 升级 vim-plug:PlugUpgrade 将需要安装的插键写入 ~/.vimrc 的如下命令之间，然后执行 :PlugInstall：1234call plug#begin()# 这里写上需要安装的插键Plug &apos;tpope/vim-sensible&apos;call plug#end() 常用插键 vim-airline/vim-airline 状态栏插件 vim-airine vim-airline/vim-airline-themes 状态来主题，预览 jiangmiao/auto-pairs 自动引号&amp;括号补全 以引号输入为例，说明如何使用这个插件。按下 “，会自动变成双引号””，此时光标位于双引号的中间，等待插入文本，文本插入结束以后，通常我们希望把光标置于右边引号的后面继续输入，此时，再按一次 “，光标就会跳转到右边引号的后面，等待我们继续输入文本 scrooloose/nerdtree 文件管理器 nerdtree :NERDTree 即可打开当前编辑文件所在的目录 按住 Ctrl, 双击 w 可以在两个窗口之间切换 把光标移动到该文件，然后按 o，即可在右边窗口打开该文件 在该窗口直接按 q 即可退出 Shougo/deoplete.nvim 自动补全插键 之前的文章也写了一些插键的使用。 最后放上我的 Vim 配置文件地址：my-config-files/vim/ 参考 Mac的VIM中delete键失效的原因和解决方案 Vim 插键及配置 jdhao——Linux 下 Neovim 安装与配置 Python 开发环境指南 Timothy——从Vim到NeoVim]]></content>
      <categories>
        <category>ToolsDev</category>
      </categories>
      <tags>
        <tag>Tools</tag>
        <tag>Vim</tag>
        <tag>neovim</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git基础 —— Github 使用技巧]]></title>
    <url>%2F2019%2F11%2F14%2Fgit-github-experiance%2F</url>
    <content type="text"><![CDATA[Git 基础学习系列 Git 基础 —— 安装 配置 别名 对象 Git 基础 —— 常用命令 Git 基础 —— 常见使用场景 Git 基础 —— Github 的使用 Github 的利用Github feature 官宣，介绍了 Github 的主要特性。 详细演示下怎么给一个项目发起 Pull Request(PR) 第一步，找到你想发起 PR 的项目，点击右上角的 Fork 按钮，然后该项目就出现在了你自己账号的 Repository 里。 第二步，把fork的项目 clone 到本地，然后修改的 bug 也好，想要新增的功能也好，总之把自己做的代码改动开发完，接着，把自己做的代码改动 push 到 你自己的 GitHub 上去。 第三步，点击你 Fork 过来的项目主页的 Pull requests 页面，点击右上角的New pull request。 页面自动会比较该项目与原有项目的不同之处，最顶部声明了是源仓库的分支与你fork过来的分支的对比。同样的我写好标题和描述，然后我们点击中间的 Create pull request 按钮，至此我们就成功给该项目提交了一个 PR。 然后就等着项目原作者 review 你的代码，并且决定会不会接受你的 PR，如果接受，那么恭喜你，你已经是该项目的贡献者之一了。 发现好用的开源项目GitHub 其中一个最重要的作用就是发现全世界最优秀的开源项目，你没事的时候刷刷微博、知乎，人家没事的时候刷刷 GitHub ，看看最近有哪些流行的项目，久而久之，这差距就越来越大，那么如何发现优秀的开源项目呢？ 关注一些活跃的大牛 Explore菜单下的Trending，看到最近的一些热门开源项目，很多人主动获取开源项目的最好的途径，可以选择“当天热门”，“一周之内热门”和“一月之内热门”来查看，并且，可以分语言来查看。 Search，按照Most Stars来筛选。 GitHub 的 Search 还有一些小技巧： 使用高级搜索的功能，搜索语法见 Understanding the search syntax； 使用 in:readme 可以扩大搜索的范围，否则直接输入输入搜索文字，只在仓库名、描述的内容中去匹配搜索； 搜索词示例：123git 最好 学习 资料 in:readme stars:&gt;2000# 搜仓库里带有 gitlab-ci.yml 的仓库，同时文件里有 after_script + stge:deploy 内容，根据代码内容搜索&apos;after_script&apos;+&apos;stage: deploy&apos; filename:.gitlab-ci.yml 除此之外，有些人如果习惯用 Google 进行搜索，那么想搜索 GitHub 上的结果，不妨前面加 GitHub 关键字就ok了，比如我在 google 里输入 GitHub android http ，每个关键字用空格隔开。 怎么选择团队适合的工作流主干开发Facebook 采用主干开发模式。如果没有质量保证的话，commit 容易出现错误，要能快速迭代，才能采用主干开发模式。 Git Flow流程太过复杂，互联公司不太常见，和主干开发模式不同，它类似于特性分支模式。Github Flow：特性分支开发测试完毕，回合到主干，既可以立即发布了 Gitlab Flow 带生产分支 master 分支用于持续集成的，特性分支会集成到 master，production 分支用于发布的。 Gitlab Flow 带环境分支：Gitlab Flow 带发布分支：因为硬件有多个版本，为了适配这些硬件，同一个时间点，可能会针对硬件发布多个版本 如何挑选合适的分支集成策略Github &gt; Insights &gt; Network 可以看到版本演进; Settings 中，有一个 Merge Button，可以选择 MR 的方式：Github 的合并策略： allow merge commits：合入主干时，会产生一个 merge commit； allow squash merging：相当于把你的提交会先合并成一个 commit，然后再提交，这样的话，你原来的特性分支没有变，主干分支多了一个 commit，主干也是线性演进； allow rebase merging：主干是一个线性演进，看着很舒服，实质上就是特性分支的一个个 cherry pick 到主干上，比如特性分支上有3个 commit，那么执行之后，主干也就产生3个 commit 了，原特性分支没有变化；上面，仅仅是 Github 的 MR 策略，与 Gitlab 的策略也是有所区别的。 可以根据软件包发布时是从什么分支上发布的，分为主干开发和分支开发，从主干分支上出包发布，就叫主干开发，从特性分支上出包的，就叫分支开发。 启用 issue 跟踪需求和任务仓库的 settings 页面，有启用 issue 的按钮，默认是勾选的，可以 set up template，可以选择预设的模板。模板文件是放在仓库的 .github 文件夹中，可以参考 vue 项目的模板 如何用 project 管理 issue？在仓库的 projects 页面可以创建 project，也是有 template 的。以后添加 issue 时，就可以选择对应的 project。 晨会过进度的时候，还是很方便直观的。后期可以通过项目看板帮我们有序的管理任务和推进。 项目团队怎么实施 code review?在仓库 settings branches 中添加规则，支持 release* 这样的规则，通配符，还可以指定 review 的其他规则，比如审核人要几个等。 通过 pull request 发起 review 的申请。 福利GitHub 上影响力很大，同时又对你们很有用的项目： free-programming-books: 这个项目整理了所有跟编程相关的免费书籍，而且全球多国语言版的都有，中文版的在这里 free-programming-books-zh ob-my-zsh: 俗话说，不会用 shell 的程序员不是真正的程序员。oh-my-zsh 毫无疑问就是目前最流行，最酷炫的 shell zsh+on-my-zsh配置教程指南（程序员必备） awesome: GitHub 上有各种 awesome 系列，简单来说就是这个系列搜罗整理了 GitHub 上各领域的资源大汇总，比如有 awesome-android, awesome-ios, awesome-java, awesome-python 等等等，就不截图了，你们自行去感受。 github-cheat-sheet: GitHub 的使用有各种技巧，只不过基本的就够我们用了，但是如果你对 GitHub 超级感兴趣，想更多的了解 GitHub 的使用技巧，那么这个项目就刚好是你需要的，每个 GitHub 粉都应该知道这个项目。 LearningNotes：这是一份非常详细的面试资料，涉及 Android、Java、设计模式、算法等等等，你能想到的，你不能想到的基本都包含了，可以说是适应于任何准备面试的 Android 开发者，看完这个之后别说你还不知道怎么面试！ 补充-Gitlab DevOps-Tools DevOps-lifecycle Gitlab-ee/boards Gitlab 的看板示例，本身企业版的开发讨论； Gitlab 代码集成 流水线 保证集成的质量，要想跑 CI，需要在 CI/CD 中注册 Runner。]]></content>
      <categories>
        <category>ToolsDev</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git 基础 —— 常见使用场景]]></title>
    <url>%2F2019%2F11%2F14%2Fgit-usage-examples%2F</url>
    <content type="text"><![CDATA[Git 基础学习系列 Git 基础 —— 安装 配置 别名 对象 Git 基础 —— 常用命令 Git 基础 —— 常见使用场景 Git 基础 —— Github 的使用 突然插入 Bugifx 工作，回退工作目录 git stash 保存所有工作内容，放到一个特殊的区域，为了避免遗忘，可以 git stash save [message] 保存一点提示信息； git stash list 查看保存列表，如 stash@{2} 和 stash@{1}，序号中数字大的代表的是较早的 stash； git stash show stash@{0} -v 比较当前工作目录和 stash 的内容做比较； git stash clear 可以清除刚刚所有保存的信息； 解决完 bug，又要切回之前的状态：1git stash pop|apply [stash] apply 作用，恢复之前存放的内容，stash 列表中的内容还在； pop 恢复之前内容后，stash 列表中的内容就不存在了； 用法：12git stash pop stash@&#123;2&#125;git stash pop 我们 pop 的时候可以加具体的序号，不加序号的（缺省情况下）为 stash@{0}。 stash 回来是有可能发生冲突的，需要解决冲突 多人单分支协作有个新特性需要开发，在远端仓库新建了特性分支 feature/add_gitcommand，现在，团队中的多人需要基于这个分支进行协作开发。 本地拉取特性分支进行开发如果远端这个分支已有同事提交了代码，而本地还没有这个分支，需要先 fetch 远端分支到本地（本地裸仓库中会增加相关 commit 信息），才能在 git branch -av 中看到这个远端分支信息：1git fetch github 注意，因为我本地仓库添加了多个远端主机，此处的 github 是我当时 git remote add 时给远端主机起的别名，一般会叫 origin。 接着，在本地创建并切换到远端特性分支：12# 拉取远端分支时，会自动将本地的这个分支和其关联git checkout -b feature/add_gitcommand github/feature/add_gitcommand 如果直接 push 的话，往往会遇到错误。因为在你提交之前，远端分支又有了新的提交，有时候内容和你修改的地方一样，还会有冲突。只要你的提交落后了，那么不管有没有冲突，推送时都会报错： 为了避免上面的问题，在本地开发提交之后，执行推送操作之前需要拉取远端在进行合并：1234git pull github# pull 等价于下面两个操作git fetch githubgit merge github/feature/add_gitcommand 发生了冲突，需要我们在推送之前先本地解决一下冲突： 查看有冲突的文件1234567hello&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEADwe are on feature/add__gitcommandwe are on michael728=======we are on feature/add__gitcommand 123&gt;&gt;&gt;&gt;&gt;&gt;&gt; c6fc3bc57c65f099a45b1c98b6ce2782a2c072f9 HEAD 和 ===== 之间的内容就是发生冲突的地方，这之间的内容是我们本地提交的内容，==== 和 &gt;&gt;&gt;&gt;&gt; 之间的是远端的内容。 删除这些标记行，然后重新 add、commit，最终 git push github即可推送到远端特性分支了，如果只关联了一个远端仓库，那么直接git push即可。 什么时候会有冲突呢？远端修改的地方，比如修改了第一行，而本地也修改了第一行，这时候 merge 的时候，就会发生冲突。 同时变更了文件名某同事在他提交时，通过 git mv 命令重命名了一个文件，index.html to index.htm，并且推送到了远端仓库中。 这时候我在本地修改了 index.html 内容，并进行了提交，准备推送到远端。因为远端又比本地多了提交记录，所以会 rejected，这时候执行：1git pull 执行完之后，发现本地 Git 自动帮我们也对文件进行了重命名并进行了内容的合并。 前面讲 Git 的文件存储时，说 Git 存放 blob 文件时是以文件内容来区分的，并不以文件名来区分；此处的变更文件名操作和变更文件内容的操作能够自动被 Git 处理，原因就在于 blob 文件并没有发生修改的冲突。 如果其中一个人既变更了文件名又修改了文件，同时另一个人也修改了该文件的同一位置的内容，就会被 Git 识别为冲突，而不能自动进行处理了，处理方法和下面一种情况类似，都需要手动来处理了。 把同一文件修改为了不同的文件名A修改了文件的文件名并进行了提交推送到了远端，B也修改了文件名，这时候也准备推送。 diff index1.html index2.html 发现两个文件内容一致，通过 git status 查看状态，需要自己手动进行处理。 Git 集成的禁忌 禁止向集成分支执行 git push -f 操作，集成分支会丢失 commit 的； 禁止向集成分支执行变更历史的操作，公共的分支严禁拉到本地，进行 rebase 操作的，因为这也会造成丢失 commit； 想知道某行代码谁修改的阅读代码时，想知道某行代码是谁修改的？ 找到对应 commit id： 1git blame src/xxx.c 查看具体提交的内容 1git show &lt;commit id&gt; 回退到历史版本 查找commit id通过git log查找想要会退到的历史版本的commit id 本地执行回退 12# 这会让工作区和暂存区都回退到这个 commit id 对应的时间点的状态git reset --hard [commit id] 强制推送1git push -f 参考：git 远程仓库版本的回退以及git reset 几种常用方式记录 cherry-pick将某一提交点的修改拿到当前分支上：git cherry-pick &lt;commit id&gt; 这会将那次的提交与当前内容进行合并，然后生成一个新的 commit。 关于这个命令，专门总结了一篇 查找 Git 仓库的活跃贡献者输出git repo中前十位最活跃的提交者：1git shortlog -s | sort -rn | head 如何将 Git 仓库备份到本地常用的传输协议： 直观区别：哑协议传输进度不可⻅；智能协议传输可⻅。 传输速度：智能协议⽐哑协议传输速度快。 创建用作备份的裸仓库，通常位于远端 哑协议克隆一个不带工作区的（bare）裸仓库： 1git clone --bare /Users/michael/Code/Git-Geek/git_learning 智能协议克隆一个裸仓库并重命名： 12# /Users/michael/Code/Git-Geek/666-backup/zhineng.gitgit clone --bare file:///Users/michael/Code/Git-Geek/git_learning/.git zhineng.git 为了将本地工作仓库备份到远端仓库，下面，切到之前的工作仓库：1234# /Users/michael/Code/Git-Geek/git_learninggit remote -v # 发现没有关联的远端仓库git remote add zhineng file:///Users/michael/Code/Git-Geek/666-backup/zhineng.git # 发生关联了git push zhineng file:///Users/michael/Code/Git-Geek/666-backup/zhineng.git 就是表示的远端备份仓库地址。 从远端备份仓库克隆：1git clone file:///Users/michael/Code/Git-Geek/666-backup/zhineng.git git_learnging_2019 从一个 Git 仓库搬迁到另外一个 Git 仓库中 新建一个空仓库B，注意，不要勾选生成 README.md 文件； git clone --bare A仓库 git push --mirror B仓库 这种方式最方便，一次性把分支、tag、commit 记录都同步过去了 参考： 从一个git仓库迁移到另外一个git仓库 本地代码库关联到另外的一个代码库12345cd existing_repogit remote rename origin old-origingit remote add origin ssh://git@github.com:2222/Michael/my-config-files.gitgit push -u origin --allgit push -u origin --tags 仓库设置多个远端仓库1234git remote add github git@github.com:Michael728/awesome-books-for-me.gitgit push -u github mastergit remote add gitee git@gitee.com:michael_xiang/awesome-books-for-me.gitgit push -u gitee master Git lfs 管理大文件Git LFS（Large File Storage, 大文件存储）是 Github 开发的一个 Git 的扩展，用于实现 Git 对大文件的支持。 Git LFS可以把音乐、图片、视频等指定的任意文件存在 Git 仓库之外，而在 Git 仓库中用一个占用空间 1KB 不到的文本指针来代替文件的存在。 通过把大文件存储在 Git 仓库之外，可以减小 Git 仓库本身的体积，使克隆 Git 仓库的速度加快，也使得 Git 不会因为仓库中充满大文件而损失性能。 使用细节，可以看码云的介绍：Git LFS 操作指南 常用命令：12345678910# 使用 Git LFS 管理指定的文件git lfs track "*.psd"# 查看当前使用 Git LFS 管理的匹配列表git lfs track# 不再使用 Git LFS 管理指定的文件git lfs untrack "*.psd"# 类似 git status，查看当前 Git LFS 对象的状态git lfs status# 枚举目前所有被 Git LFS 管理的具体文件git lfs ls-files Git FAQgit merge和git rebase的区别rebase 跟 merge 的区别你们可以理解成有两个书架，你需要把两个书架的书整理到一起去，第一种做法是 merge ，比较粗鲁暴力，就直接腾出一块地方把另一个书架的书全部放进去，虽然暴力，但是这种做法你可以知道哪些书是来自另一个书架的；第二种做法就是rebase ，他会把两个书架的书先进行比较，按照购书的时间来给他重新排序，然后重新放置好，这样做的好处就是合并之后的书架看起来很有逻辑，但是你很难清晰的知道哪些书来自哪个书架的。 只能说各有好处的，不同的团队根据不同的需要以及不同的习惯来选择就好。 rebase 和 merge 的另一个区别是rebase 的冲突是一个一个解决，如果有十个冲突，先解决第一个，然后用命令 12git add -ugit rebase --continue 继续后才会出现第二个冲突，直到所有冲突解决完，而merge 是所有的冲突都会显示出来。 另外如果rebase过程中，你想中途退出，恢复 rebase 前的代码则可以用命令 1git rebase --abort 关于git rebase还有很多知识点： 聊下git rebase -i git merge 和 git rebase 小结 Git Community Book 中文版-rebase 压缩多个Commit 合并多个 Commit 其他资料 IBM-Git 进阶：比较、回滚、撤销、分支合并和冲突解决]]></content>
      <categories>
        <category>ToolsDev</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git 基础 —— 常用命令]]></title>
    <url>%2F2019%2F11%2F14%2Fgit-useful-commands%2F</url>
    <content type="text"><![CDATA[Git 基础学习系列 Git 基础 —— 安装 配置 别名 对象 Git 基础 —— 常用命令 Git 基础 —— 常见使用场景 Git 基础 —— Github 的使用 git init创建 Git 本地仓库 远端无仓库，本地无仓库，本地新建一个仓库1git init git_learning 远端有仓库，本地无仓库，拉取远端仓库到本地1234567git clone git@github.com:Michael728/michael-git.gitcd michael-git# 提交一个 readme 文件touch README.mdgit add README.mdgit commit -m &quot;add README&quot;git push -u origin master 远端有空仓库，本地已有项目文件，关联远端仓库查看我们当前项目有哪些远程仓库可以执行如下命令：1git remote -v 如果发现没有关联远端仓库，可以这么做：12345cd micahel-gitgit init # 如果本地已经是一个 Git 仓库，这行就跳过git remote add origin git@github.com:Michael728/michael-git.git # 添加一个远端主机，并命名为 origingit push -u origin --all # --all 表示 push all branches，-u 选项指定了一个默认主机git push -u origin --tags # --tags All refs under refs/tags are pushed 将本地的master分支推送到origin主机，同时指定origin为默认主机，后面就可以不要再指定远端主机名 origin 了，直接使用git push。 远端主机名可以定义为其他，比如 github。通过 git remote add 命令，一个仓库其实可以与多个远端仓库发生关联的，这时候只要远端主机名取不一样的即可区别。为什么要给远程仓库取名字？因为我们可能一个项目有多个远程仓库，比如，Github一个，比如公司一个，这样的话，提交的时候可以提交到不同的远程仓库就需要指定不同的仓库名字了。 参考： git push 的 -u 参数具体适合含义？ Git远程操作详解 git clone下载一个远程仓库：1git clone [-b br_name] &lt;git@github.com:Michael728/michael-git.git&gt; [本地仓库名] 克隆的时候，可以指定下载远端的分支、自定义本地仓库的名字。如果不加分支名参数，git clone 命令会默认自动设置本地 master 分支跟踪克隆的远程仓库的 master 分支（其实是仓库的默认分支，大部分仓库默认分支是 master）。同时，默认远端主机设置别名为 origin。 git mv文件重命名：1git mv &lt;old filename&gt; &lt;new filename&gt; git branch git branch -r 只显示远端分支， git branch -a 显示本地分支和远程分支 新建分支新建 develop 分支，并切换到 develop 分支：1234git branch developgit checkout develop# 新建并切换分支git checkout -b develop 本地分支推送到远端仓库本地分支推送到远程服务器时，远程分支自动创建，推送本地分支到远程：1git push --set-upstream &lt;remote_host_name&gt; &lt;local_branch_name&gt;:&lt;remote_branch_name&gt; &lt;remote_host_name&gt;：远程 Git 服务器名称，一般为origin &lt;local_branch_name&gt;：本地分支名称 &lt;remote_branch_name&gt;：远程分支名称 --set-upstream参数用来关联本地分支和远程分支 一般情况下，本地分支和远程分支名称相同，所以可简化为： 1git push --set-upstream &lt;remote_host_name&gt; &lt;branch_name&gt; 参考： Git创建远程分支 阮一峰–Git远程操作详解 查看本地分支123git branch # 查看本地分支git branch -r # 查看远端分支git branh -av # 查看所有分支，信息详细点 删除分支删除本地分支：12git branch -d developgit branch -D develop # 强制删除 删除远程分支：123git push origin :&lt;remote_branch_name&gt;# 和如下命令等同git push origin --delete &lt;remote_branch_name&gt; 如果待删除的分支中的提交已经存在于其他分支，那么，需要检出到那个分支，然后才可以安全的删除该分支。当然，也可以将待删除的分支先 merge 到当前分支之后，再安全删除分支。这样做，其实是为了避免提交丢失。 意外删除分支或者其他引用后，可以使用 git reflog 命令恢复它。 分支命名可以使用层次命名的方式，方便明白分支用途。比如在 bug 分支下建立不同的分支，如 bug/pr-1023、bug/pr-17。这种斜杠语法给你的分支名引进某种结构。 通过如下的简写，可以一次查看所有分支信息： 1git show-branch bug/* 分支名命名的注意事项： 不能包含空格或其他特殊空白字符 不能包含一些特殊含义字符，比如 ~`:?`等 git add多个场景会用到这个命令: 可以用它开始跟踪新文件 把已跟踪的文件放到暂存区 还能用于合并时把有冲突的文件标记为已解决状态，这个是在解决冲突时会用到的功能 常用命令： git add -u：将文件的修改、文件的删除，添加到暂存区，用-u有个好处，避免把工作区没准备好的新文件直接加到暂存区了，用的较多； git add .：将文件的修改，文件的新建，添加到暂存区，慎用； git add -A/--all：将文件的修改，文件的删除，文件的新建，添加到暂存区，慎用； git add -A相对于git add -u命令的优点 ： 可以提交所有被删除、被替换、被修改和新增的文件到数据暂存区，而git add -u只能操作跟踪过的文件。 在发出 git add 命令时，每个文件的全部内容将被复制到对象库中，并且按照文件的 SHA1 名来索引。暂存一个文件也叫缓存一个文件或是把文件放进索引。与其把 git add 看成添加这个文件，不如看做添加这个内容 git diff比较工作区和暂存区的差异将工作区和暂存区所有文件进行比较： 1git diff 只对某些文件和暂存区进行比较：1git diff -- README.md [filename ...] 比较暂存区和 HEAD 之间的差异123git diff --cached# 或者git diff --staged 比较的是工作区和HEAD之间的差异1git diff HEAD 比较两个分支的差异1git diff master temp 只关心这两个分支中某个文件的差异：1git diff master temp -- index.html 其实，分支名就是一个指针，就是一种引用，可以直接使用 commit id 比较：1$ git diff 622a8 7e7a -- index.html 注意了：git diff A B 比较的结果可以看做是 B-A 的差集，调换 A B 顺序，正负号会有变化的。 git reset暂存区文件的恢复暂存区全部文件恢复成和 HEAD 一样：1git reset HEAD reset 命令不加 –hard，则暂存区的内容恢复成HEAD对应的内容，工作区的变更继续保留； 如果加了 –hard，则不管工作区还是暂存区，内容都变回HEAD对应的内容，危险的命令，会让你在工作区的修改丢失； git reset 有三个参数： --soft 这个只是把 HEAD 指向的 commit 恢复到你指定的 commit，暂存区 工作区不变 --hard 这个是 把 HEAD， 暂存区， 工作区 都修改为 你指定的 commit 的时候的文件状态 --mixed 这个是不加时候的默认参数，把 HEAD，暂存区 修改为 你指定的 commit 的时候的文件状态，工作区保持不变 怎样取消暂存区部分文件的修改？1git reset HEAD style.css 将工作区和暂存区保持一致有时候修改了文件，已经保存到暂存区，之后又在工作区进行了修改，此时，发现工作的效果不如暂存区的效果好，想要将工作区和暂存区保持一致。 1git checkout -- &lt;file&gt;... 其实，git status 都有友好的提示的: 如果想要变更工作区的内容，那么要想到和 checkout 命令相关； 如果想要变更暂存区的内容，那么要想到和reset 命令相关； 任何时候都可以通过 git status 查询索引的状态。 消除最近的几次提交丢弃一些 commit，直接HEAD 指向了你指定的某个 commit，同时，暂存区和工作区也恢复到哪个 commit 时的状态：1git reset --hard &lt;commitid&gt; 有些 commit 会丢失，是条危险的命令，要慎用。但是当你明确了你的需求，需要将工作区暂存区提交记录明确恢复到某个 commit 状态时，可以执行这个命令。 git commit「提交」操作。当你前面采用 add 命令将文件添加到暂存区跟踪后，需要通过commit将暂存区的内容提交到当前分支：1git commit -m &quot;test&quot; 当一些已被追踪的文件修改后，常常需要git add file，然后再git commit -m &quot;xxxx&quot;，其实这两个步骤可以合二为一：1git commit -am &quot;test&quot; 这么写个人觉得挺好，可以有效避免有些懒人git add .的方式，将一切文件都添加到了暂存区，导致最后多余文件提交入库。 amend修改最近一次 commit 的 message：1git commit --amend 修改完 message 信息之后，保存退出即可 git commit --amend命令本质上是用新的 commit 应该是替代了上一次的提交，不只是修改 message。比如上一次提交时有几个文件没有 add 以及 commit，可以重新进行 add 之后再 commit --amend 提交。但这次提交之后，在分支的 git log 中，不会增加一次新的 commit（因为被替换了嘛），看着效果相当于在父 commit 的基础上进行的修改。 修改历史提交的 message 信息：可以使用 git rebase 命令：1git rebase -i 8580 -i 会进入交互模式，有一系列指令操作对应的 commit，不要用 pick 命令，而是使用 reword 命令操作 add ref 那次 commit，然后保存，就进入修改 message 的窗口，修改完再保存，最后就会 OK 了。 12345$ git rebase -i 8580[detached HEAD b2b5486] Add ref project Date: Mon Jan 14 23:56:14 2019 +0800 1 file changed, 1 insertion(+), 1 deletion(-)Successfully rebased and updated refs/heads/master. git log -3 查看最近的3次提交，变为这样了，会发现，倒数第二次的 message 信息修改 OK 了，最新一次的 message 虽然没变，但其实，commit id 都发生了变化，「替换」的概念要记得。 git rebase 工作的过程中，就是用了「分离头指针」。rebase 意味着基于新 base 的 commit 来变更部分 commits。它处理的时候，把 HEAD 指向base 的 commit，此时如果该 commit 没有对应branch，就处于分离头指针的状态，然后重新一个一个生成新的 commit，当rebase 创建完最后一个 commit 后，结束分离头状态，Git 让变完基的分支名指向 HEAD PS：对于团队中公用的分支，例如发布分支等，禁用 rebase，因为这样会破坏历史的 commit 信息的，将来要溯源、基于构建历史拉取补丁分支等就会带来极大不便。 连续多个 commit 合并目前 commit 还在本地，没有 push 到团队分支上，想要将网页相关的 commit 合并成一个，就是从图中 55a9 开始的6个 commit 合成一个：1git rebase -i 7e7a 12345678910$ git rebase -i 7e7a[detached HEAD 1c102e6] Create a complete web page Date: Mon Jan 14 23:46:26 2019 +0800 5 files changed, 20 insertions(+) create mode 100644 index.html create mode 100644 js/a.js create mode 100644 style.css create mode 100644 styles/a.css create mode 100755 大嘴猴-头像-logo.jpgSuccessfully rebased and updated refs/heads/master. 变基过程中有可能会遇到冲突的，只要解决冲突即可，解决冲突的时候，只需要先修改有冲突的文件的内容，然后执行 git add &lt;file_with_conflict&gt;即可，不要再 git commit，否则多出来 commit 的，然后接着 git base --continue即可，参考简书-git rebase解决合并冲突 历史中不连续的 commit 合并将历史中和 readme 相关的 commit 合并，就是下图中52af 7e7a 03be 这三个 commit。 1git rebase -i 52af # 因为52af 是首个，没有父亲，因此需要补充一下 123456789101112131415161718192021$ git statusinteractive rebase in progress; onto 52af14bLast command done (1 command done): pick 52af14bNext commands to do (3 remaining commands): squash 7e7a518 modify readme squash 03bef1e Modify readme to README file (use &quot;git rebase --edit-todo&quot; to view and edit)You are currently rebasing branch &apos;master&apos; on &apos;52af14b&apos;. (all conflicts fixed: run &quot;git rebase --continue&quot;)nothing to commit, working tree clean# michael @ Michael-MBP in ~/Code/Git-Geek/git_learning on git:52af14b o [17:08:05]$ git rebase --continue[detached HEAD fe08624] Add readme.md Author: Michael728 &lt;michael@163.com&gt; Date: Mon Jan 14 23:35:44 2019 +0800 1 file changed, 1 insertion(+) create mode 100644 README.mdSuccessfully rebased and updated refs/heads/master. 最终整理成了两个 commit： 有意思的发现，有两个 commit 是没有祖先的： 如果将 temp 分支、js01 tag 删掉，Git 会清理掉下面那个树。 git pullgit pull命令的作用是，取回远程主机某个分支的更新，再与本地的指定分支合并。它的完整格式稍稍有点复杂：1git pull &lt;远程主机名&gt; &lt;远程分支名&gt;:&lt;本地分支名&gt; 比如，取回 origin 主机的 next 分支，与本地的master分支合并：1git pull origin next:master 如果远程分支是与当前分支合并，则冒号后面的部分可以省略：1234git pull origin next# 等价于下面两个命令git fetch origingit merge origin/next 参考： 阮一峰-Git远程操作详解 git pushgit push命令用于将本地分支的更新，推送到远程主机：1$ git push &lt;远程主机名&gt; &lt;本地分支名&gt;:&lt;远程分支名&gt; 如果省略远程分支名，则表示将本地分支推送与之存在”追踪关系”的远程分支（通常两者同名），如果该远程分支不存在，则会被新建。1$ git push origin master 上面命令表示，将本地的 master 分支推送到 origin 主机的 master 分支。如果后者不存在，则会被新建。 不管是否存在对应的远程分支，将本地的所有分支都推送到远程主机，这时需要使用 --all 选项：1$ git push --all origin git push 不会推送标签（tag），除非使用 --tags 选项：1$ git push origin --tags 可能会遇到 rejected 的 error，因为远端包含了一些本地是没有的变更，比如，创建远端仓库时，在远端仓库的 master 分支上新建了文件，比如 License，而本地是没有这次提交的： 把远端拉取下来：1git fetch github master 语法：1git fetch &lt;远端主机名&gt; &lt;远端分支名&gt; non-fast-forward 表示，你本地 master 分支的演进不是基于远端 master 分支进行的，二者是割裂的，经过 fetch 之后，通过 gitk --all 可以看到： 解决这个问题，可以通过 rebase 或者 merge 的方式解决，现在先采用 merge 的方式： 12345678# 切到本地 master 分支$ git merge github/masterfatal: refusing to merge unrelated histories$ git merge github/master --allow-unrelated-historiesMerge made by the &apos;recursive&apos; strategy. LICENSE | 21 +++++++++++++++++++++ 1 file changed, 21 insertions(+) create mode 100644 LICENSE 上面 fetch 和 merge 方式，和如下 pull 命令等效：1$ git pull github master --allow-unrelated-histories 现在合并之后，分支演进如下： 可以看到 merge 这种方式新生成的 commit 有两个父亲。 现在重新启动将本地的 master 分支 push 到远端：1git push github master git rm从 Git 中移除某个文件，就必须从已跟踪的文件清单中删除（从暂存区域移除文件），然后提交。可以使用 git rm 命令完成此项工作，并连带从工作目录中删除指定的文件，以后这个文件就不会出现在 Git 库中了。 当我们先把某文件从 Git 库中删除（亦即从暂存区移除），但仍然希望保留在当前工作目录中。比如当你忘记在.gitignore文件中将一些文件忽略，但是却不小心把大的日志文件添加到暂存区域时，这一做法很有用： 12# --cached 将 README 文件从暂存区移除，但是工作区目录仍然保留git rm --cached README git checkout基于某分支创建新分支：1git checkout -b &lt;new_branch_name&gt; &lt;base_branch_name&gt; 这里的 base_branch_name 是指创建分支时的「基」。 当省略时，就是基于当前分支创建； 1git checkout -b &lt;new_branch_name&gt; 当这个「基」是远端分支名时，就实现了在本地基于远端分支创建分支。 12git branch -av # 查看本地+远程分支列表git checkout -b dev origin/dev 还可以可以在checkout命令中使用 Hash 值作为起点创建分支：1git checkout -b &lt;name_of_branch&gt; &lt;commit id&gt; 除了有“切换”的意思，checkout还有一个撤销的作用。 举个例子，假设我们在一个分支开发一个小功能，刚写完一半，这时候需求变了，而且是大变化，之前写的代码完全用不了，好在你刚写，甚至都没有 git add 进暂存区，这个时候很简单的一个操作就直接把原文件还原： 1git checkout &lt;filename&gt; 参考：在git中checkout历史版本 git log查看版本演变历史：12git log --pretty=oneline # 检查提交日志，都在一行：&lt;commit id&gt; &lt;message&gt;git log --oneline # 与上面命令等价 查看某人的提交：1git log --author=michael 一个常用的选项是-p，用来显示每次提交的内容差异; 可以加上-2或者-n2来仅显示最近两次提交： 123git log -n2 # 查看最近的2次提交git log -p -2git log -n1 --format=format:%h # 查看当前分支最新的 commit id 缩略值 列出最近两周内的提交：1git log --since=2.weeks 图形化查看分支演变：1234# 加了 --all 表示查看所有分支的历史，否则只能看到当前分支的演变历史git log --all --graph# 只查看指定分支的演变历史，比如 temp 分支，此时就不能使用参数 --allgit log --oneline --graph temp 检查某个文件的历史记录：12# --follow 选项会让 Git 在日志中回溯并找到内容相关联的地整个历史记录git log --follow mydata 参考： git log命令全解析，打log还能这么随心所欲！ git-scm 2.3 Git 基础 - 查看提交历史 远程仓库的使用查看远程仓库1git remote -v 如果想查看远程仓库更多的信息，可以使用git remote show &lt;remote-name&gt;命令。 远程仓库的移除与重命名：12git remote rename &lt;old-remote-name&gt; &lt;new-remote-name&gt;git remote rename pb paul 如果因为一些原因要移除一个远程仓库，可以使用git remote rm &lt;remote-name&gt;。 添加一个新的远程 Git 仓库，同时指定一个可以轻松引用的简写：1git remote add &lt;remote_host_name&gt; &lt;url&gt; 这里的remote_host_name常常取名为origin。所以，常见的origin其实是一个你 Git 仓库跟踪的远程仓库的简写。 拉取远端仓库有但你本地没有的信息：1git fetch &lt;remote_host_name&gt; 如果你使用clone命令克隆了一个仓库，命令会自动将其添加为远程仓库并默认以origin为缩写。 git rev-parsegit rev-parse 命令可以将任何形式的提交名——标签、相对名、简写或者绝对名称，转换成对象库中实际的、绝对的提交散列 ID。 git tag列出标签12git tag # 列出所有标签git tag -l &apos;v1.8*&apos; # 列出以 v1.8 开头的所有标签 创建标签Git使用两种主要类型的标签： 附注（annotated）标签：会创建一个标签对象 轻量（ightweight）标签：轻量级标签仅仅是一个提交对象的引用，可以 git rev-parse v1 来查看它的 SHA1 值 前者会包括一些注释信息，来进一步解释这个 tag 的作用，而后者就仅仅只是一个 tag 的名字 附注标签： 1git tag -a v1.4 -m &apos;my version 1.4&apos; 通过 git show &lt;tag-name&gt; 命令可以看到标签信息。其实，还以通过 git show branch_name:file_name 查看具体分支或者标签中的文件的内容。 轻量标签： 1git tag v1.4 没用-a、-m的参数，只需要提供标签名 tag 是一个静态的名字，相当于一个 snapshot 的概念，而分支是动态的。如果你创建的 tag 名和分支名一样，容易造成混淆，就必须使用索引名全称来区分它们。比如 refs/tags/v1、refs/heads/v1 删除标签1git tag -d &lt;tagname&gt; 补打标签假设忘记给项目打标签，可以在之后加上：基于某历史节点的commit id补打Tag： 1git tag -a v1.2 &lt;commit id&gt; 共享标签默认情况下，git push命令并不会传送标签到远程服务器上。在创建完标签后你必须显示地推送标签到共享服务器上。这个过程就像共享远程分支一样，可以运行git push origin [tagname] 如果想要一次性推送很多标签，也可以使用--tags选项的git push：1git push origin --tags 检出标签根据标签打的时间点，新建一个分支： 1git checkout -b &lt;new_br&gt; &lt;tag_name&gt; 参考： The Junior Git 6 Git 基础 - 打标签 高阶命令git bisect二分查找，快速定位 bug 的提交 场景：定位 Bug，当前版本有B ug，上个版本没有，两个版本之前有上千次 commit 二分查找，N 个 patch 只需要测试 log2N 次（8k 个 path 仅需测试 13 次）可以实现测试自动化，自动查找问题 patch git bisect：只需要在初始时提供一个初始的「好」提交和「坏」提交。然后重复回答这个版本是否 OK 使用 git bisect start 开始 git bisect bad 告诉是「坏」提交，默认是 HEAD git bisect good v1.0 告诉 V1.0 是「好」提交 反复回答 git bisect good/bad 告诉是「好/坏」提交 git bisect reset 恢复到分支一开始 git bisect log 记录你回答的日志 小众命令清除未跟踪文件有时候一个仓库目录下莫名会多出一些你不想要的文件，这些文件常常是未跟踪的文件。怎么快速将它们删除呢？ 1git clean -df 将未跟踪的目录及文件删除，可以加 -n 选项，先查看有哪些文件将被删除运行！ 最后 Git使用教程笔记 Pro Git 中文 Git常用命令备忘 掘金-今年下半年，中日合拍的《Git游记》即将正式开机，我将…（上集） git术语解释staging，index，cache pcottle/learnGitBranching 分支演示网站]]></content>
      <categories>
        <category>ToolsDev</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git 基础 —— 安装 配置 别名 对象]]></title>
    <url>%2F2019%2F11%2F14%2Fgit-install-config%2F</url>
    <content type="text"><![CDATA[Git 基础学习系列 Git 基础 —— 安装 配置 别名 对象 Git 基础 —— 常用命令 Git 基础 —— 常见使用场景 Git 基础 —— Github 的使用 Git 安装Git下载地址 Windows 安装时需要注意在Configuring the line ending conversions界面，选择Checkout as-is,commit as -s，避免Windows的换行符问题。如果忘记设置，可以使用如下命令后期设置： 1git config --global core.autocrlf false 参考： GitHub 第一坑：换行符自动转换 Git 配置可以通过 查看配置： git config -l/--list git config --list [--local | --global | --system] 说明： system 不常用 local 需要在一个 Git 仓库下使用，它的配置，优先级是最高的，代表仅针对单仓库的配置 设置 Git 账号配置 user 信息12git config --global user.name &quot;michael728&quot;git config --global user.email &quot;649168982@qq.com&quot; --local：区域为本仓库 --global: 当前用户的所有仓库 --system: 本系统的所有用户 运行 git config --help 可以看到帮助文档，比如，配置错误了，可以删除：git config --unset usr.name 将 usr.name 删除，应该是 user.name。 生成 SSH Key1.先查看有没有 SSH Key，ls -al ~/.ssh，如果没有，采用如下方法生成。2.生成 ssh 公钥，不要重命名生成的文件，否则会导致 ssh 方式下载 Git 代码库失败：1ssh-keygen -t rsa -C &quot;649168982@qq.com&quot; 参数说明： -t 用来指定加密算法为 rsa； -C 后面是个注释信息，并不一定要和你 Git 账户的邮箱或者 Git 账户名保持一致，只是常常是和你账户邮箱保持一致，这样设置，就能知道这个公钥被绑定在哪个 Git 账户上了。 3.生成公钥之后，拷贝公钥的内容，粘贴到你 Github 账户的 SSH Key 设置中； 1pbcopy &lt; ~/.ssh/id_rsa.pub 如果没有 pbcopy 命令，就直接打开 id_rsa.pub 内容，复制即可； 关于公钥私钥的一些探究： 一个 ssh key 只能绑定在一个 Git 账户上，而一个 Git 账户可以绑定多个 ssh key； 公钥就相当于一个 fingerprint ，公钥和唯一一个 Git 账户绑定，那么凡是机器上有这个公钥对应的私钥，机器就有绑定账户的权限去操作相关的代码库，即在 A 机器上生成的私钥发送到 B 机器上，那么，B 机器也会有权限下载了； 参考： Github Add SSH Key 文档 简书-图解SSH原理 简书-SSH key的介绍与在Git中的使用 archlinux-SSH keys (简体中文)) Git 配置别名git config命令可以轻松为每一个命令设置别名。例如：1234git config --global alias.co checkoutgit config --global alias.br branchgit config --global alias.ci commitgit config --global alias.st status 演示将git visual定义为 gitk 的别名： 1git config --global alias.visual &apos;!gitk&apos; 设置命令的别名，可以提高操作效率。查看.gitconfig文件vim ~/.gitconfig：123456789101112131415161718192021222324[user] name = xxx email = xxx[i18n] commitencoding = utf-8 logoutputencoding = utf-8[core] quotepath = false[filter &quot;lfs&quot;] clean = git-lfs clean -- %f smudge = git-lfs smudge -- %f process = git-lfs filter-process required = true[alias] co = checkout br = branch c = commit s = status unstage = reset HEAD -- last = log -1 HEAD lg = log --graph --pretty=format:&apos;%Cred%h%Creset -%C(yellow)%d%Creset %s %Cgreen(%cr) %C(bold blue)&lt;%an&gt;%Creset&apos; --abbrev-commit --date=relative[color] ui = true 我们可以体验一个 log 的别名命令设置： 1lg = log --graph --pretty=format:&apos;%Cred%h%Creset -%C(yellow)%d%Creset %s %Cgreen(%cr) %C(bold blue)&lt;%an&gt;%Creset&apos; --abbrev-commit --date=relative 这是超厉害的别名缩写命令，试试现在的 git lg 有多酷炫吧！ 探秘 .git 目录.git 裸仓库文件夹，反映了 Git 良好的文件存储机制。 HEAD 文件，指向当前所在的分支，类似一个活动的指针，表示一个「引用」。例如当前在 develop 分支，HEAD 内容就是 ref: refs/heads/develop config 文件，是本地仓库的配置文件，git config --local --list refs 文件夹，包含了 heads 和 tags 文件夹。heads 归档的分支，tags 归档的标签，也叫做「里程碑」。 heads 文件夹下有多个文件，每个文件和仓库本地存在的分支名一致，文件内容是 commit id。文件当中存放的其实是这个分支的指针指向的 commit id。git branch -av 可以看到分支信息和 commit id。它是个 commit 类型的对象。 tags 中也有多个文件，文件名和存在 tag 名一致，内容也是 commit id。它也是个 commit 类型的对象。 objects 文件夹（核心），存放所有的 git 对象，对象哈希值前 2 位作为文件夹名称，后 38 位作为对象文件名, 可通过 git cat-file -p &lt;2位+38位&gt; 命令查看文件内容。git cat-file -t &lt;2位+38位&gt; 查看对象类型，这是一个 tree 类型的对象。内容本身是一个 blob 对象。任何文件的内容相同，在 Git 眼里，它就是唯一的一个 blob 对象。 利用 git ls-files -s 可以查看文件的关联联系，有利于窥视 Git 的内部状态，同时，它可以方便利用 git cat-file -p 散列值 查看对象内容。 还有一些暂可以不了解的文件： COMMIT_EDITMSG 文件 ORIG_HEAD 文件，好像是上一次的 commit id description 文件，仓库的描述信息文件 index 文件 hooks 文件夹 info 文件夹 logs 文件夹 Git 对象类型Git 放在对象库（object store）里的对象只有四种类型： 块 blob：文件的每一个版本表示一个 blob 对象。一个 blob 对象保存的是一个文件的数据 目录树 tree：一个目录树对象代表一层目录信息。 提交 commit：一个提交对象保存版本库每一次变化的元数据，包括作者、提交者等信息。每一个提交对象指向一个目录树对象。 标签 tag：一个标签对象分配一个任意的可读性高的名字给一个指定对象，通常是一个提交对象。 知道了一个 sha1 值，如何查看它的对象类型、对象内容、对象大小？ git cat-file -t 命令 ， 查看 git 对象的类型 git cat-file -p 命令， 查看 git 对象的内容 git cat-file -s 命令， 查看 git 对象的大小 Git 对象彼此关系commit tree blob 三个对象之间的关系：一次 commit id 对应一棵树（tree），一次快照，整个项目的快照，包含了哪些文件夹（tree）、哪些文件（blob）。blob 可以看做是一个文件，但是和文件名是没关系的，不管文件名是什么，只要文件内容相同，就是一个 blob，这种设计大大节约了存储空间。 Git 的索引Git 的索引不包含任何文件内容，它仅仅追踪你想要提交的那些内容。但执行 git commit 命令的时候，Git 会通过检查索引而不是工作目录来找到要提交的内容。 实验新建一个 git 仓库，创建一个 doc 文件夹，在 doc 文件夹中创建 readme 文件 在单纯创建 doc 文件夹时， git 不会理会； 创建 readme 文件之后，会提示有文件可以添加跟踪； 这时候执行 find .git/objects --type f， 没有发现有对象生成； 接着执行 git add doc 将文件添加到暂存区，这时候有文件对象生成了: 1234$ find .git/objects -type f.git/objects/27/e826dc62c8a3616e7c15d45a3d77cd8e7966c0$ git cat-file -t 27e8blob 接着创建 commit，git commit -m &quot;add readme&quot;，这时候文件对象内容： 1234.git/objects/27/e826dc62c8a3616e7c15d45a3d77cd8e7966c0.git/objects/87/0af27bedac0cf42d9a7637709e455fa7de7a7e.git/objects/a0/3d66adf115035c521bc08509f54d867590a458.git/objects/e6/b633ca37bf3532f87e833c8f765e07ea50cfe8 1 个 commit 对象，2 个 tree 对象，1 个 blob 对象。 为何会有2个 tree 对象呢，其中，整个工作目录是一个 tree 对象，工作目录下的 doc 文件夹对应了一个 tree 对象。 扩充：我又将之前 doc 文件夹的 readme 文件复制在仓库的根目录下，此时在 git add readme 之后，文件对象仍然无变化；但是，当 commit 之后，文件对象变多了，多了 1 个 commit，1个 tree 对象。这个多出来的 tree 对象，就是因为工作目录变化了，那么就多出来了一个 tree 对象。 Git 中的文件分类Git 将所有文件分为 3 类： 已追踪的 tracked：指已经在版本库中的文件或者已经暂存到索引中的文件。利用 git add somefile 将新文件添加为已追踪文件 被忽略的 ignored： 未被追踪的 untracked：不在前两类中的文件就是未被追踪的文件 HEAD 与 branch分离头指针123456$ git checkout 20824e0Note: checking out &apos;20824e0&apos;.You are in &apos;detached HEAD&apos; state. You can look around, make experimentalchanges and commit them, and you can discard any commits you make in thisstate without impacting any branches by performing another checkout. detached HEAD就表示你当前处于「分离头指针」的状态。其实，「分离头指针」就是表示正工作在一个没有分支的情况下，没有与分支进行挂钩, HEAD 没有指向任何分支。 处于「分离头指针」状态进行提交后，当你切换到其他分支，例如 git checkout master ，之前产生的 commit 可能会被 Git 当为垃圾清除掉。 分离头指针的应用场景在处于分支头指针状态时，你产生了一次 commit 0635f24，当你切换到其他分支后，有可能就找不到刚刚的提交了，你用 gitk --all 之后，看不到刚刚的提交的。 如果想保存刚刚的提交，需要使用如下命令将其与分支挂钩：1git branch &lt;new-branch-name&gt; 0635f24 如果临时想基于某个 commit 做变更，试试新方案是否可行，就可以采用分离头指针的方式。测试后发现新方案不成熟，直接 reset 回其他分支即可，省却了建、删分支的麻烦。 进一步理解 HEAD 和 branchHEAD 既可以指向「当前分支」的最新 commit，也可以指向历史中的某一次 commit (「分离头指针」的情况)。归根结底，HEAD 指向的就是一次 commit。 当我们做分支切换时，HEAD 会跟着切换。 例如比较最近两次提交的差异，可以用命令： 1234# 下面三个命令等效git diff xxx1 xxx2git diff HEAD HEAD^git diff HEAD HEAD~1 HEAD^1 表示 HEAD 的父亲，HEAD^^ 表示 HEAD 父亲的父亲。 HEAD^^ 和 HEAD~2等效。 Git 的特殊符号集Git 中有一个特殊符号集来指代引用名。 ^ 用来表示父提交，master^1 与 master^2 表示的都是 master 的父提交，注意了，master^2 并不是「爷爷」，嘿嘿 ~ 用来返回上一代提交，因此 master~1 表示父提交；master~2 表示的是 master~1 的父提交，也就是 master 的祖父提交！ : 可以用来指向一个产生合并冲突的文件的替代版本。 master^1 可以简写为 master^，master~1 可以简写为 master~ Git 小技巧Git 帮助文档授人以鱼不如授人以渔，先知道怎么通过帮助文档查看常用命令的说明吧： 1234git helpgit help &lt;cmd&gt; # 与 git &lt;cmd&gt; --help 等价git help &lt;cmd&gt; --web # 使用浏览器页面打开git &lt;cmd&gt; -h # 显示简略的命令帮助 gitk 图形界面gitk 后面可以跟上文件的路径， 这样能看单个文件的修改历史的具体内容。 Patch 表示的是「变更集」，某一次 commit 修改的文件集合； Author 作者 Commiter 提交人 Cherry 挑选一个 commit，放到另一个分支上，这时候，Author 和 Commiter 就有可能不是一个人了，因为你挑选的那个 commit 作者可能是 A，你 cherry pick 过来之后提交，提交人是你，但是作者信息还是 A，版权考虑。 Parent 上一次的 commit id Child 下一次的 commit id 菜单 View ，选择 All refs 可以看到所有的分支演变图 gitignore 指定不需要 Git 管理的文件.gitignore 指定哪些文件不需要纳入版本管理的。 *.d 任何 .d 结尾的文件都不需要； *.dSYN/ 任何以 .dSYM 结尾的文件夹下的文件都不要； 目录名由末尾的 / 标记。这能匹配同名的目录和子目录。 加不加 / 作用是不一样的，很微妙。比如，有一个文件夹叫 doc，那么，.gitignore 中写 doc， Git 既会忽略 doc 文件夹，也会忽略 doc 文件！只有 doc/ 这么写，才会只忽略 doc 文件夹而不忽略 doc 文件，作用才很明确。所以，如果要忽略的是文件夹，那么就显示的加上 / 吧。 一个 * 只能匹配一个文件或目录名。 起始的 ! 取反模式。 Git 允许在版本库中任何目录下有 .gitignore 文件。每个文件只影响该目录及其所有子目录。 场景：全局配置了忽略 *.io 的文件，但是 Dev 目录下的 driver.io 不能被忽略，该怎么办？ 123cd Dev# 追踪一个例外echo &quot;!driver.io&quot; &gt;&gt; .gitignore Github 现在创建仓库时，可以选择生成什么 .gitignore ，附上链接作为参考： github/gitignore/maven github/gitignore/java 这里有一个帖子讨论了为何 .idea 文件夹没有加入到 .gitignore 中，这是因为每个开发者的编辑器不一样，大部分习惯是将编辑器产生的文件夹添加到全局的忽略配置中：123# file: ~/.gitignore_global.DS_Store.idea 此外，还要配置指定全局的忽略文件配置在哪儿：1git config --global core.excludesfile /Users/michael/.gitignore_global 或者编辑全局配置文件 ~/.gitconfig:12[core] excludesfile=/Users/michael/.gitignore_global 参考： Git中全局忽略.DS_Store文件 解决冲突的工具diffmerge是一个可以用来文件对比软件。相较于 git mergetool 使用的自带的界面，diffmerge 提供了一个可交互的编辑窗口，大大提高了效率。我们可以通过简单的配置，在使用 git difftool git mergetool 时，默认使用 diffmerge 工具来进行展示差异。当然，你要是有钱，也可以选择 Beyond Compare 来作为对比软件。 选择 OS X 10.6+ Installer (Intel) 版本，安装好之后进行配置：1234567$ git config --global diff.tool diffmerge$ git config --global difftool.diffmerge.cmd &quot;/usr/local/bin/diffmerge \&quot;\$LOCAL\&quot; \&quot;\$REMOTE\&quot;&quot;$ git config --global merge.tool diffmerge$ git config --global mergetool.diffmerge.trustExitCode true$ git config --global mergetool.diffmerge.cmd &quot;/usr/local/bin/diffmerge --merge --result=\&quot;\$MERGED\&quot; \&quot;\$LOCAL\&quot; \&quot;\$BASE\&quot; \&quot;\$REMOTE\&quot;&quot; 为了避免每次运行git difftool都有提示信息，可以输入如下命令1$ git config --global difftool.prompt false 为了能够支持显示中文，需要对编码进行设置： diffmerge 的使用： git difftool [fileName] git mergetool [fileName] 使用 git mergetool 合并分支时，默认会生成以 *.orig 为扩展名的备份文件，每次都要手动删除。可以修改 Git 配置，禁止产生备份文件：1git config --global mergetool.keepBackup false 参考： 油管-git mergetool explained 对自带的 git mergetool 命令的使用介绍 油管-Git Tutorial: Diff and Merge Tools diffmerge 下载 选择 OS X 10.6+ Installer (Intel) 版本 diffmerge 帮助文档 博客园-DiffMerge安装配置使用 讲了如何配置 UTF-8 对于解决 Git 的 Merge Conflict 你有哪些经验和技巧 SOF-How to resolve merge conflicts in Git]]></content>
      <categories>
        <category>ToolsDev</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mac 环境对 Github Homebrew 等终端工具的加速设置]]></title>
    <url>%2F2019%2F11%2F13%2Ftools-tips-mac-accelerate%2F</url>
    <content type="text"><![CDATA[背景最近 Mac 升级系统之后，导致软件都得重装。发现 Homebrew 安装软件很多都是去 Github 上下载，怎么加速呢？简要做个备忘吧。 步骤首先，我是有一个 VPS 代理的，如何配置，可以看我之前的总结ss+vps+mac PS：记得用我的链接注册呀！我们都会有返利！ 在将 SS 软件打开全局模式下，速度依然很慢，这时候你需要设置终端的代理才会加速。终端代理分为： http_proxy https_proxy all_proxy 这个是针对终端所有的连接都走代理 SS 软件，支持 socks5 协议，也支持 http 协议，打开 偏好设置 –&gt; 高级 选项，可以看到 socks5 协议的 ip 以及端口，在 http 选项卡，可以看到 http 代理的信息。 我是这么配置的：123export all_proxy=&quot;socks5://127.0.0.1:1086&quot;# orexport all_proxy=&quot;http://127.0.0.1:1087&quot; 上面的端口号 1086 取决于你 SS 软件中配置的端口号。除了 socks5 协议之外，你也可以配置 http 代理。 如果为了避免每次都要执行设置代理，可以将上面的配置加到你的终端配置文件中，比如我是 ~/.zshrc： 12export all_proxy=&quot;socks5://127.0.0.1:1086&quot; &gt;&gt; ~/.zshrcsource ~/.zshrc 这时候，homebrew 安装就不会太慢了。 设置好代理以后，可以使用 curl cip.cc 查看当前自己的 ip 信息，确认代理是否设置成功。 为了加速 Git 下载，我在 ~/.gitconfig 中加入了如下的设置： 123456[https] proxy = http://127.0.0.1:1087 sslVerify = false[http] proxy = http://127.0.0.1:1087 sslVerify = false 还有一种方法，只给部分域名配置代理，这样可以避免克隆国内仓库时，速度不会受到影响： 12git config --global http.https://github.com.proxy socks5://127.0.0.1:1087git config --global https.https://github.com.proxy socks5://127.0.0.1:1087 取消 Git 代理设置： 12git config --global --unset http.proxygit config --global --unset https.proxy 补充这个 repo 放了 Github 加速的 DNS 配置，以备特殊时期使用： 123456789101112131415161718# GitHub520 Host Start185.199.108.154 github.githubassets.com199.232.68.133 camo.githubusercontent.com199.232.68.133 github.map.fastly.net199.232.69.194 github.global.ssl.fastly.net140.82.112.4 github.com140.82.113.5 api.github.com199.232.68.133 raw.githubusercontent.com199.232.68.133 user-images.githubusercontent.com199.232.68.133 favicons.githubusercontent.com199.232.68.133 avatars5.githubusercontent.com199.232.68.133 avatars4.githubusercontent.com199.232.68.133 avatars3.githubusercontent.com199.232.68.133 avatars2.githubusercontent.com199.232.68.133 avatars1.githubusercontent.com199.232.68.133 avatars0.githubusercontent.com# Star me GitHub url: https://github.com/521xueweihan/GitHub520# GitHub520 Host End 参考 使用代理加速 Mac 终端下载速度 GitHub克隆clone太慢添加代理加速访问 玩转 DNS ，顺利打开各种网站]]></content>
      <categories>
        <category>ToolsDev</category>
      </categories>
      <tags>
        <tag>Tools</tag>
        <tag>Mac</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[工作总结/思考]]></title>
    <url>%2F2019%2F10%2F14%2Fsummary-work%2F</url>
    <content type="text"><![CDATA[简介担心时间久了，人也懒了，用本文记载一下主要的工作经历吧。 配置管理201706 ~ 201805 思维方式 不要有边界思维，主人翁意识 保持改进意识，多思考 多总结、多分享 思路不清晰时，先梳理清楚思路，按照思路执行计划 凡是要么不做，要做就要做好 周边业务的沟通能力 工作内容 代码库管理 E2E 端到端可溯 二进制可追溯 代码入库可追溯 变更/发布可追溯 度量 分支 权限管理 开发环境标准自动化 开源及第三方软件 开源扫描 版本配套表]]></content>
      <categories>
        <category>DevOps</category>
      </categories>
      <tags>
        <tag>总结</tag>
        <tag>思考</tag>
        <tag>工作</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python 代码片段收藏]]></title>
    <url>%2F2019%2F09%2F07%2Fpython-useful-snippets%2F</url>
    <content type="text"><![CDATA[list 列表相关list 中最小值、最大值12345678910111213import operatorvalues = [1, 2, 3, 4, 5]min_index, min_value = min(enumerate(values), key=operator.itemgetter(1))max_index, max_value = max(enumerate(values), key=operator.itemgetter(1))print('min_index:', min_index, 'min_value:', min_value)print('max_index:', max_index, 'max_value:', max_value)# Outmin_index: 0 min_value: 1max_index: 4 max_value: 5 list 中连续元素之间的差1234567from itertools import islicels = [1,2,3,5,8]diff = [j-i for i,j in zip(ls, islice(ls, 1, None))]print(diff)# Out[1, 1, 2, 3] 删除列表中的重复元素下面这种方法不能维持顺序： 12345x = [1, 8, 4, 5, 5, 5, 8, 1, 8]list(set(x))# Out[8, 1, 4, 5] 下面的方法，可以维持顺序： 123456from collections import OrderedDictx = [1, 8, 4, 5, 5, 5, 8, 1, 8]list(OrderedDict.fromkeys(x))# Out[1,8,4,5] 并行遍历2个列表12345678910a = [1, 2, 3]b = [4, 5, 6]for (a_val, b_val) in zip(a, b): print(a_val, b_val)# Out1 42 53 6 合并列表值输入的两个数组，输出一个是数组&amp;值相加或者相乘： 1234567891011121314# inputfirst = [1,2,3,4,5]second = [6,7,8,9,10]#outputthree = [7,9,11,13,15]# The zip function is useful here, used with a list comprehension.# add[x + y for x, y in zip(first, second)]# other[x*y for x, y in zip(first, second)][max(x,y) for x, y in zip(first, second)] 参考： Python中的常用代码 字典处理字典做交、差、并123456a=&#123;'name':'michael','age':"27",'sex':'male'&#125;b=&#123;'name':'hqh','age':'27'&#125;&#123;k:a[k] for k in a.keys()-b.keys()&#125;out: &#123;'sex': 'male'&#125;dict(a.items()-b.items())out: &#123;'name': 'michael', 'sex': 'male'&#125; 需要注意的是，当字典的值有字典时，a.items()-b.items() 这种方式会报错 TypeError: unhashable type: &#39;dict&#39;； 参考： cookbook-查找两字典的相同点 简书-Python 字典操作进阶 字典的Key与Value对调12345m = &#123;'A': 1, 'B': 2, 'C': 3&#125;invert_map_key_value = lambda m: dict(zip(m.values(), m.keys()))invert_map_key_value(m)# output: &#123;1: 'A', 2: 'B', 3: 'C'&#125; 参考： 2gua-几个Python代码片段 合并字典值12345&gt;&gt;&gt; from collections import Counter&gt;&gt;&gt; A = Counter(&#123;'a':1, 'b':2, 'c':3&#125;)&gt;&gt;&gt; B = Counter(&#123;'b':3, 'c':4, 'd':5&#125;)&gt;&gt;&gt; A + BCounter(&#123;'c': 7, 'b': 5, 'd': 5, 'a': 1&#125;) 字典的增加用 update 方法往已有字典中增加键值对： 1234567891011121314151617deploy_info=dict()for idx, row in raw_data.iterrows(): temp=dict() version = row['version'] app_comp_name = row['app_comp_name'] pkg_name = "&#123;&#125;_&#123;&#125;.tar.gz".format(app_comp_name, version) time.sleep(2) data = get_verify_value(api_url,pkg_name) temp = &#123; deploy_history_id:&#123; 'app_comp_name':app_comp_name, 'version':version, 'pkg_name':pkg_name, 'data':data &#125; &#125; deploy_info.update(temp) 字符串相关索引12tag='hx/mitaka_compute/12.0.0'[m.start() for m in re.finditer('/',tag)] 参考： 在Python中查找所有出现的子字符串 将百分号的百分比字符串转为数字12p="75%"float(p.strip('%'))/100 参考： Convert to numeric Python 剔除分隔符通常做法： 123''.join('A|B|C|D|E|F|G'.split('|'))# output: 'ABCDEFG' 用 itertools.islice，因为可以节选字符串： 1234567import itertools''.join(itertools.islice('A|B|C|D|E|F|G', 6, None, 2))# output: 'DEFG'''.join(itertools.islice('A|B|C|D|E|F|G', 0, None, 2))# output: ''ABCDEFG' 美观打印1234567891011121314151617import pprint as ppanimals = [&#123;'animal': 'dog', 'legs': 4, 'breeds': ['Border Collie', 'Pit Bull', 'Huskie']&#125;, &#123;'animal': 'cat', 'legs': 4, 'breeds': ['Siamese', 'Persian', 'Sphynx']&#125;]pp.pprint(animals, width=1)# Out[&#123;'animal': 'dog', 'breeds': ['Border ' 'Collie', 'Pit ' 'Bull', 'Huskie'], 'legs': 4&#125;, &#123;'animal': 'cat', 'breeds': ['Siamese', 'Persian', 'Sphynx'], 'legs': 4&#125;] width参数指定一行上最大的字符数。设置width为1确保字典打印在单独的行 文件读写基本文件读 txt1234567891011121314151617181920212223242526272829303132333435# Note: rb opens file in binary mode to avoid issues with Windows systems# where 'rn' is used instead of 'n' as newline character(s).# A) Reading in Byte chunksreader_a = open("file.txt", "rb")chunks = []data = reader_a.read(64) # reads first 64 byteswhile data != "": chunks.append(data) data = reader_a.read(64)if data: chunks.append(data)print(len(chunks))reader_a.close()# B) Reading whole file at once into a list of lineswith open("file.txt", "rb") as reader_b: # recommended syntax, auto closes data = reader_b.readlines() # data is assigned a list of linesprint(len(data))# C) Reading whole file at once into a stringwith open("file.txt", "rb") as reader_c: data = reader_c.read() # data is assigned a list of linesprint(len(data))# D) Reading line by line into a listdata = []with open("file.txt", "rb") as reader_d: for line in reader_d: data.append(line)print(len(data)) json 读写json文件 json.loads()是将str转化成dict格式，json.dumps()是将dict转化成str格式。 json.load()和json.dump()也是类似的功能，只是与文件操作结合起来了。 12345# 解码import jsonwith open('build_info.json','r') as f: array = json.load(f)print(array) 在编码JSON的时候，还有一些选项很有用。 如果你想获得漂亮的格式化字符串后输出，可以使用 json.dumps() 的indent参数。 它会使得输出和pprint() 函数效果类似： 123456789&gt;&gt;&gt; print(json.dumps(data))&#123;"price": 542.23, "name": "ACME", "shares": 100&#125;&gt;&gt;&gt; print(json.dumps(data, indent=4))&#123; "price": 542.23, "name": "ACME", "shares": 100&#125;&gt;&gt;&gt; 保存为 json 文件： 12345# 编码import jsona = &#123;"name":"michael"&#125;with open("demo.json","w") as f: json.dump(a, f, indent=4) CookBook-6.2 读写JSON数据 简书-Python: json模块实例详解 官宣-json — JSON encoder and decoder Reading JSON file with Python 3 What is the difference between json.load() and json.loads() functions in Python? 时间日期基本时间（time）和日期（date）12345678910111213import time# print time HOURS:MINUTES:SECONDS# e.g., '10:50:58'print(time.strftime("%H:%M:%S"))# print current date DAY:MONTH:YEAR# e.g., '05/01/2019'print(time.strftime("%d/%m/%Y"))# Out15:18:0305/01/2019 字符串和日期的相互转换strptime 是将字符串转换为 datetime，其实这个方法的全称是 “string parse time”，叫做字符串解析成时间，重点在解析（parse）: 1234567from datetime import datetimedate_obj = datetime.strptime('2018-10-15 20:59:29', '%Y-%m-%d %H:%M:%S')print(type(date_obj),date_obj)# Out&lt;class 'datetime.datetime'&gt; 2018-10-15 20:59:29 strftime 是将 datetime 转换为字符串，全称是 “string format time”，翻译过来就是将字符串的形式来格式化时间，重点在格式化（format），使之以一种可读的字符串形式返回： 1234567from datetime import datetimedate_obj = datetime.now()date_string = datetime.now().strftime("%Y-%m-%d %H:%M:%S")print(type(date_string),date_string)# Out&lt;class 'str'&gt; 2019-01-05 18:41:04 参考： 3分钟学会一个小技巧 编码相关Python Requests 编码问题 requests github issue 下载Python下载文件 urlretrieve Python根据url下载目录或者文件123456789def download_package(self, package_url): print("start download_build_result") if not package_url.endswith("/"): package_url += '/' cmd = "wget -c -r -nd -np -P %s %s" % ("output", package_url) print(cmd) os.system(cmd) print(os.getcwd()) print("finish download_build_result") 数据处理Python Pandas处理Excel数据逐行处理数据 iterrows123for idx, row in data.iterrows(): project_name=row['projectName'] tag_name=row['tagName'] Pandas追加模式写入csv文件1234567data = pd.DataFrame([[1,2,3]])csv_headers=['A','B','C']data.to_csv('./Marvel3_yingpping.csv', header=csv_headers, index=False, mode='a+', encoding='utf-8')data = pd.DataFrame([[4,5,6]])data.to_csv('./Marvel3_yingpping.csv', header=False, index=False, mode='a+', encoding='utf-8')data = pd.DataFrame([[7,8,9]])data.to_csv('./Marvel3_yingpping.csv', header=False, index=False, mode='a+', encoding='utf-8') Python-CSV-Excel Python Pandas iterrows method 123for idx, row in data.iterrows(): project_name=row['projectName'] tag_name=row['tagName'] to_csv表格中文乱码ipython中直接打印df，中文没有乱码，但是to_csv方法存储时，中文有乱码。 1df.to_csv('file.csv',encoding='utf-8-sig') 参考： Pandas df.to_csv(“file.csv” encode=“utf-8”) still gives trash characters for minus sign 关于pandas中,to_csv函数输出的utf8数据用Excel打开是乱码 itero看题目： python数据处理，字典生成的一个问题答案中有位前辈用这个用的炉火纯青啊！ Shell/Linux 操作相关Python运行shell命令的函数：12345678910def run(cmd_str, fatal=True): # this is not a good implement log.command(log.term.cmd(cmd_str)) ret = os.system(cmd_str) if ret is not 0: if fatal: log.error('[ERROR] run cmd: %s failed', cmd_str) os._exit(1) else: log.info('[INFO] %s is not fatal' % cmd_str) 调用外部的命令12345678910111213#import subprocesssubprocess.call(['mkdir', 'empty_folder'])# 运行一条命令并输出得到的结果output = subprocess.check_output(['ls', '-l'])# 上面的调用是阻塞的# 如果运行shell中内置的命令，如cd或者dir，需要指定标记shell=Trueoutput = subprocess.call(['cd', '/'], shell=True)# 对于更高级的用例，可以使用 Popen constructor。 Python 3.5引进了一个新的run函数，它的行为与call和check_output很相似。如果你使用的是3.5版本或更高版本，看一看run的文档，里面有一些有用的例子。否则，如果你使用的是Python 3.5以前的版本或者你想保持向后兼容性，上面的call和check_output代码片段是你最安全和最简单的选择 参考： 计算文件的校验值可以计算文件的 md5、sha256 等值 123456789101112131415# https://pymotw.com/3/hashlib/index.html#module-hashlibdef get_verify_value(file_path, verify_type): """ 计算指定文件的校验值 :param file_path: 文件路径 :param verify_type: 校验值类型，md5 sha256 等等 :return: """ h = hashlib.new(verify_type) if not file_path: return None with open(file_path, 'rb') as f: for block in iter(lambda: f.read(4096), b""): h.update(block) return h.hexdigest() 性能相关脚本的运行时间123456789101112import timestart_time = time.clock()for i in range(10000000): passelapsed_time = time.clock() - start_timeprint("Time elapsed: &#123;&#125; seconds".format(elapsed_time))# OutTime elapsed: 0.30121700000000007 seconds 123456import timeitelapsed_time = timeit.timeit('for i in range(10000000): pass', number=1)print("Time elapsed: &#123;&#125; seconds".format(elapsed_time))# OutTime elapsed: 0.2051873060000844 seconds 计算运行时间1234567891011121314151617class Timer(object): def __enter__(self): self.error = None self.start = time.time() return self def __exit__(self, type, value, tb): self.finish = time.time() if type: self.error = (type, value, tb) def duration(self): return self.finish - self.startwith Timer() as timer: func()timer.duration()# Out0.29994797706604004 参考： CSDN- python代码片段 目录、路径相关基本目录文件操作1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283import osimport shutilimport glob# working directoryc_dir = os.getcwd() # show current working directoryos.listdir(c_dir) # shows all files in the working directoryos.chdir('~/Data') # change working directory# get all files in a directoryglob.glob('/Users/sebastian/Desktop/*')# e.g., ['/Users/sebastian/Desktop/untitled folder', '/Users/sebastian/Desktop/Untitled.txt']# walktree = os.walk(c_dir)# moves through sub directories and creates a 'generator' object of tuples# ('dir', [file1, file2, ...] [subdirectory1, subdirectory2, ...]),# (...), ...#check files: returns either True or Falseos.exists('../rel_path')os.exists('/home/abs_path')os.isfile('./file.txt')os.isdir('./subdir')# file permission (True or Falseos.access('./some_file', os.F_OK) # File exists? Python 2.7os.access('./some_file', os.R_OK) # Ok to read? Python 2.7os.access('./some_file', os.W_OK) # Ok to write? Python 2.7os.access('./some_file', os.X_OK) # Ok to execute? Python 2.7os.access('./some_file', os.X_OK | os.W_OK) # Ok to execute or write? Python 2.7# join (creates operating system dependent paths)os.path.join('a', 'b', 'c')# 'a/b/c' on Unix/Linux# 'a\b\c' on Windowsos.path.normpath('a/b/c') # converts file separators# os.path: direcory and file namesos.path.samefile('./some_file', '/home/some_file') # True if those are the sameos.path.dirname('./some_file') # returns '.' (everythin but last component)os.path.basename('./some_file') # returns 'some_file' (only last componentos.path.split('./some_file') # returns (dirname, basename) or ('.', 'some_file)os.path.splitext('./some_file.txt') # returns ('./some_file', '.txt')os.path.splitdrive('./some_file.txt') # returns ('', './some_file.txt')os.path.isabs('./some_file.txt') # returns False (not an absolute path)os.path.abspath('./some_file.txt')# create and delete files and directoriesos.mkdir('./test') # create a new direcotoryos.rmdir('./test') # removes an empty direcotoryos.removedirs('./test') # removes nested empty directoriesos.remove('file.txt') # removes an individual fileshutil.rmtree('./test') # removes directory (empty or not empty)os.rename('./dir_before', './renamed') # renames directory if destination doesn't existshutil.move('./dir_before', './renamed') # renames directory alwaysshutil.copytree('./orig', './copy') # copies a directory recursivelyshutil.copyfile('file', 'copy') # copies a file# Getting files of particular type from directoryfiles = [f for f in os.listdir(s_pdb_dir) if f.endswith(".txt")]# Copy and moveshutil.copyfile("/path/to/file", "/path/to/new/file")shutil.copy("/path/to/file", "/path/to/directory")shutil.move("/path/to/file","/path/to/directory")# Check if file or directory existsos.path.exists("file or directory")os.path.isfile("file")os.path.isdir("directory")# Working directory and absolute path to filesos.getcwd()os.path.abspath("file") 参考： 斗大的熊猫-收集的有用的 Python 代码片段 Python 删除文件夹123456789101112131415161718def onerror(func, path, exc_info): """ Error handler for ``shutil.rmtree``. If the error is due to an access error (read only file) it attempts to add write permission and then retries. If the error is for another reason it re-raises the error. Usage : ``shutil.rmtree(path, onerror=onerror)`` """ import stat if not os.access(path, os.W_OK): # Is the error an access error ? os.chmod(path, stat.S_IWUSR) func(path) else: raise 参考： shutil.rmtree fails on Windows with ‘Access is denied’ Python 切换目录执行完，返回之前目录123456789import contextlib@contextlib.contextmanagerdef cdir(path): prev_cwd = os.getcwd() os.chdir(path) try: yield finally: os.chdir(prev_cwd) 用法：12with cdir(path): func() 搜索指定目录下的文件将指定目录及其子目录下的文件搜索出来： 12345678910111213141516def find_file(start_path, name): """ search the files of name from the dir start_path，存放的是搜索文件的路径 :param start_path: the search scope of dir :param name: the name of search file :return: set of files path """ files_path = set() for rel_path, dirs, files in os.walk(start_path): # if name in files: for f in files: if name in f: full_path = os.path.join(start_path, rel_path, f) path = os.path.normpath(os.path.abspath(full_path)) files_path.add(path) return files_path 只列出文件夹下的文件夹123[ name for name in os.listdir(thedir) if os.path.isdir(os.path.join(thedir, name)) ]filter(os.path.isdir, os.listdir(os.getcwd())) How to list only top level directories in Python? Python Path相关问题1os.path.split(r"C:\foo\bar\file_name.txt") 格式化文件路径 数据库MySQL 数据库12345678910db = MySQLdb.connect("localhost","your_username","your_password","your_dbname")cursor = db.cursor()sql = "select Column1,Column2 from Table1"cursor.execute(sql)results = cursor.fetchall()for row in results: print row[0]+row[1]db.close() 参考： 斗大的熊猫-最常用的Python代码片段 MongoDB12345uri="mongodb://admin:admin@xxx.xxx.xxx.xxx:27017,xxx.xxx.xxx.xxx:27018,xxx.xxx.xxx.xxx:27019/test"client=pymongo.MongoClient(uri,replicaSet='noah-cluster',readPreference='primaryPreferred')db=client.get_default_database()decouple_history=db.rpm_decouple_release_history_infopprint(decouple_history.find_one(&#123;'service_name':'test'&#125;))]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Snippet</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python 实用技巧总结]]></title>
    <url>%2F2019%2F09%2F07%2Fpython-effective-tips%2F</url>
    <content type="text"><![CDATA[模块相关 导入模块时，可以通过模块的 __file__ 属性查看模块所在磁盘的路径位置，参考：关于Python包和模块的10个知识清单 Pip安装Pip方法一： 1234sudo apt-get purge python-pip python3-pip # Ubuntu卸载wget https://bootstrap.pypa.io/get-pip.pysudo python3 get-pip.py # 安装py3对应的pipsudo python get-pip.py # 安装py2对应的pip 方法二： 123## centos yum方式yum install -y python-setuptoolseasy_install pip Pip命令1234567python -m pip install -U pip #升级pip：pip list --outdate #查看哪些包有更新：pip install --upgrade requests // mac,linux,unix 在命令前加 sudo -H 升级一个包：pip install -U setuptools #conda update setuptools #pip freeze --local | grep -v '^\-e' | cut -d = -f 1 | xargs pip install -U # 升级所有包pip show requests # 查看 package 所在的位置等信息 pip的配置文件中： 12[list] # pip list命令接口的展示方式设置format=columns 参考： Python小技巧 在Linux上安装Python 3 linux下python开发环境之一——安装python 关于pip安装时提示pkg_resources.DistributionNotFound 错误问题 Pip源1~/.pydistutils.cfg # 配置distutils的源，easy_install 命令会走这里配置的 pip 源 参考： 修改pip/setup.py的源 实用Python一键搭建Http服务器你如果想快速且简单地共享一个目录中的文件，你只需在终端执行下面对应版本的指令： 12python -m http.server 8000 # Py3python -m SimpleHTTPServer 8000 # Py2 Python 技巧 virtualenv创建虚拟环境1virtualenv env 运行带 --no-site-packages 选项的 virtualenv 将不会包括全局安装的包。 这可用于保持包列表干净，以防以后需要访问它。（这在 virtualenv 1.7及之后是默认行为） –no-site-packages DEPRECATED. Retained only for backward compatibility. Not having access to global site-packages is now the default behavior. 参考：Pipenv &amp; 虚拟环境 ipyhonhist 显示之前的代码，不显示行号，方便复制 jupyter notebook1pip install jupyter_contrib_nbextensions &amp;&amp; jupyter contrib nbextension install 安装好 jupyter notebook 插键之后，可以在 Nbextensions 菜单选项卡中勾选启用相关扩展功能，下面是比较好用的扩展： Table of Contents：更容易导航 Autopep8：轻轻一击就能获得简洁代码 variable inspector：跟踪你的工作空间 ExecuteTime：显示单元格的运行时间和耗时 隐藏代码输入：隐藏过程，展示结果 参考：机器之心——我知道你会用Jupyter Notebook，但这些插件你都会了吗？]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Tips</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[那些年我剁手的极客时间课程]]></title>
    <url>%2F2019%2F09%2F01%2Fresource-it-geektime%2F</url>
    <content type="text"><![CDATA[前言今天看了看在「极客时间」里构建的课程，发现已经挺多的了，认真看多的却挺少，下面是我觉得值得一看的课程，老师讲的都挺认真、内容不水！今年下半年目标就把他们消化消化就足够了~ PS：此外，有需要的小伙伴也可以扫码购买，目前极客时间的返利规则已由原来的购买者和我都获得返利变为仅仅我能收到返利。所以，如果你是通过扫下面的码购买课程，可以保存下截图，加我微信，我会返利一半给你，这样也能给你带去优惠 🤓 趣谈 Linux 操作系统 趣谈网络协议 算法面试通过40讲 玩转Git三剑客 左耳朵耗子 MySQL实战45讲 Nginx核心知识100讲 Web协议详解与抓包实战]]></content>
      <categories>
        <category>阅读</category>
      </categories>
      <tags>
        <tag>资源</tag>
        <tag>返利</tag>
        <tag>课程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[IT 基础 —— 开源协议]]></title>
    <url>%2F2019%2F08%2F25%2Fit-basic-open-source-protocol%2F</url>
    <content type="text"><![CDATA[什么是开源发展史 1969 年，贝尔实验室将 Unix 代码共享给社区，为开源奠定了重要基础。 1984 年，Richard Stallman 离开 MIT，发起 GUN 项目，希望使用自由代码构建一个类 Unix 的操作系统。此后，Stallman 创立自由软件基金会（FSF），发起 GNU 通用公共协议证书（GNU General Public License, GNU GPL），开发了 GCC、Emacs 等一系列重要产品。 1991 年，Linus Torvalds 在 GPL 协议下发布了 Linux 操作系统内核。 1995 年，Apache 诞生，随即占据 Web 服务器大部分市场份额。 2000 年，开源延伸至移动和云领域，由 Google 等大企业驱动，影响技术发展路线和市场格局。 2008 年，Github 等代码托管平台，采用 pull/request 等方式协同合作，将开源推向了新高度。 2014 年，Google 开源 Kubernetes，获得极大关注。经过几年发展，Kubernetes 成为事实上的分布式架构平台。 开源协议软件的开源协议授予所有用户使用，修改以及共享的权限，并明确表示了哪些行为是准许的，哪些行为是禁止的。不同的开源协议，也有不同的侧重点。 GPL我们很熟悉的 Linux 是采用了 GPL。GPL 协议和 BSD、 MIT 等鼓励代码重用的许可很不一样。GPL 要求修改后的代码或者衍生品，也要采用 GPL 协议，既修改后的代码或者衍生品，必须也是开源和免费的。 BSD是一个给于使用者很大自由的协议。可以自由的使用，修改源代码，也可以将修改后的代码作为开源或者专有软件再发布。 MITMIT 与 BSD 类似，但是比 BSD 协议更加宽松，是目前最少限制的协议。这个协议唯一的条件就是在修改后的代码或者发行包包含原作者的许可信息。 因此，一些公司往往需要小心 GPL（GPL、AGPL、SSPL）的使用 开源中国有一篇文章介绍 MIT 协议，推荐阅读~ 总结放两张关于开源协议的总结，非常简洁易懂： 上图来自：阮一峰-如何选择开源许可证？ 上图来自：选择一个开源软件协议 对应英文网址Choose an open source license 参考 开源软件是什么意思？闭源呢？ 一个 UP 主的博客 About Open Source Licenses 陈少文-开源正在重构商业模式 opensource-logo]]></content>
      <categories>
        <category>IT 基础</category>
      </categories>
      <tags>
        <tag>开源</tag>
        <tag>基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DevOps 之 ELK 基础设施搭建]]></title>
    <url>%2F2019%2F08%2F14%2Felk-install%2F</url>
    <content type="text"><![CDATA[简介 Kibana官方文档 Installing Kibana 中提供了多种安装包对应的指导链接！本文就先选择 tar 包的方式安装。 下载 Kibana 安装包同样，Kibana 在我司镜像站上也有对应的软件包： 1234567https://mirrors.huaweicloud.com/kibana/7.3.2/wget https://mirrors.huaweicloud.com/kibana/7.3.2/kibana-7.3.2-linux-x86_64.tar.gzwget https://mirrors.huaweicloud.com/kibana/7.3.2/kibana-7.3.2-linux-x86_64.tar.gz.sha512shasum -a 512 -c elasticsearch-7.3.2-linux-x86_64.tar.gz.sha512tar xzf kibana-7.3.2-linux-x86_64.tar.gzchown -R michael kibana-7.3.2-linux-x86_64cd kibana-7.3.2-linux-x86_64 配置 Kibana12345egrep -v "^#|^$" config/kibana.yml # 如下内容是修改的配置server.port: 5601server.host: "0.0.0.0"elasticsearch.hosts: ["http://192.168.3.43:9200"]kibana.index: ".kibana" 更多配置内容，可以阅读 Configuring Kibana 运行 Kibana如下方式可以实现后台运行，避免 Ctrl+C 终止了程序： 1nohup bin/kibana &amp; 访问：http://192.168.3.43:5601/ 这时候可以看到我们之前搭建的集群节点了： Filebeat &amp;&amp; Logstash123https://mirrors.huaweicloud.com/filebeat/7.3.0/wget https://mirrors.huaweicloud.com/filebeat/7.3.0/filebeat-7.3.0-linux-x86_64.tar.gzwget https://mirrors.huaweicloud.com/filebeat/7.3.0/filebeat-7.3.0-linux-x86_64.tar.gz.sha512 目前项目中是采用的直接往 Elasticsearch 中存储数据 + Kibana 展示数据的方式。所以，Filebeat 和 Logstash 暂时没接触过。不过，在 B 站上看到一位 UP 主发了很多相关的学习教程，安利一下： EP26 - 安装与初始化配置ELK 6 ELK搜索结果 上面这位 UP 主的博客 总结本文是通过 tar 包方式安装的，发现，还不如用 RPM 包来的方便。不过配置的内容其实差不多，区别可能就是，RPM 包方式，可以直接用 systemctl 的命令查看状态、重启等。 参考 程序羊-CentOS7上ElasticSearch安装填坑记 FAQ 有帮助 极客时间-Elasticsearch核心技术与实战 这篇文章阐述了 ES 集群的主节点的仲裁等知识 搭建ELFK日志采集系统 静觅—Ubuntu 搭建 Elasticsearch 6 集群流程 阮一峰-全文搜索引擎 Elasticsearch 入门教程 ELK 架构之 Elasticsearch 和 Kibana 安装配置 使用 ELK(Elasticsearch + Logstash + Kibana) 搭建日志集中分析平台实践 手把手教你，在CentOS上安装ELK，进行服务器日志收集 Filebeat 博客园-开始使用Filebeat SpringBoot+ES 【ES】Java High Level REST Client 使用示例（增加修改） Elasticsearch Java Rest Client 上手指南（上） 博客园——springboot elasticsearch 集成注意事项 lasticsearch系列七：ES Java客户端-Elasticsearch Java client（ES Client 简介、Java REST Client、Java Client、Spring Data Elasticsearch）]]></content>
      <categories>
        <category>ELK</category>
      </categories>
      <tags>
        <tag>DevOps</tag>
        <tag>CICD</tag>
        <tag>ELK</tag>
        <tag>ES</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Boot 实战 —— 通过 Sentry 收集 Log4j2 异常日志记录]]></title>
    <url>%2F2019%2F08%2F11%2Fjava-spring-boot-sentry-log4j2%2F</url>
    <content type="text"><![CDATA[背景在日常线上运行的应用中如果报了异常，怎么在第一时间收到报错告警并且查看报错日志呢？周五就因为缺乏报错日志，导致构建服务受影响超过了 2 小时，虽然不至于「死人」，但是也确实让我意识到日志的重要性！后来临时在相关的地方加上日志，通过错误信息很快定位了到了原因，原来是数据库被运维人员做了新特性的改动，而我们服务还未适配好。想想当时的场景，还真是有点紧张~囧 今天就学习一下利用 Sentry 作为日志收集系统，结合之前学习的 log4j2 日志输出，主动收集异常日志。 Sentry我们先来 Sentry 是怎么介绍自己的： Open-source error tracking that helps developers monitor and fix crashes in real time. Iterate continuously. Boost efficiency. Improve user experience 大体意思就是：Sentry 是一款开源的错误跟踪系统，可帮助开发人员实时监控和修复崩溃。它是不断迭代的，提高效率，改善用户体验。Sentry 本身的文档也记载的比较全面，强烈安利，一般问题可以通过阅读 Doc 学习或者论坛咨询。 OK，下面我们就开始通过 Docker 安装 Sentry。 PS：如果你的 Docker 环境还未配置好，可以阅读我之前的总结：Linux——CentOS 安装 Docker 教程 前提在 Sentry Installation 页面，官方做了总结，Sentry 需要和几个服务有交互： PostgreSQL：Docker image postgres:9.5，这里明确版本是 9.5，我觉得非常棒！这保证了在未来部署的可重现，避免了不同版本差异造成部署失败的问题。 Redis 官方说如果你使用的 Ubuntu &lt; 15.04，推荐安装 chirs-lea/redis-server 文档推荐的是 Docker image redis:3.2-alpine. 硬件要求，具体的可以阅读官方文档，我这里仅仅是家里测试使用，因此无所谓。 下面的步骤其实是官方文档的翻译，但是，跟着走了一遍之后发现，服务并不能正常运行起来，但是也没啥坏处，主要步骤其实就和这个差不多，可能是某些细节漏了，因此，你可以大体浏览一下步骤。如果不想浪费时间，可以直接跳到下面的 「脚本一键安装 Sentry」小节。 创建容器需要 Docker 版本 1.10+ 克隆仓库 getsentry/onpremise。这个仓库是定制化构建你自己 Sentry 镜像的基础： 123cd /datagit clone https://github.com/getsentry/onpremise.gitcd onpremise 仓库里的 sentry.conf.py and config.yml 可供你 配置 Sentry 所用，建议先浏览一下这个配置文档。 现在开始构建我们定制好的镜像。如果你构建的镜像需要推送到你本地的镜像仓中，那么可以用如下方式先定义好镜像名再构建： 1REPOSITORY=registry.michael.com/sentry make build push 我本地没有镜像仓，只需要用如下方式构建即可： 1make build 运行依赖的服务Redis: 1234docker run \ --detach \ --name sentry-redis \ redis:3.2-alpine PostgreSQL: 123456docker run \ --detach \ --name sentry-postgres \ --env POSTGRES_PASSWORD=secret \ --env POSTGRES_USER=sentry \ postgres:9.5 Outbound Email: 1234docker run \ --detach \ --name sentry-smtp \ tianon/exim4 运行 Sentry 服务${REPOSITORY} 只的是你刚刚定义的镜像名，如果没有，默认是 sentry-onpremise。 为了测试镜像是 OK 的，可以运行如下命令: 123docker run \ --rm $&#123;REPOSITORY&#125; \ --help 现在可以生成一个 secret-key 值： 123docker run \ --rm $&#123;REPOSITORY&#125; \ config generate-secret-key 生成的值可以在 config.yml 中设置给 system.secret-key,或者通过环境变量。如果是设置在 config.yml 文件中，这时候你必须重新构建你的镜像。 运行的基本命令举例如下： 12345678docker run \ --detach \ --link sentry-redis:redis \ --link sentry-postgres:postgres \ --link sentry-smtp:smtp \ --env SENTRY_SECRET_KEY='&lt;secret-key&gt;' \ $&#123;REPOSITORY&#125; \ &lt;command&gt; 官方文档里有一行小字，说明的是后面的文档，不会特地的写上 –link 去表示链接容器，但是这些都是必须的！同时，${REPOSITORY} 会被引用为 sentry-onpremise。 运行 Web 服务暴露的是 9000 的端口，这样部署之后，可以通过 http://localhost:9000/ 访问。 12345678910docker run \ --detach \ --link sentry-redis:redis \ --link sentry-postgres:postgres \ --link sentry-smtp:smtp \ --name sentry-web \ --publish 9000:9000 \ --env SENTRY_SECRET_KEY=$&#123;SENTRY_SECRET_KEY&#125; \ sentry-onpremise \ run web 脚本一键安装 Sentry发现了 getsentry/onpremise/install.sh 这个脚本，看懂这个脚本里的内容基本上就差不多知道安装步骤了。 读一下脚本： LATEST_STABLE_SENTRY_IMAGE=&#39;sentry:9.1.2&#39; 安装的是 sentry:9.1.2 在 docker-compose.yml 中会去创建两个卷，分别是 sentry-data和 sentry-postgres，这和上面步骤是不是发现区别了，上面创建postgres 时，可没有创建卷； cp -n .env.example &quot;$ENV_FILE&quot; 会将仓库下的 .env.example 文件重命名为 .env 文件，其实里面就是为了设置一个环境变量 SENTRY_SECRET_KEY export SENTRY_IMAGE=$LATEST_STABLE_SENTRY_IMAGE 命名了一个环境变量，记录了镜像名 docker-compose build 开始构建镜像啦，其实就是类似这个命令 docker build . SECRET_KEY=$(docker-compose run --rm web config generate-secret-key 2&gt; /dev/null | tail -n1 | sed -e &#39;s/[\/&amp;]/\\&amp;/g&#39;) 运行命令获得 secret-key 值，赋值给了变量 SECRET_KEY sed -i -e &#39;s/^SENTRY_SECRET_KEY=.*$/SENTRY_SECRET_KEY=&#39;&quot;$SECRET_KEY&quot;&#39;/&#39; $ENV_FILE 将 SECRET_KEY 变量值填写到环境变量文件 .env 中 接着就是设置数据库的步骤，这其实是就是为了在数据库中添加账号数据和其他一些数据表生成 最后就是执行 cleanup 函数 执行脚本之前，我们先把之前创建的几个服务删除掉吧： 12docker stop sentry-smtp sentry-postgres sentry-redisdocker rm $(docker ps -aq) 配置邮箱通过上面的阅读，可以发现，运行脚本时，会去执行 docker build .，这个会将配置文件 config.yml 和环境变量 .env 放入镜像的。因此，我们启用发生异常时获取邮箱告警的功能，需要现在配置文件中设置好邮箱配置。 这里我们选择在 .env 中配置好环境变量，实现邮箱的配置：配置 config.yml: 123456789SENTRY_SECRET_KEY=)g=lkl1)uugx236%#)mq2o34^@a&amp;g3q85q**co*hbapm5y1*bs# 邮箱设置SENTRY_EMAIL_HOST=smtp.qq.comSENTRY_EMAIL_USER=649168982@qq.comSENTRY_SERVER_EMAIL=649168982@qq.com# 这里指的是邮箱的授权码，而非密码SENTRY_EMAIL_PASSWORD=xxxxSENTRY_EMAIL_USE_TLS=trueSENTRY_EMAIL_PORT=587 网上的教程，大多数是 SENTRY_EMAIL_HOST: &#39;smtp.exmail.qq.com&#39;,这个是企业邮箱，我们个人的不这么设置。 SENTRY_EMAIL_USER 和 SENTRY_SERVER_EMAIL 要保持一致； 这里我设置 1 分钟，就能及时收到邮箱，但是设置 5 分钟，等了 5 分钟，也没收到，不知道是何原因： 经过上面的设置，可以试试邮箱发送功能是否 OK：点击左上角头像，选择 Admin-》Mail-》测试设置 部署 sentry下面开始安装步骤： sh install.sh 执行安装脚本，脚本执行完需要一点时间，运行完成之后，会退出。中间过程会让你选择是否创建账号： 接着运行 docker-compose up -d 即可； PS：为何容器的名称是都是 onpremise 开头的呢？因为不指定名称时，会默认取目录名的。 这时候输入刚刚创建的账号登录： 配置 Sentry创建 project那我之前的 log4j2 的 demo 作为演示，这里选择一个 Java 项目，并且，我还创建了一个叫 spring-boot 的 Team。 spring-boot 项目适配官方文档-Java 给出了适用于 Java 项目的全面的适配指南，咱们使用的是 log4j2。 引入依赖12345&lt;dependency&gt; &lt;groupId&gt;io.sentry&lt;/groupId&gt; &lt;artifactId&gt;sentry-log4j2&lt;/artifactId&gt; &lt;version&gt;1.7.26&lt;/version&gt;&lt;/dependency&gt; log4j2.xml 配置修改 configuration 中加上 packages=&quot;org.apache.logging.log4j.core,io.sentry.log4j2&quot; 下面示例中的 SentryAppender 表示发送 warn 级别的日志到 Sentry Server。ConsoleAppender 仅仅表示是一个示例，表示你项目中之前使用的非 sentryappener 的例子。 123456789101112131415161718&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;configuration status="warn" packages="org.apache.logging.log4j.core,io.sentry.log4j2"&gt; &lt;appenders&gt; &lt;Console name="Console" target="SYSTEM_OUT"&gt; &lt;PatternLayout pattern="%d&#123;HH:mm:ss.SSS&#125; [%t] %-5level %logger&#123;36&#125; - %msg%n" /&gt; &lt;/Console&gt; &lt;Sentry name="Sentry" /&gt; &lt;/appenders&gt; &lt;loggers&gt; &lt;root level="INFO"&gt; &lt;appender-ref ref="Console" /&gt; &lt;!-- Note that the Sentry logging threshold is overridden to the WARN level --&gt; &lt;appender-ref ref="Sentry" level="WARN" /&gt; &lt;/root&gt; &lt;/loggers&gt;&lt;/configuration&gt; 经过测试，，因为原有项目中的 apppender 都是为了之前的作用设置的，比如控制台打印、比如输出到文件。要想将异常信息发送到 Sentry，这里的SentryAppender 是必不可少的。别忘了 appender-ref 也要设置！ 配置 DSN配置页面 介绍了如何设置 DSN（Data Source Name）。 进入 Sentry，项目的 DSN 在项目页面-》setings-》Clinet Keys(DSN) 中可以发现： 配置 DSN 有好几种方式，具体的可以在页面查看，这里介绍我采用的： 在 resources 文件夹下，新建 sentry.properties： 1dsn=http://8d53042c89774e5dba599ee67c5c8804@192.168.3.43:9000/3 默认的就是 sentry.properties，一开始我直接写在了 application.properties 中，Sentry 怎么也收不到异常日志。 代码中代码示例： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152import org.apache.logging.log4j.LogManager;import org.apache.logging.log4j.Logger;import org.apache.logging.log4j.Marker;import org.apache.logging.log4j.MarkerManager;public class MyClass &#123; private static final Logger logger = LogManager.getLogger(MyClass.class); private static final Marker MARKER = MarkerManager.getMarker("myMarker"); void logSimpleMessage() &#123; // This sends a simple event to Sentry logger.error("This is a test"); &#125; void logWithBreadcrumbs() &#123; // Record a breadcrumb that will be sent with the next event(s), // by default the last 100 breadcrumbs are kept. Sentry.record( new BreadcrumbBuilder().setMessage("User made an action").build() ); // This sends a simple event to Sentry logger.error("This is a test"); &#125; void logWithTag() &#123; // This sends an event with a tag named 'log4j2-Marker' to Sentry logger.error(MARKER, "This is a test"); &#125; void logWithExtras() &#123; // MDC extras ThreadContext.put("extra_key", "extra_value"); // NDC extras are sent under 'log4j2-NDC' ThreadContext.push("Extra_details"); // This sends an event with extra data to Sentry logger.error("This is a test"); &#125; void logException() &#123; try &#123; unsafeMethod(); &#125; catch (Exception e) &#123; // This sends an exception event to Sentry logger.error("Exception caught", e); &#125; &#125; void unsafeMethod() &#123; throw new UnsupportedOperationException("You shouldn't call this!"); &#125;&#125; 可以发现，Sentry 使用的接口和之前 log4j2 是有区别的： 12345678// 原来import org.slf4j.Logger;import org.slf4j.LoggerFactory;private final Logger log = LoggerFactory.getLogger(this.getClass());// sentryimport org.apache.logging.log4j.LogManager;import org.apache.logging.log4j.Logger;private final Logger log = LogManager.getLogger(this.getClass()); 实际过程中，这里是很多人忽视的，一定要仔细一点！ 这时候，使用我们之前的错误接口故意打印错误日志，看看 Sentry 的捕获效果吧： 总结今天在之前加入的一个技术微信群里，一位同学发了一篇怎么搭建 Zabbix 的文章，被群主踢了。后来大家讨论，这种搭建的文章，普遍质量比较低，没有太多分享的意义，应该要更多的关注一些前言的知识、或者底层的基础知识。这种观点我是比较认同的，但是谁不是一步一步慢慢来的呢？ 今天搭建 Sentry 的过程，对之前 docker-compose 的用法又有了进一步的认识，学习到了使用 .env 的方式设置容器内环境变量的方式，同时，也学习到了可以公用一种配置，让 docker-compose 文件内多个服务公用的方式。其实，自己的每一点的折腾，都会是后面的基石。只要持续积累，才会越走越顺！ 示例代码 awesome-spring-boot-examples/log4j2 参考 神奇的展示-用 Docker 部署 Sentry Bug 日志收集服务 掘金-搭建私有的前端监控服务: sentry sentry配置邮件 自建sentry后，配置了邮件服务，但是还是收不到验证邮件？ 这个问题有参考意义，还是推荐通过环境变量的方式而不是 config.yml 配置邮箱]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>DevOps</tag>
        <tag>Java</tag>
        <tag>Spring Boot</tag>
        <tag>日志</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Boot 实战 —— 日志框架 Log4j2 SLF4J 的学习]]></title>
    <url>%2F2019%2F08%2F10%2Fjava-spring-boot-log4j2%2F</url>
    <content type="text"><![CDATA[背景 Java 中比较常用的日志框架： log4j(Log for Java)：Apache 的一个开源项目，七种日志级别：OFF、FATAL、ERROR、WARN、INFO、DEBUG、TRACE logback：是一个很成熟的日志框架，其实 logBack 和 log4j 出自一个人之手，这个人就是 Ceki Gülcü。logback 比 log4j 大约快 10 倍、消耗更少的内存，迁移成本也很低，自动压缩日志、支持多样化配置、不需要重启就可以恢复 I/O 异常等优势 log4j2：作者认为，log4j2已经不仅仅是 log4j 的一个升级版本了，而是从头到尾被重写的，这可以认为这其实就是完全不同的两个框架 Spring Boot 默认使用 logback，但相比较而言，log4j2 在性能上面会更好。SpringBoot 高版本都不再支持 log4j，而是支持 log4j2。log4j2，在使用方面与 log4j 基本上没什么区别，比较大的区别是 log4j2 不再支持 properties 配置文件，支持 xml、json 格式的文件。 《阿里巴巴Java开发手册》，其中有一条规范做了「强制」要求： 应用中不可直接使用日志系统（Log4j Logback）中的 API，而应依赖使用日志框架 SLF4J 中的 API，使用日志门面模式的日志框架，有利于维护和各个类的日志处理方式统一。 Java 简易日志门面（Simple Logging Facade for Java，缩写 SLF4J），它并不是真正的日志框架,他是对所有日志框架制定的一种规范、标准、接口，并不是一个框架的具体的实现，因为接口并不能独立使用，需要和具体的日志框架实现配合使用。可以在软件部署的时候决定要使用的 Logging 框架，目前主要支援的有 Java logging API、log4j 及 logback 等框架。 理解 SLF4J接口用于定制规范，可以有多个实现，使用时是面向接口的(导入的包都是 slf4j 的包而不是具体某个日志框架中的包)，即直接和接口交互，不直接使用实现，所以可以任意的更换实现而不用更改代码中的日志相关代码。 比如：slf4j 定义了一套日志接口，项目中使用的日志框架是logback，开发中调用的所有接口都是 slf4j 的，不直接使用 logback，调用是 自己的工程调用 slf4j 的接口，slf4j 的接口去调用 logback 的实现，可以看到整个过程应用程序并没有直接使用 logback，当项目需要更换更加优秀的日志框架时(如log4j2)只需要引入 log4j2 的 jar 和 Llg4j2 对应的配置文件即可，完全不用更改 Java 代码中的日志相关的代码 logger.info(“xxx”)，也不用修改日志相关的类的导入的包( import org.slf4j.Logger; import org.slf4j.LoggerFactory;) 总结：使用日志接口便于更换为其他日志框架。 One More Thing：上面的这几段话是参考文章中截取的，也让我确实理解了为何推荐使用 SLF4J 的原因。这种做法感觉就是有点「面向接口编程」的思想，今天也查阅了一些这方面的资料，也让我想起了为何项目中写 Service 代码时，往往是先写个接口、然后在写个该接口的实现类。待有时间好好研究一些这块的优点！ 性能分析 log4j2 的性能几乎是碾压的，优势很明显。更多关于性能的评测，在官网可以看到 log4j2 依赖需要在 pom 文件中排除默认的日志框架并引入 log4j2 依赖。 12345678910111213141516171819&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;!-- 去掉logback配置 --&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-logging&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;!-- 引入log4j2依赖 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-log4j2&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; log4j2 使用123456789import org.slf4j.Logger;import org.slf4j.LoggerFactory;// 这了两种写法都 OK，推荐第一种，不用每次都要修改类名private static final Logger logger = LoggerFactory.getLogger(this.getClass());private static final Logger logger = LogManager.getLogger(UserController.class);//...logger.debug("this is debug");logger.info("this is info"); log4j2 日志级别从小到大依次是:all、trace、debug、info、warn、error、fatal、off 由于我们使用的是 slf4j 接口包，该接口包中只提供了未标有删除线的日志级别的输出。 log4j2 配置文件结构配置文件的主要结构如下： Appenders: Appender Filter Layout Policies Strategy Loggers Logger RootLogger AppenderAppender 可以理解为一个管道，定义了日志内容的去向(保存位置)。 配置一个或者多个 Filter。 配置 Layout 来控制日志信息的输出格式。 配置 Policies 以控制日志何时(When)进行滚动。 配置 Strategy 以控制日志如何(How)进行滚动。 注意点： 多个 appender 不能指向同一个日志文件，否则会报错：Configuration has multiple incompatible Appenders pointing to the same resource &#39;logs/mybatis-demo-warn.log&#39; ImmediateFlush=true，一旦有新日志写入，立马将日志写入到磁盘的文件中。当日志很多，这种频繁操作文件显然性能很低下 immediateFlush：log4j2 接收到日志事件时，是否立即将日志刷到磁盘。默认为 true。 BufferedIO: 文件流写出是否使用缓冲，true 表示使用，默认值为 false 即不使用缓冲。测试显示，即使在启用immediateFlush 的情况下，设置 bufferedIO=true 也能提高性能。 一个 LogConfig 可以使用多个 appender，一个 appender 也可以被多个 LogConfig 使用 官宣——Appender PatternLayout这是常用的日志格式化类，其它日志格式化类很少用。 1&lt;PatternLayout pattern="%d&#123;HH:mm:ss.SSS&#125; [%t] %-5level %logger&#123;36&#125; - %msg%n" charset="UTF-8"/&gt; 常用说明： 123456789101112%d&#123;HH:mm:ss.SSS&#125; 表示输出到毫秒的时间%t 输出当前线程名称%-5level 输出日志级别，-5表示左对齐并且固定输出5个字符，如果不足在右边补0%logger 输出logger名称，因为Root Logger没有名称，所以没有输出%msg 日志文本%n 换行其他常用的占位符有：%F 输出所在的类文件名，如Client.java%L 输出行号%M 输出所在方法名%l 输出语句所在的行数, 包括类名、方法名、文件名、行数 关于 pattern 的格式点击 官宣——Pattern Layout FilterFilters 决定日志事件能否被输出。过滤条件有三个值：ACCEPT(接受)，DENY(拒绝)，NEUTRAL(中立)。 常用的 Filter 实现类有： LevelRangeFilter TimeFilter ThresholdFilter 简单说就是 log4j2 中的过滤器 ACCEPT 和 DENY 之后，后续的过滤器就不会执行了，只有在 NEUTRAL 的时候才会执行后续的过滤器 1234567891011121314151617&lt;Console name="Console"&gt; &lt;!-- 设置 onMismatch="NEUTRAL" 可以让日志经过后续的过滤器 最后一个过滤器建议设置 onMismatch="DENY", 不然日志就输出了。 --&gt; &lt;Filters&gt; &lt;!-- 从大到小：error, warn, info, debug, trace --&gt; &lt;LevelRangeFilter minLevel="error" maxLevel="info" onMatch="ACCEPT" onMismatch="NEUTRAL" /&gt; &lt;!-- 只允许在每天的 8点~8点半 之间输出日志 --&gt; &lt;TimeFilter start="08:00:00" end="08:30:00" onMatch="ACCEPT" onMismatch="DENY" /&gt; &lt;/Filters&gt; &lt;PatternLayout pattern="%d&#123;HH:mm:ss.SSS&#125; [%t] %-5level %logger&#123;36&#125; - %msg%n" charset="UTF-8"/&gt;&lt;/Console&gt; LevelRangeFilter 对它们进行了 ACCEPT，而剩下的 trace Msg 和 debug Msg 则会经过下一个过滤器。 PolicyPolicy &amp; Strategy Policy 是用来控制日志文件何时(When)进行 Rolling/滚动的； Strategy 是用来控制日志文件如何(How)进行 Rolling/滚动的。 所谓「日志滚动」就是当达到设定的条件后，日志文件进行切分。比如：工程师想让系统中的日志按日进行切分，并且按月归档。 Rolling 的意思是当满足一定条件后，就重命名原日志文件用于备份，并重新生成一个新的日志文件。例如需求是每天生成一个日志文件，但是如果一天内的日志文件体积已经超过 1G，就重新生成。两个条件满足一个即可。 Policy常用的实现类: SizeBasedTriggeringPolicy，根据日志文件的大小进行滚动。单位有：KB，MB，GB CronTriggeringPolicy，使用 Cron 表达式进行日志滚动，很灵活 TimeBasedTriggeringPolicy，这个配置需要和 filePattern 结合使用，注意 filePattern 中配置的文件重命名规则。滚动策略依赖于 filePattern 中配置的最具体的时间单位，根据最具体的时间单位进行滚动。这种方式比较简洁。CronTriggeringPolicy 策略更强大 在 TimeBasedTriggeringPolicy 标签中加上了 modulate 属性并设置为 true，该属性的意思是是否对日志生成时间进行调制。若为 true，则日志时间将以 0 点为边界进行偏移计算。例如第一次日志保存时间是 3 点，modulate为 true，interval 是 4h。那么下次生成日志时间是 4点，08:00，12:00……。 1234567891011121314151617181920212223&lt;Appenders&gt; &lt;RollingRandomAccessFile name="File" fileName="logs/app.log" filePattern="logs/$$&#123;date:hh-mm&#125;/%d&#123;hh-mm-ss&#125;.app.%i.log" &gt; &lt;PatternLayout pattern="%d&#123;HH:mm:ss.SSS&#125; [%t] %-5level %logger&#123;36&#125; - %msg%n" charset="UTF-8"/&gt; &lt;Policies&gt; &lt;!-- 每 5s 翻滚一次 --&gt; &lt;!--&lt;CronTriggeringPolicy schedule="0/5 * * * * ?" /&gt;--&gt; &lt;!-- filePattern中最具体的时间单位是 秒。 这里用 TimeBasedTriggeringPolicy 替换 CronTriggeringPolicy 注意：modulate属性是指从启动时间开始算5秒，还是从0秒开始算5秒，运行一下就明白了。 modulate: true(默认值) // 会从启动时间开始算 5秒 modulate: false // 从 0秒开始算 --&gt; &lt;TimeBasedTriggeringPolicy interval="5" modulate="true"/&gt; &lt;SizeBasedTriggeringPolicy size="10 MB"/&gt; &lt;/Policies&gt; &lt;DefaultRolloverStrategy max="10" /&gt; &lt;/RollingRandomAccessFile&gt;&lt;/Appenders&gt; StrategyStrategy常用的实现类： DefaultRolloverStrategy DirectWriteRolloverStrategy 这两个 Strategy 都是控制如何进行日志滚动的。 DefaultRolloverStrategy 默认的 max为 7。 1&lt;DefaultRolloverStrategy max="7"/&gt; max 参数指定了计数器的最大值。一旦计数器达到了最大值，过旧的文件将被删除。 注意：不要认为 max 参数是需要保留的日志文件的最大数目。 max 参数是与 filePattern 中的计数器 %i 配合起作用的，其具体作用方式与 filePattern 的配置密切相关。 1.如果filePattern中仅含有date/time pattern，每次rollover时，将用当前的日期和时间替换文件中的日期格式对文件进行重命名。max参数将不起作用。 如，filePattern=&quot;logs/app-%d{yyyy-MM-dd}.log&quot; 2.如果 filePattern 中仅含有整数计数器（即%i ），每次 rollover 时，文件重命名时的计数器将每次加1（初始值为1），若达到 max 的值，将删除旧的文件。 如，filePattern=&quot;logs/app-%i.log&quot; 3.如果 filePattern 中既含有 date/time pattern，又含有 %i，每次 rollover 时，计数器将每次加 1，若达到 max 的值，将删除旧的文件，直到 data/time pattern 不再符合，被替换为当前的日期和时间，计数器再从1开始。 如，filePattern=&quot;logs/app-%d{yyyy-MM-dd HH-mm}-%i.log&quot; Appender 类型FileAppender(File)、RandomAccessFileAppender(RandomAccessFile) 相同点：写入日志信息到文件 不同点：使用的 I/O 实现类不同，前者使用 FileOutputStream，后者使用 RandomAccessFile。 官方文档说是在 bufferedIO=true (默认是 true )的情况下，性能提升 20% ~ 200%。 常用属性: fileName：来指定文件位置，文件或目录不存在则会自动创建。 immediateFlush：是否每次写入都要立刻刷新到硬盘中。默认 true，如果使用默认值可能会影响性能。 RollingFileAppender(RollingFile)、RollingRandomAccessFileAppender(RollingRandomAccessFile) 相同点：写入日志信息到文件 不同点：使用的 I/O 实现类不同，前者使用 FileOutputStream，后者使用 RandomAccessFile。 上一对的实现类不能进行「日志滚动」，而带有 rolling 字样的 appender 就可以实现「滚动」功能。有「滚动」，会判断是否满足封存文件的要求，执行日志存档操作。 RollingRandomAccessFile Appender，相比 RollingFileAppender有很大的性能提升，官网宣称是20-200% 1234567891011&lt;RollingRandomAccessFile name="File" fileName="logs/app.log" filePattern="logs/$$&#123;date:hh-mm&#125;/%d&#123;hh-mm-ss&#125;.app.%i.log" &gt; &lt;PatternLayout pattern="%d&#123;HH:mm:ss.SSS&#125; [%t] %-5level %logger&#123;36&#125; - %msg%n" charset="UTF-8"/&gt; &lt;Policies&gt; &lt;!-- 每 5s 翻滚一次 --&gt; &lt;CronTriggeringPolicy schedule="0/5 * * * * ?" /&gt; &lt;SizeBasedTriggeringPolicy size="10 MB"/&gt; &lt;/Policies&gt; &lt;DefaultRolloverStrategy max="10" /&gt;&lt;/RollingRandomAccessFile&gt;&lt;/Appenders&gt; 常用属性： filePattern：指定当发生Rolling时，文件的转移和重命名规则。至于其中的 $${date:hh-mm} 是表示了一个文件夹（以 小时-分钟）命名。 DefaultRolloverStrategy 指定了如何(How)进行翻滚，并且指定了最大翻滚次数(影响%i参数值)，超过次数之后会按照相应的规则删除旧日志。 Policies: 这里就是规定了何时进行滚动(When)，可以有多个Policy。 CronTriggeringPolicy，比如设置每 5s 进行一次翻滚 SizeBasedTriggeringPolicy 指定当文件体积大于size指定的值时，触发Rolling。例如，如果当前文件超过了 10MB，但是文件的名字还没有进行翻滚(建立新文件)，那么就会用%i的方式进行翻滚。 如果配置的是 RollingFile 或 RollingRandomAccessFile，则必须配置一个 Policy。 翻滚理解假设计数器次数设为2次 &lt;DefaultRolloverStrategy max=&quot;2&quot; /&gt;，filePattern 中既含有 date/time pattern，又含有 %i。 当满足翻滚触发条件时（时间间隔到了 OR 文件大小超了），就会启动 Rolling： app.log 第一次翻滚：app.log app.1.log // app.log -&gt; app.1.log第二次翻滚：app.log app.1.log app.2.lop // app.log -&gt; app.2.log 一个循环结束，到达了最大保存数 2 了，那么，app1.log 会被删除，下一个 app3.log 就会覆盖 app2.log，app2.log会改名为app1.log 第三次翻滚：app.log app.2.lop app.3.lop // app.log -&gt; app.3.log第四次翻滚：app.log app.3.lop app.4.lop // app.log -&gt; app.4.log 理解：编号最近的一次也就是最新的一次 log，而采取了 Policy 方式的日志，fileName 中保存的日志将不会是全量的日志，而是根据你 Policy 的条件切分后的最近一次的日志内容。 博客园-Log4j2中RollingFile的文件滚动更新机制 滚动机制介绍的很详细 CSDN-log4j2教程【RollingFileAppender】 一个 Appender 示例按月归档日志，按日进行切分，限制单文件大小为 500MB, 一天最多生成20个文件，也就是(20 * 500)MB大小的日志 12345678910111213141516171819202122&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;Configuration name="baseConf" status="warn" monitorInterval="30"&gt; &lt;Appenders&gt; &lt;RollingRandomAccessFile name="File" fileName="logs/app.log" filePattern="logs/$$&#123;date:yyyy-MM&#125;/%d&#123;yyyy-MM-dd&#125;.app.%i.log" &gt; &lt;PatternLayout pattern="%d&#123;HH:mm:ss.SSS&#125; [%t] %-5level %logger&#123;36&#125; - %msg%n" charset="UTF-8"/&gt; &lt;Policies&gt; &lt;TimeBasedTriggeringPolicy interval="1" modulate="false"/&gt; &lt;SizeBasedTriggeringPolicy size="500MB"/&gt; &lt;/Policies&gt; &lt;DefaultRolloverStrategy max="20" /&gt; &lt;/RollingRandomAccessFile&gt; &lt;/Appenders&gt; &lt;Loggers&gt; &lt;Root level="info"&gt; &lt;AppenderRef ref="File"/&gt; &lt;/Root&gt; &lt;/Loggers&gt;&lt;/Configuration&gt; Logger简单说 Logger 就是一个路由器，指定类、包中的日志信息流向哪个管道，以及控制他们的流量(日志级别) Logger 部分为两个 Logger: RootLogger(必须配置) Logger 注意：Logger 中也可以加过滤器的！ 日志重复打印问题如果 Root 中的日志包含了 Logger 中的日志信息，并且 AppenderRef 是一样的配置，则日志会打印两次。 这时候我们需要使用一个 Logger 的属性来解决，那就是 additivity，其默认值为 true，需要配置为false 123456789101112131415161718192021222324&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;Configuration name="baseConf" status="warn" monitorInterval="30"&gt; &lt;Appenders&gt; &lt;Console name="Console"&gt; &lt;PatternLayout&gt; &lt;Pattern&gt;%d %p %c&#123;1.&#125; [%t] %m%n&lt;/Pattern&gt; &lt;/PatternLayout&gt; &lt;/Console&gt; &lt;/Appenders&gt; &lt;Loggers&gt; &lt;Logger name="me.master.snail.log.LogMain" level="info" additivity="false"&gt; &lt;AppenderRef ref="Console"/&gt; &lt;/Logger&gt; &lt;Root level="trace"&gt; &lt;AppenderRef ref="Console"/&gt; &lt;Filters&gt; &lt;LevelRangeFilter minLevel="error" maxLevel="info" onMatch="ACCEPT" onMismatch="DENY" /&gt; &lt;/Filters&gt; &lt;/Root&gt; &lt;/Loggers&gt;&lt;/Configuration&gt; RootLogger 只能有 1 个，普通的 Logger 可以定义多个，可以细致到给某个类定义； 多个 Logger 配置重复了，在日志文件中会重复； 每一个 Logger 对应的 name 是包路径，表示在 name 包下的类使用 AppenderRef 指向的日志模板来输出日志； 不同的 LogConfig 之间其实是有继承关系的，子 LogConfig 会继承 parent 的属性，而所有 LogConfig 都继承自 Root LogConfig。所以即使只配置了 root logger，你一样可以在任何地方通过 LoggerFactory.getLogger 获取一个 logger 对象，记录日志; 先配置一个 Root，让所有需要使用日志的 logger 继承，然后对有特别需要的 logger 进行特殊的配置，比如我们希望 org.springframework 包只记录 error以及 warn 级别的 log，再比如，我们希望能显示mybatis 执行的 sql 的日志，都可以进行个性化的配置； Logger 等级实验12345678910&lt;logger name="org.springframework" level="INFO" additivity="true"&gt; &lt;AppenderRef ref="InfoLog"/&gt;&lt;/logger&gt;&lt;Root level="ERROR" additivity="true"&gt; &lt;AppenderRef ref="Console"/&gt; &lt;AppenderRef ref="InfoLog"/&gt; &lt;AppenderRef ref="WarnLog"/&gt; &lt;AppenderRef ref="ErrorLog"/&gt;&lt;/Root&gt; ROOT 等级设为 ERROR 时，org.springframework Logger 等级设为 OFF 时，发现原来的 warn.log 和 info.log 文件中，都只有级别大于或等于 ERROR 的日志信息了； ROOT 等级设为 ERROR 时，org.springframework Logger 等级设为 INFO 时，发现info.log 文件中，增加了 org.springframework 包的相关 INFO 级别的日志信息了； 总结： Logger 日志等级和 appender 日志等级的关系：logger 日志等级和 appender 日志等级，谁「高」听谁的； 普通 Logger 的优先级高 进阶在 log4j2 的官网建议开发者使用异步方式，这样做的好处是可以使用单独线程来打印日志，提高日志效率，避免由于打印日志而影响业务功能。 Log4j2 中的 AsyncLogger 的内部使用了 Disruptor 框架，因此要额外引入下面依赖： 123456&lt;!-- Disruptor --&gt;&lt;dependency&gt; &lt;groupId&gt;com.lmax&lt;/groupId&gt; &lt;artifactId&gt;disruptor&lt;/artifactId&gt; &lt;version&gt;3.3.7&lt;/version&gt;&lt;/dependency&gt; AsyncLogger 是官方推荐的异步方式，它提供了两种方式使用异步日志，即「全局异步」和「混合异步」。 全局异步：所有的日志都进行异步的日志记录 混合异步：同时使用同步日志和异步日志 全局异步的方式： 系统初始化的时候加上全局配置：System.setProperty(&quot;log4j2.contextSelector&quot;,&quot;org.apache.logging.log4j.core.async.AsyncLoggerContextSelector&quot;); 加载 JVM 启动参数里设置：-DLog4jContextSelector=org.apache.logging.log4j.core.async.AsyncLoggerContextSelector 开启全异步时，日志配置中需要使用普通的Root和Logger元素。如果使用了AsyncRoot或AsyncLogger，将产生不必要的开销。 混合异步： log4j2.xml 配置文件中使用 AsyncRoot/AsyncLogger 替代 Root/Logger 全异步是官方推荐的，也是性能最佳的方式，但同步异步混合使用，能够提供更大的灵活性。使用 AsyncRoot、AsyncLogger、Root、Logger 混合配置，可以实现同步异步混合。但是需要注意，配置中只能有一个 root 元素，也就是只能使用 AsyncRoot 或 Root 中的一个。 效果 示例代码 awesome-spring-boot-examples 参考Log4j2 Github-apache/logging-log4j2 掘金-zdran-Spring Boot 学习笔记(二) 整合 log4j2 博主写了一些 Spring Boot 教程 博客园-蜗牛大师-浅谈Log4j2日志框架及使用 介绍的非常详细，强烈推荐！ 博客园-Log4j2之Appenders 对 appender 介绍详细 Log4j2异步日志 CSDN-log4j2异步Logger 提供了一副异步记载日志的图 SLF4J 掘金—HollisChuang—为什么阿里巴巴禁止工程师直接使用日志系统(Log4j、Logback)中的 API]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Spring Boot</tag>
        <tag>日志</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Boot 实战 —— 日志框架 logback 的学习]]></title>
    <url>%2F2019%2F08%2F09%2Fjava-spring-boot-logback%2F</url>
    <content type="text"><![CDATA[背景 上一篇文章 Spring Boot 实战 —— 日志框架 Log4j2 SLF4J 的学习 中已经介绍了常用的日志框架的比较，本文介绍另外一个主流的日志框架 logback 展示 看懂日志 时间戳，精确到毫秒 logback 日志级别：日志级别分为：TRACE、DEBUG、INFO、WARN、ERROR、FATAL 进程 ID：进程 ID 指的是当前应用对应的 PID 分隔符：用于区分实际日志消息的开始 线程名称：括在方括号中 记录器名称：一般使用类名 日志内容：日志输出的打印内容 日志依赖1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-logging&lt;/artifactId&gt;&lt;/dependency&gt; 实际开发中我们不需要直接添加该依赖 spring-boot-starter-logging，因为 spring-boot-starter 其中包含了 spring-boot-starter-logging，该依赖内容就是 Spring Boot 默认的日志框架 logback。 PS：上一篇文章 中说明了，如果要采用 log4j2，那么需要排除 Spring Boot 自带的日志： 12345678910111213141516171819&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;!-- 去掉logback配置 --&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-logging&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;!-- 引入log4j2依赖 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-log4j2&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 控制台输出默认情况下， Spring Boot 只会记录 INFO、WARN、ERROR 级别的日志打印在控制台。Spring Boot 可以使用「调试模式」，会打印一些比较详细的额外信息，可以选用如下两种方式： 启动 JAR 模式时，加上 --debug,例如：java -jar &lt;app.jar&gt; --debug； 在配置文件中配置属性 debug=true； 这里的 DEBUG 模式只是会多打印系统默认的一些调用信息，并不会多打印你指定的 DEBUG 级别日志信息，除非你指定日志级别。 日志级别设置下面两种格式常用： logging.level.root=WARN root 日志以 WARN 级别输出信息； logging.level.com.michael.springbootlogback.congtroller=DEBUG 指定包下的类以 DEBUG 级别输出； root 表示 root 节点，它是必选节点，用来指定最基础的日志输出级别，默认是 INFO 级别，所以，此时若是不修改默认值，你直接指定其他包下的日志界别为 DEBUG 级别，其实也不会生效的。 另外，也可以设置日志组来批量设置日志级别，比如设定 com.michael.controller 和 com.michael.service 为同一组（包和包之间用英文逗号分隔）： 1logging.group.michael=com.michael.controller,com.michael.service 设置完日志组之后，给 michael 组设定日志级别： 1logging.level.michael=INFO Spring Boot 默认提供两个日志组： logging.group.web=org.springframework.core.codec,org.springframework.http,org.springframework.web logging.group.sql=org.springframework.jdbc.core 日志文件输出只需要在 Profile 配置文件，例如 application.properties 中设置 logging.file 或者 logging.path 属性即可： logging.file 设置日志文件，可以设置文件的绝对路径也可以设置相对路径，相对路径的话是相对应用的根目录，比如 logging.file=logs/demo.log; logging.path 设置日志的路径，也是既支持绝对路径也支持相对路径，比如 logging.path=logs，日志文件默认会存为 spring.log； 如果上面两个属性同时配置了，只有 logging.file 会生效；在日志文件达到 10MB 时，Spring Boot 会自动分割日志，当然，这个大小是可以通过 logging.file.max-size 属性更改的，下面谈谈有哪些配置属性。 日志配置除了上面介绍的配置属性外，还有其他一些属性，例如： logging.config 日志配置； logging.file.max-size 最大日志文件大小； logging.file.max-history 最大归档文件数量； logging.pattern.console 控制台输出的日志模式； logging.pattern.dateformat 日志的日期格式； logging.pattern.file 默认使用日志模式 logging.pattern.level 日志级别 XML 配置日志Spring Boot 中的 logback 默认使用 src/main/resources 文件夹下的 logback.xml 或 logback-spring.xml 作为日志配置。Spring Boot 官方推荐优先使用带有 -spring 的文件名作为日志配置文件。因为如果命名为 logback-spring.xml 日志配置，就可以在日志输出的时候引入一些 Spring Boot 特有的配置项。也可以通过自定义的方式指定配置文件： logging.config=classpath:logback-confg.xml application.properities 配置： 12345# 日志配置信息## 这个路径其实不指定也可以，因为 logback-spring.xml 是默认配置文件名之一logging.config=classpath:logback-spring.xml## 这里的配置是为了在 xml 配置中应用的log.level=info 一个简单的控制台输出配置： 1234567891011121314151617&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;configuration&gt; &lt;!-- application.properities中配置的变量 --&gt; &lt;springProperty scope="context" name="logLevel" source="log.level"/&gt; &lt;springProperty scope="context" name="logPath" source="log.path"/&gt; &lt;springProperty scope="context" name="logName" source="log.name"/&gt; &lt;appender name="Console" class="ch.qos.logback.core.ConsoleAppender"&gt; &lt;encoder&gt; &lt;pattern&gt;%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125; %-5level [%thread] %logger&#123;80&#125; - %msg%n&lt;/pattern&gt; &lt;charset&gt;UTF-8&lt;/charset&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;root level="$&#123;logLevel&#125;&#125;"&gt; &lt;appender-ref ref="Console"/&gt; &lt;/root&gt;&lt;/configuration&gt; 说明： appender 的 name 其实只是取的名字，你也可以叫它 STDOUT %d 表示时间，用 %d{yyyy-MM-dd HH:mm:ss.SSS} 定义了格式化时间，也可以使用 %date %-5level 表示显示日志级别，并且用 5 个字符靠左对齐，也可以用 %p 表示日志级别 %thread 表示显示日志进程名字 %logger{80} 表示日志输出者的名字，常常是类名 %msg 日志消息 %n 平台的换行符 %c 用来在日志上输出类的全名 %L 表示行号 charset 设置日志编码格式为 UTF-8，避免中文乱码 root 标签内设置日志级别 level，等同于在配置文件中设置 logging.pattern.level Logback 配置文件可以使用 property 标签自定义属性，然后在配置文件中使用。下面附上一个较复杂的配置： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;configuration&gt; &lt;!-- application.properities中配置的变量 --&gt; &lt;springProperty scope="context" name="logProfile" source="log.profile"/&gt; &lt;springProperty scope="context" name="logFileLevel" source="log.file.level"/&gt; &lt;!-- 定义日志 pattern --&gt; &lt;property name="logPattern" value="%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125; %-5level [%thread] %logger&#123;36&#125; - %c - %L&#123;4&#125; - %msg%n"/&gt; &lt;!-- 定义日志文件名称 --&gt; &lt;property name="appName" value="logback-demo"&gt;&lt;/property&gt; &lt;property name="logPath" value="log"&gt;&lt;/property&gt; &lt;!-- ch.qos.logback.core.ConsoleAppender 表示控制台输出 --&gt; &lt;appender name="console" class="ch.qos.logback.core.ConsoleAppender"&gt; &lt;!-- 日志输出格式： %d表示日期时间， %thread表示线程名， %-5level：级别从左显示5个字符宽度 %logger&#123;50&#125; 表示logger名字最长50个字符，否则按照句点分割。 %L 表示行号 %msg：日志消息， %n是换行符 --&gt; &lt;encoder&gt; &lt;!--&lt;pattern&gt;%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125; [%thread] %-5level %logger&#123;50&#125; - %msg%n&lt;/pattern&gt;--&gt; &lt;pattern&gt;$&#123;logPattern&#125;&lt;/pattern&gt; &lt;charset&gt;UTF-8&lt;/charset&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;!-- 滚动记录文件，先将日志记录到指定文件，当符合某个条件时，将日志记录到其他文件 --&gt; &lt;appender name="appLogFileAppender" class="ch.qos.logback.core.rolling.RollingFileAppender"&gt; &lt;encoder&gt; &lt;pattern&gt;$&#123;logPattern&#125;&lt;/pattern&gt; &lt;charset&gt;UTF-8&lt;/charset&gt; &lt;/encoder&gt; &lt;rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy"&gt; &lt;!-- 滚动时产生的文件的存放位置及文件名称 %d&#123;yyyy-MM-dd&#125;：按天进行日志滚动 %i：当文件大小超过maxFileSize时，按照i进行文件滚动 --&gt; &lt;fileNamePattern&gt;$&#123;logPath&#125;/$&#123;appName&#125;/%d&#123;yyyy-MM-dd&#125;-%i.log&lt;/fileNamePattern&gt; &lt;!-- 可选节点，控制保留的归档文件的最大数量，超出数量就删除旧文件。假设设置每天滚动， 且maxHistory是365，则只保存最近365天的文件，删除之前的旧文件。注意，删除旧文件是， 那些为了归档而创建的目录也会被删除。 --&gt; &lt;MaxHistory&gt;365&lt;/MaxHistory&gt; &lt;!-- 当日志文件超过maxFileSize指定的大小是，根据上面提到的%i进行日志文件滚动 注意此处配置SizeBasedTriggeringPolicy是无法实现按文件大小进行滚动的，必须配置timeBasedFileNamingAndTriggeringPolicy --&gt; &lt;timeBasedFileNamingAndTriggeringPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP"&gt; &lt;maxFileSize&gt;50MB&lt;/maxFileSize&gt; &lt;/timeBasedFileNamingAndTriggeringPolicy&gt; &lt;/rollingPolicy&gt; &lt;!--下面通过两个 Filter，记录了 WARN 和 Error 级别的日志，其实用 logger 来定义level，更方便--&gt; &lt;!--&lt;filter class="ch.qos.logback.classic.filter.LevelFilter"&gt;--&gt; &lt;!--&lt;level&gt;warn&lt;/level&gt;--&gt; &lt;!--&lt;onMatch&gt;ACCEPT&lt;/onMatch&gt;--&gt; &lt;!--&lt;onMismatch&gt;NEUTRAL&lt;/onMismatch&gt;--&gt; &lt;!--&lt;/filter&gt;--&gt; &lt;!--&lt;filter class="ch.qos.logback.classic.filter.LevelFilter"&gt;--&gt; &lt;!--&lt;level&gt;error&lt;/level&gt;--&gt; &lt;!--&lt;onMatch&gt;ACCEPT&lt;/onMatch&gt;--&gt; &lt;!--&lt;onMismatch&gt;DENY&lt;/onMismatch&gt;--&gt; &lt;!--&lt;/filter&gt;--&gt; &lt;/appender&gt; &lt;!--&lt;root level="error"&gt;--&gt; &lt;!--&lt;appender-ref ref="console"/&gt;--&gt; &lt;!--&lt;/root&gt;--&gt; &lt;!--&lt;logger name="com.michael.springbootlogback" &gt;--&gt; &lt;!--&lt;appender-ref ref="appLogFileAppender"/&gt;--&gt; &lt;!--&lt;/logger&gt;--&gt; &lt;springProfile name="$&#123;logProfile&#125;"&gt; &lt;!--&lt;logger name="org.springframework" level="info" additivity="false"&gt;&lt;/logger&gt;--&gt; &lt;logger name="com.michael" level="info"&gt; &lt;appender-ref ref="console"/&gt; &lt;/logger&gt; &lt;logger name="com.michael" level="$&#123;logFileLevel&#125;"&gt; &lt;appender-ref ref="appLogFileAppender"/&gt; &lt;/logger&gt; &lt;/springProfile&gt;&lt;/configuration&gt; 输出到 console: ConsoleAppender 需要设置这样的一个 apppender，否则日志不会打印到控制台； 输出到文件： RollingFileAppender 可以实现日志的切分 rollingPolicy 设置滚动切分的规则 totalSizeCap 用来指定日志文件的上限大小，这个设置在 maxFileSize 之后起效，也就是说，如果你文件上限设置的是 1MB，但是 maxFileSize 设置的是 10MB，那么，这个日志文件也会保存为 10MB。假设你 maxFileSize 设置的是 1MB，totalSizeCap 设置的是 2MB，那么你日志文件的个数最多也就 2 个； MaxHistory 可选节点，控制保留的归档文件的最大数量，超出数量就删除旧文件。假设设置每天滚动，且maxHistory是365，则只保存最近365天的文件。我还是喜欢这个设置，比 totalSizeCap 意义更清晰； &lt;root&gt; 可以包含零个或多个 &lt;appender-ref&gt; 元素，标识这个 appender 将会添加到这个 loger，logger 的属性： name: 用来指定受此 loger 约束的某一个包或者具体的某一个类，没写的时候会报错 level：日志打印级别，如果未设置此属性，那么当前 logger 会继承上级的级别，也就是 root 的级别； addtivity：是否向上级 loger 传递打印信息。默认是 true。设置为 false 表示该日志打印设置（控制台打印还是文件打印等具体设置）不会向根 root 标签传递，也就是说该 logger 里怎么设置的那就会怎么打印，跟 root 无关 root 是根 logger,所以他两是一回事；只不过 root 中不能有 name 和 additivity 属性，是有一个 level。 appender 是一个日志打印的组件，这里组件里面定义了打印过滤的条件、打印输出方式、滚动策略、编码方式、打印格式等等。但是它仅仅是一个打印组件，如果我们不使用一个 logger 或者 root 的 appender-ref 指定某个具体的 appender 时，它就没有什么意义 打印日志的正确姿势我通过 controller 中定义了一个接口，可以打印出各级别的错误： 1234567891011121314@GetMapping("/all")public String all() &#123; try &#123; log.debug("logger: debug"); log.info("logger: info"); log.warn("logger: warn" + " 附件个信息"); System.out.println(1 / 0); &#125; catch (Exception e) &#123; log.error("error 打印方式比较，采用 ,e：", e); log.error("error 打印方式比较，采用 +e : " + e); throw e; &#125; return "all";&#125; 比较两种打印日志的方式，显示效果有何区别： 可以发现，通过 logger.error(&quot;xxx错误&quot;,e) 的方式打印的日志会有错误堆栈信息！这明显对应定位问题有更大的帮助！也可以使用 {} 占位符来拼接字符串，而不需要使用 + 来连接字符串。注意，我们这里也是采用的 slf4j 日志门面的接口方法。 如果采用一个参数，这里的 e 会被转为 String 类型（自动调用 toString 方法） 如果不怕麻烦，就这么写： 1private final Logger log = LoggerFactory.getLogger(this.getClass()); 如果想省事，可以结合 lombok 插键，在类上使用 @SLF4J 注解，然后代码中直接使用 log.xxx 打印日志即可； 示例代码 awesome-spring-boot-examples 参考 掘金-glmapper-看完这个不会配置 logback ，请你吃瓜！ 这篇文章算是相当全了 嘟嘟独立博客-Spring Boot干货系列：（七）默认日志logback配置解析 博客园-springboot的logback.xml配置和日志记录]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Spring Boot</tag>
        <tag>日志</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Manjaro 安装体验小结]]></title>
    <url>%2F2019%2F08%2F03%2Flinux-manjaro-install%2F</url>
    <content type="text"><![CDATA[Manjaro 简介Manjaro 是一款基于 Arch Linux、对用户友好的 Linux 发行版。在 Linux 社区，Arch Linux 的确是一个异常快速、强大、轻量级的发行版，它提供最新的、最全的软件。然而，Arch Linux 面向高级用户，普遍认为，缺乏技术专长或者没有耐心的人是无法玩转 Arch Linux的。 Manjaro 由奥地利、法国和德国的爱好者共同开发，提供了 Arch Linux 操作系统的所有优点，同时注重用户友好性和可用性。 Manjaro 提供32位和64位版本，适合新手以及经验丰富的 Linux 用户。 Manjaro 与 Arch 有许多相同的功能，包括： “滚动发行”开发模式，可提供最新的系统，而无需安装新版本 可用 AUR 然而，Manjaro 拥有自己的一些额外的功能，包括： 简化、用户友好的安装过程 自动检测计算机的硬件（例如显卡） 为系统自动安装必要的软件（例如显卡驱动程序） 它自己的专用软件仓库，以确保提供完全测试过的稳定的软件包 轻松安装和使用多个内核。 补充 Arch Linux（或 Arch /ˈɑːrtʃ/)） 是一款基于 x86-64 架构的 Linux发行版。系统主要由自由和开源软件组成，支持社区参与。系统设计以 KISS 原则（保持简单和愚蠢）为总体指导原则，注重代码正确、优雅和极简主义，期待用户能够愿意去理解系统的操作。Arch Linux 系统安装、删除和更新软件的软件包管理器叫做 pacman。 AUR 的全称是 Arch User Repository，是 Arch Linux/Manjaro 用户的社区驱动存储库，创建 AUR 的目的是使共享社区包的过程更容易和有条理。使用它可以在 Arch Linux/Manjaro 系统中安装和更新软件包。这个软件仓库的软件包是相当丰富，可以查看这个网站的统计Repository statistics，它的软件列表可以在Archlinux AUR查看 安装 Manjaro双系统基本知识如下： [折腾日记]win10 ,ubuntu双系统安装避坑指南 Windows 下安装 Ubuntu 双系统(更新) rEFInd 总结注意点： 要是遇到启动不了的问题，可以用老毛桃制作个U盘修复引导即可，所以事先建议搞一个; 制作 Manjaro U盘启动盘一开始使用的是 UltraISO，后来换成了 Rufus，就 OK 了; 安装引导时要选择创建的 /boot 分区， 此外，我是双硬盘，一开始按照单硬盘的方法，怎么也启动不了，后来需要在安装 Windows 系统的 SSD 盘上划出了 600MB 空间用来挂载 /boot 分区并安装引导； 官网系统镜像下载，推荐从 USTC中科大镜像下载几个主要版本： Xfce是一个用于类UNIX操作系统的轻量级桌面环境。它的目标是快速和系统资源低耗，同时仍然保持视觉上的吸引力和对用户友好的特性。所以，家里另外一台低配置的旧笔记本，我安装了这个版本。 KDE是一个功能丰富多样的桌面环境，提供几种不同风格的菜单来访问应用程序。还有一个优秀的内置界面，可以方便地访问、下载、安装新的主题、小部件等。 虽然在用户友好度上做的非常好，但KDE也是相当消耗系统资源的，跟XFCE比较起来，启动程序、使用桌面环境都明显偏慢。运行 Manjaro 的 64 位 KDE 桌面使用大约需要 550MB 的内存。我自己的就笔记本配置还可以，就安装了这个版本，确实很易用！ GNOME桌面环境是作为GNU项目的一部分来开发的，它旨在简单易用，并且完全可用。 我从另外一块机械硬盘上划分了 100GB 空间用来安装，分区参考： 大小 挂载点 用途 40G / 用于存放系统相当于win10的C盘 8G /swap 一般设为电脑内存大小或2倍 600MB /boot 引导分区 所有剩余的空间 /home 用户存储数据用 源配置中国的 mirrors，在 终端 执行下面的命令从官方的源列表中对中国源进行测速和设置： 12sudo pacman-mirrors -g # 排列源，可不执行sudo pacman-mirrors -c China -m rank # 更改源，在跳出的对话框里选择想要的源 为 Manjaro 增加中文社区的源来加速安装软件，在 /etc/pacman.conf 中添加 archlinuxcn 源，末尾加上： 123[archlinuxcn]SigLevel = Optional TrustedOnlyServer = https://mirrors.tuna.tsinghua.edu.cn/archlinuxcn/$arch 安装 archlinuxcn-keyring 包以导入 GPG key，否则的话 key 验证失败会无法安装： 1sudo pacman -S archlinuxcn-keyring 同步并更新系统： 1sudo pacman -Syyu 输入法fcitx 是 Free Chinese Input Toy for X 的缩写，国内也常称作小企鹅输入法，是一款 Linux 下的中文输入法: 1234sudo pacman -S fcitx-googlepinyinsudo pacman -S fcitx-im # 选择全部安装sudo pacman -S fcitx-configtool # 安装图形化配置工具sudo pacman -S fcitx-skin-material 解决中文输入法无法切换问题: 添加文件 ~/.xprofile： 123export GTK_MODULE=fcitxexport QT_IM_MODULE=fcitxexport XMODIFIERS="@im=fcitx" 输入法需要重启生效 pacman1234567sudo pacman -S 软件名 # 安装sudo pacman -R 软件名 # 删除单个软件包，保留其全部已经安装的依赖关系sudo pacman -Rs 软件名 # 除指定软件包，及其所有没有被其他已安装软件包使用的依赖关系sudo pacman -Ss 软件名 # 查找软件sudo pacman -Sc # 清空并且下载新数据sudo pacman -Syu # 升级所有软件包sudo pacman -Qs # 搜索已安装的包 yayYay 是用 Go 编写的 Arch Linux AUR 包管理工具。具体可以查看 Arch Wiki 注意：很多教程比较老了，yaourt 目前已经停止维护，用户可以考虑迁移到 aurman 或 yay， 安装 yay： 1sudo pacman -S yay 配置 yay 的 aur 源为清华源 AUR 镜像： 1yay --aururl "https://aur.tuna.tsinghua.edu.cn" --save 修改的配置文件位于 ~/.config/yay/config.json ，还可通过以下命令查看修改过的配置: 1yay -P -g yay 的常用命令： 12345yay -S package # 从 AUR 安装软件包yay -Rns package # 删除包yay -Syu # 升级所有已安装的包yay -Ps # 打印系统统计信息yay -Qi package # 检查安装的版本 yay 安装命令不需要加 sudo。 Git123git config --global user.name "Michael728"git config --global user.email "649168982@qq.com"ssh-keygen -t rst -C "649168982@qq.com" zsh123456sudo pacman -S zsh # 安装zshecho $SHELL # 查看大概年前 shellchsh -s /bin/zsh # 修改默认shell，这个是修改当前用户的终端，如果要修改 root 账户，需要切换到 root用户wget https://github.com/robbyrussell/oh-my-zsh/raw/master/tools/install.sh -O - | shsudo pacman -S autojumpgit clone https://github.com/zsh-users/zsh-syntax-highlighting.git $&#123;ZSH_CUSTOM:-~/.oh-my-zsh/custom&#125;/plugins/zsh-syntax-highlighting 需要重启生效 具体的 zsh 配置教程，可以阅读之前的总结： zsh+on-my-zsh配置教程指南（程序员必备） ss1sudo pacman -S shadowsocks-qt5 上面是安装了一个 ss 的客户端，编辑添加好帐号之后，还需要设置一下端口转发设置之后，浏览器访问才 OK： 12345sudo pacman -S privoxy # 安装代理转发，用于将 socks5 代理转换为 http 代理sudo bash -c 'echo "forward-socks5 / 127.0.0.1:1080 ." &gt;&gt; /etc/privoxy/config'git config --global http.proxy 'socks5://127.0.0.1:1080'git config --global https.proxy 'socks5://127.0.0.1:1080'sudo systemctl start privoxy.service 接着，你还需要去设置网络代理：系统设置-》网络-》设置-》代理，socks代理 那里进行配置 127.0.0.1:1080。 很多网上的教程都说需要再安装一个 switchyomega 插件，事实上，最新版本的 Chrome 已经不支持直接拖动 crx 文件安装插件了。 这时候浏览器网络其实已经 OK 了，访问 Google 也正常。你会发现访问国内网站速度并不好，这是因为国内网站不走代理其实网速更好！这时候实现自动的切换，就可以在上面的设置之后，去 Google 应用商店安装好 proxy-switchyomega 扩展。 进行设置主要有 3 点： 情景模式中，proxy 配置上 socks5 的代理； 情景模式中，auto switch 中，首先勾选上 规则列表表规则 走 proxy！ 规则列表设置，在 autoproxy 中，输入规则类表网址：https://raw.githubusercontent.com/gfwlist/gfwlist/master/gfwlist.txt，然后更新，这样在规则列表中的网站就会走上面的代理了； 安装并设置好这个扩展插件之后，我们可以在系统设置-》网络-》设置-》代理中，恢复默认配置。这样在浏览器中，这个扩展选中 auto switch 它会自动判断是否走代理。 终端代理终端代理安装 proxychain-ng，sudo pacman -S proxychains-ng 安装，配置： 12sudo vim /etc/proxychains.conf # 添加如下内容socks5 127.0.0.1 1080 使用时在需要代理的命令前加 proxychains4 就可以了，例如：proxychains4 ping www.google.com 当然，端口转发软件还有 polipo 教程介绍的， polipo sudo vim /etc/polipo/config： 123socksParentProxy = "localhost:1080"socksProxyType = socks5proxyAddress = "0.0.0.0" 然后重启： 1systemctl start polipo 还有一篇教程: iamlightsmile——人生苦短，我用Manjaro！提到了 pac 代理： 123sudo pip install genpacgenpac --proxy="SOCKS5 127.0.0.1:1080" --gfwlist-proxy="SOCKS5 127.0.0.1:1080" -o autoproxy.pac --gfwlist-url="https://raw.githubusercontent.com/gfwlist/gfwlist/master/gfwlist.txt" # 生成 pac 文件genpac --pac-proxy "SOCKS5 127.0.0.1:1080" --gfwlist-proxy="SOCKS5 127.0.0.1:1080" --gfwlist-url="https://raw.githubusercontent.com/gfwlist/gfwlist/master/gfwlist.txt" --output="/home/michael/.config/PAC/gfw_whitelist/whitelist.pac" 在设置—&gt;网络设置—&gt;代理设置中选择自动代理，URL 填写生成的 PAC 文件地址，file://文件路径/文件名(可以直接把文件拖到URL栏)。 补充： electron-ssr 这款也是 ss 软件，就是没有支持的加密算法，就没用，这是这款软件的开发者的博客 记录在开发electron-ssr过程中遇到的问题。 1yay -S electron-ssr 安装中文字体为啥会突出一下要安装中欧给你问字体呢，因为我使用过程发现系统里的中文字变成了一个个小白方框的格子，安装好中文字体并重启后，就显示正常了： 123456sudo pacman -S wqy-zenheisudo pacman -S wqy-bitmapfontsudo pacman -S wqy-microheisudo pacman -S ttf-wps-fontssudo pacman -S adobe-source-han-sans-cn-fontssudo pacman -S adobe-source-han-serif-cn-fonts 常用软件1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071# deepin 系的软件sudo pacman -S deepin-picker # 深度取色器sudo pacman -S deepin-screen-recorder # 录屏软件，可以录制 Gif 或者 MP4 格式sudo pacman -S deepin-screenshot # 深度截图sudo pacman -S deepin-system-monitor # 系统状态监控yay -s deepin-wine-wechatyay -S deepin-wine-timyay -S deepin-wine-baidupanyay -S deepin.com.thunderspeed# 开发软件sudo pacman -S jdk8-openjdksudo pacman -S makesudo pacman -S cmakesudo pacman -S clangsudo pacman -S nodejssudo pacman -S npmsudo pacman -S golandsudo pacman -S vimsudo pacman -S mavensudo pacman -S pycharm-professional # Python IDEsudo pacman -S intellij-idea-ultimate-edition # JAVA IDEsudo pacman -S goland # Go IDEsudo pacman -S visual-studio-code-bin # vscodesudo pacman -S qtcreator # 一款QT开发软件sudo pacman -S postman-binsudo pacman -S insomnia # REST模拟工具sudo pacman -S gitkraken # GIT管理工具sudo pacman -S wireshark-qt # 抓包sudo pacman -S zealsudo pacman -S gitkraken # Git 管理工具# 办公软件sudo pacman -S google-chromesudo pacman -S foxitreader # pdf 阅读sudo pacman -S bookworm # 电子书阅读sudo pacman -S unrar unzip p7zipsudo pacman -S goldendict # 翻译、取词sudo pacman -S wps-officeyay -S typora # markdown 编辑yay -S electron-ssr # 缺少我需要的加密算法yay -S xmind# 设计sudo pacman -S pencil # 免费开源界面原型图绘制工具# 娱乐软件sudo pacman -S netease-cloud-music# 下载软件sudo pacman -S aria2sudo pacman -S filezilla # FTP/SFTP# 图形sudo pacman -S gimp # 修图# 系统工具sudo pacman -S albert #类似Mac Spotlight，另外一款https://cerebroapp.com/yay -S copyq # 剪贴板工具，类似 Windows 上的 Ditto# 终端sudo pacman -S screenfetch # 终端打印出你的系统信息，screenfetch -A 'Arch Linux'sudo pacman -S htopsudo pacman -S batsudo pacman -S yakuake # 堪称 KDE 下的终端神器，KDE 已经自带，F12 可以唤醒sudo pacman -S net-tools # 这样可以使用 ifconfig 和 netstatyay -S tldryay -S tig # 命令行下的 git 历史查看工具yay -S treeyay -S ncdu # 命令行下的磁盘分析器，支持Vim操作yay -S mosh # 一款速度更快的 ssh 工具，网络不稳定时使用有奇效 chrome这篇文章介绍了一个以代理模式启动 Chrome 的方法: 1google-chrome-stable --proxy-server=socks5://127.0.0.1:1080 wireshark-qtWireshark 是一款免费开源的包分析器，可用于网络排错、网络分析、软件和通讯协议开发以及教学等。然而不幸的是官方网站上仅提供了 Windows 和 MacOS 的版本。不过不用担心，你依然可以使用 pacman 直接从 Arch 的 community 软件源里直接安装 wireshark-qt 。wireshark-qt 就是用 qt 做成的 wireshark 前端界面，它依赖于终端版的 wireshark-cli 。 这里提示一点： 通常直接安装完后启动 wireshark 会提示 /usr/bin/dumpcap 无权限，有些用户会因此选择在命令行里 sudo wireshark 打开 wireshark，这其实很不安全。正确做法是运行命令 gpasswd -a username wireshark 然后重新启动，详情可以参见 Arch Wiki 。 Maven1cp /opt/maven/conf/settings.xml /opt/maven/conf/settings.xml.backup 然后在 华为云镜像 按照指导配置 Maven 镜像就可以了 MySQL WorkbenchMySQL Workbench在archlinux中出现 Could not store password: The name org.freedesktop.secrets was not provided by any .service files 的错误 解决方案是安装 gnome-keyring 包： 1sudo pacman -S gnome-keyring 写 SQL 语句，记得要先加上 use &lt;schema&gt;; ，否则可查不出结果。 至于怎么在 Manjaro 上安装 MySQL 呢？我选择使用 Docker 安装，可以参考之前写的一篇文章： 使用容器 Docker 创建开发环境 系统设置DolphinDolphin 是 KDE 下默认的文件管理器。 在系统设置-》桌面行为-》工作空间-》点击行为，勾选”双击打开文件和文件夹“； 在菜单中搜索”常规“-》确认，勾选”将文件或文件夹移至回收站“； 默认程序Win 键打开菜单搜索”默认程序”，可以修改浏览器等默认程序； 更多一些使用技巧，可以查看这里撸Linux——Manjaro 效果 总结为何会有这篇文章呢？其实主要是去年也就是 2018 的 MBP 的 touchbar 出现了不显示的问题，于是上周就预约了西湖店的 Genius Bar 维修。结果意外收获是，说 2018 款的 15寸有缺陷，他们会替换掉整个键盘和电池！不过需要等待一周才行，所以，回来就鼓捣了之前的旧的笔记本，安装了 Manjaro 尝尝鲜。 Manjaro KDE 这个版本使用下来感觉还是不错的，界面也比较符合使用习惯，很多地方做的适配让从 Windows 迁移过来的用户并不会发觉用的不顺手，常用的软件也都有，真是强烈推荐计算机相关的学生尽早使用起来，也正好学习了 Linux，反正是“装机有益”吧，但是千万别陷入整天关注美化的道路上…… 多说一句，苹果的产品的质量真是让人失望，网上一堆类似问题的用户，看来以后买个好点的 Windows 本子，装个双系统，也能用的很 High 了！ 参考 标点符——Manjaro Linux的安装体验 rovo98——Manjaro linux 安装与配置 queensferry——Manjaro Linux + KDE 安装使用手记 cnblogs——完美脱离Windows!! Linux发行版第一系统 Manjaro 开箱教程 :) 折腾之 Manjaro 安装使用指北 撸Linux——我的Linux桌面常用软件列表 (2019年春)]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Manjaro</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Boot 实战 —— MyBatis（注解版）使用方法]]></title>
    <url>%2F2019%2F07%2F20%2Fjava-spring-boot-mybatis%2F</url>
    <content type="text"><![CDATA[简介MyBatis 官网 是这么介绍它自己的： MyBatis 是一款优秀的持久层框架，它支持定制化 SQL、存储过程以及高级映射。MyBatis 避免了几乎所有的 JDBC 代码和手动设置参数以及获取结果集。MyBatis 可以使用简单的 XML 或注解来配置和映射原生类型、接口和 Java 的 POJO（Plain Old Java Objects，普通老式 Java 对象）为数据库中的记录。 示例代码 awesome-spring-boot-examples 依赖这里仅展示和 MyBatis 相关的数据库依赖项，完整的示例，请下载示例代码。 12345678910&lt;!--mysql--&gt;&lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;2.1.0&lt;/version&gt;&lt;/dependency&gt; spring-boot-start 系列的包，真是给 Spring Boot 开发带来了极大的便利，它的项目地址是： Github-mybatis/spring-boot-starter 官宣-What is MyBatis-Spring-Boot-Starter? 推荐 配置创建 users 表的 SQL： 1234567891011121314151617181920212223242526SET FOREIGN_KEY_CHECKS=0;-- ------------------------------ Table structure for `users`-- ----------------------------DROP TABLE IF EXISTS `users`;CREATE TABLE `users` ( `id` bigint(20) NOT NULL AUTO_INCREMENT COMMENT '主键id', `userName` varchar(32) DEFAULT NULL COMMENT '用户名', `passWord` varchar(32) DEFAULT NULL COMMENT '密码', `user_sex` varchar(32) DEFAULT NULL, `nick_name` varchar(32) DEFAULT NULL, PRIMARY KEY (`id`)) ENGINE=InnoDB AUTO_INCREMENT=28 DEFAULT CHARSET=utf8;-- ------------------------------ Records of sys_user-- ----------------------------INSERT INTO `users` VALUES (1,'michael翔', '123', 'MAN', 'zx');INSERT INTO `users` VALUES (2,'张小敬', '123', 'MAN', 'zxj');INSERT INTO `users` VALUES (3,'李司辰', '123', 'MAN', 'lsc');INSERT INTO `users` VALUES (4,'崔器', '123', 'MAN', 'cq');INSERT INTO `users` VALUES (5,'姚汝能', '123', 'MAN', 'yrn');INSERT INTO `users` VALUES (null,'檀棋', '123', ' WOMAN', 'tq');INSERT INTO `users` (`userName`,`passWord`,`user_sex`,`nick_name`) VALUES ('michael', '123', 'MAN', 'zx'); 说明： id 设置的是自增，当插入数据时，可以不传或者传 null 值，都可以； 插入数据，可以指定 column 也可以不指定； application-dev.properties： 1234567891011swagger.enable=trueserver.port=8081spring.datasource.url=jdbc:mysql://192.168.3.43:3306/beta?serverTimezone=UTC&amp;useUnicode=true&amp;characterEncoding=utf-8&amp;useSSL=truespring.datasource.username=rootspring.datasource.password=123456spring.datasource.driver-class-name=com.mysql.cj.jdbc.Drivermybatis.type-aliases-package==com.michael.springbootmybatis.modelmybatis.configuration.map-underscore-to-camel-case=true 配置驼峰属性自动映射，例如实体中属性为 userSex,数据库属性为 user_sex，MyBatis 默认是不能自动转换的。我们可以配置 mybatis.configuration.map-underscore-to-camel-case 实现自动映射。如果不进行此配置，通常我们要自定义以下结果集映射： 123456@Results(&#123; @Result(property = "userSex", column = "user_sex"), @Result(property = "nickName", column = "nick_name")&#125;)@Select("SELECT * FROM users WHERE id = #&#123;id&#125;")UserEntity getUserById(Long id); 在很多 Select 语句需要做结果映射时，自然是相当麻烦。除了上面配置「驼峰属性自动映射」，也可以用在 @Results 中使用 id 来标识一个映射关系，然后可以用 @ResultMap 复用这个映射关系： 1234567891011@Select("SELECT * FROM users")@Results(id = "user", value = &#123; @Result(property = "userSex", column = "user_sex"), @Result(property = "nickName", column = "nick_name")&#125;)@Select("SELECT * FROM users WHERE id = #&#123;id&#125;")List&lt;UserEntity&gt; getAll();@ResultMap("user")@Select("SELECT * FROM users WHERE id = #&#123;id&#125;")UserEntity getUserById(Integer id); 代码这里仅展示关键的部分的代码，完整可看下文的示例代码。 实体类： 12345678910111213141516171819202122@Data@ApiModel(description = "UserEntity 实体类")public class UserEntity implements Serializable &#123; private static final long serialVersionUID = 1L; @ApiModelProperty(value = "用户 id", dataType = "Long") private Long id; @ApiModelProperty(value = "用户名", required = true) private String userName; @ApiModelProperty(value = "密码") private String passWord; @ApiModelProperty(value = "性别") private UserSexEnum userSex; @ApiModelProperty(value = "昵称") private String nickName; @Override public String toString() &#123; return "userName " + this.userName + ", password " + this.passWord + " , sex " + this.userSex; &#125;&#125; dao/mapper 接口，数据库交互（Data Access Object）层： 123456789101112131415161718192021222324252627public interface UserMapper &#123;// @Results(&#123;// @Result(property = "userSex", column = "user_sex", javaType = UserSexEnum.class),// @Result(property = "nickName", column = "nick_name")// &#125;) @Select("SELECT * FROM users") Page&lt;UserEntity&gt; getAll();// @Results(&#123;// @Result(property = "userSex", column = "user_sex"),// @Result(property = "nickName", column = "nick_name")// &#125;) @Select("SELECT * FROM users WHERE id = #&#123;id&#125;") UserEntity getUserById(Long id); @Insert("INSERT INTO users(userName, passWord, user_sex, nick_name) " + "VALUES(#&#123;userName&#125;, #&#123;passWord&#125;, #&#123;userSex&#125;, #&#123;nickName&#125;)") @Options(useGeneratedKeys = true, keyProperty = "id")// @SelectKey(statement = "select last_insert_id()", keyProperty = "id", before = false, resultType = Integer.class) void insert(UserEntity user); @Update("UPDATE users SET userName=#&#123;userName&#125;,nick_name=#&#123;nickName&#125; WHERE id = #&#123;id&#125;") void update(UserEntity user); @Delete("DELETE FROM users WHERE id= #&#123;id&#125;") void deleteUserById(Long id);&#125; 说明： insert 这里用了一个 @Options 的注解，实现了「主键回填」的功能，也就是说，再创建好一个 user 之后，user 请求体中的 id 属性会自动赋值好； @SelectKey 注解被注释掉了，这个注解也同样可以实现「主键回填」的功能； service 接口： 123456789101112131415161718192021222324252627282930313233343536373839public interface UserService &#123; /** * 查询所有用户 * * @return */ Map&lt;String,Object&gt; getAll(int pageNum, int pageSize); /** * 根据用户 ID 查询用户 * * @param id 用户 ID * @return */ UserEntity getUserById(Long id); /** * 新增一个用户 * * @param user */ void insert(UserEntity user); /** * 更新用户信息，用户 ID 不传，会更新失败 * * @param user */ String update(UserEntity user); /** * 根据用户 ID 删除用户 * * @param id */ String deleteById(Long id);&#125; service 接口的实现类： 1234567891011121314151617181920212223242526272829303132333435363738394041@Servicepublic class UserServiceImpl implements UserService &#123; @Autowired private UserMapper userMapper; @Override public Map&lt;String,Object&gt; getAll(int pageNum, int pageSize) &#123; //将参数传给这个方法就可以实现物理分页了，非常简单。 PageHelper.startPage(pageNum, pageSize); PageInfo&lt;UserEntity&gt; pageInfo = new PageInfo&lt;&gt;(userMapper.getAll()); Long total = pageInfo.getTotal(); List&lt;UserEntity&gt; users = pageInfo.getList(); Map&lt;String,Object&gt; map = new HashMap&lt;&gt;(); map.put("total", total); map.put("data", users); return map; &#125; @Override public UserEntity getUserById(Long id) &#123; return userMapper.getUserById(id); &#125; @Override public void insert(UserEntity user) &#123; userMapper.insert(user); &#125; @Override public String update(UserEntity user) &#123; userMapper.update(user); return "success"; &#125; @Override public String deleteById(Long id) &#123; userMapper.deleteUserById(id); return "success"; &#125;&#125; controller 类： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172@RestController@RequestMapping("/api/v1/")@Api(tags = &#123;"用户相关接口"&#125;, value = "用户模块")public class UserController &#123; @Autowired private UserService userService; /** * 查询全部用户 * * @return */ @ApiOperation(value = "获取用户列表", notes = "获取全部用户信息") @RequestMapping(value = "/users", method = RequestMethod.GET) public Map&lt;String,Object&gt; getUsers( @RequestParam(name = "pageNum", defaultValue = "1", required = false) int pageNum, @RequestParam(name = "pateSize", defaultValue = "2", required = false) int pageSize) &#123; return userService.getAll(pageNum, pageSize); &#125; /** * 根据用户 ID 查询用户 * * @param id * @return */ @ApiOperation(value = "查询单用户", notes = "根据用户id 查询其信息") @ApiImplicitParam(name = "id", value = "用户id", paramType = "query", required = true) @GetMapping("/user/&#123;id&#125;") public UserEntity getUser(Long id) &#123; UserEntity user = userService.getUserById(id); return user; &#125; /** * 存储用户信息 * * @param user */ @ApiOperation(value = "存储用户信息", notes = "存储用户详细信息") @RequestMapping(value = "/user", method = RequestMethod.POST) public String save(UserEntity user) &#123; userService.insert(user); // 用到了 主键回填 的配置 return "Create success, user id: " + user.getId(); &#125; /** * 更新用户信息 * * @param user */ @ApiOperation(value = "更新用户信息", notes = "更新用户的个人信息") @PutMapping("/user/") public void update(@RequestBody UserEntity user) &#123; userService.update(user); &#125; /** * 根据用户 ID 删除用户 * * @param id */ @ApiOperation(value = "删除用户", notes = "根据用户id删除用户信息") @ApiImplicitParams(&#123; @ApiImplicitParam(name = "id", value = "用户id", required = true, paramType = "path") &#125;) @RequestMapping(value = "/user/&#123;id&#125;", method = RequestMethod.DELETE) public void delete(@PathVariable("id") Long id) &#123; userService.deleteById(id); &#125;&#125; 启动类： 123456789@SpringBootApplication@MapperScan("com.michael.springbootmybatis.mapper")public class SpringBootMybatisApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(SpringBootMybatisApplication.class, args); &#125;&#125; @MapperScan(&quot;com.winter.mapper&quot;) 这个注解非常的关键，这个对应了项目中 mapper/dao 所对应的包路径。 如果不用上面的方式，就需要在每个 mapper/dao 类上使用 @Mapper 注解； 分页通常，在进行查询时，我们为了避免一次性返回所有结果，造成接口响应慢等问题。通常会进行分页。比如查询所有用户的接口，实际应用中，用户数据可能会很多，如果全部一次返回，明显不合适。这时候，就需要进行分页查询。 本文我们选用插键 pagehelper-spring-boot-starter 要进行分页。 添加依赖123456&lt;!-- 分页插件 --&gt;&lt;dependency&gt; &lt;groupId&gt;com.github.pagehelper&lt;/groupId&gt; &lt;artifactId&gt;pagehelper-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.2.5&lt;/version&gt;&lt;/dependency&gt; 分页配置需要添加相应的配置： 1234567#pagehelper分页插件pagehelper.helperDialect=mysqlpagehelper.reasonable=truepagehelper.supportMethodsArguments=truepagehelper.params=count=countSqlpagehelper.row-bounds-with-count=truepageSizeZero=true 分页插键参数介绍： helperDialect：分页插件会自动检测当前的数据库链接，自动选择合适的分页方式 reasonable：分页合理化参数，默认值为 false。当该参数设置为 true 时，pageNum&lt;=0 时会查询第一页， pageNum&gt;pages（超过总数时），会查询最后一页。默认 false 时，直接根据参数进行查询 params：为了支持 startPage(Object params) 方法，增加了该参数来配置参数映射，用于从对象中根据属性名取值， 可以配置 pageNum,pageSize,count,pageSizeZero,reasonable，不配置映射的用默认值， 默认值为 pageNum=pageNum;pageSize=pageSize;count=countSql;reasonable=reasonable;pageSizeZero=pageSizeZero。 supportMethodsArguments：支持通过 Mapper 接口参数来传递分页参数，默认值 false，分页插件会从查询方法的参数值中，自动根据上面 params 配置的字段中取值，查找到合适的值时就会自动分页 pageSizeZero：默认值为 false，当该参数设置为 true 时，如果 pageSize=0 或者 RowBounds.limit = 0 就会查询出全部的结果（相当于没有执行分页查询，但是返回结果仍然是 Page 类型）。我测试时，发现不设置，pageSize=0 也会返回全部； 代码变动mapper 中查找全部用户的方法改成如下： 12@Select("SELECT * FROM users")Page&lt;UserEntity&gt; getAll(); service 接口和其实现类的方法改成： 1PageInfo&lt;UserEntity&gt; getAll(int pageNum, int pageSize); service 接口实现类： 1234567@Overridepublic PageInfo&lt;UserEntity&gt; getAll(int pageNum, int pageSize) &#123; //将参数传给这个方法就可以实现物理分页了，非常简单。 PageHelper.startPage(pageNum, pageSize); PageInfo&lt;UserEntity&gt; pageInfo = new PageInfo&lt;&gt;(userMapper.getAll()); return pageInfo;&#125; 注意点： PageHelper.startPage(pageNo,pageSize); 只对其后的第一个查询有效； controller 类： 1234567@ApiOperation(value = "获取用户列表", notes = "获取全部用户信息")@RequestMapping(value = "/users", method = RequestMethod.GET)public PageInfo&lt;UserEntity&gt; getUsers( @RequestParam(name = "pageNum", defaultValue = "1", required = false) int pageNum, @RequestParam(name = "pateSize", defaultValue = "2", required = false) int pageSize) &#123; return userService.getAll(pageNum, pageSize);&#125; 进一步上面的分页结果返回的内容有点多，一些属性并不想放在返回体中。可以进一步优化。编写工具类限定关心的属性。 分页查询结果封装类： 1234567891011121314151617181920212223@Datapublic class PageResult &#123; /** * 当前页码 */ private int pageNum; /** * 每页数量 */ private int pageSize; /** * 记录总数 */ private long totalSize; /** * 页码总数 */ private int totalPages; /** * 数据模型 */ private List&lt;?&gt; content;&#125; 分页查询工具类： 1234567891011121314151617public class PageUitls &#123; /** * 将分页信息封装到统一的接口 * * @param pageInfo * @return */ public static PageResult getPageResult(PageInfo&lt;?&gt; pageInfo) &#123; PageResult pageResult = new PageResult(); pageResult.setPageNum(pageInfo.getPageNum()); pageResult.setPageSize(pageInfo.getPageSize()); pageResult.setTotalSize(pageInfo.getTotal()); pageResult.setTotalPages(pageInfo.getPages()); pageResult.setContent(pageInfo.getList()); return pageResult; &#125;&#125; 接口方法： 123456/** * 查询所有用户 * * @return */PageResult getAll(int pageNum, int pageSize); 接口实现类： 12345678@Overridepublic PageResult getAll(int pageNum, int pageSize) &#123; //将参数传给这个方法就可以实现物理分页了，非常简单。 PageHelper.startPage(pageNum, pageSize); List&lt;UserEntity&gt; users = userMapper.getAll(); PageInfo&lt;UserEntity&gt; pageInfo = new PageInfo&lt;&gt;(users); return PageUitls.getPageResult(pageInfo);&#125; 这样改写后，返回体就简洁许多了： 12345678910111213141516171819202122&#123; "pageNum": 1, "pageSize": 2, "totalSize": 3, "totalPages": 2, "content": [ &#123; "id": 1, "userName": "Michael翔", "passWord": "123", "userSex": "MAN", "nickName": "ZX" &#125;, &#123; "id": 2, "userName": "HQH", "passWord": "123", "userSex": "WOMAN", "nickName": "QQ" &#125; ]&#125; IN 查询关于 MyBatis 的 IN 查询，也是试验了很久，才 OK 的。 StackOverflow 上就有类似的问题 How to use Annotations with iBatis (myBatis) for an IN query?。 为了测试 MyBatis IN 查询，我们将之前的根据 ID 查询用户信息的接口进行修改，让它支持根据输入的 ID 列表查询多用户信息。 controller： 12345678910@ApiOperation(value = "查询指定 ID 的用户", notes = "根据用户 id 列表查询其信息")@ApiImplicitParam(name = "ids", value = "用户 id 列表", paramType = "path", required = true)@GetMapping(value = "/user/&#123;ids&#125;")public PageResult getUser(@RequestParam(name = "pageNum", defaultValue = "1", required = false) int pageNum, @RequestParam(name = "pageSize", defaultValue = "2", required = false) int pageSize, @PathVariable String ids) &#123; List&lt;String&gt; idLst = Arrays.asList(ids.split(",")); PageResult user = userService.getUserById(pageNum, pageSize, idLst); return user;&#125; 这里有个小注意点，@ApiImplicitParam 注解中的 paramType = &quot;path&quot; 记得修改为 path，因为请求参数中包含路径变量了，否则渲染 URL 时，会出问题。 mapper 类： 12345678910@Select(&#123; "&lt;script&gt;", "SELECT * ", "FROM users WHERE id IN", "&lt;foreach item='id' index='index' collection='ids' open='(' separator=',' close=')'&gt;", "#&#123;id&#125;", "&lt;/foreach&gt;", "&lt;/script&gt;"&#125;)List&lt;UserEntity&gt; getUserById(@Param("ids") List&lt;String&gt; ids); 说明： item 标识集合中每一个元素进行迭代是的别名，很多教程中设置为 item，我这里改为 id 也是 OK，而且也易于理解； index 指定一个名字，用于表示在迭代过程中，每次迭代到的位置，从 0 开始； open 表示该语句以什么开始； separator 表示在每次进行迭代之间以什么符号作为分隔符； close 表示以什么结束； collection 属性，该属性是必须指定的，但是在不同情况下，该属性的值是不一样的； @Param 的设置比较关键，相当于给其修饰的参数指定一个别名： 使用 @Param，默认会和参数名同名，或者以注解传入的变量名为准。变量名将作为 @Select 中的可用参数，比如，我这里这样定义 @Param(&quot;ids2&quot;) List&lt;String&gt; ids，那么，@Select 中可用参数名将是 ids2，collection 也须定义为 ids2，否则会报错：nested exception is org.apache.ibatis.binding.BindingException: Parameter &#39;list&#39; not found. Available parameters are [ids2, param1]; 不使用 @Param 时，那么，此时 collection 需要定义为 list，否则会报错：nested exception is org.apache.ibatis.binding.BindingException: Parameter &#39;list2&#39; not found. Available parameters are [collection, list]; 上面的说明参考自 mybatis查询sql中in条件使用(foreach) ，没有找到官方文档支撑，待补充。 动态 SQL待后续补充 spring boot(8)-mybatis三种动态sql MyBatis注解应用之动态SQL语句 FAQMyBatis 中 # 和 $ 的区别 #{} 解析为一个 JDBC 预编译语句（Prepared Statement）的参数标记符 ?。#{} 是经过预编译的，是安全的。因为 SQL 语句已经预编译好了，传入参数的时候，不会重新生产 SQL 语句。 ${} 是非安全的，存在 SQL 注入风险。${} 将传入的数据都当成一个字符串，会对自动传入的数据加一个双引号。 例如： 1select * from emp where ename = '用户名' 如果使用 ${}，用户名被传入例如‘smith or 1 = 1’，那无论 ename 是否匹配都能查到结果。 使用 ${} 的情况，order by、like 语句只能用 ${},用 #{} 会多个 &#39; &#39; 导致 SQL 语句失效。此外动态拼接 SQL，模糊查询时也要用 ${}。 MyBatis 官网 —— Parameters 的例子值得阅读： 12345678@Select("select * from user where id = #&#123;id&#125;")User findById(@Param("id") long id);@Select("select * from user where name = #&#123;name&#125;")User findByName(@Param("name") String name);@Select("select * from user where email = #&#123;email&#125;")User findByEmail(@Param("email") String email); 上面的写法，可以直接使用如下替换： 12@Select("select * from user where $&#123;column&#125; = #&#123;value&#125;")User findByColumn(@Param("column") String column, @Param("value") String value); 关于这个问题的讨论： 知乎——mybatis中的#和$的区别 ？最好能说的稍微详细点 谢谢 CSDN——mybatis中的#和$的区别 参考 官宣-MyBatis XML 纯洁的微笑-Spring Boot(六)：如何优雅的使用 Mybatis 本文的主要参考文章之一，入门挺好 CSDN-larger5-[增删改查] SpringBoot + MyBatis（注解版） 这位博主的示例，代码结构和风格都比较规范，值得学习 CSDN-LuisChen的博客-Spring boot Mybatis 整合（完整版） 博客园-Ruthless-SpringBoot+Mybatis+Pagehelper分页 查询结果关系映射那块，该文章介绍的 @ResultMap 比较方便； 分页 CSDN——分页查询效率为什么高？ 关于分页的讨论 CSDN-SpringBoot使用Mybatis注解开发教程-分页-动态sql 分页参考 博客园-朝雨忆轻尘-Spring Boot：实现MyBatis分页 推荐，PageResult 的优化，参考此文 PageHelper-官宣-如何使用分页插件 廖雪峰——分页查询 FAQ 知乎——这也许是你不曾留意过的 Mybatis 细节]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Spring Boot</tag>
        <tag>Data Base</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Boot 实战 —— 集成 Swagger 生成 RESTful API 文档]]></title>
    <url>%2F2019%2F07%2F14%2Fjava-spring-boot-swagger%2F</url>
    <content type="text"><![CDATA[简介Swagger 官网是这么描述它的：The Best APIs are Built with Swagger Tools。 Swagger 是一套基于 OpenAPI 规范构建的开源工具，可以帮助我们设计、构建、记录以及使用 Rest API。Swagger 主要包含了以下三个部分： Swagger Editor：基于浏览器的编辑器，我们可以使用它编写我们 OpenAPI 规范。 Swagger UI：它会将我们编写的 OpenAPI 规范呈现为交互式的 API 文档，后文我将使用浏览器来查看并且操作我们的 Rest API。 Swagger Codegen：它可以通过为 OpenAPI（以前称为 Swagger）规范定义的任何 API 生成服务器存根和客户端 SDK 来简化构建过程。 Spring Boot 使得开发 RESTful 服务变得简单。那么编写 Spring Boot 接口，为何要用 Swagger 呢？ 代码改变，文档就会改变。只需要少量的注释，Swagger 就可以根据代码自动生成 API 文档。 Swagger UI 是一份交互式的 API 文档，可以直接在 Web 界面调用 API。这里有一份 Swagger UI 的 Live Demo，看看官方是怎么写 RESTful API 的。 示例代码 awesome-spring-boot-examples 添加依赖pom.xml 引入 Swagger 相关的依赖： 123456789101112&lt;!-- swagger2 --&gt;&lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger2&lt;/artifactId&gt; &lt;version&gt;$&#123;swagger.version&#125;&lt;/version&gt;&lt;/dependency&gt;&lt;!-- swagger2 ui --&gt;&lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger-ui&lt;/artifactId&gt; &lt;version&gt;$&#123;swagger.version&#125;&lt;/version&gt;&lt;/dependency&gt; 使用 property 定义了 Swagger 的版本，因此还需要添加： 1&lt;swagger.version&gt;2.9.2&lt;/swagger.version&gt; 依赖说明： springfox-swagger2 Swagger 的 Java 实现 springfox-swagger-ui Swagger UI 页面的依赖 Swagger 配置类使用注解 @Configuration 编写 Swagger 配置类—— SwaggerConfig。 新建 config 的包，创建 SwaggerConifg 的配置类： 1234567891011121314151617181920212223242526272829303132//通过@Configuration注解，让Spring来加载该类配置@Configuration//通过@EnableSwagger2注解来启用Swagger2@EnableSwagger2//@ConditionalOnExpression 为Spring的注解，用户是否实例化本类，用于是否启用Swagger的判断（生产环境需要屏蔽Swagger）@ConditionalOnExpression("$&#123;swagger.enable:true&#125;")public class SwaggerConfig &#123; // select()函数返回一个ApiSelectorBuilder实例用来控制哪些接口暴露给Swagger来展现，本例采用指定扫描的包路径来定义， // Swagger会扫描该包下所有Controller定义的API，并产生文档内容（除了被@ApiIgnore指定的请求） @Bean public Docket createRestApi() &#123; // apiInfo()用来创建该Api的基本信息（这些基本信息会展现在文档页面中 ApiInfo apiInfo = new ApiInfoBuilder() .title("标题: Spring Boot 项目集成 Swagger 示例文档") .description("描述: 我的博客地址是 https://michael728.github.io") .termsOfServiceUrl("https://michael728.github.io/") .version("1.0") .build(); Docket docket = new Docket(DocumentationType.SWAGGER_2) .apiInfo(apiInfo) // select()函数返回一个ApiSelectorBuilder实例 .select() // 决定了暴露哪些接口给 Swagger .paths(regex("/api/.*")) .build() .useDefaultResponseMessages(false) .glo return docket; &#125;&#125; 说明： @Configuration 是告诉 Spring Boot 需要加载这个配置类； @EnableSwagger2 是启用 Swagger2，没加的话，就看不到效果了； ApiInfo 对象用来设置一些文档的版本号、联系人邮箱、网站、版权、开源协议等等信息（这些基本信息会展现在文档页面中）。并使用 Docket.apiInfo() 方法来设置； Docket 上增加筛选。提供了 apis() 和 paths() 两个方法帮助我们在不同级别上过滤接口： apis() 这种方式我们可以指定包名的方式，让 Swagger 只去某些包下面扫描； paths() 这种方式可以通过筛选 API 的 url 来进行筛选； @ConditionalOnExpression(&quot;${swagger.enable:true}&quot;) 这个注解控制了是否启用 Swagger，我们需要在 appplication.properties 中加上 swagger.enable=true 编写控制器类——Controller 类我们先介绍一下在用 Swagger 时的常用注解： @API 类的注解，可以给控制器增加描述和标签信息。用在请求的类上，代表了这个类是 Swagger 的资源 tags：控制器标签，对该类进行「分类」，参数是个字符串数组，如果配置了多个值，会在多个分类中看到； value：该参数没什么意义，在 UI 界面上并不显示，可不用配置 @ApiModel 类注解，对 API 涉及的对象做描述，可用于响应实体类，说明实体作用 value Model 展示时的名称，默认是 实体类的名称，比如 UserEntity； description 实体类的描述 类成员变量的的注解： @ApiModelProperty 用在实体类的属性上 value 属性字段描述； required 参数是否必选； name 重写字段名称； dataType 重写字段类型； allowEmptyValue 是否允许为空； allowbleValues 该字段允许的值。当我们 API 某个参数为枚举类型时，使用这个参数就可以清楚高速 API 使用者能允许传入的值 方法的注解： @ApiOperation 描述方法的用途，用来展开对接口的描述 value 接口简要描述； notes 接口发布说明，详细描述； @ApiImplicitParams 用于描述接口的非对象参数集，一般与 @ApiImplicitParams 组合使用 @ApiImplicitParam 描述参数信息 value 参数意义的描述 name 参数名字； required 默认 false，参数是否必传 dataType 参数数据类型，只作为标志说明，并没有实际验证 Long String paramType 参数类型，表示参数放在哪里 query，默认值，Query String 的方式传参，请求参数的获取：@RequestParam path 路径参数，请求参数的获取：@PathVariable header 请求参数的获取：@RequestHeader @PathVariable 路径参数，给类似 @GetMappIng(&quot;/user/{id}&quot;) 参数通过路径传入 其他： @ApiIgnore：用于类或者方法上，屏蔽接口不被显示在页面上； @Profile({&quot;dev&quot;,&quot;test&quot;})：用于配置类上，表示对什么环境启用； @ApiParam 不能直接用在方法上，而是用在方法的形参定义中，下文会有示例； 实体类示例： 123456789101112131415161718192021@Data@ApiModel(value = "用户实体")public class UserEntity &#123; public static final long serialVersionUID = 1L; @ApiModelProperty(value = "用户 id") private int id; @ApiModelProperty(value = "用户名", required = true) private String userName; @ApiModelProperty(value = "密码" ) private String passWord; @ApiModelProperty(value = "性别") private UserSexEnum userSex; @ApiModelProperty(value = "昵称" ) private String nickName; public UserEntity(Integer id, String userName, String passWord) &#123; this.id = id; this.userName = userName; this.passWord = passWord; &#125;&#125; 下面是一个控制类的示例： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859@RestController@RequestMapping("/api/v1/")@Api(tags = &#123;"用户相关接口"&#125;, value = "用户模块")public class UserController &#123; // 模拟数据库 public static List&lt;UserEntity&gt; users = new ArrayList&lt;&gt;(); static &#123; UserEntity user1 = new UserEntity(1, "michael", "123"); UserEntity user2 = new UserEntity(2, "qq", "123"); UserEntity user3 = new UserEntity(3, "hh", "123"); users.add(user1); users.add(user2); users.add(user3); &#125; @ApiOperation(value = "获取用户列表", notes = "获取全部用户信息") @RequestMapping(value = "/users", method = RequestMethod.GET) public List&lt;UserEntity&gt; getUsers() &#123; return users; &#125; @ApiOperation(value = "查询单用户", notes = "根据用户id 查询其信息") @ApiImplicitParam(name = "id", value = "用户id", paramType = "query", required = true) @GetMapping("/user/&#123;id&#125;") public UserEntity getUser(@PathParam("id") int id) &#123; UserEntity user = users.get(id); return user; &#125; @ApiOperation(value = "存储用户信息", notes = "存储用户详细信息") @RequestMapping(value = "/user", method = RequestMethod.POST) public UserEntity saveUser(@ApiParam(value = "用户信息", required = true) @RequestBody UserEntity user) &#123; users.add(user); return user; &#125; @ApiOperation(value = "删除用户", notes = "根据用户id删除用户信息") @ApiImplicitParams(&#123; @ApiImplicitParam(name = "id", value = "用户id", required = true, paramType = "path") &#125;) @RequestMapping(value = "/user/&#123;id&#125;", method = RequestMethod.DELETE) public int deleteUser(@PathVariable("id") int id) &#123; users.remove(id); return id; &#125; @ApiOperation(value = "更新用户信息", notes = "更新用户的个人信息") @PutMapping("/user/") public UserEntity updateUser(@RequestBody UserEntity user) &#123; int id = user.getId(); UserEntity oldUser = users.get(id); users.set(id, user); return user; &#125;&#125; 启动启动应用，访问 localhost:8080/swagger-ui.html 可以访问到 Swagger UI，可以点击 Try it out 按钮，调用 API： 页面上还会有一个 Models 的分类。Swagger UI 会根据我们在实体上使用的 @ApiModel 和 @ApiModelProperty 注解来自动补充实体以及其属性的描述和备注。 示例代码 awesome-spring-boot-examples One More ThingWeb API 的风格开发 API，先了解一下有哪些 Web API 的风格吧： RPC：RPC 面向过程，RPC 形式的 API 组织形态是类和方法，API 的命名往往是一个动词，比如 GetUserInfo,CreateUser; REST：REST 面向资源，也是下文将要介绍的一种 API 风格； GraphQL：就是面向数据查询，采用GraphQL，甚至不需要有任何的接口文档，在定义了Schema之后，服务端实现Schema，客户端可以查看Schema，然后构建出自己需要的查询请求来获得自己需要的数据 REST上文提到了 RESTful API 的概念，我觉得，不如趁机了解一下。因为在实际的项目中发现，并不是每个 Spring Boot 的开发人员都能意识到开发的 API 要尽量符合 RESTful 规则的。REST 实际上只是一种设计风格，它并不是标准。 术语： Endpoint 终点，可以理解为路径，表示 API 的具体网址。 API（Application Programming Interface)，应用程序编程接口 REST 是 Representational State Transfer 的缩写。如果一个架构符合 REST 原则，就称它为 RESTful 架构。RESTful API 就是 REST 风格的 API Resource：资源，即数据。 Representational：某种表现形式，比如用 JSON，XML，JPEG 等； State Transfer：状态变化。通过 HTTP 动词实现 在 RESTful 架构中，每个网址代表一种资源（resource），所以网址中不能有动词，只能有名词，而且所用的名词往往与数据库的表格名对应。 资源的操作RESTful 的核心思想就是，客户端发出的数据操作指令都是”动词 + 宾语”的结构。比如，GET /articles 这个命令，GET 是动词，/articles 是宾语。 对于资源的具体操作类型，由 HTTP 动词表示（括号里是对应的 SQL 命令）： GET（SELECT）：从服务器取出资源（一项或多项）。 POST（CREATE）：在服务器新建一个资源。 PUT（UPDATE）：在服务器更新资源（客户端提供改变后的完整资源）。 PATCH（UPDATE）：在服务器更新资源（客户端提供改变的属性）。 DELETE（DELETE）：从服务器删除资源 还有两个不常用的 HTTP 动词： HEAD：获取资源的元数据。 OPTIONS：获取信息，关于资源的哪些属性是客户端可以改变的 知乎上的一个回答，我觉得很精辟： 看 Url 就知道要什么 看 http method 就知道干什么 看 http status code 就知道结果如何 一位答主给出的示例： 1234GET /rest/api/getDogs --&gt; GET /rest/api/dogs 获取所有小狗狗GET /rest/api/addDogs --&gt; POST /rest/api/dogs 添加一个小狗狗GET /rest/api/editDogs/:dog_id --&gt; PUT /rest/api/dogs/:dog_id 修改一个小狗狗GET /rest/api/deleteDogs/:dog_id --&gt; DELETE /rest/api/dogs/:dog_id 删除一个小狗狗 信息过滤 Filtering如果记录数量很多，服务器不可能都将它们返回给用户。API 应该提供参数，过滤返回结果 ?limit=10：指定返回记录的数量 ?offset=10：指定返回记录的开始位置。 ?page=2&amp;per_page=100：指定第几页，以及每页的记录数 参考 CSDN-Spring Boot集成Swagger 官宣-Swagger IBM-在 Spring Boot 项目中使用 Swagger 文档 蜻蜓HTTP-springboot 集成完整的swagger2 API 介绍 阮一峰-RESTful API 设计指南 阮一峰-RESTful API 最佳实践 segmentfault-Philipp Hauer-[译]RESTful API 设计最佳实践 推荐 RESTful Service API 设计最佳工程实践和常见问题解决方案 总结的相当好，博客值得阅读 华为云-API设计中关于RPC和REST 两种风格选择的个人理解 跟着 Github 学习 Restful HTTP API 设计 梁桂钊——人人都是 API 设计师：我对 RESTful API、GraphQL、RPC API 的思考 作者分享了一些阿里团队里做法 阿里研究员谷朴：API 设计最佳实践的思考 朱晔的互联网架构实践心得S2E5：浅谈四种API设计风格（RPC、REST、GraphQL、服务端驱动）]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Spring Boot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Boot 实战 —— 入门]]></title>
    <url>%2F2019%2F07%2F07%2Fjava-spring-boot-hello-world%2F</url>
    <content type="text"><![CDATA[简介目前没有系统学习过 Spring 框架，参与工作时，直接参与到了 Spring Boot 项目的开发。目前还比较菜，所以，你要是和我一样，不妨也跳过 Spring 框架的学习，直接学习 Sring Boot。 官方文档的一段介绍： Spring Boot makes it easy to create stand-alone, production-grade Spring-based Applications that you can run. We take an opinionated view of the Spring platform and third-party libraries, so that you can get started with minimum fuss. Most Spring Boot applications need very little Spring configuration. You can use Spring Boot to create Java applications that can be started by using java -jar or more traditional war deployments. We also provide a command line tool that runs “spring scripts”. 大体意思是说，Spring Boot 可以轻松创建可以运行的独立的，基于生产级 Spring 的应用程序。这个框架简化了我们 Spring 的配置。可以使用 Spring Boot 创建 Java 应用，只需要使用 java -jar 或 war 包部署方式就可以启动。也内嵌了 Tomcat，在开发时无需以 war 包也可以运行应用。 示例代码 awesome-spring-boot-examples 环境下面是本文编写时，我机器的环境： Java 1.8.0_181 Maven 3.5.4 创建项目本文目的是创建一个基本的 RESTful Web 服务。创建 Spring Boot 服务的方式主要有两种： 在 IDEA 中使用 Spring Initializr 创建，我个人比较倾向这种方式，方便快捷； 访问网站 Spring Initializr 网站，勾选相关项目依赖，最后生成一个初始化项目，导入 IDE。 下面主要介绍 IDEA 如何初始化一个 Sring Boot 项目： 1.File-New-Porject，选择 Spring Initializr，选择 SDK 版本；2.输入项目的元数据信息，关系到项目的路径、pom 文件中项目的 Maven 坐标（GAV）； 3.选择需要的 Maven 依赖，这里 Spring Boot 版本，我选择了 2.1.6 版本； 4.最后一步指定项目存放位置； src/main/java 中有项目代码文件，根目录下是入口类：SpringBootHelloWorldApplication 类。@SpringBootApplication 注解，这是整个 Spring Boot 的核心注解，它的目的就是开启 Spring Boot 的自动配置。 src/main/resources 下是配置文件：application.properties src/test/ 下的测试入口：Chapter1ApplicationTests 添加控制器类 —— Controller通常在项目中对外提供的 API 都会放在叫做 Controller 的包下。 我们创建一个 Controller 的包，并添加一个叫做 HelloWorld 的类： 12345678910@RestControllerpublic class HelloWorld &#123; @GetMapping("/hello") public String sayHello() &#123; return "Hello World"; &#125;&#125; @RestController 注解加在这个类上，使之变为一个 Controller 这是我们启动项目，便可以通过地址 localhost:8080/hello 或 127.0.0.1:8080/hello 看到 sayHello 函数执行的内容。 查看控制台的输出，我们可以知道 Spring Boot 项目启动时，默认的端口是 8080 Profile 配置文件官方文档中有关于 Profile 的描述。 Prorile 有 轮廓、外形、简况的含义，这里我就把它理解为「配置描述」好了。src/main/resources 目录是 Spring Boot 的配置目录，Spring Boot 的默认配置文件位置为：src/main/resources/application.properties。 在实际项目中，生产、beta 不同环境将采用不同的配置，比如数据库配置等等。这时候，我们只需要创建多分 Profile 文件即可。 除了 application.properties 文件，配置文件还可以采用下面的命名规则application-{profile}.properties。Environment 中具有一组可选的值。如果没有设置需要激活什么配置文件，就默认激活 default 配置，即 application-default.properties。 指定的配置文件都是从同一个位置被激活，即从标准的配置文件 application.properties，这一点要记住！ 如果指定了多个配置文件，采取 last-win 策略，即「最后获胜侧率」。这句话意思是什么呢，就是说，在你的 application.properties 中如果指定了激活好几个配置文件，那么，最后指定的那个配置文件才会生效。 我们分别创建两个环境配置文件： application-dev.properties 测试环境 1server.port=8081 application-prod.properties 生产环境 1#server.port=8082 Spring Boot 的配置文件除了可以使用 properties 文件之外，还支持的 YAML 文件 通过 application.prperties 指定 Profileapplcation.properties 公共配置文件。激活 Dev 配置文件，需要在 application.properties 设置： 123#这里定义8080主要是为了看端口设置是否会被 dev 覆盖server.port=8080spring.profiles.active=dev 这时候启动程序时，我们查看控制台就可看到 Dev 环境被激活了，应用端口是 8081。这时候观察 application.properties 的端口设置是否会会生效。经过测试可以发现，此时8080 端口被 Dev 的配置覆盖了。 接着，我们激活 Prod 配置，注意，此时我将 Prod 端口配置注释掉了，这时候观察 application.properties 的端口设置是否会会生效。经过测试可以发现，此时8080 端口生效了。 通过 Environment 指定 Profile除了上面在 application.properties 指定激活的配置外，还可以在 Envirionment 中设置相关环境变量激活： 1spring.profiles.active=dev 经过测试，我在 Environment 中设置环境变量激活了 Dev 的配置，然后在 application.properties 激活的是 Prod 的配置，最终控制台日志显示， Dev 配置被激活。 jar 方式运行时如果采用 mvn clean package 打出 jar 包，那么可以使用如下方式指定 Profile： 1java -jar spring-boot-hello-world-0.0.1-SNAPSHOT.jar --spring.profiles.active=dev 在命令行方式启动 Spring Boot 应用时，连续的两个减号 -- 就是对 application.properties 中的属性值进行赋值的标识。通过命令行来修改属性值是Spring Boot 非常重要的一个特性，通过此特性，理论上已经使得我们应用的属性在启动前是可变的，所以其中端口号也好、数据库连接也好，都是可以在应用启动时发生改变。 补充：我们有时候利用 java 方式启动时，会带参数 -D，这个怎么理解呢？ use -D to define system properties 可以阅读下面两个链接： java程序启动参数-D详解 Why do JVM arguments start with “-D”? Spring Boot 配置文件中的花样，看这一篇足矣！ 自定义属性参数我们可以在 Profile 中指定一些 propety 的值，在程序中可以获取到。 在 application-dev.properties 定义如下： 12server.port=8081author.name=Michael 接着，我们在 Controller 类中使用 @Value 注，即可获取到这个属性： 1234567891011@RestControllerpublic class HelloWorld &#123; @Value(value = "$&#123;author.name&#125;") private String authorName; @GetMapping("/hello") public String sayHello() &#123; return "Hello World By " + authorName; &#125;&#125; 使用随机数在配置文件中，可以使用 ${random} 来生成不同类型的随机数。 123456book.value = $&#123;random.value&#125;book.intValue = $&#123;random.int&#125;book.longValue = $&#123;random.long&#125;book.uuid = $&#123;random.uuid&#125;# 1000 以内的随机数book.randomNumber = $&#123;random.int(1000)&#125; 热部署只需要引入 spring-boot-devtools 依赖即可。引入依赖之后，重新编译修改的类文件或者配置文件， Spring Boot 框架会自动重启： 12345&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt;&lt;/dependency&gt; 在 IDEA 的顶部菜单栏的 Build 中可以看到编译相关的选项。 定制 BannerBanner 就是指我们在启动应用时控制台一开始打印的那个内容，默认是打印 Spring Boot。 src/main/resorces 下新建一个名为 banner.txt 的内容； 复制你想显示的内容到 banner.txt。 个性化 Banner 来源： http://patorjk.com/software/taag http://www.network-science.de/ascii/ https://github.com/Blankj/awesome-comment 送一个有趣的 Banner： 12345678910111213141516171819202122////////////////////////////////////////////////////////////////////// _ooOoo_ //// o8888888o //// 88" . "88 //// (| ^_^ |) //// O\ = /O //// ____/`---'\____ //// .' \\| |// `. //// / \\||| : |||// \ //// / _||||| -:- |||||- \ //// | | \\\ - /// | | //// | \_| ''\---/'' | | //// \ .-\__ `-` ___/-. / //// ___`. .' /--.--\ `. . ___ //// ."" '&lt; `.___\_&lt;|&gt;_/___.' &gt;'"". //// | | : `- \`.;`\ _ /`;.`/ - ` : | | //// \ \ `-. \_ __\ /__ _/ .-` / / //// ========`-.____`-.___\_____/___.-`____.-'======== //// `=---=' //// ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ //// 佛祖保佑 永不宕机 永无BUG ////////////////////////////////////////////////////////////////////// 补充知识spring-boot-starterSpring Boot 提供了很多”开箱即用“的依赖模块，都是以 spring-boot-starter-xx 作为命名的。下面列举一些常用的模块： spring-boot-starter-logging ：使用 Spring Boot 默认的日志框架 Logback。 spring-boot-starter-log4j ：添加 Log4j 的支持。 spring-boot-starter-web ：支持 Web 应用开发，包含 Tomcat 和 spring-mvc。 spring-boot-starter-tomcat ：使用 Spring Boot 默认的 Tomcat 作为应用服务器。 spring-boot-starter-jetty ：使用 Jetty 而不是默认的 Tomcat 作为应用服务器。 spring-boot-starter-test ：包含常用的测试所需的依赖，如 JUnit、Hamcrest、Mockito 和 spring-test 等。 spring-boot-starter-aop ：包含 spring-aop 和 AspectJ 来支持面向切面编程（AOP）。 spring-boot-starter-security ：包含 spring-security。 spring-boot-starter-jdbc ：支持使用 JDBC 访问数据库。 spring-boot-starter-redis ：支持使用 Redis。 spring-boot-starter-data-mongodb ：包含 spring-data-mongodb 来支持 MongoDB。 spring-boot-starter-data-jpa ：包含 spring-data-jpa、spring-orm 和 Hibernate 来支持 JPA。 spring-boot-starter-amqp ：通过 spring-rabbit 支持 AMQP。 spring-boot-starter-actuator ： 添加适用于生产环境的功能，如性能指标和监测等功能。 SpringBoot 目录结构常用目录结构理解： controller：控制层，前端控制器，负责页面访问控制，controller 是用来接收页面参数，并且调用逻辑处理，最后组织页面响应的地方。我们不可以在controller 进行逻辑处理，controller 只应该负责用户 API 入口和响应的处理。主要是对外提供的 API 接口，用户使用服务时的入口处，可以结合 swagger 生成对应的 API 文档 service：业务层，逻辑层，主要是业务类代码，归档了前端控制器中相关服务的操作方法接口类，该文件夹下包含子 impl 文件夹，归档对应的实现接口 domain：实体类，归档对应的实体（Entity），一个实体尝尝就对应着数据库中一张表 dao：数据访问层，实体类对应的数据库操作接口类，它与数据库进行交互，封装了对数据库的 CURD 操作 config：配置信息类 utils：工具类 constant：常量接口类 当请求来了，controller 就会将相应的请求分发到相应的 service层，在 service 层中再调用 dao 层进行数据库交互。这里的 dao 层其实就是之前的 model 层，封装了对数据库的操作。这样一来，就把业务处理逻辑从 controller 中分离出来，从而实现了解耦。 领域模型分层领域模型规约，熟悉一下： DO（ Data Object）：与数据库表结构一一对应，通过 DAO 层向上传输数据源对象。★★★ DTO（ Data Transfer Object）：数据传输对象，Service 或 Manager 向外传输的对象。★★★ BO（ Business Object）：业务对象。 由 Service 层输出的封装业务逻辑的对象。 AO（ Application Object）：应用对象。 在Web层与Service层之间抽象的复用对象模型，极为贴近展示层，复用度不高。 VO（ View Object）：显示层对象，通常是 Web 向模板渲染引擎层传输的对象。★★★ POJO（ Plain Ordinary Java Object）：在本手册中， POJO专指只有setter/getter/toString的简单类，包括DO/DTO/BO/VO等。 Query：数据查询对象，各层接收上层的查询请求。 注意超过2个参数的查询封装，禁止使用Map类来传输。 领域模型命名规约： 数据对象：xxxDO，xxx即为数据表名。★★★ 数据传输对象：xxxDTO，xxx 为业务领域相关的名称。目前项目中，牵扯到和其他周边部署系统需要实体类接受数据时，这样的对象往往以 DTO 结尾 ★★★ 展示对象：xxxVO，xxx 一般为网页名称。目前项目中 Ctroller 层涉及的请求体，通常以 VO 结尾。★★★ POJO是DO/DTO/BO/VO的统称，禁止命名成xxxPOJO。 参考 江南一点雨-初识Spring Boot框架 boot-features-external-config-profile-specific-properties 官宣 博客园-静默虚空-Spring Boot 之 Profile 使用 InfoQ-胡正林-Spring Boot 多环境配置最佳实践 偏底层，了解 Profile 激活流程可查阅 新年彩蛋：Spring Boot自定义Banner 梁桂钊-Spring Boot 揭秘与实战（一） 快速上手 spring-boot-starter 目录结构参考 Spring Boot工程结构(推荐) 【系统学习SpringBoot】目录结构（建议） Spring Boot基础(三):Spring Boot项目推荐工程结构 使用SpringBoot的推荐项目目录结构 浅谈MVC分层架构中的层次 YezhiweiBlog-Spring Boot 工程结构规范——项目定义级包结构 博客园-阿里巴巴Java开发手册中的DO、DTO、BO、AO、VO、POJO定义 知乎-PO BO VO DTO POJO DAO DO这些Java中的概念分别指一些什么？ Spring Boot 启动原理： 老钱-SpringBoot 究竟是如何跑起来的?]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Spring Boot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Chrome 扩展神器 Vimium 使用教程——快速搜索收藏的书签]]></title>
    <url>%2F2019%2F06%2F23%2Fvideo-tools-chrome-vimium%2F</url>
    <content type="text"><![CDATA[起点一直想要尝试通过录制视频的方式，分享一些经验，工具的、学习的等等。今天终于在 B 站投稿了第一个视频，不知道是否有小伙伴会去看到。 学习在 B 站好好搜索了一番，学习一下视频剪辑的教程，下面罗列一些我找到的有用的教程 视频剪辑： WillTV-活动作品我的教学类视频制作流程分享，用什么录屏软件和剪辑软件，视频制作心得感受 WillTV-10分钟上手Final Cut Pro X，零基础新手快速入门，视频剪辑基本操 片头： WillTV-5分钟制作专业级视频片头，快速制作一个intro/outro，如何做3D片头动画 字幕： WillTV-到底要不要上字幕？上字幕的优劣分析与我的看法，为什么要上字幕 WillTV-5款免费商用字体推荐，视频up主字体版权问题，无需授权免费商用字体 WillTV-极速上字幕方法，语音转写自动生成字幕，免费快速上字幕 天JIANG-[字幕教程]怎么做字幕/利用PR和ARCTIME做字幕 背景音乐： WillTV-版权BGM哪里找，我怎么找背景音乐，适合vlog视频的正版音乐库 常用软件 arctime 字幕 成果最终，展示一下录制的成果： 视频链接： https://www.bilibili.com/video/av56598067]]></content>
      <categories>
        <category>ToolsDaily</category>
      </categories>
      <tags>
        <tag>Chrome</tag>
        <tag>Video</tag>
        <tag>教程</tag>
        <tag>利器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Github 使用 Travis CI 实现 Hexo 博客自动部署]]></title>
    <url>%2F2019%2F06%2F16%2Fcicd-hexo-blog-travis%2F</url>
    <content type="text"><![CDATA[想学一下 Travis CI 的用法，带着目的学习效果更佳。那么，我最终的目的就是实现 Github 上的Hexo 博客仓库有内容更新后，自动运行 Hexo 部署命更新博客。 Travis CITravis CI 在 Github 的 Marketplace 中可以看到，这是它 Marketplace 的链接:Travis CI Continuous Integration，简称 CI：意思是，在一个项目中，任何人对代码库的任何改动，都会触发 CI 服务器自动对项目进行构建，自动运行测试，自动编译，甚至自动部署到测试环境。这样做的好处就是，随时发现问题，随时修复。因为修复问题的成本随着时间的推移而增长，越早发现，修复成本越低。 Travis CI 是在线托管的 CI 服务，用 Travis 来进行持续集成，不需要自己搭服务器。 官网对使用 Travis CI 有详细的使用步骤： 前往 Travis-ci.com and Sign up with GitHub. 接受授权 选择你想要使用 Travis CI 的仓库 或者 你也可以在 Github-settings-Applications-TravisCI-Configure 中去更新配置； 在你仓库怎增加 .travis.yml 文件，这个文件定义了构建的步骤，例如安装依赖等等。 将 .travis.yml 文件推送到你的远端仓库，然后就会触发 Travis CI 构建； 登录 Travis CI然后选择你的仓库查看构建任务的执行详情； Job Lifecycle – Job 生命周期Travis CI 为每种编程语言提供默认构建环境和默认的阶段集。 创建虚拟机为你的Job提供构建环境，将存储库克隆到其中，安装可选的插件，然后运行构建阶段。 job 的声明周期，主要包含两大部分： install：安装依赖，官网有专门讲解的 Installing Dependencies script：运行构建脚本； 在 installation 阶段之前（beofore_install）、在 script phase 之前（before_script）或之后（after_script），你可以运行自定义命令； 当构建成功或失败置换后，可以使用 after_success（例如构建文档）或 after_failure（例如上载日志文件）阶段执行其他操作（actions）。 在 after_failure 和 after_success 中，您可以使用 $TRAVIS_TEST_RESULT 环境变量获取构建结果。 完整的 job 生命周期(包括三个可选的部署阶段，以及在检出 git 存储库 和更改到存储库目录) 如下： apt addons 可选安装 cache components 可选安装 before_install install before_script script before_cache (for cleaning up cache) 可选 after_success or after_failure before_deploy 可选 deploy 可选 after_deploy 可选 after_script 一次构建任务可有许多 job 组成。 Install Phase默认依赖项安装命令取决于项目语言。 例如，Java 构建使用 Maven 或 Gradle，具体取决于存储库中存在的构建文件。 1install: ./install-dependencies.sh When using custom scripts they should be executable (for example, using chmod +x) and contain a valid shebang line such as /usr/bin/env sh, /usr/bin/env ruby, or /usr/bin/env python. 你可以选择跳过安装依赖项阶段： 1install: true 自定义构建阶段Ruby 构建示例： 1script: bundle exec thor build 可以定义多脚本命令： 123script:- bundle exec rake build- bundle exec rake builddoc 这样的定义，如果第一行命令返回值非 0，并不会影响第二行命令的执行。但是最后的总结果是会标记为 fail 。 想要实现那种「串行」效果，可以这么写： 1script: bundle exec rake build &amp;&amp; bundle exec rake builddoc 更负载一点的构建命令，就将构建的步骤写到脚本文件中，然后： 1script: ./scripts/run-tests.sh 构建中断下面的四个阶段中，任意阶段中命令抛出非 0，构建都会被中断： before_install install before_scrip script 如下阶段的退出不会影响构建结果。但是，如果其中一个阶段超时，则构建将标记为失败：after_successafter_failureafter_scriptfter_deploy和 部署部署是 job 生命周期中的可选阶段。这个阶段定义了使用持续部署方法去将你的代码部署到 Heroku, Amazon 或其他支持的平台。如果构建失败，那这一步自然会被跳过的。 将文件去部署时，通过将 skip_cleanup 添加到 .travis.yml 中，可以阻止Travis CI 重置您的工作目录并删除在构建期间所做的所有更改（类似于这个命令的效果 git stash --all）： 12deploy: skip_cleanup: true 注意点：before_deploy 和 after_deploy 在执行每个部署任务时，都会被触发执行。 更多内容，查看 Job Lifecycle 补充： Heroku 是一个支持多种编程语言的云平台即服务。在 2010 年被 Salesforce.com 收购。Heroku作为最开始的云平台之一[1]，从2007年6月起开发，当时它仅支持 Ruby，但后来增加了对 Java、Node.js、Scala、Clojure、Python 以及（未记录在正式文件上）PHP 和 Perl的支持。基础操作系统是 Debian，在最新的堆栈则是基于 Debian 的Ubuntu。 Build Stagesbuild stages 是一个将 job 分组的方法。在每个 stage 中平行的执行 job。但是如果一个 stage 执行失败，会影响到后续的 stage 执行。这不就是 pipeline 的模型吗？ 在 stages section 定义 stages 的顺序： 1234stages: - compile - test - deploy 更多内容，查看 Build Stages 部署 Hexo 博客Travis 准备为了能够实现代码推送到 Github，需要给 Travis CI Github 的 Persional access tokens，在 settings- Developer settings 可以生成一个。 然后进入 Travis 中的项目设置界面，可以给具体的代码库进行设置，比如增加环境变量： 主要加了一个环境变量 GH_TOKEN，这个在后面的 .travis.yml 中会用到。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748# 指定构建环境是Node.js，当前版本是稳定版anguage: node_jsnode_js: stableenv: global: - URL_REPO: github.com/Michael728/michael728.github.io.git# 设置钩子只检测blog-source分支的push变动branches: only: - hexo# 设置缓存文件cache: directories: - node_modules#在构建之前安装hexo环境before_install: - npm install -g hexo-cli#安装git插件和搜索功能插件install: - npm install # 设置git提交名，邮箱；替换真实token到_config.yml文件before_script: - git config user.name "Michael728" - git config user.email "649168982@qq.com" # 替换同目录下的_config.yml文件中github_token字符串为travis后台刚才配置的变量，注&gt;意此处sed命令用了双引号。单引号无效！ - sed -i "s/github_token/$&#123;GH_TOKEN&#125;/g" _config.yml || exit 1# 执行清缓存，生成网页操作script: - hexo clean - hexo generate - echo $&#123;ENV_TEST&#125; - hexo deploy# configure notifications (email, IRC, campfire etc)# please update this section to your needs!# https://docs.travis-ci.com/user/notifications/notifications: email: - 649168982@qq.com on_success: change on_failure: always 这份 yml 文件我做了一些调整，hexo deploy 失败，就是会显示失败，而参考文章中有一些写在了 after_scripts 中，不方便查看是否部署成功了。 有文章)介绍了可以对 token 进一步加密，然后在 .travis.yml 中直接配置密码，这样也可以走通，免走了去配置环境变量的步骤。个人还是偏向去配置环境变量. 按照指导，包括官网的指导-Encryption keys，由于网络太慢，没走通； 将密码写在环境中也是比价好的一种方式！ 代码库准备之前的博客代码库只有一个 master 分支，存放的都是 hexo g 命令生成的静态文件。于是，我需要： 本地准备好博客代码库 新建一个叫 hexo 的分支：git checkout -b hexo 添加 .travis.yml 文件 将之前我的博客源文件拷贝到该分之下，并删除node_modules、public文件夹 同时，我也将主题文件下的 .git 目录删除了，因为我并需要 submodule 的方式去下载主题仓库了 然后将站点配置文件进行一下修改 12345678deploy:- type: git #repo: git@github.com:Michael728/michael728.github.io.git #下方的gh_token会被.travis.yml中sed命令替换 repo: https://github_token@github.com/Michael728/michael728.github.io.git branch: master- type: baidu_url_submitter 说明：github_token 这个字段看到了吗？在 .travis.yml 文件中，会使用环境变量 GH_TOKEN 替换掉它的。因为构建机器上没有配置 ssh 免密，所以需要使用这种 token+http 的方式实现代码的推送 到此基本配置完毕，下载新建文章之后，只需要 git push origin hexo 推送到远端分支，在 Travis CI 中会自动执行部署脚本的。 一开始部署都 OK，后来发现博客的分享按钮和图标显示都有问题。后来发现 next 主题下和 next/source/lib/needsharebutton 下都有 .gitignore 文件。这样当然去部署时，不会带相关配置文件了。于是，我将 .gitignore 文件都重命名了。后来再执行推送时，部署就 OK 了。 所以，现在我只需要在 Hexo 分支编辑，就可以自动触发 CI 去发布博客啦。甚至手机端都可以直接写篇博客了！美滋滋~~~ 总结整个过程走下来，感觉和我现在工作中打造的 DevOps 流水线系统很像。开源的这些作品有很多优秀的点值得学习和借鉴，需要去多体验。 昨天在家中折腾搭建好的 Gitlab 和 Gitlab-Runner 应该也可以实现这样的功能，因为它也有一个 .gitlab-ci.yml 来定义 CI/CD 流水线。改天有时间，研究一下。 参考 Hexo+github搭建个人博客（三）：Travis CI持续集成,自动部署博客 掘金-Hexo遇上Travis-CI：可能是最通俗易懂的自动发布博客图文教程 Travis CI Github 项目与 Travis CI 集成 使用 Travis CI 自动更新 GitHub Pages 推荐]]></content>
      <categories>
        <category>DevOps</category>
      </categories>
      <tags>
        <tag>DevOps</tag>
        <tag>CICD</tag>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用 Dockcer-Compose 安装 Gitlab 服务]]></title>
    <url>%2F2019%2F06%2F15%2Fdocker-compose-install-gitlab-runner%2F</url>
    <content type="text"><![CDATA[DevOpS 环节中，代码托管是必不可少的。本文介绍如何利用 docker-compose 搭建 Gitlab 服务。 gitlab 镜像gitlab 分为两个版本： gitlab-ce 社区版 gitlab-ee 企业收费版 本文的镜像，使用的是社区版本。社区办的镜像，可以在gitlab/gitlab-ce 查看。 硬件要求查看 官宣-Requirements CPU 1 core supports up to 100 users but the application can be a bit slower due to having all workers and background jobs running on the same core 2 cores is the recommended number of cores and supports up to 500 users 4 cores supports up to 2,000 users 8 cores supports up to 5,000 users 16 cores supports up to 10,000 users 32 cores supports up to 20,000 users 64 cores supports up to 40,000 users More users? Run it on multiple application servers Memory 4GB RAM + 4GB swap supports up to 100 users but it will be very slow 8GB RAM is the recommended memory size for all installations and supports up to 100 users 16GB RAM supports up to 2,000 users 32GB RAM supports up to 4,000 users 64GB RAM supports up to 8,000 users 128GB RAM supports up to 16,000 users 256GB RAM supports up to 32,000 users More users? Run it on multiple application servers docker-compose 示例123456789101112131415161718192021222324252627282930313233343536373839version: "3"services: gitlab: image: 'gitlab/gitlab-ce:latest' restart: always hostname: 'gitlab.michael.com' container_name: 'devops-gitlab' ports: - '81:80' - '443:443' - '23:22' environment: GITLAB_OMNIBUS_CONFIG: | external_url "http://gitlab.michael.com" gitlab_rails['gitlab_shell_ssh_port'] = 23 gitlab_rails['time_zone'] = 'Asia/Shanghai' # email setting gitlab_rails['smtp_enable'] = true gitlab_rails['smtp_address'] = "smtp.163.com" gitlab_rails['smtp_port'] = 25 gitlab_rails['smtp_user_name'] = "michael_show728@163.com" gitlab_rails['smtp_password'] = "xxx" gitlab_rails['smtp_domain'] = "163.com" gitlab_rails['smtp_authentication'] = "login" gitlab_rails['smtp_enable_starttls_auto'] = true gitlab_rails['gitlab_email_from'] = "michael_show728@163.com" gitlab_rails['smtp_tls'] = false gitlab_rails['smtp_openssl_verify_mode'] = 'peer' user["git_user_email"] = "michael_show728@163.com" volumes: - '/data/gitlab/config:/etc/gitlab' - '/data/gitlab/logs:/var/log/gitlab' - '/data/gitlab/data:/var/opt/gitlab' networks: - gitlab_netnetworks: gitlab_net: name: gitlab_net 为了在我机器上 192.168.3.66 能够识别这个域名，我通过配置 hosts 文件，将容器的宿主机 IP 和这个域名做了映射： 1192.168.3.43 gitlab.michael.com 经过试验，挂卷的目录，即宿主机的目录，如果没有创建的话，默认会创建的。有时候没有配置文件是没关系的，但是有时候却会有影响，比如 Nginx 的配置文件你没有事先归档在宿主机的目录上，这时候启动 Nginx 就不会起作用。这里启动 gitlab-ce 没有问题，所以，无须利用 docker cp 的方式，预先拷贝一些配置文件出来。 123456789$ docker exec -it devops-gitlab bashroot@gitlab:/# cat /etc/hosts127.0.0.1 localhost::1 localhost ip6-localhost ip6-loopbackfe00::0 ip6-localnetff00::0 ip6-mcastprefixff02::1 ip6-allnodesff02::2 ip6-allrouters192.168.240.2 gitlab.michael.com gitlab 可以看到，在容器网络中，gitlab.michael.com 这个域名对应的 IP 是 192.168.240.2。我在局域网里用我自己另一台机器 ping 这个 IP，是不通的。因为我在家是没有 DNS 域名服务器的。这个 IP 很关键，在后面的配置中起到了关键作用。 配置详解ports端口 81:80 的配置是因为我容器的宿主机的 80 端口是给 Nginx 用了。在同一台机器上，为了不引起端口冲突，将 81 端口和容器的 80 端口映射。 访问 gitlab 服务下面地址皆可： 宿主机 IP:81，即 192.168.3.43:81 gitlab.michael.com:81 这样的网址并不优美，因此，我在 Nginx 中增加了一个 gitlab.conf 的配置文件，这样就可以直接使用 gitlab.michael.com 访问了： 1234567891011121314151617181920212223242526upstream gitlab&#123; # 域名对应 gitlab配置中的 external_url # 端口对应 gitlab 配置中的 nginx['listen_port']，通过环境变量可设置 server 192.168.3.43:81;&#125;server&#123; listen 80; # 此域名是提供给最终用户的访问地址 server_name gitlab.michael.com; location / &#123; # 这个大小的设置非常重要，如果 git 版本库里面有大文件，设置的太小，文件push 会失败，根据情况调整 client_max_body_size 50m; proxy_redirect off; #以下确保 gitlab中项目的 url 是域名而不是 http://git，不可缺少 proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; # 反向代理到 gitlab 内置的 nginx proxy_pass http://gitlab; index index.html index.htm; &#125;&#125; 关于使用容器搭建 Nginx 可参考之前的文章：使用容器 Docker 创建开发环境 端口 &#39;23:22&#39; 表示将宿主机的端口 23 和容器的端口 22 映射。ssh 默认端口就是 22，我们使用 ssh 协议登录宿主机时，就是用的 22 端口。因此，如果 22:22 这种映射的话，会影响登录宿主机的。也有文章修改了宿主机的 sshd 默认端口，但是我没有这么做。有需要的话，可以查看通过 docker 搭建自用的 gitlab 服务 gitlab_rails[&#39;gitlab_shell_ssh_port&#39;] = 23 这个环境变量的设置很关键，当我们选择 ssh 协议方式克隆代码库时，复制的地址将会自动变为：ssh://git@gitlab.michael.com:23/root/gitlab-demo.git 12345678# michael @ Michael-MBP in ~/Code/00-Temp [15:25:21]$ git clone ssh://git@gitlab.michael.com:23/root/gitlab-demo.gitCloning into 'gitlab-demo'...remote: Enumerating objects: 6, done.remote: Counting objects: 100% (6/6), done.remote: Compressing objects: 100% (2/2), done.remote: Total 6 (delta 0), reused 0 (delta 0)Receiving objects: 100% (6/6), done. external_url这里的 external_url 配置的是外部 URL，会影响项目的访问地址，如果不配置，项目的访问地址会是一个随机字符串，在云服务器上搭建时尤其要注意这一点。 例如，新建项目的 HTTP 地址为：http://gitlab.michael.com/root/gitlab-demo，这里的地址中的 gitlab.michael.com 就是我在 docker-compose.yml 文件中配置的环境变量。 我发现仅配置了 hostname 为域名时，外部 URL 默认和这个域名保持了一致，也实现了 external_url 的作用。 开启邮件服务我们在使用 github 等类似的平台工具的时候都会用到邮件服务，比如你在 github 上进行注册、密码重置、有人给你的开源项目提 issue 等等的时候，你通常都会收到邮件提醒。 gitlab 肯定也会有这个功能的，下面我们就来开启这个功能，在此之前需要准备一个邮箱账号，这个账号是用来负责发送邮件的，需要开启 smtp 协议支持。本文以 163 邮箱为例。 说明： gitlab_rails[&#39;smtp_address&#39;] ：SMTP服务地址，不同的服务商不同 gitlab_rails[&#39;smtp_port&#39;] ：服务端口 gitlab_rails[&#39;smtp_user_name&#39;] ：用户名，自己注册的 gitlab_rails[&#39;smtp_password&#39;] ：客户端授权秘钥（获取方式，下图讲解） gitlab_rails[&#39;gitlab_email_from&#39;] ：发出邮件的用户，注意跟用户名保持一致 user[&quot;git_user_email&quot;] ：发出用户，注意跟用户名保持一致 亲测，当你使用管理员账户登录时，添加用户之后，上面的配置能够成功发送邮件： 了解更多，查看 官网 SMTP 设置 数据持久化通过挂卷的方式，将 gitlab 的相关数据保存到宿主机上： 当地的位置 容器的位置 作用 /data/gitlab/config /etc/gitlab 用于存储GitLab配置文件 /data/gitlab/logs /var/log/gitlab 用于存储日志 /data/gitlab/data /var/opt/gitlab 用于存储应用数据 gitlab-runnerdockerhub 中有gitlab/gitlab-runner的景象。 Runner 的配置文件是 /etc/gitlab-runner/config.toml，它的字段说明，可以查看文档： Gitlab-runner Advanced configuration 创建 runner 容器先这种方式运行一下，将配置文件拷贝出来，之后再通过 docker-compose 的方式启动： 1234567mkdir -p /data/gitlab-runnerdocker run -d --name gitlab-runner --restart always \ -v /var/run/docker.sock:/var/run/docker.sock \ --network=gitlab_net \ --add-host=gitlab.michael.com:192.168.240.2 \ gitlab/gitlab-runner:latestdocker cp gitlab-runner:/etc/gitlab-runner /data/gitlab-runner/config 上面这种方式，通过 network 的方式，将 runner 和 gitlab server 机器处于同一网络下。所以，当在 runner 中配置 host 之后，IP 就是可达的了。域名会被解析到。 12345678910$ docker exec -it gitlab-runner bashroot@55fc04a0d51a:/# cat /etc/hosts127.0.0.1 localhost::1 localhost ip6-localhost ip6-loopbackfe00::0 ip6-localnetff00::0 ip6-mcastprefixff02::1 ip6-allnodesff02::2 ip6-allrouters192.168.240.2 gitlab.michael.com192.168.240.3 55fc04a0d51a 将之前的 runner 容器停止： 12docker stop gitlab-runnerdocker rm gitlab-runner docker-compose.yml 示例： 1234567891011121314151617version: "2.1"services: runner: image: 'gitlab/gitlab-runner:latest' container_name: 'gitlab-runner' restart: always volumes: - '/data/gitlab-runner/config:/etc/gitlab-runner' - '/var/run/docker.sock:/var/run/docker.sock' networks: - gitlab_net extra_hosts: - "gitlab.michael.com:192.168.240.2"networks: gitlab_net: external: true 获取 Runner 信息gitlab-runner 容器正常运行之后，注册到 gitlab 上的方式有两处： 管理员从 管理中心-Runner 中，注册时使用这里的 shared runner token，这种方式添加的 Runner 将作为 shared Runner 进入具体的项目 设置-CI/CD-Runner-专用 Runner，这种方式添加的 Runner 将作为 专用 Runner 注册 Runner注册 Runner 时，关于 excutor 有好几种类型可以选择，我尝试了 shell 和 docker 两种类型。 shell12345678910111213141516$ docker exec -it gitlab-runner gitlab-runner registerRuntime platform arch=amd64 os=linux pid=32 revision=ac2a293c version=11.11.2Running in system-mode.Please enter the gitlab-ci coordinator URL (e.g. https://gitlab.com/):http://gitlab.michael.com/Please enter the gitlab-ci token for this runner:Wt3GuGq1nAdKWaeBrGM7Please enter the gitlab-ci description for this runner:[8bc594b5f4f4]: shared runnerPlease enter the gitlab-ci tags for this runner (comma separated):centos,sharedRegistering runner... succeeded runner=P6Pme8J5Please enter the executor: ssh, docker+machine, kubernetes, parallels, docker-ssh, shell, virtualbox, docker-ssh+machine, docker:shellRunner registered successfully. Feel free to start it, but if it's running already the config should be automatically reloaded! docker添加共享 runner： 123456789101112131415161718$ docker exec -it gitlab-runner gitlab-runner registerRuntime platform arch=amd64 os=linux pid=31 revision=ac2a293c version=11.11.2Running in system-mode.Please enter the gitlab-ci coordinator URL (e.g. https://gitlab.com/):http://gitlab.michael.com/Please enter the gitlab-ci token for this runner:5SSZ_QcjnLFv9s36ALsLPlease enter the gitlab-ci description for this runner:[7e5c74d87239]:Please enter the gitlab-ci tags for this runner (comma separated):dockerRegistering runner... succeeded runner=5SSZ_QcjPlease enter the executor: ssh, virtualbox, docker+machine, docker-ssh+machine, kubernetes, docker-ssh, parallels, shell, docker:dockerPlease enter the default Docker image (e.g. ruby:2.1):alpine:latestRunner registered successfully. Feel free to start it, but if it's running already the config should be automatically reloaded! 选择 docker 为 excutor 时，config.toml 内容配置成这样，实现了网络的畅通： 123456789101112131415161718192021222324252627$ cat config.tomlconcurrent = 1check_interval = 0[session_server] session_timeout = 1800[[runners]] name = "michael demo" url = "http://gitlab.michael.com/" token = "Wt3GuGq1nAdKWaeBrGM7" executor = "docker" [runners.custom_build_dir] [runners.docker] tls_verify = false image = "alpine:latest" extra_hosts = ["gitlab.michael.com:192.168.240.2"] network_mode = "gitlab_net" privileged = true disable_entrypoint_overwrite = false oom_kill_disable = false disable_cache = false volumes = ["/cache"] shm_size = 0 [runners.cache] [runners.cache.s3] [runners.cache.gcs] 主要就是添加了网络配置： 12extra_hosts = ["gitlab.michael.com:192.168.240.2"]network_mode = "gitlab_net" gitlab-runner 虽然是基于 docker 安装的，但是它每个 stage 执行是由 runner 在主机另起一个 docker 容器来执行的，执行完毕后自动销毁，并不是在 gitlab-runner 容器内部启动新的容器。 runner 相当于一个在主机的 agent 程序，来负责接收任务、分发并创建新的容器执行任务，最后回传执行结果到 gitlab。 设置 runner这时候，我们可以在「管理中心」的 Runner 中看到所有的 Runner 信息。 注意点：在同一个 git-runner 容器中，注册过之后，重置了 token，上一个 token 就会失效。尽管在管理中心会看到两个 runner，但是通过查看 git-runner 日志，其中有一个是失效的。此外，我一开始注册之后，流水线始终提示缺少 runner。很奇怪，因为去 Runner 界面查看，是 available 状态的。后来去管理中心看了一下，原来，新创建的runner，默认情况下，只对打 tag 的 commit 触发任务，否则会找不到对应 tag 的机器！除非，你勾选上无需 tag。 此外，同一个 gitlab-runner 我分别注册了两次，设置的 tag 不一样。使用的是项目的 token 和 共享的 token，二者皆是有效的。这时候注册的时候，会显示两个 runner，二者都会被成功调用。 CI/CD关于 gitlab 的 CI/CD 功能，更多可以查看 GitLab Documentation GitLab CI/CD GitLab CI/CD Pipeline Configuration Reference。 流水线要使用流水线功能，前提是 repo 中要有 .gitlab-ci.yml 文件。 一个示例： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758stages: - install_deps - test - build - deploy_test - deploy_production# 安装依赖install_deps: stage: install_deps only: - develop - master script: - pwd - echo "now install_deps stage" tags: - docker# 运行测试用例test: stage: test only: - develop - master script: - pwd - echo "now test stage" tags: - shell# 编译build: stage: build only: - develop - master script: - pwd - echo "now build stage 1" tags: - docker# 部署测试服务器deploy_test: stage: deploy_test only: - develop script: - echo "now deploy_test stage"# 部署生产服务器deploy_production: stage: deploy_production only: - master script: - echo "now deploy_production stage" 参考gitlab-ce Omnibus GitLab documentation Omnibus GitLab documentation Configuring omnibus settings Configuration options cnodejs-使用docker-compose搭建gitlab 挺全的，还介绍了 gitlab runner 的使用，推荐 掘金-通过 docker 搭建自用的 gitlab 服务 segmentfault-使用docker搭建gitlab环境 邮箱配置参考 gitlab-runner Run GitLab Runner in a container 千峰教育-基于 Docker 安装 GitLab Runner Building Docker images with GitLab CI/CD 利用 Gitlab CI/CD 构建 Docker 镜像，可以查看 Docker搭建自己的Gitlab CI Runner CI/CD GitLab Documentation GitLab CI/CD GitLab CI/CD Pipeline Configuration Reference]]></content>
  </entry>
  <entry>
    <title><![CDATA[Docker Compose 方式下的容器网络基础知识点]]></title>
    <url>%2F2019%2F06%2F15%2Fdocker-compose-networks%2F</url>
    <content type="text"><![CDATA[前言本周使用 Docker Compose 方式搭建了 sonarqube 的服务，并进行了总结。遇到的问题： 我在本地的机器上，一开始用 Compose 的方式创建了一个 MySQL 的容器了。然后在再利用另一份 docker-compose.yml 文件创建 sonarqube 容器时，尝试配置 MySQL 替代 sonarqube 默认采用的 H2 数据库。但是 sonarqube 却怎么也无法连接上 MySQL。 为了解决这个网络不通的问题，需要了解一下容器间网络通信的基础。 networks关于 Compose 的网络，官网有专门的一节进行介绍。查看Networking in Compose By default Compose sets up a single network for your app. Each container for a service joins the default network and is both reachable by other containers on that network, and discoverable by them at a hostname identical to the container name. Compose 默认给你的 app 设置一个网络。 service 中的每个容器默认都加入这个网络，容器之间彼此是互通的。并且，可以利用容器名字识别到。 Note: 你 app 的网络默认情况下是和你的 project name 有关的。这个 project name 其实就是你 docker-compose.yml 文件存放的那个目录的名字。比如，目录名叫 db，那么默认情况下会创建一个叫 db_default 的网络。你可以使用 --project-name 或 COMPSE_PROJECT_NAME 环境变量。 举个栗子,docker-compose.yml： 12345678910version: "3"services: web: build: . ports: - "8000:8000" db: image: postgres ports: - "8001:5432" 假设，上面这个文件放在 myapp 文件夹下。那么，当你 docker-compose up -d 之后： 一个叫 myapp_default 网络被创建； 一个使用 web 配置的容器会被创建，它以 web 的名字加入了 myapp_default 这个网络； 一个使用 db 配置的容器会被创建，它以 db 的名字加入了 myapp_default 网络； Each container can now look up the hostname web or db and get back the appropriate container’s IP address 现在，每个容器都可以查找主机名 web 或 db，并获取相应容器的 IP 地址。例如，web 应用的代码可以使用 URL postgres://db:5432 连接数据库并使用它。 重要的是要注意 HOST_PORT 和 CONTAINER_PORT 之间的区别。前者是指的是宿主机的端口，后者指的是容器中的端口。容器网络中的服务间使用的是 CONTAINER_PORT 通信。HOST_PORT 定义了是为了容器网络外被调用的。所以，前面才使用的是 postgres://db:5432 而不是 postgres://db:8001。因为他们属于同一个容器网络中。 在官网的 Compose file version 2 reference 一段中，也有相关网络介绍。 Networks to join, referencing entries under the top-level networks key. 这句话需要注意到，services 下级的服务中 networks 指定的网络不是指要创建的网络，而是这个服务要加入的网络。 所以说，这时候如果你指定了一个没有的网络，就会报错啦，类似这种： 1ERROR: Service "mongodb" uses an undefined network "mogo_net" 需要定义才能加入。经过试验，我在 Compose 文件中，使用 top-level 的 networks 定义一下网络，运行时，会自动创建网络： 123456789101112131415version: "2"services: mongodb: image: mongo:4 container_name: devops-mongo # 容器名 ports: - "27017:27017" volumes: - "/data/docker_local/mongo/configdb:/data/configdb" - "/data/docker_local/mongo/data/db:/data/db" command: --auth # 开启授权验证 networks: - mongo_netnetworks: mongo_net: 发现这时候没有报错了，但是它自动创建的网络好像也不叫 mong_net 而是根据规则，创建的 db_mongo_net 的网络。虽然不报错，但是我觉得有点别扭，查看了一下，可以利用 name 的标签定义一下网络。 12345678910111213141516version: "2.1"services: mongodb: image: mongo:4 container_name: devops-mongo # 容器名 ports: - "27017:27017" volumes: - "/data/docker_local/mongo/configdb:/data/configdb" - "/data/docker_local/mongo/data/db:/data/db" command: --auth # 开启授权验证 networks: - mongo_netnetworks: mongo_net: name: mongo_net 这时候启动时，日志显示就比较符合预期了： 「好奇心宝宝」附身，如果我 name 指定想要的值，上一层，有必要一致吗？ 12345678910111213141516version: "2.1"services: mongodb: image: mongo:4 container_name: devops-mongo # 容器名 ports: - "27017:27017" volumes: - "/data/docker_local/mongo/configdb:/data/configdb" - "/data/docker_local/mongo/data/db:/data/db" command: --auth # 开启授权验证 networks: - mongo_netnetworks: default: name: mongo_net 上面的这种改法会报错：ERROR: Service &quot;mongodb&quot; uses an undefined network &quot;mongo_net&quot;。所以，顶层的 networks 下一层及的网络名称，要和服务中要加入的名称保持一致才行。这样一试，貌似对上面创建的 db_mongo_net 的网络而不报错的现象理解了。省略了 name, 那么 name 就按照默认规则创建网络了，其实就是类似于： 12345678910111213141516version: "2.1"services: mongodb: image: mongo:4 container_name: devops-mongo # 容器名 ports: - "27017:27017" volumes: - "/data/docker_local/mongo/configdb:/data/configdb" - "/data/docker_local/mongo/data/db:/data/db" command: --auth # 开启授权验证 networks: - mongo_netnetworks: mongo_net: name: db_mongo_net 注意点：name 这个标签，这样的用法需要在 Compose 2.1 版本及以上才能使用 通过上面的对比，对 networks 有了初步了解了。那么，Compose 文件中式还不是一定要创建网络才行呢？可不可以利用已有的网络呢？后面的 external 会有介绍。 PS：通过 docker network ls/rm/create .. 等命令，可以查看或操作容器的网络。 links Links allow you to define extra aliases by which a service is reachable from another service. They are not required to enable services to communicate - by default, any service can reach any other service at that service’s name. In the following example, db is reachable from web at the hostnames db and database: 通过链接，您可以给某个 service 定义别名，通过该别名可以从其他服务访问服务。默认情况下，任何服务都可以通过该服务的名称访问任何其他服务。下面的例子中，db 是一个服务名，在 web 服务中，给 db 定义了一个别名 database。那么，在 web 服务中，既可以通过 db 又可以通过 databse 查找到主机名了。 123456789version: "3"services: web: build: . links: - "db:database" db: image: postgres Specify custom networks Instead of just using the default app network, you can specify your own networks with the top-level networks key. This lets you create more complex topologies and specify custom network drivers and options. You can also use it to connect services to externally-created networks which aren’t managed by Compose. 为了不使用默认的网络，你可以使用 compsose 文件的 top-level 关键字 networks 自定义网络。这让你可以创建更复杂的拓扑并指定自定义网络驱动程序和选项。 你还可以使用它将服务连接到不由 Compose 管理的外部创建的网络。 Here’s an example Compose file defining two custom networks. The proxy service is isolated from the db service, because they do not share a network in common - only app can talk to both. 这里有一个例子，自定义了两个网络。 proxy 服务和 db 服务是隔离的。因为它俩不共享一个网络，只有 app 服务能够和他俩都能通信。 123456789101112131415161718192021222324252627version: "3"services: proxy: build: ./proxy networks: - frontend app: build: ./app networks: - frontend - backend db: image: postgres networks: - backendnetworks: frontend: # Use a custom driver driver: custom-driver-1 backend: # Use a custom driver which takes special options driver: custom-driver-2 driver_opts: foo: "1" bar: "2" externalexternal: true 加上这行表示我这个服务用的网络是用外部的网络，不用自动创建。否则，会按照规则默认创建网络的，例如 db_default、sonarqube_default 这些网络就是默认创建的。如果这个时候没有对应的外部网络，会弹出如下的提示： 12Creating network "db_default" with the default driverERROR: Network mysql_net declared as external, but could not be found. Please create the network manually using `docker network create mysql_net` and try again. 注意点：对于 compose 3.3 及更低版本，外部不能与其他网络配置键（driver，driver_opts，ipam，internal）一起使用。版本 3.4 及更高版本不再存在此限制。 external 标签官网有详细介绍。 Use a pre-existing network如果你想要你的容器加入到一个已存在的网络中，使用 external 选项: 12345678910111213141516version: "3.7"services: proxy: build: ./proxy networks: - outside - default app: build: ./app networks: - defaultnetworks: outside: external: true 这时候不会去创建一个 [projectname]_outside 的网络， Compose 会去查找一个已存在的叫做 outside 的网络，并且将它和 proxy 服务相连。 参考 官宣-dockerhub-sonarqube compose-file-v2/#network compose/networking 专门讲解了 compose networking]]></content>
      <categories>
        <category>容器</category>
      </categories>
      <tags>
        <tag>Docker</tag>
        <tag>network</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用 Docker Compose 方式搭建 SonarQube 服务]]></title>
    <url>%2F2019%2F06%2F13%2Fdocker-compose-install-sonarqube%2F</url>
    <content type="text"><![CDATA[前言在 CICD 流水线中，代码质量其实是很关键的一环。SonarQube 是一个「持续代码质量」检测的服务。在 DevOps 持续集成中对把控代码质量很有帮助。 命令行启动首先以命令行的方式启动，将默认的一些配置拷贝到本地磁盘，比如插键、配置文件等： 1234567mkdir -p /data/sonardocker run -d --name sonarqube -p 9000:9000 -p 9092:9092 sonarqube:7.7-communitydocker cp sonarqube:/opt/sonarqube/conf /data/sonardocker cp sonarqube:/opt/sonarqube/extensions /data/sonarwget -P /data/sonar/extensions/plugins https://github.com/SonarQubeCommunity/sonar-l10n-zh/releases/download/sonar-l10n-zh-plugin-1.27/sonar-l10n-zh-plugin-1.27.jardocker stop sonarqubedocker rm sonarqube 为了对 sonarqube 进行汉化，下载了中文插键。更多的插键下载，可以访问：插键 配置数据库我使用的是 MySQL 数据库，为了实现权限分离，创建了单独的 sonar 数据库和对应的账号： 1234567#docker exec -it devops-mysql#mysql -u root -pmysql&gt; CREATE DATABASE sonar CHARACTER SET utf8 COLLATE utf8_general_ci;mysql&gt; CREATE USER 'sonar' IDENTIFIED BY 'sonar';mysql&gt; GRANT ALL ON sonar.* TO 'sonar'@'%' IDENTIFIED BY 'sonar';mysql&gt; GRANT ALL ON sonar.* TO 'sonar'@'localhost' IDENTIFIED BY 'sonar';mysql&gt; FLUSH PRIVILEGES; 数据库我也是用 docker 创建的，可以参考之前的文章使用容器 Docker 创建开发环境。 连接数据库1234567docker run -d --name sonarqube \ -p 9000:9000 \ -e sonar.jdbc.username=root \ -e sonar.jdbc.password=123456 \ -e sonar.jdbc.url="jdbc:mysql://192.168.3.43:3306/sonar?useUnicode=true&amp;characterEncoding=utf8&amp;rewriteBatchedStatements=true&amp;useConfigs=maxPerformance&amp;useSSL=false" \ -v /data/sonar/extensions:/opt/sonarqube/extensions \ sonarqube:7.7-community Use of the environment variables SONARQUBE_JDBC_USERNAME, SONARQUBE_JDBC_PASSWORD and SONARQUBE_JDBC_URL is deprecated, and will stop working in future releases. 网上一些教程还是采用的旧的环境变量，官网已经说快要废弃了。 Compose 方式启动如果你 MySQL 和 sonarqube 服务是在一个 docker-compose.yml 文件中的话，那么它们默认会处于同一个容器网络中，sonarqube 是可以连接上的。对这块网络知识不了解的，可以查看这个总结：Docker Compose 方式下的容器网络基础知识点 如果是在同一台机器上，MySQL 容器已经创建好了，和 sonarqube 不是同一个 docker-compose.yml 方式创建的，那么，这时候就需要配置，才能让两个容器实现网络互通。 sonarqube 的 docker-compose.yml： 123456789101112131415161718192021222324version: "2.4"services: sonar: image: sonarqube:7.7-community container_name: devops-sonar ports: - "9000:9000" - "9002:9002" volumes: - "/data/sonar/conf:/opt/sonarqube/conf" - "/data/sonar/extensions:/opt/sonarqube/extensions" - "/data/sonar/logs:/opt/sonarqube/logs" - "/data/sonar/data:/opt/sonarqube/data" environment: sonar.jdbc.username: sonar #root管理员用户密码 sonar.jdbc.password: sonar #创建test用户 sonar.jdbc.url: "jdbc:mysql://devops-mysql:3306/sonar?useUnicode=true&amp;characterEncoding=utf8&amp;rewriteBatchedStatements=true&amp;useConfigs=maxPerformance&amp;useSSL=false" restart: always networks: - db_netnetworks: db_net: external: true 可以发现，这时候 sonarqube 网络和 MySQL 网络是通的，而且，使用 service name 或者 container name 都可以查询到主机。因此，sonar.jdbc.url 可以配置成： jdbc:mysql://mysql:3306/sonar?useUnicode=true&amp;characterEncoding=utf8&amp;rewriteBatchedStatements=true&amp;useConfigs=maxPerformance&amp;useSSL=false jdbc:mysql://devops-mysql:3306/sonar?useUnicode=true&amp;characterEncoding=utf8&amp;rewriteBatchedStatements=true&amp;useConfigs=maxPerformance&amp;useSSL=false 我们的服务已经正常启动啦： 示例代码本文的 docker-compose 文件，归档在：awesome-docker-service-for-me]]></content>
      <categories>
        <category>DevOps</category>
      </categories>
      <tags>
        <tag>DevOps</tag>
        <tag>Docker</tag>
        <tag>CICD</tag>
        <tag>代码质量</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS Nginx 安装及配置]]></title>
    <url>%2F2019%2F06%2F08%2Fcicd-centos-install-nginx%2F</url>
    <content type="text"><![CDATA[概念 了解 Nginx 的基本概念 安装12apt-get install nginx # Ubuntuyum install nginx -y # CentOS 配置文件1nginx -t # 检查配置文件正确性 test configuration and exit 主要文件位置 which nginx # or whereis nginx：查看主程序文件 /etc/init.d/：下创建了启动脚本nginx（需手动配置），支持service nginx start命令 /var/log/nginx：日志文件夹，/var/log/nginx/error.log：错误日志文件，/var/log/nginx/access.log：访问日志文件 /etc/nginx/nginx.conf：Nginx全局站点配置文件，日志文件可以在/etc/nginx/nginx.conf中配置，默认读取的配置文件 /etc/nginx/conf.d：自定义Nginx站点配置文件存放目录 /etc/nginx/conf.d/default.conf：网站默认站点配置 /usr/share/nginx/html：网站文件默认存放目录 sites-available：则是管理大量站点时服务器的一种通用配置。 sites-enabled：则是一种单独配置，需要使用enabled时，需要使用ln命令软连接到相应网站。 1sudo ln -s ~/path/to/your/mysite/mysite_nginx.conf /etc/nginx/sites-enabled/ /etc/nginx/nginx.conf中有如下语句：12include /etc/nginx/conf.d/*.conf;include /etc/nginx/sites-enabled/*; 可见，配置文件放在sites-avaliable文件夹中，需要创建软连接在sites-enabled中，才会生效。 server_name的作用其实是当该机器上同时部署了其他域名服务时起作用的。 如果nginx中只配置一个server域的话，则nginx是不会去进行server_name的匹配的。因为只有一个server域，也就是这有一个虚拟主机，那么肯定是发送到该nginx的所有请求均是要转发到这一个域的，即便做一次匹配也是没有用的。还不如干脆直接就省了。如果一个http域的server域有多个，nginx才会根据$hostname去匹配server_name进而把请求转发到匹配的server域中。此时的匹配会按照匹配的优先级进行，一旦匹配成功进不会再进行匹配 参考： nginx server_name怎么可有可无 location接受两个参数，一个字符串或者正则，和一段代码。字符串用于匹配某个特定目录。 123location / &#123; autoindex on; autoindex_exact_size off; # 默认是开，以b为单位，关闭后，会显示MB GB 注意点nginx 默认的账号权限太低，没有部分文件的访问权限，导致访问时出现 403 Forbidden。 配置文件 /etc/nginx/nginx.conf：1user nginx; 应该修改为：1user root; Nginx运行1/usr/sbin/nginx -h # 查看帮助 12345/usr/sbin/nginx -c /etc/nginx/nginx.conf # 默认也会读取该配置文件，所以，可以不加-c参数nginx # 运行/usr/sbin目录下的nginx的命令nginx -s reload # 运行这句话的前提是，nginx正在运行，重载，如果之前运行了stop，那么会提示出错 &quot;/run/nginx.pid&quot; failedservice nginx startservice nginx status FAQQ1：nginx: [error] open() “/usr/local/var/run/nginx.pid” failed (2: No such file or directory) nginx 重启报错:nginx Q2：中文乱码Nginx的server的配置内容，增加一行：charset utf-8; Nginx 显示中文乱码解决 Q3：权限问题导致Nginx 403 Forbidden错误的解决方法 权限问题导致Nginx 403 Forbidden错误的解决方法 参考 写给Web开发人员看的Nginx介绍 nginx配置初探 nginx配置文件参数详解（完整版） Nginx浏览目录配置及美化]]></content>
      <categories>
        <category>DevOps</category>
      </categories>
      <tags>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx 基础知识学习]]></title>
    <url>%2F2019%2F06%2F08%2Fcicd-nginx-basic%2F</url>
    <content type="text"><![CDATA[资料基础资料 掘金-前端开发者必备的Nginx知识 介绍的比较综合，正向代理反向代理的区别、负载均衡等知识，都有介绍 静默虚空-Nginx 简易教程 博客园上的一篇推荐文章 简书-全面了解Nginx到底能做什么 Nginx的负载均衡 - 加权轮询 (Weighted Round Robin) 上篇，这个介绍了upstream资源池的调度算法之一，在其专栏还有其他介绍。 平滑的基于权重的轮询算法 ：本文也是介绍资源池调度算法的 理解nginx的配置：介绍的比较全面的一篇文章 Nginx实战（五） 反向代理 Understanding Nginx HTTP Proxying, Load Balancing, Buffering, and Caching 13 Nginx Location Directive Examples including Regular Expression Modifiers 关于location的作用介绍，很全面 Nginx的Upstream来做负载 部署两台WEB ：这个文章虽然比较少，但是里边明确了upstream名称和proxy_pass配置的对应关系。 proxy_pass的小说明：关于proxy_pass的一些FAQ Nginx 性能优化 百万并发下 Nginx 的优化之道 agentzh 的 Nginx 教程 常用命令12345678nginx -s stop 快速关闭Nginx，可能不保存相关信息，并迅速终止web服务。nginx -s quit 平稳关闭Nginx，保存相关信息，有安排的结束web服务。nginx -s reload 因改变了Nginx相关配置，需要重新加载配置而重载。nginx -s reopen 重新打开日志文件。nginx -c filename 为 Nginx 指定一个配置文件，来代替缺省的。nginx -t 不运行，而仅仅测试配置文件。nginx 将检查配置文件的语法的正确性，并尝试打开配置文件中所引用到的文件。nginx -v 显示 nginx 的版本。nginx -V 显示 nginx 的版本，编译器版本和配置参数。 反向代理 将server节点下的location节点中的proxy_pass配置为：http:// + upstream名称 app.conf：123456789101112131415161718192021222324252627282930313233343536373839404142upstream micahel-machine-manager &#123; server 100.253.128.222:40012; server 100.253.128.223:40012;&#125;upstream michael-machine-server &#123; server 100.253.128.55:40020; server 100.120.128.56:40020;&#125;server &#123; listen 80; server_name michael-api.site.com; client_max_body_size 20M; client_body_buffer_size 10M; proxy_redirect off; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_next_upstream error timeout invalid_header http_502 http_503 http_504; proxy_ignore_client_abort on; proxy_read_timeout 180; proxy_buffering on; proxy_buffer_size 8k; proxy_buffers 8 8M; gzip on; gzip_min_length 1000; gzip_types text/plain text/css application/json text/xml application/xml application/xml+rss text/javascript; location /MachineManager/ &#123; proxy_pass http://michael-machine-manager; &#125; location /MachineServer/ &#123; proxy_pass http://michael-machine-server; &#125; access_log /var/log/nginx/cid.site.com-access.log main;&#125; 如何配置 Nginx 呢？可以利用这个神器： NginxConfig]]></content>
      <categories>
        <category>DevOps</category>
      </categories>
      <tags>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用 docker-compose 安装搭建 RabbitMQ 集群]]></title>
    <url>%2F2019%2F06%2F07%2Fdocker-rabbitmq-env%2F</url>
    <content type="text"><![CDATA[本文介绍如何利用 Docker 方式创建 rabbitmq 集群。 rabbitmq 介绍在利用 Docker 创建 rabbitmq 容器之前，先了解 rabbitmq 的基础知识。 集群模式RabbitMQ 的 Cluster 集群模式一般分为两种，「普通模式」和「镜像模式」。 普通模式：默认的集群模式，以两个节点（rabbit01、rabbit02）为例来进行说明。对于 Queue 来说，消息实体只存在于其中一个节点 rabbit01（或者 rabbit02），rabbit01 和 rabbit02 两个节点仅有相同的元数据，即队列的结构。当消息进入 rabbit01 节点的 Queue 后，consumer 从 rabbit02 节点消费时，RabbitMQ 会临时在 rabbit01、rabbit02 间进行消息传输，把 A 中的消息实体取出并经过 B 发送给 consumer。所以 consumer 应尽量连接每一个节点，从中取消息。即对于同一个逻辑队列，要在多个节点建立物理 Queue。否则无论 consumer 连 rabbit01 或 rabbit02，出口总在 rabbit01，会产生瓶颈。当 rabbit01 节点故障后，rabbit02 节点无法取到 rabbit01 节点中还未消费的消息实体。如果做了消息持久化，那么得等 rabbit01 节点恢复，然后才可被消费；如果没有持久化的话，就会产生消息丢失的现象。 镜像模式：将需要消费的队列变为镜像队列，存在于多个节点，这样就可以实现 RabbitMQ 的 HA 高可用性。作用就是消息实体会主动在镜像节点之间实现同步，而不是像普通模式那样，在 consumer 消费数据时临时读取。缺点就是，集群内部的同步通讯会占用大量的网络带宽。 节点类型 RAM node：内存节点将所有的队列、交换机、绑定、用户、权限和 vhost 的元数据定义存储在内存中，好处是可以使得像交换机和队列声明等操作更加的快速 Disk node：将元数据存储在磁盘中，单节点系统只允许磁盘类型的节点，防止重启 RabbitMQ 的时候，丢失系统的配置信息 RabbitMQ 要求在集群中至少有一个磁盘节点，所有其他节点可以是内存节点，当节点加入或者离开集群时，必须要将该变更通知到至少一个磁盘节点。如果集群中唯一的一个磁盘节点崩溃的话，集群仍然可以保持运行，但是无法进行其他操作（增删改查），直到节点恢复。解决方案：设置两个磁盘节点，至少有一个是可用的，可以保存元数据的更改。 安装知识点 建立集群时，节点中的 Erlang Cookie 值要一致，默认情况下，文件在 /var/lib/rabbitmq/.erlang.cookie。 erlang 是通过主机名来连接服务，必须保证各个主机名之间可以 ping 通。可以通过编辑 /etc/hosts 来手工添加主机名和 IP 对应关系。如果主机名 ping 不通，rabbitmq 服务启动会失败。 123$ rabbitmqctl stop_app # 停止rabbitmq服务$ rabbitmqctl join_cluster rabbit@node1 # node2和node1构成集群, node2必须能通过node1的主机名ping通$ rabbitmqctl start_app # 开启rabbitmq服务 –ram 指的是作为内存节点,要是想做为磁盘节点的话,就不用加 –ram 这个参数了。在 RabbitMQ 集群里，必须至少有一个磁盘节点存在 1$ rabbitmqctl join_cluster --ram rabbit@node1 更改节点属性 123456$ rabbitmqctl stop_app # 停止rabbitmq服务$ rabbitmqctl change_cluster_node_type ram # 更改节点为内存节点Turning rabbit@node2 into a ram node$ rabbitmqctl change_cluster_node_type disc # 更改节点为磁盘节点Turning rabbit@node2 into a disc node$ rabbitmqctl start_app # 开启rabbitmq服务 查看集群的状态 1rabbitmqctl cluster_status 开启 web 管理工具 cluster 搭建起来后若在 web 管理工具中 rabbitmq_management 的 Overview 的 Nodes 部分看到 Node statistics not available 的信息，说明在该节点上web管理插件还未启用。 直接在显示提示信息的节点上运行： 1rabbitmq-plugins enable rabbitmq_management docker-compose基于 bitnami/bitnami-docker-rabbitmq 镜像，在一台机器上可以创建一个 rabbitmq cluster： docker-compose.yml 内容： 1234567891011121314151617181920212223242526272829303132333435363738version: '2'services: stats: image: bitnami/rabbitmq:3.7 environment: - RABBITMQ_NODE_TYPE=stats - RABBITMQ_NODE_NAME=rabbit@stats - RABBITMQ_ERL_COOKIE=s3cr3tc00ki3 ports: - '15672:15672' volumes: - 'rabbitmqstats_data:/bitnami' queue-disc1: image: bitnami/rabbitmq:3.7 environment: - RABBITMQ_NODE_TYPE=queue-disc - RABBITMQ_NODE_NAME=rabbit@queue-disc1 - RABBITMQ_CLUSTER_NODE_NAME=rabbit@stats - RABBITMQ_ERL_COOKIE=s3cr3tc00ki3 volumes: - 'rabbitmqdisc1_data:/bitnami' queue-ram1: image: bitnami/rabbitmq:3.7 environment: - RABBITMQ_NODE_TYPE=queue-ram - RABBITMQ_NODE_NAME=rabbit@queue-ram1 - RABBITMQ_CLUSTER_NODE_NAME=rabbit@stats - RABBITMQ_ERL_COOKIE=s3cr3tc00ki3 volumes: - 'rabbitmqram1_data:/bitnami'volumes: rabbitmqstats_data: driver: local rabbitmqdisc1_data: driver: local rabbitmqram1_data: driver: local docker-compose 语法格式： 1docker-compose [-f &lt;arg&gt;...] [options] [COMMAND] [ARGS...]` 运行 docker-compose up -d 运行，如果 docker-compose.yml 命名为其他名字，可以通过 -f 参数指定文件。该镜像默认账号密码是 ：user/bitnami 如上方式，会在主机上创建若干 volume，下面是一些关于 volume 的操作： 1234删除不使用的本地 volumesdocker volume prunedocker volume lsdocker volume rm &lt;volume name&gt; 如上创建好之后，是属于「普通模式」的集群。如果要设置为「镜像模式」，可以参考 Rabbitmq镜像集群部署，比较简单，在管理界面配置： Virtual host： 可选参数，针对指定vhost下的queue进行设置 Name: policy的名称 Pattern: queue的匹配模式(正则表达式) Definition：镜像定义，包括三个部分ha-mode, ha-params, ha-sync-mode ha-mode:指明镜像队列的模式，有效值为 all/exactly/nodes all：表示在集群中所有的节点上进行镜像 exactly：表示在指定个数的节点上进行镜像，节点的个数由ha-params指定 nodes：表示在指定的节点上进行镜像，节点名称通过ha-params指定 ha-params：ha-mode模式需要用到的参数 ha-sync-mode：进行队列中消息的同步方式，有效值为automatic和manual priority：可选参数，policy的优先级 其他方式创建容器节点123docker run -d --hostname rabbit1 --name myrabbit1 -p 15672:15672 -p 5672:5672 -e RABBITMQ_ERLANG_COOKIE='rabbitcookie' rabbitmq:3.6.15-managementdocker run -d --hostname rabbit2 --name myrabbit2 -p 5673:5672 --link myrabbit1:rabbit1 -e RABBITMQ_ERLANG_COOKIE='rabbitcookie' rabbitmq:3.6.15-managementdocker run -d --hostname rabbit3 --name myrabbit3 -p 5674:5672 --link myrabbit1:rabbit1 --link myrabbit2:rabbit2 -e RABBITMQ_ERLANG_COOKIE='rabbitcookie' rabbitmq:3.6.15-management 多个容器之间使用 --link 连接，此属性不能少；--link &lt;docker-name or docker-id&gt;:alias,alias 是源容器在 link 下的别名 Erlang Cookie值必须相同，也就是 RABBITMQ_ERLANG_COOKIE 参数的值必须相同； 要想知道 Erlang Cookie 位置，首先要取得 RabbitMQ 启动日志里面的 home dir 路径，作为根路径。使用：docker logs 容器名称 查看。 加入 RabbitMQ 节点到集群设置节点1： 12345docker exec -it myrabbit1 bashrabbitmqctl stop_apprabbitmqctl resetrabbitmqctl start_appexit 设置节点2，加入到集群： 123456docker exec -it myrabbit2 bashrabbitmqctl stop_apprabbitmqctl resetrabbitmqctl join_cluster --ram rabbit@rabbit1rabbitmqctl start_appexit 参数 --ram 表示设置为内存节点，忽略次参数默认为磁盘节点。 设置节点3，加入到集群： 123456docker exec -it myrabbit3 bashrabbitmqctl stop_apprabbitmqctl resetrabbitmqctl join_cluster --ram rabbit@rabbit1rabbitmqctl start_appexit 设置好之后，使用 http://物理机ip:15672 进行访问了，默认账号密码是 guest/guest 参考MQ 安装： CentOs7.3 搭建 RabbitMQ 3.6 Cluster 集群服务与使用 王磊的博客-RabbitMQ系列（五）使用Docker部署RabbitMQ集群 docker-compose配置rabbitmq集群服务器 官宣-Clustering Guide RabbitMQ 集群部署 MQ 使用： rabbbitmq 堆积分析 RabbitMQ使用教程（四）如何通过持久化保证消息99.99%不丢失？]]></content>
      <categories>
        <category>容器</category>
      </categories>
      <tags>
        <tag>Docker</tag>
        <tag>容器</tag>
        <tag>消息队列</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[利用 Docker 安装 CICD 神器 Jenkins]]></title>
    <url>%2F2019%2F06%2F04%2Fcicd-docker-jenkins%2F</url>
    <content type="text"><![CDATA[Jenkins 学习系列： CentOS 安装 CICD 利器 Jenkins 利用 Docker 安装 CICD 神器 Jenkins 本文主要介绍如何利用 Docker 来快速搭建 Jenkins，相比较以前的方式，方便快捷很多！ 准备工作由于是基于 Docker 安装 Jenkins，因此，你的环境上必须要安装好 Dokcer，并配置好加速器，不然下载镜像速度可能会比较慢。怎么安装，可以参考如下文章： Linux–CentOS 安装 Docker 教程 Docker 入门指南——常用命令 使用容器 Docker 创建开发环境 Docker 命令运行 Jenkinsjenkinsci/blueocean 是官方推荐的镜像版本，集成了流水线插键，推荐： 123456789docker run \ -u root \ --name devops-jenkins \ -d \ -p 8080:8080 \ -p 50000:50000 \ -v /data/docker_local/jenkins-data:/var/jenkins_home \ -v /var/run/docker.sock:/var/run/docker.sock \ jenkinsci/blueocean:1.15.1 参数说明： -u root：（可选）由于默认的 jenkins用户无权访问 /var/run/docker.sock，您需要以 root 身份运行 Jenkins 以允许 Jenkins 在你流水线上生成 docker 容器执行步骤。这仅影响在 Jenkins 主节点上的运行，如果你计划在你的流水线执行机上去执行，那这不是必须的。 jenkinsci/blueocean 容器的端口 8080 到主机上的端口 8080。 第一个数字代表主机上的端口，而最后一个代表容器的端口。因此，如果您为此选项指定 -p 49000:8080 ，您将通过端口主机端口 49000 访问 Jenkins 更多对参数的说明，访问Installing Jenkins Docker-Compose 运行 Jenkins12345678910111213version: "3"services: jenkins: image: jenkinsci/blueocean:1.15.1 container_name: devops-jenkins # 容器名 user: root restart: always ports: - "8080:8080" - "50000:50000" volumes: - "/data/docker_local/jenkins-data:/var/jenkins_home" - "/var/run/docker.sock:/var/run/docker.sock" 配置配置插键代理为了提高插键的下载速度，插键高级配置中，配置国内的代理： https://mirrors.tuna.tsinghua.edu.cn/jenkins/updates/update-center.json 有一个页面，专门查看 Jenkins 镜像状态的： the status of Jenkins mirrors 常用命令查看 Jenkins 的运行日志： 1docker logs -f jenkins 归档 awesome-docker-service-for-me 参考 官宣-安装Jenkins-中文 发现翻译的并不是特别好，推荐看英文 K8S牛刀小试CI之Jenkins on Docker篇(二)/) Jenkins Blue Ocean 的使用 这也是一个有用的插键]]></content>
      <categories>
        <category>DevOps</category>
      </categories>
      <tags>
        <tag>cicd</tag>
        <tag>DevOps</tag>
        <tag>Jenkins</tag>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用容器 Docker 创建开发环境]]></title>
    <url>%2F2019%2F06%2F02%2Fdocker-create-develop-environment%2F</url>
    <content type="text"><![CDATA[Docker 容器学习笔记系列： Linux–CentOS 安装 Docker 教程 Docker 入门指南——常用命令 使用容器 Docker 创建开发环境 个人在开发时能方便快捷的搭建对应的测试环境，比如搭建一个 Redis 数据库、MongoDB 数据库、Elasticsearch 服务。这样就不用拿公共的基础设施做测试了，避免损坏数据、破坏了线上环境。 本文就介绍如何利用容器 Docker 来快速搭建开发测试环境。 补充：关于 Mac 上 Docker 的使用，可以阅读 docker-for-mac MySQL简单创建12345docker run -d \--name mysql \-p 3306:3306 \-e MYSQL_ROOT_PASSWORD=123456 \mysql:5.7 参数说明： -d：以后台方式运行 --name：将运行的容器命名为 mysql -p：端口映射，host_ip:container_ip，将主机的 3306 端口映射为 容器内部的 3306 端口，数据库连接时，是连接的你的 host_ip，这二者的顺序不要搞混 -e：设置环境变量，指定 root 账号的密码为 123456 上面这种方式运行后，我们将容器中的 mysql 数据和配置文件拷贝到宿主机上。（获取原始配置文件）。 因为没有将宿主机和容器相关目录挂载，这样会导致容器如果被删除，数据会丢失。 12345678# 创建好目录，不然会报错mkdir -p /dada/docker_local/mysql# 将容器中的 mysql 配置文件复制到宿主机中指定路径下，路径你可以根据需要，自行修改docker cp mysql:/etc/mysql/mysql.conf.d/mysqld.cnf /data/docker_local/mysql/config# 将容器中的 mysql 存储目录复制到宿主机中docker cp mysql:/var/lib/mysql/ /data/docker_local/mysql/data 这里放一份默认的配置文件 mysqld.cnf：123456789[mysqld]pid-file = /var/run/mysqld/mysqld.pidsocket = /var/run/mysqld/mysqld.sockdatadir = /var/lib/mysql#log-error = /var/log/mysql/error.log# By default we only accept connections from localhost#bind-address = 127.0.0.1# Disabling symbolic-links is recommended to prevent assorted security riskssymbolic-links=0 完成上面的操作之后，将已经运行的容器删除：1docker rm mysql 正式创建接下来正式运行 MySQL 容器：1234567docker run -d \--name mysql \-p 3306:3306 \-v /data/docker_local/mysql/config/mysqld.cnf:/etc/mysql/mysql.conf.d/mysqld.cnf \-v /data/docker_local/mysql/data/mysql:/var/lib/mysql \-e MYSQL_ROOT_PASSWORD=123456 \mysql:5.7 -v 将宿主机中的文件挂载到将容器中，容器中产生的数据会持久化下来，语法：-v [host-src:]container-dest[:&lt;options&gt;] 其实，如果你一开始就有了默认的配置文件，那么，就可以跳过之前的步骤，直接运行正式的创建 MySQL 容器的命令。 MongoDB创建容器1234567891011# 创建持久化目录mkdir -p /data/docker_local/mongo/configdbmkdir -p /data/docker_local/mongo/data/dbdocker run -d \--name mongo \-v /data/docker_local/mongo/configdb:/data/configdb \-v /data/docker_local/mongo/data/db:/data/db \-p 27017:27017 \mongo:4 \--auth 启动参数含义在 MySQL 启动时已经见过了，除了 auth： --auth：开启权限验证模式。默认情况下，mongo 数据库没有添加认证约束，为了增强数据库的安全性，我们需要对数据库添加授权认证。当我不加这个认证约束时，一个数据库的账号可以操作另一个数据库的数据，只有加了这个参数，我们针对某些数据库设置的角色，才仅在这个数据库上生效。 添加管理员账号 进入容器1docker exec -it mongo mongo admin 进入容器 mongo，运行命令 mongo admin，实现了： 进入 mongo 命令行 切换为 admin 数据库 创建一个拥有最高权限的 root 账号：1db.createUser(&#123; user: &apos;admin&apos;, pwd: &apos;123456&apos;, roles: [ &#123; role: &quot;root&quot;, db: &quot;admin&quot; &#125; ] &#125;); role 角色参数： Read：允许用户读取指定数据库 readWrite：允许用户读写指定数据库 dbAdmin：允许用户在指定数据库中执行管理函数，如索引创建、删除，查看统计或访问system.profile userAdmin：允许用户向system.users集合写入，可以找指定数据库里创建、删除和管理用户 clusterAdmin：只在admin数据库中可用，赋予用户所有分片和复制集相关函数的管理权限 readAnyDatabase：只在admin数据库中可用，赋予用户所有数据库的读权限 readWriteAnyDatabase：只在admin数据库中可用，赋予用户所有数据库的读写权限 userAdminAnyDatabase：只在admin数据库中可用，赋予用户所有数据库的userAdmin权限 dbAdminAnyDatabase：只在admin数据库中可用，赋予用户所有数据库的dbAdmin权限 root：只在admin数据库中可用。超级账号，超级权限 创建访问指定数据库的用户管理员已经创建成功后，我们需要重新连接 mongo 数据库，用管理员进行登录，并为目标数据库创建目标用户 12345678910111213# 进入容器，并切换到 admin 数据库docker exec -it mongo mongo admin# 授权 admindb.auth("admin", "123456");# 创建访问指定数据库的用户use beta;db.createUser(&#123; user: 'test', pwd:'test', roles: [ &#123;role:"readWrite",db:"beta"&#125;]&#125;);db.auth("test","test");# 尝试插入一条数据use betadb.test.insertOne(&#123;name:"michael",age:"28"&#125;)# 搜索 test collection 全部记录db.test.find() test 用户可以对(也只能对) beta 库进行操作 补充： 查看容器运行日志：docker logs mysql docker-composedocker-compse 俗称 Docker 三剑客，这里试试用它来同时启动 MySQL、MongoDB 吧： 12345678910111213141516171819202122232425version: "2"services: mongodb: image: mongo:4 container_name: mongodb # 容器名 ports: - "27017:27017" volumes: - "/data/docker_local/mongo/configdb:/data/configdb" - "/data/docker_local/mongo/data/db:/data/db" command: --auth # 开启授权验证 mysql: image: mysql:5.7 container_name: mysqldb # 容器名 ports: - "3306:3306" command: mysqld --character-set-server=utf8mb4 --collation-server=utf8mb4_unicode_ci #设置utf8字符集 restart: always environment: MYSQL_ROOT_PASSWORD: 123456 #root管理员用户密码 MYSQL_USER: test #创建test用户 MYSQL_PASSWORD: test #设置test用户的密码 volumes: - "/data/docker_local/mysql/config/mysqld.cnf:/etc/mysql/mysql.conf.d/mysqld.cnf" - "/data/docker_local/mysql/data/mysql:/var/lib/mysql" 进入到上面编写的docker-compose.yml文件的目录，运行命令： 123456789101112131415161718# 启动所有服务docker-compose up -d# 单启动 mysqldocker-compose up -d mysql# 暂停 mysqldocker-compose stop mysql# 重新启动容器docker-compose restart mysql# 登录到容器中docker-compose exec mysql bash# 删除所有容器和镜像docker-compose down# 显示所有容器docker-compose ps# 查看mysql的日志docker-compose logs mysql# 查看mysql的实时日志docker-compose logs -f mysql nginx使用 Nginx 容器搭建文件服务区 file.conf： 123456789101112server &#123; client_max_body_size 4G; listen 8889; ## listen for ipv4; this line is default and implied server_name &lt;host_ip or domain_name&gt;; # 换成你服务器的 IP 或绑定的域名 charset utf-8; root /data; location / &#123; autoindex on; # 要想设置nginx的目录浏览功能，必须要打开下面这个参数 autoindex_exact_size off; # 默认是开，以b为单位，关闭后，会显示MB GB autoindex_localtime on; &#125;&#125; docker-compose.yml： 1234567891011version: "2"services: nginx: image: nginx container_name: nginx # 容器名 ports: - "8889:8889" volumes: - "/data/nginx/conf.d:/etc/nginx/conf.d" - "/data/nginx/data:/data" restart: always 为了避免中文乱码，需要配置 charset utf-8; 怎么给文件服务器设置访问密码呢？只需要修改一下配置即可：1234567891011121314server &#123; client_max_body_size 4G; listen 8889; ## listen for ipv4; this line is default and implied server_name 207.148.104.42; charset utf-8; root /data; location / &#123; auth_basic "Restricted"; auth_basic_user_file /data/pass_file; autoindex on; autoindex_exact_size off; autoindex_localtime on; &#125;&#125; 生成用户名和密码： 1htpasswd -c -d pass_file michael htpasswd 命令没有的话，需要：yum install httpd-tools -y 安装； -c 创建一个文件； -d 强制 CRYPT 加密密码（最多8个字符，不安全） -s Force SHA encryption of the password (insecure) 参考：Nginx配置静态文件服务 控制访问 nginx 的 IP网段的写法是这样的：192.168.1.0/24 这样的形式。 123deny 192.168.1.11;deny 192.168.1.123;deny 192.168.1.0/24; # 屏蔽整个192.168.1.* C段IP 允许某几个 IP 能访问，其他 IP 均不能访问： 123allow 192.168.1.1;allow 192.168.1.2;deny all; 示例： 12345678910111213141516server &#123; client_max_body_size 4G; listen 8889; ## listen for ipv4; this line is default and implied server_name 207.148.104.42; charset utf-8; root /data; location / &#123; allow 112.10.84.226; deny all; auth_basic "Restricted"; auth_basic_user_file /data/pass_file; autoindex on; autoindex_exact_size off; autoindex_localtime on; &#125;&#125; [原创]nginx如何禁止指定IP或IP段访问 Nginx基础篇（4）- Nginx请求限制和访问控制 FAQifconfig command not found 解决办法1yum install net-tools -y 本文示例 Github-awesome-docker-service-for-me 参考 使用Docker快速搭建各种测试环境 本文主要参考 Docker初步实践 CSDN-docker安装mongo及开启用户认证 docker-compose 安装mysql5.7 使用 Docker Compose 搭建 MySQL 数据库主从复制实例]]></content>
      <categories>
        <category>容器</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>Env</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker 入门指南——常用命令]]></title>
    <url>%2F2019%2F06%2F02%2Fdocker-useful-often-commands%2F</url>
    <content type="text"><![CDATA[Docker 容器学习笔记系列： Linux–CentOS 安装 Docker 教程 Docker 入门指南——常用命令 使用容器 Docker 创建开发环境 前面已经介绍了 Docker 的安装方式，本文总结一下使用 Docker 的基本概念和常用命令。 基本概念镜像 Image镜像是一些打包好的已有的环境，可以被用来启动和创建容器 容器 Container容器是镜像的实例化 容器的UUIDUUID – 通用唯一标识符（Universally Unique Identifier） 容器有三种方式来进行标识： 长UUID 短UUID Name UUID 是 Docker daemon 产生的，在一台主机上是唯一的，在创建容器的时候可以通过 --name 来指定容器的名字，如果不指定会自动分配一个字符串名称。 通过 docker ps、docker inspect 等命令可以查看到容器的标识信息 容器启动过程 检查本地是否存在指定的镜像，不存在就从公有仓库下载 利用镜像创建并启动一个容器 分配一个文件系统，并在只读的镜像层外面挂载一层可读写层 从宿主主机配置的网桥接口中桥接一个虚拟接口到容器中去 从地址池配置一个 ip 地址给容器 执行用户指定的应用程序 执行完毕后容器被终止 镜像 查看 image 列表： 1docker iamges 下载镜像： 1docker pull registry.domain.com/library/ubuntu:14.04 制作镜像12# 常用下面这种方式制作镜像，Dockerfile 文件更透明docker build [-f DockerfileName] -t image_name DockerfilePath 这里 DockerfilePath 是 Context 上下文目录，在创建的时候会全部上传到 Docker Server 端，所以这个目录不要太大。 参数说明： -f/--file：Name of the Dockerfile (Default is ‘PATH/Dockerfile’)，Dockerfile的完整路径 -t/--tag：Name and optionally a tag in the ‘name:tag’ format，指定了镜像名称，镜像的名字及 tag，通常 name:tag 或者 name 格式 --no-cache：Do not use cache when building the image，这篇文章介绍了使用这个参数的场景，构建镜像中有时候包含 git clone 命令，会默认使用缓存，新代码就不会下载了，所以，有时候需要加上这个参数； --pull，默认 false。Always attempt to pull a newer version of the image，设置该选项，总是尝试 pull 镜像的最新版本 其他的 build 参数，可以采用 docker build -h 查看。 删除镜像删除 image 之前，需要先删除 container:12docker ps -adocker rm container_id/container_name 删除 image:12docker rmi &lt;image-id&gt;docker rmi &lt;image-name&gt;:&lt;tag&gt; 删除虚悬镜像(dangling image)：12345$docker image ls -f dangling=true #列出虚悬镜像$ docker image pruneWARNING! This will remove all dangling images.Are you sure you want to continue? [y/N] y 无tag镜像(dangling)显示无 tag 镜像：1$ docker images --filter &quot;dangling=true&quot; 当新构建的镜像占用这个镜像ID的 repo:tag 时，会出现这些图像，将其保留为 ： 或 untagged。可以使用如下命令批量删除这类镜像1$ docker rmi $(docker images -f "dangling=true" -q) 迁移镜像保存镜像到文件，语法格式：1docker save [OPTIONS] IMAGE [IMAGE...] 例如：123docker save image_name -o file.tar# Ordocker save image_name --output file.zip 将镜像保存一个 tar 包文件了，也可以是 zip 格式的压缩包。 加载一个 tar 包的镜像：1docker load -i file.tar 容器操作 查看运行中的容器 1docker ps 查看所有容器 1docker ps -a 显示运行的容器里的进程信息 1docker top cid 此处， cid 表示你运行的容器名 显示容器详细信息 1docker inspect cid 日志查看 123docker logs cid# 实时查看日志输出docker logs -f cid 查看容器root用户密码 1docker logs cid 2&gt;&amp;1 | grep &apos;^User: &apos; | tail -n1 容器运行语法格式：1Usage: docker run [OPTIONS] IMAGE [COMMAND] [ARG...] 例如：1docker run -it --name cidregistry.domain.com/library/ubuntu:14.04 如果直接 docker run -it registry.domain.com/library/ubuntu 可能会出错，因为不加 tag ，默认就去运行 latest 版本，而本地没有 latest 版本，所以，需要将 image+tag，以冒号分隔拉去。 -i 交互操作 -t 终端 --name 指定容器名字 -d 后台运行一个容器 --rm，表明退出容器后随之将其删除，可以避免浪费空间 -p 映射端口 -v 挂载 volumn --privileged=false 容器内 root 拥有真正 root 权限 当处于一个容器中时，利用exit退出容器 在容器中运行一段程序 1docker run ubuntu apt-get update 启动已终止（stop）容器：1docker restart 3e8 # 3e8 为容器的 id 号，不需要全写，也可以用容器名替代 进入容器 进入正在运行的容器，退出不会造成容器停止： 1docker exec -it cid /bin/bash 附着到正在运行的容器中，退出时会导致容器终止，不常用： 1docker attach cid 从容器拷贝文件出来拷贝文件出来1docker cp cid:/container_path to_path 删除容器123456docker rm cid# 强制删除docker rm -f cid# 删除所有容器# -q 表示只列出容器的 id 值docker rm `docker ps -a -q` 容器运行状态修改1docker start/stop/kill/restart cid 更改容器名字1docker rename old new 修改容器，制作镜像image 相当于类，container 相当于实例，不过可以动态给实例安装新软件，然后把这个 container 用 commit 命令固化成一个 image：1docker commit -m "修改yum源" -a "michaelxiang" cid registry.domain.com/ci/centos-os:latest 这种制作镜像的方式并不推荐，因为不如 Dockerfile 方式透明。 推送镜像12docker login registry.domain.com -u username -p passworddocker push registry.domain.com/michael/IMAGE[:TAG] 如果支持 accesstoken 权限认证： 1docker login registry.domain.com -u test -p ACCESSTOKEN:XXXXXXXXXXXXX:ACCESSTOKEN docker-compose它允许用户通过一个单独的 docker-compose.yml 模板文件（YAML 格式）来定义一组相关联的应用容器为一个项目（project）。 Compose 中有两个重要的概念： 服务 (service)：一个应用的容器，实际上可以包括若干运行相同镜像的容器实例。 项目 (project)：由一组关联的应用容器组成的一个完整业务单元，在 docker-compose.yml 文件中定义。 Compose 的默认管理对象是项目，通过子命令对项目中的一组容器进行便捷地生命周期管理 如何写docker-compose.yml，Docker compose file 参考文档 官宣-Overview of docker-compose CLI Docker 三剑客之 Compose 项目 其他你可以通过以下命令来便捷的查看镜像、容器、数据卷所占用的空间： 1docker system df docker 配置daemon.json 文件123456789&#123; "insecure-registries": ["registry.xxx.com"], "registry-mirrors": ["https://xxxx.mirror.domain.com"], "exec-opts": ["native.cgroupdriver=systemd"], "storage-driver": "overlay2", "storage-opts": [ "overlay2.override_kernel_check=true" ]&#125; FAQQ1：Docker 空间问题Docker长时间运行后的volumes目录清理 悟能-Docker长时间运行后的volumes目录清理 参考命令： 官宣——Command-Line Interfaces (CLIs) 强烈推荐 Docker 使用总结 本文的主要参考 Docker 入门教程 Docker —— 从入门到实践 只要一小时，零基础入门Docker SF-docker命令详解 简书-Docker命令使用 Docker命令行参考(8) – docker images列出镜像 删除无 tag 镜像 镜像登录： docker搭建私有仓库、自签发证书、登录认证 容器间的通信： Docker容器与宿主机同网段互相通信 关于对docker run –link的理解 cizixs-docker 容器的网络模式]]></content>
      <categories>
        <category>容器</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[程序流程图学习笔记]]></title>
    <url>%2F2019%2F06%2F01%2Ftools-dev-program-flowchart%2F</url>
    <content type="text"><![CDATA[最近刚刚加入了部署小组，对接各个部署系统，业务逻辑有点繁杂，这时候想起来之前学过的流程图，或许，它可以帮我顺利整理出各个业务逻辑吧，因此，有了本文。 概念流程图（FlowChart）是表示算法、工作流或流程的一种框图表示，它以不同类型的框代表不同种类的步骤，每两个步骤之间则以箭头连接。这种表示方法便于说明解决已知问题的方法。流程图在分析、设计、记录及操控许多领域的流程或程序都有广泛应用。 符号 美国国家标准协会是1960年代就开始制定流程图及一些标准符号[3]。而在1970年，国际标准化组织采用其方案[4]。现时通用的版本ISO 5807是在1985年修订[5]。 所以，流程图的绘制是有标准的，每种符号都有其代表的含义。做事，就要做专业。 循环流程图示例for 循环for 循环形式：123for (表达式 1；表达式 2；表达式 3)&#123; 执行语句；&#125; while 循环while 循环形式：123while (条件表达式)&#123; 执行语句；&#125; do-while 循环do-while 循环形式： 123do&#123; 执行语句；&#125; while(条件表达式) 经验 如果你在公司里不是一锤定音式的人物的话，你就需要对你的文档进行版本管理。流程图也不例外，什么时间发布的什么版本，都要清楚地标出来，「最新」是个用不得的词。 参考 wiki-流程图 office-建立基本流程圖 这个包含了一些 Visio 制作流程图的技巧 edraw-流程图专栏 这里介绍了很多技巧 丁宇-画Web流程图的一点心得 该作者博客还总结了一篇英文版的 The definitive guide to Web flowcharts 编程基本功训练：流程图画法及练习 介绍了一些比较复杂的例子，借鉴意义 【软件工程】看我火眼金睛——系统流程图、程序流程图、数据流图、活动图、状态图、顺序图辨析 介绍了流程图、时序图、数据流程图等基本概念 博客园-大 CC-看懂UML类图和时序图 浏览量630.6K，克隆量149.8K的流程图长什么样？]]></content>
      <categories>
        <category>ToolsDev</category>
      </categories>
      <tags>
        <tag>绘图</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux——CentOS 安装 Docker 教程]]></title>
    <url>%2F2019%2F06%2F01%2Fdocker-centos-install%2F</url>
    <content type="text"><![CDATA[Docker 容器学习笔记系列： Linux–CentOS 安装 Docker 教程 Docker 入门指南——常用命令 使用容器 Docker 创建开发环境 本文主要介绍 CentOS 系统安装 Docker 的流程。 前提条件OS 要求CentOS7: The centos-extras repository must be enabled. This repository is enabled by default, but if you have disabled it, you need to re-enable it.The overlay2 storage driver is recommended 卸载旧的版本较旧版本的 Docker 被称为 docker 或 docker-engine。如果已安装这些，请卸载它们以及相关的依赖项： 12345678910sudo yum remove docker \ docker-client \ docker-client-latest \ docker-common \ docker-latest \ docker-latest-logrotate \ docker-logrotate \ docker-selinux \ docker-engine-selinux \ docker-engine /var/lib/docker 目录下保存着镜像、容器、卷、网络。官方文档安装的 docker-ce 包，内部源中只有 docker-engine包，docker-ce 是最新的社区版本的包名。 安装 Docker CE使用源安装设置源1.安装依赖的包，yum tils 提供了 yum-config-manager 套件， device-mapper-persistent-data 和 lvm2 是 devicemapper 存储驱动所依赖的包。 123$ sudo yum install -y yum-utils \ device-mapper-persistent-data \ lvm2 2.使用如下命令设置 stable 源： 123$ sudo yum-config-manager \ --add-repo \ https://download.docker.com/linux/centos/docker-ce.repo 国内可选择清华大学源-Docker Community Edition 镜像使用帮助 安装 Docker CE1.安装最新版本的 Docker CE：1$ sudo yum install docker-ce 2.要安装特定版本的 Docker CE，可在 repo 中列出可用版本，然后选择并安装：1$ yum list docker-ce --showduplicates | sort -r Docker 安装之后， docker 组就被创建了，但没有用户加到这个群组中。 3.启动 Docekr：1$ sudo systemctl start docker 4.可以通过运行 hello-world 镜像来验证 docker 的安装成功：1sudo docker run hello-world` 这个命令下载一个测试镜像，在容器中运行它。当容器运行时，它会打印一条信息并退出。 从 RPM 包安装如果无法使用 Docker的源来安装 Docker，则可以下载适用于您的发行版的 .rpm 文件并手动安装。每次要升级 Docker 时都需要下载新文件。 去 https://download.docker.com/linux/centos/7/x86_64/stable/Packages/ 下载 rpm 包 安装 Docker CE：$ sudo yum install /path/to/package.rpm 升级 Docker CE使用 yum -y upgrade docker-ce 升级版本。 卸载 卸载 Docker 包：$ sudo yum remove docker-ce 主机上的镜像、容器、卷或自定义配置文件不会自动删除。为了删除这些文件，可以运行如下命令：$ sudo rm -rf /var/lib/docker 你必须手动删除任何已编辑的配置文件 注意点 如果非 root 用户想要使用 Docker，你应该将该用户添加到 docker 组中：sudo usermod -aG docker your-user 安装 Docker CE 之后，它在基于 DEB 的发行版上会自动启动。在基于 RPM 的发行版上，需要使用相应的 systemctl 或 service 命令手动启动它 使用 systemd 控制 Docker使用 systemd 控制 Docker 手动启动大多数 Linux 发行版使用 systemctl 启动服务，如果没有，就用 service命令： systemctl:$ sudo systemctl start docker service:$ sudo service docker start 系统自启If you want Docker to start at boot, see如果你想要实现开启自启 docker，可以看看这篇文章 Configure Docker to start on boot 1systemctl list-unit-files|grep docker # 查看 Docker 服务状态 配置 Docker daemon 选项推荐的方法是使用平台独立的 daemon.json 文件，默认位于 /etc/docker/ 中。详细配置项，查看官宣-Daemon configuration file，有一份中文的备注说明：docker daemon(dockerd)配置文件daemon.json。 你可以使用 daemon.json 配置几乎所有守护程序配置选项。下面的例子配置了两个选项。你不能使用 daemon.json 机制配置的一个选项是 HTTP proxy。 Runtime directory and storage driver你可能想要通过移动镜像、容器和卷到独立分区来控制磁盘空间。 为了实现这个，可以在 daemon.json 中做如下配置：1234&#123; &quot;data-root&quot;: &quot;/mnt/docker-data&quot;, &quot;storage-driver&quot;: &quot;overlay&quot;&#125; HTTP/HTTPS proxyDocker 守护进程使用 HTTP_PROXY, HTTPS_PROXY 和 NO_PROXY 环境变量在它的启动环境中来配置 HTTP 和 HTTPS 代理。你不能使用 daemon.json 文件来配置这些环境变量。 如果你使用的是 HTTP 或 HTTPS 代理服务器，例如在公司设置中，则需要将此配置添加到 Docker systemd 服务文件中。 1.为 docker 服务创建一个 systemd 目录：1$ sudo mkdir -p /etc/systemd/system/docker.service.d 2.创建一个文件 /etc/systemd/system/docker.service.d/http-proxy.conf，加入 HTTP_PROXY 环境变量：12[Service]Environment=&quot;HTTP_PROXY=http://proxy.example.com:80/&quot; 或者，如果你使用 HTTPS 代理服务，创建一个文件 /etc/systemd/system/docker.service.d/https-proxy.conf，加入 HTTPS_PROXY 环境变量：12[Service]Environment=&quot;HTTPS_PROXY=https://proxy.example.com:443/&quot; 3.如果你拥有内部的 Docker registries 服务或者要使用国内的镜像加速器-daocloud.io，你需要通过指定 NO_PROXY 环境变量来不通过代理访问它们：12[Service]Environment=&quot;HTTP_PROXY=http://proxy.example.com:80/&quot; &quot;NO_PROXY=localhost,127.0.0.1,docker-registry.somecorporation.com,daocloud.io&quot; 这样，你访问 NO_PROXY 中的网址时，就不会走代理，速度会比较快。 Or, if you are behind an HTTPS proxy server:12[Service]Environment=&quot;HTTPS_PROXY=https://proxy.example.com:443/&quot; &quot;NO_PROXY=localhost,127.0.0.1,docker-registry.somecorporation.com&quot; 一个实际配置的栗子：1234567mkdir -p /etc/systemd/system/docker.service.d/ # 先保证有这个目录cat &lt;&lt;&apos;EOF&apos;&gt;/etc/systemd/system/docker.service.d/http-proxy.conf # 这里一定要记得让内部镜像仓地址不要走代理,否则无法访问我们私有的镜像仓[Service]Environment=&quot;HTTP_PROXY=http://127.0.0.1:3128/&quot;Environment=&quot;HTTPS_PROXY=http://127.0.0.1:3128/&quot;Environment=&quot;NO_PROXY=localhost,127.0.0.0/8,.domain.com&quot;EOF 4.Flush changes:1$ sudo systemctl daemon-reload 5.重启 Docker：1$ sudo systemctl restart docker 6.验证配置项已经被加载：12$ systemctl show --property=Environment dockerEnvironment=HTTP_PROXY=http://proxy.example.com:80/ 如果你采用的 HTTPS 代理：12$ systemctl show --property=Environment dockerEnvironment=HTTPS_PROXY=https://proxy.example.com:443/ 手动创建 systemd 单元文件当你手动安装 Docker 时，如果你想要用 systemd 管理 Docker，可以安装两个单元文件 service 和 socket，参考 moby/contrib/init/systemd/，下载文件至 /etc/systemd/system。 配置使用 docker 镜像仓库选择一：ustc的镜像新版的 Docker 使用 /etc/docker/daemon.json（Linux） 配置 Daemon： 123&#123; &quot;registry-mirrors&quot;: [&quot;https://docker.mirrors.ustc.edu.cn&quot;]&#125; USTC-Docker镜像使用帮助 选择二：Docker 中国官方镜像加速123&#123; &quot;registry-mirrors&quot;: [&quot;https://registry.docker-cn.com&quot;]&#125; Docker 中国官方镜像加速 Docker 拖取镜像默认走的是 HTTPS 协议（443端口），一般私有仓库都没有合法的 HTTPS 证书，通过通过配置私有仓库为非安全仓库：123&#123; &quot;insecure-registries&quot; : [&quot;hub.h.com&quot;]&#125; insecure-registries 就是配置的非安全仓库的地址。 测试配置的结果： busybox是一个集成了一百多个最常用linux命令和工具的软件,同时它也是一个最小的Linux系统，它提供了该系统的主要功能，例如grep、find、mount以及telnet等但不包含一些与GNU相关的功能和选项 1docker pull busybox Docker 存储驱动Linux kernel 4.0以后才支持的overlay2（Linux kernel 3.18以后才支持的叫overlayFS）。同时请确保docker的服务端版本不低于1.12，否则无法支持。uname -sr 可以查看系统内核版本。 Docker 1.12.6/v17.03 文档中 CentOS7 系统下安装时，明确说明，用于生产时，必须使用 devicemapper 驱动的 direct-lvm 模式，需要我们提前准备好块设备，以提供更好的稳定性和性能。默认使用 devicemapper 驱动的 loop-lvm 模式，因为安装简单，只适用于测试环境。从 docker info 信息可以看出，loop-lvm 模式最大可用空间只有107GB。生产环境下必须使用 devicemapper 驱动的 direct-lvm 模式，使用块设备，速度更快并且能更有效地使用系统资源。 在 Docker v17.06 及以后的版本中，关于 OverlayFS 存储驱动，尽量使用 overlay2 而不要使用 overlay，官方的说明是 overlay 可以使用但不建议。使用 overlay2 时 Linux 系统内核要求4.0以上，或者 CentOS7 的内核在 3.10.0-693 以上。Docker-CE v17.06 及以上，在使用 overlay2 驱动时，还需要设置额外的参数，以禁止检测内核为4.0版本。 12345678910111213141516171819202122232425262728293031#查看当前存储驱动docker info|grep -i storage#停止Dockerservice docker stop#清空数据，如果有啥需要的请自己备份rm -rf /var/lib/docker/*#修改配置文件vi /etc/docker/daemon.json#如果没有这个文件或没有内容，就直接把下面的粘贴进去#不然就只添加那一条#如果不是在最后一行加请自行在末尾添加逗号&#123; "storage-driver": "overlay2"&#125;#如果是CentOS7或者RedHat7内核在3.10.0-693以下的，设置额外的参数：&#123; "storage-driver": "overlay2", "storage-opts": [ "overlay2.override_kernel_check=true" ]&#125;#当然，也可以通过给docker修改启动参数的方式来# 1.修改/etc/init.d/docker# 这个直接在 dockerd 后面加参数就行，不过其实和下面的差不多# 2.修改/etc/sysconfig/docker# 改成类似 other_args="-s overlay2"# 3.修改/usr/lib/systemd/system/docker.service# 改成类似 ExecStart=/usr/bin/dockerd -s overlay2#启动dockerservice docker start 通常在生产构建机器上，一般系统盘大小都不大，都会挂载一个较大容量的数据盘，比如 data 目录。那么，为了避免日后 Docker 的根目录 /var/lib/mock过大，撑爆系统盘，我们需要想办法修改一下 Docker 的根目录，主要有两种办法： 1.先备份 /var/lib/docker的内容，然后在创建/data/docker的软连接: ln -s /data/docker /var/lib/docker 2.修改 daemon.json 配置： 123456&#123;# before before 17.06-ce"graph": "/data/docker",# docker after 17.06-ce"data-root":"/data/docker",&#125; 参考 官宣-Get Docker CE for CentOS 官宣-Control Docker with systemd-Docker代理设置 如何在CentOS 7中安装Docker 这篇文章中提到为了使用 overlay2 必须升级 CentOS 内核，其实也可以不用的 Dockuer Hub 镜像： 第二天堂-Docker 设置 socks5 代理或使用国内镜像 伊布-国内 docker 仓库镜像对比 文中附有一个测试镜像速度的脚本 阿里云-Docker 镜像加速器 华为云-Docker Hub 服务 存储驱动： 老高的技术博客-centos升级内核版本以支持overlay2 深入了解Docker存储驱动 一个关于容器和 K8s 相关的社区 官宣-Use the OverlayFS storage driver 官宣-Docker storage drivers senra-Docker切换OverLay(2)——提高性能，加快速度 CentOS7.x系统中使用Docker时，在存储方面需要注意的问题 运维笔记-DOCKER更改镜像存储位置 描述了常见修改存储位置的两个方法，同时，提到了新旧版本的配置项的注意点 SOF-How to change the docker image installation directory 解释了不同版本根目录配置项的区别]]></content>
      <categories>
        <category>容器</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【转】说说云计算中的地域和可用区概念]]></title>
    <url>%2F2019%2F06%2F01%2Fcloud-concept-region-az%2F</url>
    <content type="text"><![CDATA[原文链接： 说说云计算中的地域和可用区概念 亚马逊 AWS 是公共云计算的先驱，一些云计算中重要的产品设计和基础概念可以说都是亚马逊引入的。这其中有两个非常重要的概念：地域（Region）和可用区（AZ：Availabe Zone）。很多第一次接触云计算的同学，光看这两个名字的字面意义，虽然也能够猜出大致的意思，但深入的学习了解云计算一段时间之后，才能深刻的体会这两个概念对于云计算的重要影响。包括国内的这些云计算服务商，也是过了很长时间才陆续在产品中引入可用区的设计的。 理想情况下，我们当然希望云计算能够彻底消除地域的影响，就像我们用电的时候不用关心发电厂在哪里一样。但现实显然没有那么美好，不同地域的机房之间的网络还做不到像电网一样透明。所以在云计算产品的最底层，首先需要考虑不同地域的影响。不同地域之间，一般只能通过公网连通，内部之间网络是不通的。当然，对于云计算服务商来说，为管理需要，一般还是会通过有限的带宽来连通不同地域的机房，用于云计算内部资源管理，以及一些特殊的产品场景，比如跨地域的镜像复制。但因为内部带宽有限，一般不会完全开放给用户使用。 所以，地域就是物理意义上的不同地方的机房，这个不同地方，一般来说距离较远，机房之间用光纤直连的成本较高。并且相对来说会在用户需求量较大的地方部署地域机房，比如阿里云的云服务器的地域在境内有杭州，上海，北京，深圳，青岛，海外已经上线的包括香港、硅谷和新加坡。实际上阿里云一开始是没有上海地域的，因为上海杭州距离较近，部署直连光纤的成本也相对可控，阿里内部之前很多应用都是分别部署在杭州和上海，基本上是当作一个地域来使用的，后来可能因为需求大而分开了。 所以，地域很好理解，就是物理上相隔较远的机房，因为跨地域的机房之间的带宽无法满足内网需求，所以不同地域的机器之间内网是不通的。当然，随着骨干网络等物理层基础设施的发展，未来跨地域内网连通并非完全不可能的事情。在这个过程中，公共云计算服务商也可能根据用户的诉求，在某些场景开放一些有限的内部网络带宽来做产品，比如，前面说的阿里云的跨地域镜像复制，以及最近推出来的OSS跨地域复制等。一般来说，在数据和存储领域内的产品会先行支持跨地域的功能，毕竟数据容灾是更强烈的需求。 那么，同一个地域之内又分成多个可用区，为什么要搞这么复杂？原因很简单，IT系统从远古时代就有同城容灾的需求，那使用云计算以后，怎么实现同城跨机房容灾呢？如果用户购买的云服务器无法区分在哪个机房，那么就无法在业务应用层面来设计同城容灾。所以云计算服务商提出了同地域内不同可用区的概念，简单点理解，可以认为就是同城不同机房，云计算服务商会从底层的机房电力/网络等层面仔细设计来保障一个可用区出现故障的时候不会影响到另外一个可用区，当然你要说杭州彻底被钱塘江潮淹没的情况，那可用区也救不了你，要在业务应用层面考虑通过不同的地域来设计异地容灾了。 所以，简单来说，可以将地域理解为不同城市的机房，将可用区理解为同一个城市的不同机房。当然，实际上不同可用区也可能是在同一个机房，可用区的概念严格来说是按照电力和网络设备等相互独立来设计的。同一个地域内的不同可用区之间，内网是连通的，但是网络的响应时间会有差异。下面是我用阿里云杭州地域做的一次 ping 的测试，来观察同地域不同可用区之间的网络情况。 主机1在杭州可用区 B，主机2在杭州可用区 D，数据库 1 在杭州可用区 B。同一个可用区内，从主机 1 ping 数据库 1 的结果如下： 12345ping rdsxxx.mysql.rds.aliyuncs.comPING rdsxxx.mysql.rds.aliyuncs.com (100.98.xx.xxx) 56(84) bytes of data.64 bytes from 100.98.xx.xxx: icmp_seq=1 ttl=56 time=0.260 ms64 bytes from 100.98.xx.xxx: icmp_seq=2 ttl=56 time=0.472 ms64 bytes from 100.98.xx.xxx: icmp_seq=3 ttl=56 time=0.396 ms 同地域跨不同可用区，从主机 2 ping 数据库1 的结果如下： 12345ping rdsxxx.mysql.rds.aliyuncs.comPING rdsxxx.mysql.rds.aliyuncs.com (100.98.xx.xxx) 56(84) bytes of data.64 bytes from 100.98.xx.xxx: icmp_seq=1 ttl=54 time=1.63 ms64 bytes from 100.98.xx.xxx: icmp_seq=2 ttl=54 time=1.73 ms64 bytes from 100.98.xx.xxx: icmp_seq=3 ttl=54 time=1.74 ms 很明显，不同可用区之间的内网是连通的，但响应时间比同一个可用区之内要慢 1ms 多。所以，在实际应用中，如果需要考虑同城容灾或者同城双活，需要尽量将应用和数据库分布部署在不同的可用区。如果对响应时间高度敏感，则建议部署在同一个可用区内。在购买云服务器和数据库的时候，要注意选择了。 另外，目前阿里云大数据平台主要部署在杭州地域，如果业务应用的数据需要进入到阿里云大数据平台加工处理，则云服务器和数据库最好优先在杭州地域购买，以后阿里云应该会在更多地域部署大数据平台。不过悲催的是，杭州机房资源整体上比较紧张，杭州地域的云服务器时不时可能断供一小段时间。 总结这里写一下自己对「地域」和「可用区」的理解： 这两个概念都是对管理的主机的的一个区域的划分。「地域」这个划分的范围比较大，好比一个城市圈的范围。那么「可用区」这个范围可以理解为城市圈中的一个个小区。这个小区住不下了，可以去另外一个小区住。同一个地域里，可用区之间访问是方便、快捷的，所以，一个服务部署时，常常需要在同一「地域」下的不同「可用区」中都部署一下，这样一个挂了、另外一个可以撑起来，不至于服务全挂了。 补充资料 云计算之路-阿里云上：地域与可用区 云区域（region)，可用区（AZ），跨区域数据复制（Cross-region replication）与灾备（Disaster Recovery）（部分1 云区域（region)，可用区（AZ），跨区域数据复制（Cross-region replication）与灾备（Disaster Recovery）（部分2）]]></content>
      <categories>
        <category>Cloud</category>
      </categories>
      <tags>
        <tag>Cloud</tag>
        <tag>概念</tag>
        <tag>术语</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[利用 Hexo + Github Pages 搭建博客并优化 Next 主题教程]]></title>
    <url>%2F2019%2F05%2F19%2Fhexo-blog-full-note%2F</url>
    <content type="text"><![CDATA[概述本文总结一下 Hexo 搭建博客的主要流程，能够在日后快速恢复博客环境。 Hexo 的官方文档写的已经很全面了，本文仅将一些注意点列出。 安装 Hexo 的文档参考： 官宣-Hexo 文档 前提安装 Hexo 之前，你的电脑上需要有 Node.js Git 如果是 Mac 用户， 您在编译时可能会遇到问题，请先到 App Store 安装 Xcode，Xcode 完成后，启动并进入 Preferences -&gt; Download -&gt; Command Line Tools -&gt; Install 安装命令行工具 安装 Hexo全局安装 hexo-cli：1npm install -g hexo-cli 如果遇到权限的问题，可以使用如下命令：1sudo chown -R $(whoami) /usr/local/lib/node_modules/ 设置 /usr/local/lib/node_modules/ 文件夹属于当前用户。 此外，如果你要使用 root 权限安装的话，可以使用 sudo -s 切为 root 用户进行相关操作。这么做的话，会将一些文件夹的默认属组设置为 root 了，不推荐。 npm 权限问题： Global installs (sudo npm i -g) fail on Mac after 6.5 upgrade. Works fine after 6.4.1 downgrade npm，yarn如何查看源和换源 建站123hexo init MyBlogcd MyBlognpm install 执行完毕之后，博客其实已经 OK 了： 12hexo ghexo s 执行上面命令即可本地预览博客内容了。 部署官宣-站点配置文件 内容中介绍了很多字段的用途 Hexo 提供快速一键部署，将博客部署到 GIthub Pages。 安装 hexo-deployer-git：12$ cd MyBlog$ npm install hexo-deployer-git --save 修改站点配置文件中的配置：12345# npm install hexo-deployer-git --savedeploy:- type: git repo: git@github.com:Michael728/michael728.github.io.git branch: master 执行部署：1hexo d 常用命令hexo 常用指令 1234567hexo version # 显示hexo版本hexo new &lt;title&gt; # 创建新文章hexo g/generate # 生成静态文件hexo clean # 清除缓存文件和已生成的静态文件（public）hexo server # 启动本地服务器hexo d/deploy # 部署网站hexo list &lt;type&gt; # 列出网站资料 npm 常用指令12345678npm install 模块名 -g --save # g全局安装 save安装包信息将加入到dependencies（生产阶段的依赖）npm install gulp@3.9.1 # 指定版本npm install # 该命令可以根据dependencies配置安装所有的依赖包npm update [-g] 模块名npm outdated 模块名 # 检查模块是否过时npm ls -g # 查看全局安装的模块npm uninstall 模块名npm info hexo-cli # 查看hexo-cli模块的信息 npm常用命令 【原】npm 常用命令详解 Hexo 写作技巧 Sanarous-hexo博客Next主题进阶写作技巧 NexT 主题内置标签 Hexo 搭建个人博客系列：写作技巧篇 Note语法：1234567&#123;% note [class] [no-icon] %&#125;这里写你需要写的内容&#123;% endnote %&#125;// 注意上面的class和no-icon属性是可以选择的[class] : default | primary | success | info | warning | danger.[no-icon] : Disable icon in note. 示例：123&#123;% note success no-icon %&#125;success形式的类别&#123;% endnote %&#125; 效果： success形式的类别 这里使用 no-icon 表示不显示图标，可选，默认会带有图标。 使用主题自带 FontAwesome 图标源码：123- &lt;i class=&quot;fa fa-pencil&quot;&gt;&lt;/i&gt; 铅笔- &lt;i class=&quot;fa fa-cloud-upload&quot;&gt;&lt;/i&gt; 上传- &lt;i class=&quot;fa fa-download&quot;&gt;&lt;/i&gt; 下载 效果： 铅笔 上传 下载 文本居中源码：123456&#123;% cq %&#125;人生乃是一面镜子，从镜子里认识自己，我要称之为头等大事，也只是我们追求的目的！&#123;% endcq %&#125; 效果： 人生乃是一面镜子，从镜子里认识自己，我要称之为头等大事，也只是我们追求的目的！ 主题自带 label 标签首先在主题 _config.xml 配置：12# Label tag.label: true 源码：1&#123;% label primary@primary内容 %&#125; 效果：primary内容 主题自带 tabs 标签主题配置文件： 1234567# Tabs tagtabs: enable: true transition: tabs: true labels: true border_radius: 0 语法：12345&#123;% tabs [Unique name], [index] %&#125;&lt;!-- tab [Tab caption]@[icon] --&gt;Any content (support inline tags too).&lt;!-- endtab --&gt;&#123;% endtabs %&#125; Unique name 为每个标签页组唯一的名称 index 为初始激活的标签页 Tab caption 为标签页名称，不指定时为所属标签页组名称加索引 icon 为 Font awesome图标，可选 源码示例：1234567891011&#123;% tabs 选项卡, 2 %&#125;&lt;!-- tab --&gt;这是选项卡 1 内容&lt;!-- endtab --&gt;&lt;!-- tab --&gt;这是选项卡 2 内容&lt;!-- endtab --&gt;&lt;!-- tab --&gt;这是选项卡 3** 哇，你找到我了！φ(≧ω≦*)♪～&lt;!-- endtab --&gt;&#123;% endtabs %&#125; 效果：选项卡 1选项卡 2选项卡 3这是选项卡 1 内容这是选项卡 2 内容这是选项卡 3* 哇，你找到我了！φ(≧ω≦)♪～ 主题自带样式按钮源码：1&#123;% btn https://www.baidu.com, 点击下载百度, download fa-lg fa-fw %&#125; 效果：点击下载百度 Hexo 其他知识图床由于一直使用的是「微博图床」，渣浪微博和简书开启了图片防盗链，请大家在博客中加入以下标签来绕过： 1&lt;meta name="referrer" content="never" /&gt; ​​​​ Next 主题只需要在 themes/next/layout/_partials/head/head.swig 中添加上面一行内容即可。 Next 主题 theme-next/hexo-theme-next 安装 Next12$ cd MyBlog$ git clone https://github.com/theme-next/hexo-theme-next themes/next Next 扩展都安装在themes/next/source/lib文件夹下 12cd MyBloggit clone https://github.com/theme-next/hexo-theme-next themes/next 启动 Next 主题编辑站点配置文件 _config.yml：1theme: next # 启用next主题 主题设置 next-开始使用 设置语言站点配置文件：1language: zh-CN # 最新版中，不再使用zh-Hans 设置菜单编辑主题配置文件： 123456789menu: home: / || home #about: /about/ || user #tags: /tags/ || tags #categories: /categories/ || th archives: /archives/ || archive #schedule: /schedule/ || calendar #sitemap: /sitemap.xml || sitemap #commonweal: /404/ || heartbeat 菜单内容的设置格式是：item name: link || icon。其中 `item name 是一个名称，这个名称并不直接显示在页面上，她将用于匹配图标以及翻译。 设置菜单项的显示文本。在第一步中设置的菜单的名称并不直接用于界面上的展示。Hexo 在生成的时候将使用 这个名称查找对应的语言翻译，并提取显示文本。这些翻译文本放置在 NexT 主题目录下的 languages/{language}.yml （{language} 为你所使用的语言）。 icon 使用的是 fontawesome 图标，严格区分大小写。 设置头像将准备好的头像放置在主题目录下的 source/images/ 中。 12345avatar: # In theme directory (source/images): /images/avatar.gif # In site directory (source/uploads): /uploads/avatar.gif # You can also use other linking images. url: /images/logo.jpg 百度统计 登录百度统计， 定位到站点的代码获取页面 复制 hm.js? 后面那串统计脚本 id，如： 编辑 主题配置文件， 修改字段 baidu_analytics 字段，值设置成你的百度统计脚本 id 阅读次数使用 LeanCloud 参考这个 为NexT主题添加文章阅读量统计功能 1234leancloud_visitors: enable: true # 启用了 valine，所以这里可以置为 false app_id: xxx app_key: xxx 设置 RSS主题配置文件中，rss 字段设为空，启用，设为 false 则不启用。启用的话，需要安装插键：1npm install hexo-generator-feed --save 添加标签页面 新建页面 hexo new page tags 设置页面类型，编辑刚新建的页面，将页面的类型设置为 tags ，主题将自动为这个页面显示标签云1234title: 标签date: 2014-12-22 12:39:04type: &quot;tags&quot;--- 如果有集成评论服务，页面也会带有评论。 若需要关闭的话，请添加字段 comments 并将值设置为 false，如：12345title: 标签date: 2014-12-22 12:39:04type: &quot;tags&quot;comments: false--- 修改菜单，在菜单中添加链接。编辑 主题配置文件 ， 添加 tags 到 menu 中 标签示例：1234title: 标签测试文章tags: - Testing - Another Tag 请参阅 Hexo 的分类与标签文档，了解如何为文章添加标签或者分类 补充：12345categories:- Diarytags:- PS3- Games 分类方法的分歧如果您有过使用WordPress的经验，就很容易误解Hexo的分类方式。WordPress支持对一篇文章设置多个分类，而且这些分类可以是同级的，也可以是父子分类。但是Hexo不支持指定多个同级分类。下面的指定方法：123categories:- Diary- Life 会使分类Life成为Diary的子分类，而不是并列分类。因此，有必要为您的文章选择尽可能准确的分类。 并列分类，了解一下：123categories:- [Linux]- [Tools] 并列+子分类，再了解一下：123categories:- [Linux, Hexo]- [Tools, PHP] 同样的方法，添加分类页面：1$ hexo new page categories 设置字体设置字体可参考:官宣-字体 设置代码高亮主题代码高亮预览 1234# Code Highlight theme# Available value: normal | night | night eighties | night blue | night bright# https://github.com/chriskempson/tomorrow-themehighlight_theme: night eighties 侧边栏社交链接主题配置文件：1234567social: GitHub: https://github.com/Michael728 || github 微博: https://weibo.com/1838446070/profile?topnav=1&amp;wvr=6 || weibo 博客园: https://www.cnblogs.com/michael-xiang/ || globe 知乎: https://www.zhihu.com/people/michaelXoX || globe Twitter: https://twitter.com/728_michael || twitter Telegram: https://t.me/michaelxiang || telegram 图标名称 是 Font Awesome 图标的名字（不必带 fa- 前缀）。 enable 选项用于控制是否显示图标，你可以设置成 false 来去掉图标 1234social_icons: enable: true icons_only: false transition: false 开启打赏功能只需要 主题配置文件 中填入 微信 和 支付宝 收款二维码图片地址 即可开启该功能：12345678910reward_settings: # If true, reward would be displayed in every article by default. # You can show or hide reward in a specific article throuth `reward: true | false` in Front-matter. enable: true animation: false comment: 我知道是不会有人点的，但万一有人想不开呢👇reward: wechatpay: /images/wechatpay.jpg alipay: /images/alipay.png 友情链接12345678910111213# Blog rollslinks_icon: linklinks_title: 关注列表 #Linkslinks_layout: block#links_layout: inlinelinks: #Title: http://example.com Blog List: https://michael728.github.io/2018/09/16/blog-interesting/ ZeeCoder: https://zcheng.ren/posts/ ehlxr: https://ehlxr.me/ 卡瓦邦噶: https://www.kawabangga.com/ David Dai: https://blog.stdioa.com/ 建站日志: https://michael728.github.io/2016/09/03/blog-logfile/ 站点建立时间这个时间将在站点的底部显示，例如 ©2013 - 2015。 编辑 主题配置文件，新增字段 since： 订阅微信公众号12345# Wechat Subscriberwechat_subscriber: enabled: true qcode: /uploads/wechat-qcode.jpg description: 欢迎您扫一扫上面的微信公众号，订阅我的博客！ 设置动画效果主题配置文件设置。比较在乎速度，可以关闭动画。 123456789101112131415161718# Use velocity to animate everything.motion: enable: true async: false transition: # Transition variants: # fadeIn | fadeOut | flipXIn | flipXOut | flipYIn | flipYOut | flipBounceXIn | flipBounceXOut | flipBounceYIn | flipBounceYOut # swoopIn | swoopOut | whirlIn | whirlOut | shrinkIn | shrinkOut | expandIn | expandOut # bounceIn | bounceOut | bounceUpIn | bounceUpOut | bounceDownIn | bounceDownOut | bounceLeftIn | bounceLeftOut | bounceRightIn | bounceRightOut # slideUpIn | slideUpOut | slideDownIn | slideDownOut | slideLeftIn | slideLeftOut | slideRightIn | slideRightOut # slideUpBigIn | slideUpBigOut | slideDownBigIn | slideDownBigOut | slideLeftBigIn | slideLeftBigOut | slideRightBigIn | slideRightBigOut # perspectiveUpIn | perspectiveUpOut | perspectiveDownIn | perspectiveDownOut | perspectiveLeftIn | perspectiveLeftOut | perspectiveRightIn | perspectiveRightOut post_block: fadeIn post_header: slideDownIn post_body: slideDownIn coll_header: slideLeftIn # Only for Pisces | Gemini. sidebar: slideUpIn 设置背景动画编辑 主题配置文件， 搜索 canvas_nest 或 three_waves，根据您的需求设置值为 true 或者 false 即可 我只启用了 canvas_nest 12canvas_nest: //cdn.jsdelivr.net/gh/theme-next/theme-next-canvas-nest@1.0.0/canvas-nest.min.jscanvas_nest_nomobile: //cdn.jsdelivr.net/gh/theme-next/theme-next-canvas-nest@1/canvas-nest-nomobile.min.js 搜索–Local Search1$ npm install hexo-generator-searchdb --save 站点配置文件，新增如下内容：12345search: path: search.xml field: post format: html limit: 10000 编辑主题配置文件，启用本地搜索：123# Local searchlocal_search: enable: true 不蒜子统计编辑 主题配置文件 中的 busuanzi_count 的配置项：123456789busuanzi_count: enable: true total_visitors: true total_visitors_icon: user total_views: true total_views_icon: eye # 文章阅读次数，关闭，避免与leanclound_visitors冲突 post_views: false post_views_icon: eye fancybox fancyBox is a tool that offers a nice and elegant way to add zooming functionality for images, html content and multi-media on your webpages 检查_config.yml 中是否开启了 fancybox 找到 vendors，把 fancybox 和 fancybox_css 设置成推荐值 参考： 文章里面的图片点击没有反应，也没有放大效果 [solved] 内容分享theme-next-needmoreshare2：12cd themes/nextgit clone https://github.com/theme-next/theme-next-needmoreshare2 source/lib/needsharebutton 主题配置文件配置：12345678910111213141516needmoreshare2: enable: true postbottom: enable: true options: iconStyle: box boxForm: horizontal position: bottomCenter networks: Weibo,Wechat,Douban,QQZone,Twitter,Facebook float: enable: false options: iconStyle: box boxForm: horizontal position: middleRight networks: Weibo,Wechat,Douban,QQZone,Twitter,Facebook 评论Next 评论配置很简单，支持很丰富。 front matter 中设置 comments: false，当前页就不会显示评论框了。 Disqus 评论启用，但是得网络畅通才能看到：1234disqus: enable: true shortname: xxx count: true 编辑 主题配置文件， 将 disqus 下的 enable 设定为 true，同时提供您的 shortname。count 用于指定是否显示评论数量 ValineValine这个评论系统也是用到了 leancloud 点击登录或注册Leancloud; 创建应用(如果已经创建了博客应用，就不用再创建了) 获取 APP ID 和 APP KEY: 刚刚创建的应用 &gt; 设置 &gt; 应用 KEY 1234567891011valine: enable: false # When enable is set to be true, leancloud_visitors is recommended to be closed for the re-initialization problem within different leancloud adk version. appid: xxx # your leancloud application appid appkey: xxx # your leancloud application appkey notify: true # mail notifier , https://github.com/xCss/Valine/wiki https://valine.js.org/notify.html verify: true # Verification code placeholder: ヾﾉ≧∀≦)o来啊，快活啊! # comment box placeholder avatar: identicon # wavatar retro gravatar style https://github.com/xCss/Valine/wiki/avatar-setting-for-valine guest_info: nick,mail,link # custom comment header pageSize: 10 # pagination size visitor: true # leancloud-counter-security is not supported for now. When visitor is set to be true, appid and appkey are recommended to be the same as leancloud_visitors&apos; for counter compatibility. Article reading statistic https://valine.js.org/visitor.html visitor 文章访问量统计。 recordIP，默认是 fasle，是否记录评论者IP valine 配置项查看 头像设置，可以用你对应的邮箱设置 Gravatar，这样你评论时，就是注册时使用的邮箱了。 邮件提醒，进入Leancloud&gt;选择你的评论所存放的应用&gt;设置&gt;邮件模板，按下图设置好用于重置密码的邮件主题&gt;然后保存:12345&lt;p&gt;Hi, &#123;&#123;username&#125;&#125;&lt;/p&gt;&lt;p&gt;你在 &#123;&#123;appname&#125;&#125; 的评论收到了新的回复，请点击查看：&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://michael728.github.io/&quot; style=&quot;display: inline-block; padding: 10px 20px; border-radius: 4px; background-color: #3090e4; color: #fff; text-decoration: none;&quot;&gt;马上查看&lt;/a&gt;&lt;/p&gt; 参考： valine-admin 在 NexT 中使用 Valine 评论系统 hexo next 新增阅读排行页面参考这两个教程： hexo next 新增阅读排行页面 打造个性超赞博客Hexo+NexT+GitHubPages的超深度优化 在 NexT 中使用 Valine 评论系统 在Hexo博客中加入豆瓣读书页面hexo-douban 可以实现生成豆瓣读书、电影、游戏的页面。具体的使用方法可以看项目的主页或者这篇文章 在Hexo博客中加入豆瓣读书页面 1hexo clean &amp;&amp; hexo douban -bm &amp;&amp; hexo g &amp;&amp;hexo deploy 看板娘 EYHN/hexo-helper-live2d Hexo 博客照着配置就行 live2d-看板娘预览 用Live2D让看板喵入住你的Hexo博客吧(^o^)/~ 给博客添加能动的看板娘(Live2D)-关于模型的二三事 Hexo 博客看板娘配置进阶 博客园添加Live2d看板娘 博客园增加看板娘 SEO 优化 Hexo博客Next主题SEO优化方法 Hexo-Next搭建个人博客（SEO优化） Hexo+Next主题搭建博客安装美化及SEO优化指南 最后博客建完的地址：https://michael728.github.io/ 参考 hexo：（三）hexo Next 主题下载和配置 打造个性超赞博客Hexo+NexT+GitHubPages的超深度优化 手摸手教你用github和hexo搭建个人博客（五） hexo的next主题个性化配置教程 NexT 主题的扩展以及设置 Sanarous-使用Hexo+Next主题搭建自己的个人博客]]></content>
      <categories>
        <category>ToolsDaily</category>
      </categories>
      <tags>
        <tag>Blog</tag>
        <tag>Hexo</tag>
        <tag>Note</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【转】程序员的核心能力]]></title>
    <url>%2F2019%2F05%2F11%2Fthink-core-skill-programmer%2F</url>
    <content type="text"><![CDATA[原文链接：程序员的核心能力 阅读博客时发现的这篇文章，觉得说的挺有道理，转载一下。自己近期也感觉到了一些焦虑感，觉得太多东西要学了，各个技术公众号、论坛，传递出来的这些东西，都让人感觉焦虑！一直在大容量的「被灌输」，自己的主动思考却少之又少，这必然不是成长的长久之道！ 程序员要掌握的知识，要具备的能力实在太多，多得头发都不够掉。 大体有两大方向。一是对工具的熟练掌握，如操作系统、网络、IO、编程语言等；另一个是用代码为现实问题生成解决方案的能力，这其中最重要的是抽象能力。 前一个方向是很容易意识到的，很多现象可以说明这一点，比如，世面上介绍如何使用语言、框架的书汗牛充栋；比如，很多人眼里进这一行的门槛是上1个月的语言培训课。 工具的意义不容否认，为此我还写过一篇《工具优先》。但工具的生命周期其实很短，从个人发展角度看，把过多时间投入到半衰期很短的事物上，并不划算。我入门时接触的是Pascal, BasicScript, ASP, IIS，不知道现在还有没有人用这些。很多程序员也赶时髦，本来写java的，golang流行了，python流行了，学！本来搞业务开发的，大数据火了，机器学习火了，学！打的旗号自然很鲜明：持续学习。几次之后，却怅然若失，貌似没一个是拿得出手的，不过是低水平重复，换个工具，继续做原来的事而已。充其量效率提高了，但效率型工作是可替代性最强的，被其它人替代，被机器替代。 一颗上进爱学习的心，怎么就被辜负了呢？因为核心能力没有提升。人的能力好比电子围绕原子核旋转，大部分情况下处于巡航状态，在这过程中不断积蓄能量，始终向核心方向用力，就会跃迁到更高级轨道（这里指更靠近核心的轨道，实际电子是更远离核心的道）。“一万小时理论”和“10万行代码理论”只片面强调了量，如果没有聚焦核心，刻意练习，只能是低水平重复，甚至轨道降级。 核心是抽象能力。这个世界的运行，有讲逻辑的，也有不讲逻辑的。程序员要处理的事是讲逻辑的那部分，因为你所依赖的计算机是讲逻辑的，要让它意气用事，感情用情，目前还很困难。通过抽象，我们识别并保留逻辑部分，抛弃其它内容，然后用计算机语言翻译、实现这个逻辑，进而解决问题。 抽象这个词，本身就挺抽象的。到底什么是抽象？ 抽象是去除多余和细节。比如下面这个标志，一看就懂是座拱桥，但并没有显示拱桥的幅度、宽度和长度，因为这些数据对于你意识到这是一座拱桥并没有帮助。 什么是多余信息，取决于目的。考虑地铁换乘图，其目的是告诉乘客该搭哪条线，在哪里换乘，所以保留了结构关系：站点的分布，以及线路的汇合点，但忽略了物理关系：站点的地理位置、相对距离，甚至扭曲了线路的方向。而如果是开车用的导航图，则必须保证比例尺和实际情况一致，方向也不能有差错，以免误导。 抽象是建立模板或蓝图。不少公司里有邮件模板、文档模板、PPT模板、报销单模板，等等，它们规定好了结构、风格，并留出一个个空白，使用的时候填空就好。模板描述不变的内容，变量则延迟到使用场景中确定。Java编程时，经常要应用各种设计模式，其实质是通过抽象，固化不变的，封装变化的。比如，很常用的模板方法，流程和步骤无论什么场景都不变，已经在父类写好了，将具体场景的方法在父类里声明，但延迟到子类实现，封装的是方法实现。又比如，创建对象时，不常写new Tesla()，而是运用简单工厂模式，写成TeslaFactory.create()，因为对象的创建是易变的。与其在特斯拉多一个型号时，把所有new的地方都改一遍，不如在create方法里集中改。 总之，抽象是应对变化，或者说寻找不变性的手段。既可以是不同事物之间的不变性，也可以是同一事物不同历史时间的不变性。虽然这里讲的是编程，但其应用远不止于此，看看贝索斯是怎么说的： 我常被问一个问题：“在接下来的10年里，会有什么样的变化?”……但我很少被问到“在接下来的10年里，什么是不变的?”我认为第二个问题比第一个问题更加重要，因为你需要将你的战略建立在不变的事物上。 有了上面的解释，便不难理解面向对象编程的原则：依赖接口而不是实现，依赖抽象类而不是具体类。它让代码的适应性更强，将来少改代码，少出错。同时，做一些参数设定时，更加有理有据，而不是trial and error。线程池大小怎么定？不用关心具体工作，分析阻塞和非阻塞的时间比例，应用Amdahl’s law搞定。队列大小怎么定？不管究竟放的是什么，确定你期望的排队时长，用Little’s law算下。 世面上鲜有讲如何培养抽象思维的书，设计模式一类的，算搭一点边，但那是人家抽象的结果，而不是关于抽象的方法。也许我们在运用这些模式，或浏览一些工具和类库的代码过程中，偶有灵光一现，能从这些结果中反推作者的设计思想和精妙之处，毕竟它们也是抽象的结果。 学习使用工具时，如果多个心眼，留意为什么有这个工具，做了什么取舍，工具于你将不仅是效率意义。做业务开发时，如果不是简单地翻译需求，多想一层，哪里易变，哪里不易变，如何隔离变化，再简单的开发，于你也有精进意义。 抽象的层级可以有很多，能做多少层级的抽象是一种能力，而判断需要多少层级的抽象则是一种艺术。 地上一个猴，树上七个猴，一共有几个猴？1+7=8，一共八个猴，用数字符号代替猴子，这是第一层。从对象到数字，大多数人对此熟悉到甚至没有意识到这是一种抽象。再进一层，则有些困难了，当初我理解“加速度”这个概念，就费功。不光是数量，还有结构的抽象，关系的抽象。当然，它们离我们都很远…… 可是，真的很远吗？当大部分人在关心如何写程序时，有人开始研究如何用程序写程序，当大部分人在关心如何看书、学习时，有人在教别人看书、学习。]]></content>
      <categories>
        <category>思考</category>
      </categories>
      <tags>
        <tag>思考</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JetBrains PyCharm/IDEA 使用技巧总结]]></title>
    <url>%2F2019%2F05%2F11%2Ftools-dev-pycharm-idea%2F</url>
    <content type="text"><![CDATA[工欲善其事必先利其器 基本概念IDEA 没有类似 Eclipse 的工作空间的概念（workspace），最大单元就是 Project。这里可以把 Project 理解为 Eclipse 中的 workspace。Module 可以理解为 Eclipse 中的 project。一个 工程（Project） 下可以创建多个 模块（Moudle）。 src 目录，用于存放代码 .idea 目录和 project01.iml 文件都是 IDEA 工程特有的。 删除 module ，这样不会删除代码文件，只是从 Project 中移除组织关系，如下图： 系统设置设置显示收藏栏等工具栏 取消更新取消 IDEA 自动更新，避免引入不稳定的问题： 设置Tab为4个空格Editor-&gt;Code Style-&gt;Java/Python，不要勾选Use Tab character 支持滚轮调节字体大小Editor-&gt;General，勾选 Change font size(Zoom) with Command+Mouse Wheel 鼠标滑过，显示文档Editor-&gt;General，Show quick documentation on mouse move，输入延迟时间。鼠标滑过类、方法时，显示文档说明 显示行号和方法分隔符在 Editor-&gt;General-&gt;Apperance 中，勾选： Show line numbers 显示行号 Show method separators 这个是显示方法分隔符的，我没勾选 Show whitespace 显示空格符号，针对 Python，「游标卡尺」的名号不是白叫的，所以，必须设置显示空格、缩进等 参考： 舒服的pycharm设置 给提示时忽略大小写Java 是严格区分大小写的，未设置时，输入 str 时，它不会提示 String，要想实现忽略大小写的情况它也能智能提示，可以进行如下设置，而且，这样设置它也不是完全按照首字母进行匹配了，比如你输入 hmap 时，也会看到 HashMap 的智能提示，相当方便。Editor-&gt;Genreral-&gt;Code Completion： 这个设置是非常有帮助的，强烈推荐设置。可以顺带勾选上 Show the documentation，这样在补充时，也会显示文档。 取消单行方法折叠的设置IDEA 中对于单行方法会默认折叠，使代码更紧凑。但是我阅读代码时，不太喜欢这种默认设置。可以根据如下设置修改： Settings-&gt;Editor-&gt;General-&gt;Code Folding-&gt;One-line methods，取消勾选即可 自动导包 import popupEditor-&gt;General-&gt;Auto Import-&gt;Python-&gt;Show import popup 手动导包的快捷键是 Alt+Enter 设置换行符默认为LFEditor-&gt;Code Style 页面不仅能设置换行符，还可以设置 wrap columns。 参考： IntelliJ换行CRLF, LF, CR的解释和默认设置 设置 File Encodings 文件编码Settings-&gt;Editor-&gt;File Encodings，编码全都设为 UTF-8。 不建议勾选 Transparent native-to-ascii convention 设置头信息Settings-&gt;Editor-&gt;File and Code Templates-Files-&gt;Includes-&gt;File Header 设置如下模板 Python 头信息设置： 123456#!/usr/bin/env python# -*- coding: utf-8 -*-# @Date : $&#123;DATE&#125; $&#123;TIME&#125;# @Author : $&#123;USER&#125;# @File : $&#123;NAME&#125;.py# @Software: $&#123;PRODUCT_NAME&#125; Java 头信息设置： 1234567/** * description: * * @author $&#123;USER&#125; * @date $&#123;DATE&#125; * @time $&#123;TIME&#125; */ 自动编译有时候我们需要操作 class 文件时，却忘记了对 java 类文件进行编译，从而还是对旧的文件进行了操作。 import 每个类而非整个包，少用通配符settings &gt; Editor &gt; Colors Style &gt; Java &gt; Imports &gt; Class count to use import with ‘*’ 设置大一点。 当 Java 类中 import 某个包下的类超过这里设置的个数，就会换成用星号来代替，比如 import java.util.* 设置 Tab 标签页File-&gt;Editor-&gt;General-&gt;EditorTable-&gt;Tab closing Policy-&gt;Tab limit 在 Windows-&gt;Editor Tabs 可以设置标签页的相关内容，比如： Tabs Placement 放置位置，我勾选了 Top 勾选了 Sort Tabs By Filename 勾选了 Open New Tabs At The End 取消勾选 Show tab in single row，避免打开类文件多时，选择不方便 我设置最多打开标签页10个，同时将位置移到了右边，通过alt+←/→可以切换工作区。默认是10，即最多打开十个窗口，再打开新的就会把之前的窗口T掉！ IntelliJ IDEA设置打开窗口的数量 自定义 Terminalsettings-&gt;Tools-&gt;Terminal Shell path 原来的值是: C:\Windows\System32\cmd.exe Windows 修改为： C:\Program Files\Git\bin\bash.exe 修改为 Git bash 的终端； &quot;C:\Windows\System32\cmd.exe&quot; /k &quot;&quot;%CMDER_ROOT%\vendor\init.bat&quot;&quot; 修改为 Cmder 的终端，这种方式就会弹出 Cmder 的窗口，需要配置系统变量 CMDER_ROOT，值为：D:\Green-SF\cmder。 设置 Terminal 窗口字体和大小：Editor–&gt;Color Scheme–&gt;Console Font，在右侧面板修改Font为自己想要的字体。 参考： Pycharm官宣-Terminal Github-Run cmder inside IntelliJ idea Windows 上切换 Jetbrains IDE 的 terminal 为 PowerShell 或 cmder 版本控制下文件变化的显示settings—Version Control—Show directories with changed descendants 开启后若想调整文件夹的显示颜色：settings—Version Control—File Status Color 打开内存使用状态settings—Appearance &amp; Behavior—Appearance—Show memory indicator 参考： 玄玉-idea配置小结 博主介绍的很详细 用 * 标识编辑过的文件这样被修改的文件会以 * 号标识出来： Editor –&gt; General –&gt; Editor Tabs，勾选 Mark modifyied(*) 脚本运行结束后留在命令行这样脚本运行中的变量在脚本结束后还可以调用，调试时还是挺好用 pycharm常用设置和技巧 添加 JavaDOC 注释 把光标停在类名或者方法名上，然后 Alt+enter，出现几个选项，选择 Add Javadoc 就 OK 了 默认 Fix doc comment 是没有设置快捷键的，我这里把他设置成 Alt + M 参考： 开源中国-IDEA添加JavaDOC注释 方法 快捷键 生成 JavaDOCJavadoc 用于描述类或者方法的作用，具体介绍，可查看CSDN-Javadoc 使用详解 12Locale：输入语言类型：zh_CNOther command line arguments：-encoding UTF-8 -charset UTF-8 缓存和索引的清理IDEA 首次加载项目时，都会创建索引。创建索引的过程，暂时不要去编辑代码，避免遇到未知问题。有时候意外断电或蓝屏，出现索引损坏情况，可以清除缓存和索引，还原成默认状态。 File-Invalidate Caches 这个会将本地修改历史也会清理掉，如果想要将这个数据保留，LocalHistory 需要提前备份： 1234# system 目录，系统文件目录，是 IDEA 与开发项目一个桥梁目录，里边主要有缓存、索引、容器文件输出等等/Users/michael/Library/Caches/IntelliJIdea2018.2/LocalHistory# 顺带看一下 config 目录，是 IDEA 个性化设置目录，是整个 IDE 设置目录/Users/michael/Library/Preferences/IntelliJIdea2018.2 参考： Where is IntelliJ IDEA config stored in OSX? 官宣-Directories used by the IDE to store settings, caches, plugins and logs 显示窗口 split有时候可以将当前窗口 split，可以垂直或者水平分割，方便阅读代码 省电模式在菜单栏 File 下面有一个选项是 Power Save Mode，这个叫「省电模式」，如果不小心勾选了这个选项，那么会关掉代码检查和代码提示等功能，所以需要注意。 快捷菜单Mac 的 Command 键一般是对应了 Win 的 Ctrl 键，在 Win 上，还可以用 Alt+&lt;n&gt; 打开相关窗口，在 Mac 上同样要使用 Command+&lt;n&gt;。 除此以外，还可以在 Settings-Keymap 中，设置快捷键、输入快捷键查看对应的功能。 快捷键设置 alt+r：打开最近项目 ctrl+shift+o：打开项目 自动补全快捷键，默认是 ctrl+空格，这个和一些中文输入法的切换快捷键冲突了，于是，我多设置了一个 ctrl+/ ： 常用快捷键在介绍常用快捷键之前，先看看这个快捷键 ctrl+shift+a，Find Action 快捷键，输入关键词，不会的就问它，超级赞！！！★★★ alt+↑/↓: 快速在方法间跳转 ★★ alt+p：打开Python控制台 ★★★ alt+insert 生成代码(如 get, set 方法,构造函数等) 或者右键（Generate），在 Mac 上是 ctrl+n ★★★ alt+enter 万能键，任何地方都可以尝试使用，不同场景有不同的表现方式，比如自动导包等功能，不管出错了不知道怎么办，知道怎么办想这么办时都按下这个快捷键，有惊喜，万能纠错键 ★★★ alt+f7 找当前变量、方法在哪些地方用了 find usaged ★★★ alt+f12 打开命令行终端(view-&gt;tool window) ★★★ ctrl+space 万能提示键，基本代码补全 ctrl+f4：关闭当前页 ctrl+f12: 结构视图 File Structure，查看 class method field，阅读源码查看类方法时很方便 ★★★ ctrl+home、ctrl+end 回到页首/页尾，关键字 Move Caret to Text End 或者 开头 Move Caret to Text Start，参考 查看接口继承关系： ctrl+h 查看类型继承关系 type hierarchy,只能查看向上向下继承关系，而不能看实现了哪些接口。查看继承关系，右击，点击 Digram 查看； ctrl+alt+h 查看函数调用层次结构关系 call hierarchy，可以看到函数被哪些地方调用了，但是需要谨慎，部分人不会注意到后面的调用次数！为了防止遗漏，建议使用 alt+f7 这个快捷键 ★★★ ctrl+alt+b 查找接口的实现类 注释 ctrl+/ 注释 ctrl+shift+/ 多行注释 ctrl+u 查看当前方法的父方法 super method，比如 service 的实现类中，跳转到覆盖的接口方法 ctrl+d 复制当前行 ★★ ctrl+e 打开最近文件 ★★★ ctrl+p 有时候敲了方法，忘记方法可以使用什么参数，那么这个快捷键可以显示 parameter info 删除当前行 ctrl+y 删除当前行 ★★★ ctrl+x 剪切（会删除当前行）★★★ ctrl+w 不断按下这个快捷键，选择代码块范围逐步扩大；★★★ 换行 shift+enter 向下另起一行 ★★★ ctrl+alt+enter 向上另起一行 ★★★ crtl+q 查询documentation ctrl+鼠标点击 查看内置函数啥的 ctrl+alt+←/→ 快速跳转光标刚刚所在行 ★★★ ctrl+alt+b 所有的实现类（Implementation）★★★ ctrl+alt+h 谁调用了这个方法，查看调用层次（Call Hierarchy）★★ ctrl+alt+L，格式化代码（Reformat Code） ★★★ ctrl+alt+o 优化 imports Optimize Imports，优化导入的类和包 ★ ctrl+shift+enter 补全语句，complete current statement 不管光标是不是在行尾，可以补全必要的字符，比如行尾的分号 ★★ ctrl+shift+b 查看接口中方法的实现方法； ctrl+shift+u：大小写转换，在 Edit-&gt;Toggle Case 中能看到选项 ★ ctrl+shift+v：从最近的缓冲区粘贴 ctrl+shift+backspace 快速跳转到最后修改的地方 ★★★ ctrl+shift+v 在 Pycharm 中，访问历史粘贴板 ★★ ctrl+shift+/- 代码块折叠★ ctrl+alt+shit+j 多目标选择选择的词，或者用alt+鼠标点击也可以实现效果，Select All occurrences★★ ctrl+alt+shit+t 重构利器 shift+f6：文件重命名 ★★★ shift+f2：跳转到上一个高亮错误 或 警告位置 搜索 shift 双击，搜索一切，不管是 IDE 功能、快捷键、文件、方法、变量，它都能搜索，使用频率很高的一个快捷键！可以按最近使用过的文件名, 类名, 方法名等去搜索定位! ★★★ ctrl＋n：快速按照名字搜索类 ctrl＋shift＋n：快速搜索文件 ctrl+shift+f: 在整个项目中 或 指定目录里 进行全局搜索 ★★★ ctrl＋alt+shift＋n：快速搜索函数 参考： 极客学院-IntelliJ IDEA 使用教程-快捷键 alt+enter 快捷键的妙用万能接错/生成返回值变量。创建对象时，可以先 new 后alter+enter，IDEA 会自动补全，直接让你输入对象名： 其他 scroll from source，点击这个按钮，可以快速跳转到打开的文件所在的文件夹中，非常有用提高效率的按钮 ★★★ 模板模板： Editor-&gt;Live Templetes，可以做一些用户的定义，可修改 关注 iteration 关注 other 关注 output 关注 plain Editor-&gt;General-&gt;Postfix Completion 不可修改 常用模板 psvm 再按 Tab 生成 main 方法，或者，输入 main 之后，再按 ctrl+j sout 输出函数 soutp 打印函数的形参 soutv 打印变量值，就近的打印变量的值； soutm 打印方法的名字 xxx.out 打印某变量 xxx 的值； fori 循环，按 tab/enter 进入下一处修改 itar 循环控制语句是 xxx.length iter 增强 for 循环（for each） users.for+tab 快速生成 users 的增强 for 循环 list.for 集合 list.fori list.forr 逆序遍历，倒序遍历 ifn 条件判断，判断等于 null inn 不等于 null prsf 私有静态的常量 psf 生成 public static final psfs 生成 public static final String 快捷键 ctrl/command+j 可以查看有哪些缩写字符。 更多关于模板的知识，点击官宣-live templates 参考： IntelliJ 创建main函数快捷 修改模板在 Live Templates 中修改模板 abbreviation 模板的缩略名称 template text` 模板的 diamante 片段 应用范围，点解 Define，选择 Java 添加一个 String 类型的带注释的模板，叫 prsc： 12345/** * $VAR1$ */ private String $VAR2$; $END$ 版本控制 VCS 添加 Github 账户 Settings-&gt;Version Control-&gt;GitHub 为何要添加这个账户呢？ 因为你就可以直接在 VCS 菜单栏中克隆代码库，多种方式： Checkout from Version Control -&gt; Git Git -&gt; Clone 可以选择待下载的代码库 File -&gt; Project from Version Control -&gt; Git 在 Github 创建仓库VCS -&gt; Import into Version Control -&gt; Share Porject on GitHub 会将代码仓库提交到 GitHub 上，新建一个仓库 使用 Git 工具 查找背锅侠：Annotate/Blame 选中 Annotate 的 Commit，点击 Show Diff 观察差异（Ctrl+D） 查看当前文件的历史版本：工具栏有个时间标志，Show History，查看最近是否有人修改过，通过 Ctrl+D 查看对比——Alt+H 高级筛选方式查找 commit 记录 显示差异： Show Diff —— Ctrl+D 右键菜单中有一个 Open On Github，跳转到正在浏览的行所在的文件，方便分享讨论具体问题 调试&amp;源码阅读技巧 step over F8 下一步，当前断点如果是一个方法，不会进入方法体内； step into F7 下一步，当前断点如果是一个方法，则进入方法体内，不过默认情情况下并不会进入 java.* 等类的方法中。如果需要进入，可以在 Setting -&gt; Stepping 中设置,排除即可 force step into Alt+Shift+F7 下一步，当前行如果是一个方法，强制进入方法体内； step out Shift+F8 跳出 run to curser Alt+F9 运行到鼠标所在行，临时设置断点，有用 resume program F9 运行到下一个断点处，是不是有点像 pdb 中的 c 快捷键； stop Command+F2 停止 view breakpoints 查看所有断点，可以在运行时选择哪些断点暂停略过； mute breakpoints 所有断点失效/生效的切换； 调试器是什么debugger 调试器，“除虫器”，调试器是用来告诉 JVM，请你在具体的哪个断点处停下来 堆 Heap: 所有对象都在堆上分配 栈 Stack：先进后出 LIFO 后进先出，Last In First Out 线程：每个线程会有一个方法栈，出栈，后进先出，你自己的是 main 线程，观察这个方法栈即可； 栈帧 Stack Frame：方法栈中的每一个小方块，局部变量仅存在于方法的栈帧中，当方法运行完，栈帧就会被丢弃 可以修改执行结果，修改执行流程中的值： 右击调试器中的变量，View/Edit Text 右击调试器中的变量，Set Value 跳转到源代码 右击调试器中的变量，Jump to Type Source 条件断点在循环里增加条件判断，具体操作：在断点处右击，在某个条件下，实施断点。 查看表达式的值（可以查看已有变量的值）： 线程断点我们可以在断点上使用鼠标右键弹出断点设置框，在 Suspend 选择 Thread 选项。断点的多线程属性可以设置默认属性，点击 Make Default 按钮，设置默认 Suspend 属性 调用栈ctrl+alt+h 快捷键 参考： IDEA的查询引用、调用关系图的功能 Intellij IDEA神器常用技巧八-2018版本新增快捷键 挖掘IntelliJ IDEA的调试功能 DEBUG 模式下提前返回，而不终止程序在 Frames 窗口下，选择当前的 Frame，右击，选择 Force Return。 这个功能在调试的时候十分有用，既可节约运行的时间，避免程序重启，又可以避免程序走到后面不想调试的步骤去。 参考： Intellij IDEA 在DEBUG模式下如何不执行后续代码直接停止程序？ 查看继承关系快捷键：Ctrl+H IDEA查看接口或类的继承实现关系图 IntelliJ IDEA 中如何查看一个类的所有继承关系(当前类的所有继承关系图) 还有一个更加厉害的功能 show diagram，可以查看继承链。鼠标右键中有 Diagrams 的菜单。快捷键：Ctrl+Alt+Shift+U 蓝色实线是指继承关系 绿色实线表示的是接口的继承关系 绿色虚线是指接口实现关系 详细介绍参考： cnblogs-使用IntelliJ IDEA查看类的继承关系图形 设置程序环境变量Run-&gt;Edit Configurations-&gt;Environment-&gt;Environment variables 1System.getenv("HOME_TEST"); Maven 设置不推荐使用 IDEA 自带的 Maven 配置。在 Settings -&gt; Build Excution Deployment -&gt; Build Tools -&gt; Maven 中修改： Maven home directory maven 安装目录 User settings file 勾选 Override，改为自己的 settings.xml 文件 Local repository 依赖包存储位置 在 Settings -&gt; Build Excution Deployment -&gt; Build Tools -&gt; Maven -&gt; Importing 中： 勾选 Import Maven projects automatically pom 文件增加了新依赖，会自动下载； 为了避免每次打开或者新建项目时，都要设置一次 Maven 的配置，可以给 IDEA 设置默认 maven 版本： 选择 File -&gt; Other Settings -&gt; Settings For New Projects... -&gt; Build,Execution,Deployment -&gt; Build Tools -&gt; Maven，找到 maven 配置的地方，选择需要默认配置的版本，保存。至此便完成了默认 maven 版本的配置。 参考： CSDN - IDEA 配置自定义maven 高效定位代码-无处不在的跳转project之间跳转ctrl+alt+左右方括号： 查看快捷键ctrl+shift+a：搜搜快捷键 查看最近文件ctrl+e可以在ctrl+shift+a：搜索reccent … 快速跳转到最后修改的地方ctrl+shift+backspace 快速跳转到最后修改的地方 利用书签跳转 F11：添加、取消书签 ctrl+f11：添加、取消有标记的书签 ctrl+&lt;n&gt;：跳转到有标记的书签处 添加收藏 Favoritesalt+shift+f：add to favorities 编辑区和文件区的跳转alt+1进入文件区esc：进入编辑区 精准搜索类搜索ctrl+n：快速搜索类 文件搜索快速打开指定的文件，方便★★★：ctrl+shift+n 函数搜索-symbolctrl+shift+alt+n 搜索 Maven 依赖包中的内容有时候可能需要在源码分析时想要搜索 Maven 依赖包中的内容，只要如下设置即可扩大搜索范围： ctrl+shift+f -&gt;scope-&gt;All Places 重构 Shift+F6 重命名所有的文件，类名，函数名，属性名都可以重命名，值得点赞的是，只要你使用 Shift+F6 重命名，所有使用过这个名称的地方都会跟着改变； 函数的重构，Ctrl+F6 重构函数当你需要重构方法时，无论是增加参数，修改返回值，还是更改函数实现，只需要Ctrl+F6，就可以把所有用到此函数的地方一起重构 参考： 你们都在用IntelliJ IDEA吗？或许你们需要看一下这篇博文 列操作 选中单词转大写 多光标选中 多光标 按住 Alt 键，可以快速实现多光标、块选择。 界面中的基本功能如果没有如老师那样的窗口，可点击view-&gt;tool buttons打开 alt+&lt;n&gt;快捷键 ★★★如下图圈出的数字 n，可以使用alt+&lt;n&gt;的方式快捷使用，替代鼠标操作。 注意，Mac 使用的是 command+&lt;n&gt;方式； 打开收藏 ★★★在一些调试的函数那里打断点，然后alt+7收藏中就会方便的查看； TODO在项目中使用# TODO，可以在Alt+6中看到哪些待开发的备注 必备插件关于插键，单独总结了关于插键的文章 FAQQ: intellj Idea中给新建的项目导入jar包？ 推荐intellij idea Project Structure 讲解 Q: 找不到提示IntelliJ cannot find any declarations Right-click src folder Mark Directory as &gt; Sources Root Q: IDEA编译通过能运行但是出现红色下划线原因就是可能没有清除原来的历史缓存，导致一些错误，解决方法是：File-Invalidate Caches，然后重启IDEA 最后近期由于微博图床挂了，所以，截图都看不了了，点击原文链接，可查看图片： PyCharm/IDEA 使用技巧总结 参考 IntelliJ IDEA 使用教程 简书-IntelliJ IDEA 教程 技巧篇 作者写了一系列的总结 你有哪些想要分享的 PyCharm 使用技巧？ IntelliJ IDEA神器使用技巧 Java人员正确使用 IntelliJ IDEA的方式 挖掘IntelliJ IDEA的调试功能 IDEA 注册-lanyu Github-judasn/IntelliJ-IDEA-Tutorial IntelliJ IDEA 2019.3.3 便携增强版 张振伟的博客/IDEA 作者写了很多 IDEA 使用技巧的文章，推荐]]></content>
      <categories>
        <category>ToolsDev</category>
      </categories>
      <tags>
        <tag>IDE</tag>
        <tag>IDEA</tag>
        <tag>Pycharm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ss+vps+mac]]></title>
    <url>%2F2019%2F04%2F27%2Ftools-ss-vps%2F</url>
    <content type="text"><![CDATA[Vultr 选择的是日本的节点，发现速度比较不错，油管视频 1080P 无压力！而且，感觉 Vultr 的界面也很清新，用着很方便。 我自搭梯子，选择的是：Shadowsocks-libev+开启simple-obs插键+BBR加速 20191013 更新，发现使用 kcptun 加速效果更明显！于是改为Shadowsocks-libev+开启simple-obs插键+ kcptun加速 Vultr 通过我的链接注册充值，你我都可以获得 $10 账户返利，所以，如果有需要，就点击注册吧： Vultr 注册返利链接 VPSvultr速度比较： vultr-downloadspeedtests vultr中文网 我选择的节点是日本的节点，离得近，速度能快点。 建议选择 Ubuntu 18 或者 CentOS 8 开始的版本，这样就默认开启了 BBR 的设置，有加速的效果。 设置时区时区保持一致很重要，尤其是 v2ray 方式： 123456# 查看时间和本地时间是否一致date -R# 设置一致，东八区sudo -icp /usr/share/zoneinfo/Asia/Shanghai /etc/localtimedate -R BBRBBR 开启，可以起到加速作用。如果用的是 CentOS 8 或者 Ubuntu 18 的话，可能都不需要开启，因为默认就开启了。 BBR 一键安装： 1wget --no-check-certificate https://github.com/teddysun/across/raw/master/bbr.sh &amp;&amp; chmod +x bbr.sh &amp;&amp; ./bbr.sh 安装过程，需要重启机器一次。重启之后，输入 lsmod | grep bbr 看到输出有 bbr 则代表 OK 了。 参考： 上网配置 bbr 开启和 ssr 搭建 Ubuntu 18.04/18.10快速开启Google BBR的方法 辅助工具 https://tools.ipip.net/traceroute.php http://ping.pe/ping.php https://www.uuidgenerator.net/ shadowsocks安装 ss在 VPS 机器上安装好 ss 客户端： 123wget --no-check-certificate -O shadowsocks-all.sh https://raw.githubusercontent.com/teddysun/shadowsocks_install/master/shadowsocks-all.shchmod +x shadowsocks-all.sh./shadowsocks-all.sh 2&gt;&amp;1 | tee shadowsocks-all.log 注意，建议选择 Shadowsocks-libev 版本。 按照提示，设置好端口、密码、选择加载 simple-obfs 插件。 卸载的命令： 1./shadowsocks-all.sh uninstall ss 服务端相关配置启动脚本后面的参数含义，从左至右依次为：启动，停止，重启，查看状态。 Shadowsocks-Python 版：/etc/init.d/shadowsocks-python start | stop | restart | status ShadowsocksR 版：/etc/init.d/shadowsocks-r start | stop | restart | status Shadowsocks-Go 版：/etc/init.d/shadowsocks-go start | stop | restart | status Shadowsocks-libev 版：/etc/init.d/shadowsocks-libev start | stop | restart | status 配置文件： 1234567891011Shadowsocks-Python 版：/etc/shadowsocks-python/config.jsonShadowsocksR 版：/etc/shadowsocks-r/config.jsonShadowsocks-Go 版：/etc/shadowsocks-go/config.jsonShadowsocks-libev 版：/etc/shadowsocks-libev/config.json netstat -nl | grep 12250 或 ss -nl | grep 12250 可以查看 ss 服务的端口，12250 仅仅是示例，需要换成你自己设置的 ss 端口。 ss 服务端配置参考： 1234567891011121314[root@vultr ss]# cat /etc/shadowsocks-libev/config.json&#123; "server":"0.0.0.0", "server_port":12250, "password":"xxxx", "timeout":300, "user":"nobody", "method":"aes-256-gcm", "fast_open":false, "nameserver":"8.8.8.8", "mode":"tcp_and_udp", "plugin":"obfs-server", "plugin_opts":"obfs=http"&#125; 加速配置kcptun除了上面介绍的 BBR 加速方式之外，还有 kcptun 的加速。二者选择一种即可。 1234mkdir /data &amp;&amp; cd /datawget --no-check-certificate https://github.com/kuoruan/shell-scripts/raw/master/kcptun/kcptun.shchmod +x ./kcptun.sh./kcptun.sh 配置： 端口：默认29900，即为KCPTUN与其客户端连接使用的端口，默认即可，这个端口号其实也是有用的，客户端启用 kcptun 插件时，端口要写这个，而不是 ss 的端口号！！！ 要加速的地址：默认 127.0.0.1。 要加速的端口：设置为你的 SS/SSR 使用的端口，这里要注意！！！ 密码：自己设置，用于KCPTUN客户端连接使用，不要使用默认密码。 加密方式选择：较强的加密方式会影响网速，建议默认aes或不加密。 加速模式：默认fast即可。随后可以手动修改为其它模式，测试加速效果。 MTU：默认1350即可。 sndwnd：发送窗口大小，与服务器的上传带宽大小有关，这项与rcvwnd的比例会影响加速效果，可以暂时设置为默认的512，服务端的这个值和客户端的 rcvwnd 关系紧密，影响速度，需要调试 rcvwnd：接收窗口大小，与服务器的下载带宽大小有关，也可以暂设置为默认的512，或者1024也可以。 以下几项中，除了数据压缩外，其它保持默认参数即可。建议关闭数据压缩，可以在一定程度上提升传输效率。 其余各项设置，保持默认即可，设置完成后，按任意键开始安装过程。 安装好之后，记录下最后的输出信息，后面有用。 kcptun 服务端配置参考： 123456789101112131415161718[root@vultr ss]# cat /usr/local/kcptun/server-config.json&#123; "listen": ":39901", "target": "127.0.0.1:12250", "key": "xxxx", "crypt": "aes", "mode": "fast2", "mtu": 1350, "sndwnd": 2048, "rcvwnd": 2048, "datashard": 10, "parityshard": 3, "dscp": 0, "nocomp": false, "quiet": false, "tcp": false, "pprof": false&#125; KCPTUN常用功能及命令： KCPTUN安装目录：/usr/local/kcptun KCPTUN的参数配置文件：/usr/local/kcptun/server-config.json 启动：supervisorctl start kcptun 停止：supervisorctl stop kcptun 重启：supervisorctl restart kcptun 状态：supervisorctl status kcptun 打印出服务器信息：./kcptun.sh show ——— 多亏了这个命令，看到了 remoteaddr 值，这个也是启用 kcptun 插键后，你本地 ss 客户端要配置的 IP 和 端口号 更新：./kcptun.sh update 查看日志：./kcptun.sh log 卸载：./kcptun.sh uninstall 更多使用说明 cd /data &amp;&amp; ./kcptun.sh help 配置参数调试： 同时在两端逐步增大 client rcvwnd 和 server sndwnd; 尝试下载，观察如果带宽利用率（服务器＋客户端两端都要观察）接近物理带宽则停止，否则跳转到第一步。 参考： KCPTUN-网络加速方案 kuoruan/shell-scripts Kcptun 服务端一键安装脚本 KCPTUN ss 客户端客户端下载 Shadowsocks各种客户端 ShadowsocksX-NG/releases Mac 客户端下载 xtaci/kcptun shadowsocks/shadowsocks-android Android 插键-shadowsocks/kcptun-android kcptun 加速需要使用的插键 插键-shadowsocks/simple-obfs-android 客户端配置shadowsocks 客户端要设置的是你 vps 上 kcptun 的默认端口，例如 29900，而不是你设置的 shadowsocks 端口，否则，你使用 kcptun 插键将不会生效，网络会无法访问，除非你客户端不启用 kcptun 插键。 端口号填写 KCPTun 的端口号，这个注意点坑了我好久！ 加密方式填写 SS 的加密方式 密码填写 SS 的密码 插件直接手动输入 kcptun。 插件选项填写 tcptun 安装完成图中的 手机参数可使用 下面的记录即可 NG 客户端插键配置 kcptun 插键选项： 1key=xxx;crypt=aes;mode=fast3; simple-obfs 插键选项： 1obfs=http;obfs-host=www.bing.com v2ray 方式在使用 v2ray 之后，发现这个方式更加便捷一点，因为它既支持 shadowsocks 协议，又支持 vmess 协议，提供两种链接方式。 于是，目前（20191103）就采用了 v2ray 的方式+bbr加速+kcptun加速，然后配置了 v2ray 和 ss 的链接方式。 一键安装脚本： 1bash &lt;(curl -s -L https://git.io/v2ray.sh) v2ray 端口：62666 选择安装 ss ss 端口：62888 v2ray 配置生成器：https://intmainreturn0.com/v2ray-config-gen/ 输入 v2ray url 可生成 vmess URL 链接 / 输入 v2ray qr 可生成二维码链接 输入 v2ray ssqr 可生成 Shadowsocks 二维码链接 相关路径： 在 Linux 中，日志通常在 /var/log/v2ray/access.log 文件中 教程 v2ray 官方文档 白话文教程 白话文教程-社区版 V2Ray完全使用教程 服务端搭建Shadowsocks和V2Ray详解 这位博主，貌似真的把可用的账号提供出来了！ 油管视频-V2Ray官方脚本搭建教程 客户端神一样的工具们 官方文档里也放了链接（这个连接需要 FQ 才能打开），下面列一下我自己用的： yanue/V2rayU Mac 最新一次更新 20190920 2dust/v2rayNG Andriod 最新一次更新 20191101 v2ray/v2ray-core FAQ查看日志 查看本地客户端的 ss 日志：点击小飞机-》显示日志-》~/Libray/Logs/ss-local.log 查看本地 kcptun 插键是否启动： ps -ef | grep kcptun 查看服务端 kcptun 的日志，如果本地请求正常发送，那么会有日志输出：cd data &amp;&amp; ./kcptun.sh log 其他Docker方式 docker文档 docker-ss-搜索结果 网关方式： 油管达人分析的各种方式的优缺点 他最推荐的还是网关方式，此外还有 trojan、软路由等方式 参考 haoel-科学上网 耗子叔写的 聪聪-SS/SSR 简介 写给非专业人士看的 Shadowsocks 简介 VPS+ShadowsocksR 搭建自己的 VPN Ubuntu 16.04下Shadowsocks服务器端安装及优化 秋水逸冰-使用 Docker 快速部署 Shadowsocks-libev + v2ray-plugin 使用docker快速部署shadowsocks-libev+v2ray-plugin代理]]></content>
      <categories>
        <category>ToolsDaily</category>
      </categories>
      <tags>
        <tag>ss</tag>
        <tag>vps</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux lvm 分区知识笔记]]></title>
    <url>%2F2019%2F04%2F23%2Flinux-lvm-partion%2F</url>
    <content type="text"><![CDATA[盘面上可以细分出扇区（Sector）与柱面（Cylinder)两种单位，其中扇区每个为512bytes那么大。 通常所说的”硬盘分区”就是指修改磁盘分区表，它定义了”第n个磁盘块是从第 x个柱面到第y个柱面”.因此，当系统要读取第n个磁盘块时，就是去读硬盘上第x个柱面到第y个柱面的信息. 整块磁盘的第一个扇区特别重要，因为它记录了整块磁盘的重要信息： 主引导分区（Master Boot Record, MBR）：可以安装引导加载程序的地方，有446bytes. 分区表（partition table）：记录整块磁盘分区的状态，有64bytes。 磁盘分区表（partion table）在分区表所在的64bytes容量中，总共分为四组记录区。每组记录区记录了该区段的起始与结束的柱面号码。 其实所谓的分区只是针对那个64bytes的分区表进行设置而已。 硬盘默认的分区表仅能写入四组分区信息 四组分区信息我们称为主（Primary）或者扩展（Extended）分区。 分区最小单位为柱面（cylinder）。 分区的优点： 数据安全 有助于数据读取的速度和性能 扩展分区的目的是使用额外的扇区记录分区信息，扩展分区本身并不能拿来格式化。由扩展分区切出来的分区，就被称为逻辑分区（logical partition）。逻辑分区的设备名称号码由5号开始。 主分区、扩展分区和逻辑分区的定义： 主分区与扩展分区最多可以有4个（磁盘限制） 扩展分区最多只有1个（操作系统限制） 逻辑分区是由扩展分区持续切割出来的分区 能够被格式化后作为数据访问的分区为主分区与逻辑分区，扩展分区无法格式化。 逻辑分区的个数依操作系统而不同，SATA硬盘则有11个逻辑分区（5号到15号）。 分区是个很麻烦的东西，因为它是以柱面为单位的“连续”磁盘空间，且扩展分区又是类似独立的磁盘空间。 扩展分区是不能直接用的，他是以逻辑分区的方式来使用的，所以说扩展分区可分成若干逻辑分区。 他们的关系是包含的关系，所有的逻辑分区都是扩展分区的一部分。 磁盘分区LVM卷管理123456789disk=/dev/vdbpvcreate $disk # 磁盘还没有分主分区或者扩展分区，就可以直接创建物理卷（Physical volume (PV) ）了，物理卷的名字就是磁盘的名字/分区的名字vgcreate ci-vg $disk # 创建卷组Volume group (VG)，卷组名为 ci-vg1lvcreate -L 100G -n app_data ci-vg # or lvcreate -L 100G --name app_data ci-vg，将ci-vg 卷组中的 100G 空间划分为逻辑卷Logical volume (LV)，逻辑卷名为 app_data# lvcreate -l +100%FREE -n app_data ci-vg 将卷组百分百的空间都划分给 app_data 这个逻辑卷lvdisplay # 查看逻辑卷路径mkfs.ext3 /dev/ci-vg/app_data # 格式化mount /dev/ci-vg/app_data /data # 挂载，前提是要有 /data 目录df -Th # 查看 接着，为了开机自动挂载，执行： 1echo "mount /dev/ci-vg/apkg /apkg" &gt;&gt; /etc/rc.d/rc.local 这个命令在有些情况不会生效，开机自启挂载磁盘，稳妥的方式推荐编辑 /etc/fstab 文件：1/dev/ci-vg/app_data /data ext3 defaults 0 0 分区常用命令 lsblk：查看磁盘分区情况 ★★★ vgdisplay: 查看卷组信息 vgs： 查看卷组信息，简略 fdisk -l：查看系统内分区信息 扩容1234pvcreate /dev/vdc # 新增磁盘vdc，创建为物理卷vgextend ci-vg1 /dev/vdc # 将新增的物理卷添加到已有的逻辑卷组中lvextend -l +100%FREE /dev/ci-vg/data_app # # 用 lvextend 将 /dev/ci-vg1/apkg 所在卷组所有剩余空间都分配给了它resize2fs /dev/ci-vg/data_app # # 磁盘格式是 ext2 ext3 ext4 使用 resize2fs， xfs使用 xfs_growfs 对扩容后的 LV 格式大小调整 扩容参考 手把手教你给 CentOS 7 添加硬盘及扩容(LVM) Linux LVM分区之VG扩容、LV扩容、LV缩减、LVM快照 Linux LVM 动态扩容（在线） FAQQ1：发现开机启动时，rc.local没有自启动执行尝试了chmod +x /etc/rc.d/rc.local之后，问题依旧，排除了权限的问题。编辑rc.local文件，在touch /var/locak/subsys/local下一行，加上sleep 10，问题解决。 Q2: -bash: pvcreate: command not found通过yum install lvm2安装，支持命令。 参考 LVM (简体中文)) Linx卷管理详解 Linux逻辑卷详解总结 Linux 磁盘和分区 Linux LVM简明教程 开机挂载 CentOS 6.3开机自动挂载磁盘和文件夹 fstab 文件格式介绍]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>分区</tag>
        <tag>lvm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[笔记-玩转Spring全家桶]]></title>
    <url>%2F2019%2F04%2F18%2Fnote-spring%2F</url>
    <content type="text"><![CDATA[trends.embed.renderExploreWidget("TIMESERIES", {"comparisonItem":[{"keyword":"spring","geo":"US","time":"today 12-m"},{"keyword":"springboot","geo":"US","time":"today 12-m"},{"keyword":"ejb","geo":"US","time":"today 12-m"}],"category":0,"property":""}, {"exploreQuery":"geo=US&q=spring,springboot,ejb&date=today 12-m,today 12-m,today 12-m","guestPath":"https://trends.google.com:443/trends/embed/"});]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Note</tag>
        <tag>Java</tag>
        <tag>Spring Boot</tag>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[工作中常用的 Shell 命令及技巧]]></title>
    <url>%2F2019%2F04%2F14%2Flinux-useful-shell-commands-in-work%2F</url>
    <content type="text"><![CDATA[字符串相关操作从 URL 截取字段默认去除url的最后斜线： 12url=http://xxx/patch/xxx/xxxx/tar_name=$(echo $&#123;url%*/&#125;|awk -F '/' '&#123;print $NF&#125;') shell 判断字符串包含1if [[ $tar =~ tar.gz ]];then echo "包含";fi Shell判断字符串包含关系的几种方法 字符串切割截取最近项目中遇到了一个问题，之前一直正常的版本号，突然格式不对，多了不必要的前缀。经过定位，发现之前写的脚本是根据下划线 _ 分割，截取最后的一段作为版本号 version。但是使用的语法有点问题，做个笔记。 1234$&#123;varible##*string&#125; 从左向右截取最后一个string后的字符串$&#123;varible#*string&#125; 从左向右截取第一个string后的字符串$&#123;varible%%string*&#125; 从右向左截取最后一个string后的字符串$&#123;varible%string*&#125; 从右向左截取第一个string后的字符串 示例：有这样的一个字符串：release_eu_1.0.0.202011221152，它执行上面的截取操作，输出如下： 12345678$ echo $&#123;version##*_&#125;1.0.0.202011221152$ echo $&#123;version#*_&#125;eu_1.0.0.202011221152$ echo $&#123;version%%_*&#125;release$ echo $&#123;version%_*&#125;release_eu 所以，工作中遇到的那个问题解决了，应该使用两个 # 的截取方式。不得不感叹，shell 真是强大。 参考： cnblogs/shell 字符串分割与连接 调试 bash 脚本的技巧 加 -x 参数运行 bash 脚本时，会显示执行的语句 12# 也可以在 demo.sh 中加上 set -xbash -x demo.sh 设置环境变量，然后通过如上方式运行脚本时，会显示行号 1export PS4='+$&#123;BASH_SOURCE&#125;:$&#123;LINENO&#125;:$&#123;FUNCNAME[0]&#125;: ' 参考 [耗子叔-如何调试BASH脚本](https://coolshell.cn/articles/1379.html/comment-page-1#comment-1965637 快速输入历史命令输入关键词之后，连续使用ctrl+r快速切换 In reverse-i-search (Ctrl+R ) ,Any method to switch between similar commands in history linux – 在反向搜索(Ctrl R),任何在历史记录中类似命令之间切换的方法 Ctrl+p/n 向上/向下 显示缓存命令 Ubuntu终端常用的快捷键 ssh 远程执行命令需要远程到其他节点上执行一些 shell 命令，示例： 123456789#! /bin/shset -xssh root@192.168.3.43 &gt; /dev/null 2&gt;&amp;1 &lt;&lt; EOFcd /tmptouch test.txtexitEOFecho done 参考： 简书-【ssh】ssh远程执行命令 for 循环123456789101112131415echo "Start Datetime:" $(date +"%Y-%m-%d %H:%M:%S")for i in &#123;1..3&#125;do echo $i git pull --all if [ $? -ne 0 ] then echo "不成功" # 睡眠2s sleep 2 else break fidoneecho "End Datetime:" $(date +"%Y-%m-%d %H:%M:%S") 参考： Linux下Shell的for循环语句 Shell脚本中的分号使用 if 判断判读字符串($str)是否包含另一个字符串($str1)： 方法1： 123if [ `echo $str | grep -e '$str1'` ] ; then echo yesfi 方法2(如果$str1在判断中直接使用字符串而不是变量，则不能加引号，如if [[ $str =~ ^dx ]]判读字符串$str是否以dx开头，^dx不能加引号)： 123if [[ $str =~ $str1 ]] ; then echo yesfi 比较两个字符串是否相等的办法是： 1if [ "$test"x = "test"x ]; then 这里的关键有几点： 使用单个等号，我发现，2个等号也 OK； 注意到等号两边各有一个空格：这是unix shell的要求 注意到&quot;$test&quot;x最后的x，这是特意安排的，因为当$test为空的时候，上面的表达式就变成了x = testx，显然是不相等的。而如果没有这个 x，表达式就会报错：[: =: unary operator expected 参考： shell中if做比较 Bash 加 -xe 表示什么意思-e 使shell立即退出，某些东西会返回一个错误(这通常在shell脚本中用作故障保护机制),-x 允许详细执行脚本，你可以看到发生了什么 将-xe参数传递给/ bin / bash的做法是什么 Shell 中的引号https://blog.csdn.net/miyatang/article/details/8077123 Shell定义变量和给变量赋值将命令的执行结果赋值给变量123var=&apos;pwd&apos;# 或者var=$(pwd) 将 Bash 的内置命令 read 读入的内容赋值给变量1echo -n &quot;Enter var:&quot;;read var 通配符与特殊符号 符号 意义 * 代表0个到无穷多个任意字符 ？ 代表一定有一个任意字符 [] 同样是代表一定有一个在中括号内的字符（非任意字符）。例如，[abcd]代表一定有一个字符，可能是这四个中的一个 [-] 若减号在括号内，代表在编码顺序内的所有字符。例如，[0-9]代表0-9之间所有数字，因为数字的语系编码是连续的 [^] 若中括号第一个字符是^，表示原向选择，例如[^abc]代表一定有一个字符，只要是非a,b,c的其他字符就接收 示例 找出/etc/目录下文件夹名字刚好有5个字母的文件名：ll -d /etc/????? 找出/etc/下面文件名含有数字的的文件名：ll -d /etc/*[0-9]* 找出/etc/下面文件名开头非小写字母的文件名：ll -d /etc/[^a-z]* 将上面例子找到的文件复制到/tmp中：` bash 中的特殊符号 符号 内容 # 注释符号 \ 转义符号，将特殊字符或通配符还原成一般字符 竖线 管道 ; 连续命令执行分隔符，连续命令的界定 ~ 用户的主文件夹 $ 使用变量的前导符 &amp; 作业控制，将命令变成背景下工作 ! 逻辑运算意义上的“非” >,&gt;&gt; 数据流重定向，输出导向，分别是“替换”与“累加” &lt;,&lt;&lt; 数据流重定向，输入导向 ‘’ 单引号，不具有变量置换的功能 “” 具有变量置换的功能 `` 两个重音符中间为可以先执行的命令，也可以使用$() () 中间为子shell的起始与结束 {} 中间为命令块的组合 给Linux新增硬盘之后的操作12fdisk -l #查看磁盘情况，发现有磁盘没有分区，比如是/dev/xvdefdisk /dev/xvde #进行磁盘分区的操作 fdisk磁盘分区时，可以输入m，会有提示：123456789101112131415161718Command (m for help): mCommand action a toggle a bootable flag b edit bsd disklabel c toggle the dos compatibility flag d delete a partition l list known partition types m print this menu n add a new partition o create a new empty DOS partition table p print the partition table q quit without saving changes s create a new empty Sun disklabel t change a partition's system id u change display/entry units v verify the partition table w write table to disk and exit x extra functionality (experts only) 我依次这么输入的： 1234567add a new partition:npartion type:pPartion number:分区个数 1First sector默认值:EnterLase sector默认值:Enterprint the partion table:pwrite table to disk and exit:w 分区完成之后，需要格式化 1mkfs -t ext4 /dev/xvde1 将新建分区挂载到/data目录下： 12mkdir /datamount /dev/xvde /data 挂载完毕，输入df -hT可以查看到新建的分区 设置文件系统的自动挂载1vi /etc/fstab 添加/dev/xvde1 /data ext4 defaults 0 1 在 fstab 配置文件中加入挂载点之后其实就已经是开机自动挂载了，不需要用 mount 命令挂载。但是还是用 mount 实在，因为最后还是需要写入/etc/fstab 第一段可以用分区名，也可以用 blkid 的方式获取 UUID 的值 参考： www.jianshu.com/p/7b8c3509d5fe 玩转 Linux 之：磁盘分区、挂载知多少？ LVM) Linux 磁盘管理 备份原有配置文件只将不带注释的内容提取出来，作为配置文件 12mv /etc/vsftpd/vsftpd.conf /etc/vsftpd/vsftpd.conf_bakgrep -v "#" /etc/vsftpd/vsftpd.conf_bak &gt; /etc/vsftpd/vsftpd.conf -v 参数表示反选 修改主机名 Linux下修改主机名hostname 查看Linux系统版本12345lsb_release -a # 适用于所有Linux系统cat /etc/os-release #推荐cat /etc/redhat-release # 仅适用于Redhat系列的Linux系统uname -a # 查看Linux内核cat /proc/version # 查看Linux内核 Linux 命令行：查看系统版本的几种方法 Linux查看安装的系统版本 显示 shell 执行过程1set -x 如果想隐藏某一行的内容： 12345set -xxxxxset +xyyyyset -x Linux 查看脚本的执行过程 Shell脚本调试技术 查看端口占用123[root@centos7.4 software]# netstat -apn 查看当前运行的所有进程的端口使用情况[root@centos7.4 software]# netstat -apn | grep 端口号 查看指定端口使用情况[root@centos7.4 software]# kill 指定端口的pid号 杀死指定进程（端口号对应的pid） 打印第X行1head -n X | tail -n 1 分行显示 Path 环境变量显示你的环境变量PATH，一个目录一行： 1echo $PATH | tr : \\n atime mtime ctime 的含义 atime (access time) 访问时间，表示文件最后被访问的时间； mtime (modify time) 修改时间，文件内容被修改的最后时间，平常我们 ls -l 查看文件是，显示的就是 mtime； ctime (change time) 变化时间，文件的元数据发生变化的时间，例如权限、所有者等，通俗来讲，就是文件属性或文件位置改动的时间； 利用 stat file_name 可以查看文件 「amc」time 。 1echo "hello" &gt;&gt; issue 写文件操作（&gt;&gt; 方式）不会导致 atime(访问时间）的修改，但是 mtime 和 ctime 会发生修改。mtime 修改了我们可以理解的，毕竟我们修改了文件的， 那为何ctime也修改了呢， 仔细可以发现我们文件的大小发生了变化，也就是元数据发生了变化，所以ctime也是要变化的 参考： linux中文件的三种time（atime,mtime,ctime） 重定向相关 CSDN-Linux里的2&gt;&amp;1究竟是什么 防火墙有时候需要服务器上需要打开防火墙的端口： 1234sudo firewall-cmd --zone=public --add-port=60001/udp --permanentsudo firewall-cmd --reload#之后检查新的防火墙规则firewall-cmd --list-all 由于只是用于开发环境，所以打算把防火墙关闭掉 12345678910111213//临时关闭防火墙,重启后会重新自动打开systemctl restart firewalld//检查防火墙状态firewall-cmd --statefirewall-cmd --list-all//Disable firewallsystemctl disable firewalldsystemctl stop firewalldsystemctl status firewalld//Enable firewallsystemctl enable firewalldsystemctl start firewalldsystemctl status firewalld 参考： CentOS 7开放端口和关闭防火墙 shell echo 输出带颜色输出格式 设置底色，字体颜色：echo -e &quot;\033[底色;字体颜色m 内容 \033[0m&quot; 设置字体颜色：echo -e &quot;\033[字体颜色m 内容 \033[0m&quot; 其中 \033 是 ESC 健的八进制，\033[即告诉终端后面是设置颜色的参数，显示方式，前景色，背景色均是数字 字体颜色 背景色 颜色 30 40 黑色 31 41 红色 32 42 绿色 33 43 黃色 34 44 蓝色 35 45 紫红色 36 46 青蓝色 37 47 白色 但有一点要注意，如果输出带颜色的字符后并没有恢复终端默认设置，后续的命令输出仍旧会采用之前的颜色，如果是在脚本中设置了颜色而未恢复，则整个脚本的输出都会采用之前的颜色，因此如果不希望影响后面文字的输出，最好是在输出带颜色的文字之后恢复终端默认设置，\033[0m 关闭所有属性 示例： 1234# 字颜色为绿色echo -e "\033[32m download new package (version $version) \033[0m"# 红底黑字echo -e "\033[41;37mMichael翔\033[0m" 参考： shell脚本中echo显示内容带颜色 切割大文件与合并压缩文件1234567# 切割split -b 90m -d janusgraph-0.4.0-hadoop2.zip janusgraph-0.4.0-hadoop2-split.split -b 90m -d jdk-8u232-linux-x64.tar.gz jdk-8u232-linux-x64-split.# 合并cat janusgraph-0.4.0-hadoop2-split* &gt;&gt; janusgraph-0.4.0-hadoop2.zipcat jdk-8u232-linux-x64-split* &gt;&gt; jdk-8u232-linux-x64.tar.gz 修改文件句柄数有时候需要修改文件的最大打开数量 查看目前的限制： 1ulimit -n 方法一： 1ulimit -n 65535 这种方法仅针对本次开机有效，重启之后就无效了。 方法二： 打开 /etc/security/limits.conf，添加如下内容到文件最后： 1234* soft nofile 65535* hard nofile 65535* soft nproc 65535* hard nproc 65535 * 代表针对所有用户 noproc 是代表最大进程数 nofile 是代表最大文件打开数 soft 和 hard 一起设置才好使 FAQQ:Linux各目录的作用 linux各文件夹的作用 /usr 目录结构 Unix目录结构的来历 Q：http://blog.csdn.net/u011109356/article/details/54928955/dev/xvda1 占满 Linux 好文 Linux工具快速教程 glmapper-shell 脚本简单归纳和实践 资源推荐 Github-命令行的艺术]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mac 配置教程-开发篇]]></title>
    <url>%2F2019%2F04%2F14%2Ftools-dev-mac%2F</url>
    <content type="text"><![CDATA[将 Mac 日常使用的软件和开发软件区分开，将之前写的 Mac 配置的文章分成了两篇： Mac 配置教程-日常篇 Mac 配置教程-开发篇 支持 NTFS 磁盘阅读文章 Mac 免费支持 NTFS 格式的移动硬盘/U盘 图床这篇文章介绍的 优雅的图床工具，简直完美～ uPic 支持利用 Github 或者 Gitee 作为图床，赞了！微博图床封了之后，这个是一个好选择！设置快捷键是 command+shift+p，文档 PicGo 设置快捷键是 command+shift+p，文档 iPic 设置快捷键 Command+Shift+u 免密登录安装 Homebrew 的指导见 Mac 配置教程-日常篇 1234brew install ssh-copy-idssh-copy-id root@1.2.3.4# 等价于ssh-copy-id -i ~/.ssh/id_rsa.pub root@1.2.3.4 -p 22 ssh-copy-id 这个工具，它的原理其实是把自己的公钥（默认使用 ~/.ssh/id_rsa.pub 这个文件中的内容）复制到目标服务器的~/.ssh/authorized_keys 文件内。 可以利用 SSH 的配置文件来记住已有的配置，快速登录： 编辑~/.ssh/config 文件: 12345Host ss HostName x.x.x.x User root Port 22 IdentityFile ~/.ssh/id_rsa 后续，仅需要ssh ss，即可免密登录。 图解 SSH 原理 网络分析 HTTP View 超酷的HTTP(S)的调试助手，一键拦截HTTP(S)，仔细研究和检查流量，并准确地发现您的代码正在发送什么。 编程字体 Hack 专为在源代码中使用而设计的开源字体 Git 下载安装 123$ ssh-keygen -t rsa -C "649168982@qq.com"$ git config --global user.name "Michael728"$ git config --global user.email "649168982@qq.com" 我的 Git 配置文件在：my-config-files/git 更多的设置，阅读 https://michael728.github.io/2019/11/14/git-install-config/ FAQQ1： git status乱码执行：git config --global core.quotepath false参考：Git Status 中文乱码解决 Q2：Github 下载速度慢 加快国内访问Github网站的速度 国内为何访问Github如此慢 Homebrew &amp; Cask &amp; launchrocket在安装其他软件之前，这个首先要介绍安装一下，可以理解为 Mac 平台下的包管理器，用命令行可以安装一下软件工具。 Homebrew-官网安装 brew 命令： 1/usr/bin/ruby -e "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)" Homebrew cask可以优雅、简单、快速的安装和管理 OS X 图形界面程序，比如 Google Chrome 和 Dropbox，安装 cask 命令： 1brew tap caskroom/cask 常用命令： 12345678910111213brew search xxx // 搜索brew cask search xxx // 搜索brew list --versions // 查看安装过的包列表，同时显示版本号brew update // 更新 brewbrew upgrade &lt;package_name&gt; // 更新用brew安装的软件brew cleanup // 清理旧版本的包缓存时，清除安装包brew cask cleanup // 清除安装包brew doctor // 检测brew outdated // 看一下哪些软件可以升级brew info xxx // 查看某个软件信息brew cask info xxx // 查看某个软件信息brew unlink vimbrew link macvim 更多命令可以通过man brew查看： brew 命令官网 SF-homebrew的tap功能详解 CSDN-mac的homebrew命令详解&amp;全部选项翻译 HelloDog-macOS 使用 Homebrew 的经验分享 Homebrew 能够安装哪些软件： brew search xxx 在官网浏览 在Homebrew formulas index查看详细的使用信息 测试安装是否成功： 1234brew install wgetbrew cask install google-chromebrew cask install cakebrew # brewbrew cask install launchrocket # 管理 brew 安装的 service 的工具，安装之后可以看所有的 service 的运行状态 brew 方式安装的软件都在/usr/local/Cellar目录下，执行brew link xxx，则会在/usr/local/share创建软连接。 brew cask 方式安装的软件在/usr/local/Caskroom目录下 Homebrew已成为Mac开发用户必不可少的工具, 大部分开发工具的安装和环境构建都非常方便. 但是如果配合Cakebrew和LaunchRocket, 那将会更方便管理。 brew和brew cask有什么区别？：cask 更偏向图形化软件的安装。 Homebrew 源加速我目前采用的加速方法，可以查看这篇文章 Mac 环境对 Github Homebrew 等终端工具的加速设置 还可以用修改原的方式加速，效果并不好，具体参考：阿里镜像源-brew 参考： Homebrew有比较快的源（mirror）吗？ Homebrew Cask 源使用帮助 Homebrew专栏 使用brew cask来安装Mac应用 拓展预览程序123456789brew cask install qlcolorcode \ qlstephen \ qlmarkdown \ quicklook-json \ qlimagesize \ qlvideo \ provisionql \ quicklookapk \ betterzip \ qlcolorcode 预览代码时带有语法高亮 qlstephen 预览无拓展名的纯文本文件插件 qlmarkdown quicklook-json 预览JSON文件 qlimagesize 在预览窗口显示图片分辨率及文件大小，并在Finder中显示图片的格式 qlvideo 让QuickLook兼容.mkv等非原生支持的视频格式，但并不能正常播放，只能显示出一些视频的缩略图和信息 provisionql 预览iOS / macOS应用和配置信息 quicklookapk 预览Android APK文件 betterzip 查看Zip压缩文件的信息以及文件目录 安装一些有用的工具（包含开发工具）123456789101112131415161718192021222324252627282930313233343536# 免密工具brew install ssh-copy-id# 安装 Git 工具brew install git-extras# 代码统计工具brew install cloc# 连接虚拟机工具brew install mosh# 多终端会话软件 tmuxbrw install tmux# 视频下载工具 https://github.com/ytdl-org/youtube-dlbrew install youtube-dl# 纠正输入的命名 https://github.com/nvbn/thefuckbrew install thefuck# HTTP 请求工具 https://github.com/jakubroztocil/httpiebrew install httpie# 全文搜索工具，find 命令对全文搜索有心无力brew install ack# MySQL 命令行终端工具，提供语法提示和高亮brew install mycli # 键盘敲击在屏幕上显示brew cask install keycastr# 安装字体# https://github.com/ryanoasis/nerd-fonts#option-4-homebrew-fontsbrew tap homebrew/cask-fontsbrew cask install font-hack-nerd-font# 安装 docker https://docs.docker.com/docker-for-mac/brew cask install docker# 下载工具 qBittorrent增强版 https://github.com/c0re100/qBittorrent-Enhanced-Editionbrew cask install c0re100-qbittorrent# vscodebrew cask install visual-studio-code# 终端brew cask install iTerm2# wiresharkbrew cask install wireshark git-extras 提供了一些有用和有趣的命令，例如 git summary 程序员内功系列–常用命令行工具 Brew安装快速预览插件 sindresorhus/quick-look-plugins 安装 JDK参考： CSDN-MAC安装JDK及环境变量配置 Java升级那么快，多个版本如何灵活切换和管理？ Jabba jenv sdkman 提供了切换功能 在 Mac 上默认的安装位置在： 1ls -1 /Library/Java/JavaVirtualMachines MavenMaven 的安装，可以看我的配置 repo my-config-files/maven/ alfred因为篇幅有限，专门总结了一篇介绍 alfred 的使用： Beyond CompareBeyond Compare：非常好用的diff工具； 123cd /Applications/Beyond\ Compare.app/Contents/MacOS/mv BCompare BCompare.realvim BCompare 添加如下内容： 123#!/bin/bash rm &quot;/Users/$(whoami)/Library/Application Support/Beyond Compare/registry.dat&quot; &quot;`dirname &quot;$0&quot;`&quot;/BCompare.real &amp; 第二行即删除注册信息. 第三行则为启动真实的 BCompare 文件. 参考： CSDN——Beyond Compare for mac 无限试用方法 诗意——Beyond Compare for Mac 无限试用方法 Charles Charles 注册码/破解 DashDash：计算机语言文档神器； 选中文本搜索开发文档：alt/option+s ForkLift 3Mac 上的 Finder 的增强版本，FTP 工具，官网有视频介绍，强烈安利！ 被忽视的 FTP 与文件管理工具：ForkLift 3 for Mac go2shell从官网下载安装，然后打开，同意安装到Finder。 go2shell官网 Mac通过安装Go2Shell实现“在当前目录打开iTerm2” iTerm2 快捷键打开ITerm2:打开设置，keys-hotkey-show/hide window，我设置快捷键为command+~ 切分屏幕：command+d 水平切分，command+Shift+d垂直切分；Command + [ 和 Command + ] 来切换到左侧或者右侧的标签页。 一个标签页中开的窗口太多，有时候会找不到当前的鼠标，command+/找到它。 按command+;弹出自动补齐窗口，列出曾经使用过的命令 按command+Shift+h弹出历史粘贴记录窗口，command+Shift+;弹出历史命令记录窗口。 command+d，新建垂直标签，利用 command+[/] 左右切换标签窗口。 1234567ctrl + w —往回删除一个单词，光标放在最末尾ctrl + k —往前删除到末尾，光标放在最前面（可以使用ctrl+a）ctrl + u 删除光标以前的字符ctrl + k 删除光标以后的字符ctrl + a 移动光标至的字符头ctrl + e 移动光标至的字符尾ctrl + l 清屏 iTerm2 中选择文本有三种方式，分别是： 双击：选中单词 三击：选中整行 参考： 你应该知道的 iTerm2 使用方法–MAC终端工具 皮肤+字体 皮肤资源 dracula：本人采用的就是这个主题，因为VScode中也是它。 字体安装： 123# https://github.com/ryanoasis/nerd-fonts#option-4-homebrew-fontsbrew tap homebrew/cask-fontsbrew cask install font-hack-nerd-font Iterm2 里配置非 acsii 字体。(Preferences -&gt; Profiles -&gt; Text -&gt; Non-Ascii-Font 选择 nerd-font)。之后重启 Iterm2 生效 这套皮肤+字体的设置主要是为了配合zsh终端下的现实效果，zsh的使用配置，见文章：zsh+on-my-zsh配置教程指南（程序员必备） 最后效果如下图： 皮肤安装教程见： iTerm 2 &amp;&amp; Oh My Zsh【DIY教程——亲身体验过程】 最简单iTerm2 + oh-my-zsh打造Mac炫酷终端教程-菜鸟版实操整理 FAQQ1: iterm 本地终端中文不乱码，ssh远程中文乱码 iterm 配置utf8编码，本地终端中文不乱码，ssh远程中文乱码，咋整啊 Medishttps://github.com/luin/medis redis 数据库客户端 MySQL sequelpro mysql 客户端，颜值高。免费 navicat-premium 虽然收费，但是真的好用！ navicat 无限制试用，参考 NavicatPremium12无限重置试用脚本（MacOS版） Navicat12 无限试用 Navicat premium 12 for mac 无限试用 Node Node官网：下载LTS版本 12sudo npm install -g hexo # 博客所需sudo npm install gitbook-cli -g # 笔记所需 MoshMosh 表示移动 Shell(Mobile Shell)，是一个用于从客户端跨互联网连接远程服务器的命令行工具。它能用于 SSH 连接，但是比 Secure Shell 功能更多。它是一个类似于 SSH 而带有更多功能的应用。程序最初由Keith Winstein 编写，用于类 Unix 的操作系统中，发布于 GNU GPL V3 协议下。 Mosh 最大的特点是基于UDP方式传输，支持在服务端创建一个临时的Key供客户端一次性连接，退出后失效；也支持通过SSH的配置进行认证，但数据传输本身还是自身的 UDP 方式。 Mosh 有两个非常有用的功能 会话的中断不会导致当前正在前端执行的命令中断，相当于你所有的操作都是在 screen 命令中一样在后台执行。 会话在中断过后，不会立刻退出，而是启用一个计时器，当网络恢复后会自动重新连接，同时会延续之前的会话，不会重新开启一个。 Mosh 替换 SSH 链接，需要你本机和远端 host 都安装 mosh 才OK： 123brew install mosh # macyum install mosh # centosapt-get install mosh # ubuntu PS： 我用这款工具的主要原因是，在家里我的 Mac 连接虚拟机的速度非常慢，ssh 到虚拟机执行命令非常卡顿，使用 mosh 之后流畅了许多。 CentOS 有时候还需要有 epel 源才能安装成功 yum -y install epel-release 有时候需要服务器上需要打开防火墙的端口： 12sudo firewall-cmd --zone=public --add-port=60001/udp --permanentsudo firewall-cmd --reload Python3安装 在Mac OS X上安装Python 3 Python3-Anaconda 1echo 'export PATH="~/anaconda3/bin:$PATH"' &gt;&gt; ~/.bash_profile 安装之后记得重启终端。 Postman Postman官网 Pycharm 官宣-Pycharm lanyus 福利，细心读者能发现 :) SourceTree源码管理：SourceTree sourcetree官网 typoraMarkdown 编辑器： typora官网 neovim 相关 neovim 安装及插键配置 zsh真是不得不介绍的神器，专门写了一篇文章： zsh+on-my-zsh配置教程指南（程序员必备） Mac 下环境变量规则及管理 VScode 官宣-VS Code 打造性感好用的VS Code编辑器 在 VS code 中快捷键 Shift + Command + p 输入 code ,选择安装 code 命令： 然后就可以在终端中这么打开 VS Code了 ： 1code .vimrc Mac 相关好文精华其实在最后 :) 推荐-Mac OS X 配置指南 | Mac OS X Setup Guide 比较系统的文章 Mac开发和编程工具 Mac 提升开发效率的小工具 GitBook-Mac-程序员的自我修养 serhii-londar/open-source-mac-os-apps Github 资源 sb2nov/mac-setup Installing Development environment on macOS 阅读 Mac 下各种编程语言开发环境配置指引 donnemartin/dev-setup macOS 开发环境设置 最后原文链接：Mac 配置总结]]></content>
      <categories>
        <category>ToolsDev</category>
      </categories>
      <tags>
        <tag>Tools</tag>
        <tag>Mac</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python 模块的加载顺序]]></title>
    <url>%2F2018%2F12%2F15%2Fpython-package-import-order%2F</url>
    <content type="text"><![CDATA[基本概念module模块， 一个 py 文件或以其他文件形式存在的可被导入的就是一个模块 package包，包含有 init 文件的文件夹 relative path相对路径，相对于某个目录的路径 absolute path绝对路径，全路径 Python 解释器是如何查找包和模块的Python 执行一个 py 文件，无论执行的方式是用绝对路径还是相对路径，interpreter 都会把文件所在的 directory 加入 sys.path 这个 list 中，并且是索引为 0 的位置。Python 就是在 sys.path 中查找包和模块的。 1234567891011121314151617181920# test.py# coding:utf-8import sysprint(sys.path)print('Now in main.py')def hello(): print('michael hello')if __name__ == '__main__': hello()# 执行 python test.py$ python test.py['/tmp/module-package/app', '/usr/lib64/python27.zip', '/usr/lib64/python2.7', '/usr/lib64/python2.7/plat-linux2', '/usr/lib64/python2.7/lib-tk', '/usr/lib64/python2.7/lib-old', '/usr/lib64/python2.7/lib-dynload', '/usr/lib64/python2.7/site-packages', '/usr/lib/python2.7/site-packages']Now in test.pymichael hello Python 解释器查找包的顺序解释器查找包： 解释器会默认加载一些 modules，除了sys.builtin_module_names 列出的内置模块之外，还会加载其他一些标准库，都存放在sys.modules字典中。 然后就是搜索 sys.path 路径下的模块了。 1234In [3]: import sysIn [4]: print(sys.builtin_module_names)('_abc', '_ast', '_codecs', '_collections', '_functools', '_imp', '_io', '_locale', '_operator', '_signal', '_sre', '_stat', '_string', '_symtable', '_thread', '_tracemalloc', '_warnings', '_weakref', 'atexit', 'builtins', 'errno', 'faulthandler', 'gc', 'itertools', 'marshal', 'posix', 'pwd', 'sys', 'time', 'xxsubtype', 'zipimport') 这样的查找顺序将会导致同名包或模块被遮蔽。 示例2：123456789101112131415161718192021222324# tree$ tree . -L 1.├── __init__.py├── name├── os.py├── test2.py├── test.py└── test.pyc# test2.pyimport osfrom redis import Redisfrom test import helloprint('Now in test2.py')print(os.getcwd())# 执行 python test2.py$ python test2.pyTraceback (most recent call last): File "test2.py", line 2, in &lt;module&gt; from redis import RedisImportError: No module named redis 这里的 os 模块并不是是 built-in module，上面已经将 sys.builtin_module_names 内容打印出来了。只是 Python 解释器启动时就加载到了 sys.modules中缓存起来了。所以，即使在同目录下有同名模块，解释器依然是可以找到正确的 os 模块的！如果你在import os之前，先执行del sys.modules[&#39;os&#39;]，那么，标准模块 os 就会被同目录下的 os.py 屏蔽了。 redis 属于第三方模块，默认安装位置是 Python 环境变量中的 site-packages，解释器启动之后，会将此目录加到 sys.path，由于当前目录会在 sys.path 的首位，当前目录的 redis 优先被找到了，site-packages 中的 redis 模块被屏蔽了。 综上所述，搜索的一个顺序是：sys.modules 缓存 -&gt; sys.path[0] 即当前目录查找 -&gt; sys.path[1:]路径查找。 同时发现，模块被加载的时候，其中非函数或类的语句，例如 print(&#39;hello&#39;)、name=michael等，是会在 import的时候，默认就执行了。 交互式执行环境的查找顺序交互执行环境，解释器会自动把当前目录加入到sys.path，这一点和直接执行文件是一样的，但是这种方式下，sys.path[0] 是存储的当前目录的相对路径，而不是绝对路径。 1234In [4]: import sysIn [5]: sys.path[0]Out[5]: '' 模块中的 __file__ 变量文件中的 __file__当模块以文件的形式出现 file 指的是模块文件的路径名，以相对路径执行 file 是相对路径，以绝对路径执行 file 是绝对路径： 123456789# test3.pyprint __file__# 执行 python test.py$ python test3.pytest3.py$ python /tmp/module-package/app/test3.py/tmp/module-package/app/test3.py 交互式 Shell 中的 __file__前交互式 Shell 的执行并不是以文件的形式加载，所以不存在 __file__ 这样的属性： 1234567In [8]: __file__---------------------------------------------------------------------------NameError Traceback (most recent call last)&lt;ipython-input-8-358d5687b810&gt; in &lt;module&gt;()----&gt; 1 __file__NameError: name '__file__' is not defined sys.argv[0] 变量sys.argv[0] 是获得入口执行文件路径，__file__ 是真实被执行模块的文件路径。比如下面例子中，test2.py 就是入口执行文件，而 test.py 就是在 import 时真实被执行的模块 12345678910# test.pyprint(__file__)print(sys.argv[0])# test2.pyimport test# 执行 python test2.py/tmp/module-package/app/test.py # __file__test2.py # sys.argv[0] sys.modules 的作用载入的模块存放在何处？ 答案是 sys.modules。 模块一经载入， Python 会把这个模块加入 sys.modules 中供下次载入使用，这样可以加速模块引入，起到缓存作用。sys.modules 是一个 dict 类型的值。 123456789101112In [14]: sys.modules['requests']---------------------------------------------------------------------------KeyError Traceback (most recent call last)&lt;ipython-input-14-8aefaef0aed5&gt; in &lt;module&gt;()----&gt; 1 sys.modules['requests']KeyError: 'requests'In [15]: import requestsIn [16]: sys.modules['requests']Out[16]: &lt;module 'requests' from '/usr/lib/python2.7/site-packages/requests/__init__.pyc'&gt; 123# 没有预先引入 math，但是 sys.modules 中已经有这个键In [18]: sys.modules['math']Out[18]: &lt;module 'math' from '/usr/lib64/python2.7/lib-dynload/math.so'&gt; 需要注意的是， sys.modules[&#39;math&#39;] 尽管可以看到 math 键，但是，要使用它，还是需要显示 import math 之后才能使用的，因为那只是 Python 解释器后台缓存的，你不显示引入，本地空间还是不会去发现它。 总结Python 通过查找 sys.path 来决定包的导入，Python解释器启动时加载的模块缓存 &gt; 同级目录 &gt; sys.path[1:]。Python 中的特有属性 __file__ 以及 sys.argv[0]、sys.argv[0]、sys.modules 可以帮助分析包的查找和导入过程。 解决这个问题，请教了大牛同事，果然一下子让我明白了。于是，自问自答了在 SegmentFault 上提的问题： Python 包的引入顺序到底是怎样的？ 参考 三月沙-如何理解 Python 的模块查找原理与方式 本文内容主要参考，但是该文章中提到的os属于built-in moulde的理解是有误的，本文中修正了理解。 构建一个模块的层级包 The Python Standard Library Medium-Python 的 Import 陷阱 CSDN-Python 模块搜索路径 提交了 PYTHONPATH 这个环境变量的作用 librarybook-The sys module 官宣-System-specific parameters and functions]]></content>
      <categories>
        <category>Python</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Python 调试模块 ipdb]]></title>
    <url>%2F2018%2F12%2F15%2Fpython-debug-ipdb%2F</url>
    <content type="text"><![CDATA[授人以鱼不如授人以渔，掌握调试方法是学习提升的一个必备条件。前几天因为探索了一下 Python 模块引入路径的问题，看到「翔 Core」用 pdb 调试的很溜，因此，今天研究一下 ipdb好啦。 安装ipdb 是 pdb 模块的升级版，会启动一个 ipython 的调试窗口。 1pip install ipdb 使用 python -m ipdb demo.py 直接运行程序，不需要再程序中去插入内容； import ipdb;ipdb.set_trace()，这种用法需要在程序内部插入语句，类似插入「断点」的效果； 帮助文档在 ipdb 窗口，输入 h ，会看到帮助文档，h &lt;command&gt; 可以查看具体命令的帮助。 1234567891011121314Documented commands (type help &lt;topic&gt;):========================================EOF cl disable interact next psource rv unta clear display j p q s untilalias commands down jump pdef quit source upargs condition enable l pdoc r step wb cont exit list pfile restart tbreak whatisbreak continue h ll pinfo return u wherebt d help longlist pinfo2 retval unaliasc debug ignore n pp run undisplayMiscellaneous help topics:==========================exec pdb 常用命令 a(rgs)：打印当前函数的参数列表 ★★★ b(reak) [ ([filename:]lineno | function) [, condition] ]：设置断点，可以接行数或者行数名作为参数，比如，b 8 就是在第8行打断点，还可以给外部的文件加上断点 b file_name:line_number，如果只敲 b ，会显示全部断点 c(ont(inue))：继续执行，当遇到断点时才会停止 ★★★ cl(ear) filename:lineno ：可以清除断点，不过不加「断点号」，可以清除所有断点 disable bpnumber [bpnumber ...] ：禁用指定[断点号]的断点 enable bpnumber [bpnumber ...]：启用指定[断点号]的断点 Enter：重复上次命令 ★★★ j(ump)：设置下一步执行的行，这个语句可以让你跳过某些语句的执行，并不是网上一些文章说的跳到某行，跳到某行可不是代表会跳过某些语句的，文档最准确 ll or l：查看当前将要运行的代码段 n(ext)：让程序运行下一行，如果当前语句有一个函数调用，用 n 是不会进入被调用的函数体中的 ★★★ pp expression or p expression：前者以 pprint 方式打印表达式的值，后者 print 方式 ★★★ q(uit)：退出调试，同时，你也可以使用 Ctrl+D退出调试 r(eturn)：继续执行，直到当前函数返回 ★★★ restart &quot;restart&quot; is an alias for &quot;run&quot;. ：是 run 命令的别名，重新启动调试器； run [args...] ：这里的参数会作为运行脚本的参数，等价于 python demo.py [args...]，可以通过 sys.argv 查看参数列表，重新运行时，断点等信息会保留的 s(tep)：和 n 相似，但是如果当前有一个函数调用，s 会进入被调用的函数体中 ★★★ w(here)：打印一个堆栈跟踪， ! ：感叹号后面跟着语句，可以直接改变某个变量的值 示例断点示例下面是一个关于断点的示例：执行 b 7、b 12 之后，输入 ll 查看，最左侧的 1、2 就是断点号，输入 c ，下次运行到断点处，执行就会停下来。 123456789101112131415ipdb&gt; ll----&gt; 1 a = 'michael' 2 print(a) 3 4 def hello(name): 5 print('hello') 6 for i in range(5):1 7 print(i) 8 print(name) 9 10 11 hello('michael')2 12 x = 10 13 y = 20 执行 disable 1，下次执行到「断点1」处，就不会停下来了，输入 b 可以查看全部断点： 1234ipdb&gt; bNum Type Disp Enb Where1 breakpoint keep no at /Users/michael/Code/00-Temp/b.py:72 breakpoint keep yes at /Users/michael/Code/00-Temp/b.py:12 如果想清除「断点2」，那么执行 cl 2 即可： 12ipdb&gt; cl 2Deleted breakpoint 2 at /Users/michael/Code/00-Temp/b.py:12 run 示例1234567891011ipdb&gt; run --name michaelRestarting b.py with arguments: --name michael&gt; /Users/michael/Code/00-Temp/b.py(1)&lt;module&gt;()----&gt; 1 a = 'michael' 2 print(a) 3ipdb&gt; import sysipdb&gt; sys.argv['b.py', '--name', 'michael'] 看到上面的结果，确实等价于 python b.py --name michael。 注意点在 ipdb 调试窗口，虽然可以随时给变量赋值，但是要注意变量的名字和 ipdb 的命令不能重复了，否则会出错，可以用 !b=123 来规避这个问题。 案例背景遇到这个错误： 1AttributeError: 'module' object has no attribute 'processor' 网上有相关问题： https://stackoverflow.com/questions/1250103/attributeerror-module-object-has-no-attribute 主要是两种常见的错误会造成这个： 模块命名和标准模块命名冲突了； 循环引用 分析搜索项目中哪些地方引入 platform 1grep -rIin 'import platform' 同时，还可以在使用 platform.processor() 方法前面加上 print(paltform.__file__) 查看启动 Python 时，就自动加载的模块： 1python -v 或者 12import syssys.modules['platform'] 查看运行编包命令时，加载的模块： 1python -v /usr/bin/pkg 将以上输出对比了一下，先排除标准模块会引入 platform ，因为标准模块，一般都是「自包含」。然后和 python -v 对比，发现编包命令多加载了一个第三方 blessings 模块，是不是它引入 platform 的呢？ 发现，正常的构建机器上，这个模块是 1.6.1 版本，而目前发现问题的机器，这个包版本是 1.7 版本。那么，来看看，他俩之间的差异： Github-erikrose/blessings包，点击分支，查看 Tag 1.7 的提交记录，发现了这个提交 1from platform import python_version_tuple 1.7 版本中，这一行删除了，所以发生了差异。 根本原因： 1pkgutil.iter_modules(package.__path__) 相关问题 SOF-AttributeError: ‘module’ object has no attribute 最后学完这个 ipdb 的调试，再回头看看 Pycharm 的 debug 功能，貌似都能理解了！ 参考 使用IPDB调试Python代码 IBM-Python 代码调试技巧 油管-Introduction to the Python Debugger]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>debug</tag>
        <tag>method</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python 标准库 argparse 的用法]]></title>
    <url>%2F2018%2F12%2F09%2Fpython-argparse-note%2F</url>
    <content type="text"><![CDATA[argparse 是 Python 内置的一个用于命令项选项与参数解析的模块。Python 也有第三方的库可用于命令行解析，而且功能也更加强大，比如 docopt，Click Argparse主要有三个步骤： 创建 ArgumentParser() 对象 调用 add_argument() 方法添加参数 使用 parse_args() 解析添加的参数 参数说明add_argument12ArgumentParser.add_argument(name or flags...[, action][, nargs][, const][, default][, type][, choices][, required][, help][, metavar][, dest]) 每个参数解释如下: name or flags - 选项字符串的名字或者列表，例如 foo 或者 -f, –foo。 action - 命令行遇到参数时的动作，默认值是 store。 store_const，表示赋值为const； append，将遇到的值存储成列表，也就是如果参数重复则会保存多个值; append_const，将参数规范中定义的一个值保存到一个列表； count，存储遇到的次数；此外，也可以继承 argparse.Action 自定义参数解析； nargs - 应该读取的命令行参数个数，可以是具体的数字，或者是?号，当不指定值时对于 Positional argument 使用 default，对于 Optional argument 使用 const；或者是 * 号，表示 0 或多个参数；或者是 + 号表示 1 或多个参数。 const - 一个在 action 和 nargs 选项所需的常量值。 default - 不指定参数时的默认值。 type - 命令行参数应该被转换成的类型。 choices - 参数可允许的值的一个容器。 required - 可选参数是否可以省略 (仅针对可选参数)。 help - 参数的帮助信息，当指定为 argparse.SUPPRESS 时表示不显示该参数的帮助信息. metavar - 在 usage 说明中的参数名称，对于必选参数默认就是参数名称（上面的 name or flags），对于可选参数默认是全大写的参数名称. dest - parse_args() 方法返回的对象所添加的属性的名称。默认情况下，对于可选参数选取最长的名称，中划线转换为下划线. 官方示例123456789101112131415161718# 创建了 ArgumentParser 对象，该对象具有解析命令行转为 Python 数据类型的全部信息parser = argparse.ArgumentParser(description='Process some integers.')# 增加参数parser.add_argument('integers', metavar='N', type=int, nargs='+', help='an integer for the accumulator')parser.add_argument('--sum', dest='accumulate', action='store_const', const=sum, default=max, help='sum the integers (default: find the max)')parser.add_argument('--foo', action='store_true')parser.add_argument('--bar', action='store_false')# 调用 parse_args() 会返回对象的两个属性，integers 和 accumulate。 integers 属性是一个列表# 如果在命令行中指定了 --sum，例如 python a.py 1 --sum ，则 accumulate 属性将是 sum() 函数，# 如果没有加上 --sum，例如 python a.py 1，则 accumulate 为 max() 函数&gt;&gt;&gt; parser.parse_args(['--sum', '7', '-1', '42'])Namespace(accumulate=&lt;built-in function sum&gt;, integers=[7, -1, 42]) 这里的 store_const 可以这么理解，它对应的属性是可以手动赋值的，比如这里的 accumulate，该属性值是自动获取： 如果参数中使用了 --sum，那么后面不赋值，accumulate 也会根据取 const 指定的值取值； 如果参数中没有出现 --sum，那么这个可选参数会去 default 指定的值，如果不指定默认值，会取值 None 这里的 store_false 可以这么理解，它对应的属性也是不可以赋值的，是自动获取的： 命令行使用了 --foo，这个属性就为 True，否则为 False 命令行使用了 --bar，这个属性就为 False，否则就为 True 互斥示例123group = parser.add_mutually_exclusive_group()group.add_argument("-v", "--verbose", action="store_true")group.add_argument("-q", "--quiet", action="store_true") 源代码本文示例代码可见： python-useful-modules/learn_argparse/ 参考： 极客学院-argparse 官宣-Python argparse 知乎-Python-argparse-命令行与参数解析 简书-python argparse用法总结 理解了 store 和 互斥参数]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>cli</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mac 配置教程-日常篇]]></title>
    <url>%2F2018%2F12%2F08%2Ftools-daily-mac%2F</url>
    <content type="text"><![CDATA[今年终于在推出 2018 款 MBP 时，看到升级了 CPU，我就果断下手「拔草」。本文记录使用 Mac 的一些配置，会长期更新。 为了控制文章的篇幅，我将 Mac 使用配置分成了两篇： Mac 配置教程-日常篇 Mac 配置教程-开发篇 系统配置记录一些 Mac 系统配置方面的技巧，让使用起来更方便。 快捷键整理 Enter：选中一个文件按下 Enter，直接改名 Ctrl 多用于命令行快捷键，Command 多用于图形化快捷键 选中桌面的所有需归档资料，Command+Shift+n，会将文件归档到一个文件夹下 调度中心设置：右 Ctrl，显示桌面 触发角 辅助功能-鼠标与控制板-触控板选项-启用拖移 Option+Command+v 类似剪切的功能，就是粘贴后，原来文件会被剪切过来。复制文件后，除了用快捷键，还可以在文件夹空白处右键，然后再按住 「⌥」，原本的「粘贴项目」就变成了「将项目移动到这里」 删除文件： Command+Delete 工具栏添加垃圾箱，然后选择待删除文件，点击垃圾箱即可删除 Command+Option+c 复制文件路径 按住 Option 很多菜单会发生些小变化，比如左上角苹果图标点开，按住 Option 『关于本机』会变成『系统信息』 Control + Command + Space emoji 表情 Command+Up：回到上一层文件夹 Command+Down：如果是文件夹就进入文件夹，如果是文件就打开 Ctrl + Command + q 锁屏 单词，选中，三指，自动翻译单词 Command+Shift+. 临时性切换显示/隐藏 Command+Alt+i: Chrome开发者工具，F12功能 command＋shift＋G Finder中如何输入路径直接跳转，参考 command+shift+C 电脑 command+shift+H 个人 command+shift+D 桌面 command+shift+A 程序 终端快捷键 Ctrl + A：移动到行首 Ctrl + E：移动到行尾 Ctrl + K：删除到行尾 Ctrl + U：删除到行头 Ctrl + N：移动到下一行 Ctrl + P：移动到上一行 设置允许「任何来源」的应用 —— 解决文件已损坏报错有时候会遇到这种错误「报错：无法打开已损坏的安装包」，打开终端，键入命令，输入密码，然后回车： 12sudo spctl --master-disabledefaults write com.apple.LaunchServices LSQuarantine -bool false 打开「安全性与隐私」，发现久违的「任何来源」回来了。 改建为了将外置键盘和Mac键盘的option键、command键保持一致的顺序，做如下修改：设置-键盘-修饰键-选择键盘（选择外设键盘）-调整顺序 Mac系统切换机械键盘win和alt键 使用 Shift 键Shift 键类似于可视模式，比如在某个位置点击光标并按住 Shift 键不松开，再去另一个位置点击一次，就可以选中两次点击位置之间的文本内容。 触控板 四指捏合，展开全部应用 辅助功能-鼠标 开启三指拖拽 参考： 用了那么久 Mac，才知道触控板原来还有这些功能 Mac Split View屏幕分割 长按左上角放大的绿色按钮，然后就会选择放置应用的区域！ 参考： Mac Split View屏幕分割 更改默认文件打开方式两指轻按文件，显示简介中，可以看到打开方式选项。 菜单栏显示投屏的按钮升级 macOS Big Sur 系统之后，发现菜单栏上找不到投屏的按钮，需要进行设置。系统偏好设置-》程序坞与菜单栏-》屏幕镜像，勾选「在菜单栏中显示」，选择「始终」： 电池 按住 Option 键并点按菜单栏中的电池图标，以显示电池状态菜单 增强 Tab 键 —— Tab 键适用于所有控制偏好设置-&gt;键盘-&gt;快捷键 全键盘控制改为「所有控制」 电脑改名电脑改名: 系统偏好设置 - 共享 - 电脑名称 其他 如何更改 Mac 帐户和个人文件夹的名称 Mac修改账户名称和个人目录后，进不去系统怎么办？ 技巧创建多个桌面可以创建多个桌面，使用常见快速切换。 四指在触控板往上滑动，然后右上角可以点击加号新建桌面。四指左右滑动，可以在不同桌面之间切换。 日常软件分屏软件目前在用的是一款付费软件 magnet，也不贵，6元，感觉还挺好用，下面是它的常用快捷键： spectacle 这款软件时免费的，也可以体验一下： option+command+←：窗口左边停靠 option+command+→：窗口右边停靠 option+command+f：窗口全屏 视频播放器 官宣-IINA播放器 人人影视客户端 截图 腾讯-截图 snipaste 强烈推荐，Windows 平台也有。F1 截图，F3 贴图 设定了快捷键为 Ctrl+Shift+a 下载工具qBittorrent： qBittorrent 下载 搜索插键 qBittorrent下载の道 关于 qBittorrent 连接更多 tracker 的一点补充 qBittorrent 下载安装和高级设置使用教程 | 添加 trackers 优化下载速度 tracker 列表： torrents ngosang/trackerslist newtrackon 还有一个下载工具，不过没试用过，做个记录：Photon 视频制作 OBS 免费的录屏软件 ArcTime 字幕工具，用来给视频添加字幕，免费。 状态栏图标管理 Dozer 免费开源，brew cask install dozer，足够用了，推荐 Dozer 的用法也很简单，只需要按住 Command 键，然后将应用图标拖动至它显示的两个圆点之间，那么这之间的图标就会隐藏。我给它设置了一个快捷键 Command+Shift+H vanilla 免费，按住 Command 键，拖动顶部状态栏图标归档之后，就会隐藏图标了。 Bartender：一款非常实用的 Menubar 菜单栏管理工具，付费的 CatchMouseMac双屏时，通过快捷键快速切换到另外一屏。 catchmouse下载 mac下双屏切换 cheatsheet在使用一些软件时，长按 Command 按键，会出现快捷键菜单 官宣-cheatsheet ClipyGithub 上面开源免费的一款剪贴板软件，简单好用！关键的是还免费，so hacker~ DownieDownie：下载各网站视频且更新频繁； encrypto文件加密软件： encrypto 免费的加密软件 firefox火狐的浏览器还是不错的，尽管主力还是 Chrome，用火狐主要是因为国内不需要梯子也可以账号同步。但是国内和国际版，账号系统没打通的，要想使用国际版的账号，那么可以在设置-》首选项-》同步中，找到「切换至全球服务」，然后登陆即可。 下载：现在火狐浏览器国际版去哪里下载？ - 马里亚纳的秋刀鱼的回答 - 知乎 参考： firefox 国际版 账户登录 国内账户 切换 同步问题 iMazing[Mac/Win]备份/管理iOS设备 iTunes 的替代品 licecap一款用来制作 Gif 动态图片的小软件： licecap官网 manico默认，长按option，显示dock应用，数字快速切换应用。 Mos Mos 鼠标平滑滚动软件，很好用。免费开源 123$ brew cask install mos$ brew update$ brew cask reinstall mos NightOwlNightOwl ：一款让 Mojave 深色模式更加智能的神器，可以将当前开启的某些软件单独设置成「始终显示为浅色」，这样，即使系统在深色模式下，这些被勾选的软件也会依然显示为浅色界面。 NightOwl OnedriveOnedrive 用来同步文档用的，作为「同步盘」使用，我用来存储电子书，还不错。它的在线版需要梯子才能访问，但是客户端使用是OK的，安卓客户端/、Mac 客户端也都有。 它的汉化有些含义不是很好理解，这里做个简要记录： 「始终保留在此设备上」 表示将文件的状态和在线（远端）不关联，及时远端删除了，本设备上的该文件也还在； 「释放空间」 表示将文件从本机上删除，节省本机的空间，但是远端文件并没删除； 「保持脱机」 脱机保存到你的电脑。这意味着，即使未连接到 Internet，也可以随时打开和更改它们。重新连接网络时，OneDrive 将根据脱机时所做的任何更改更新联机版本。 在没有 Internet 连接时脱机文件会很方便，但它们也会占用你电脑上的空间 参考： OneDrive 图标的含义是什么？ PopClip当你在 Mac 上用鼠标选择文字后 PopClip 即会出现。然后即可执行针对内容的特定操作，包括「拷贝」、「复制」以及其它插件操作例如「发送至 Evernote」等。 我安装了扩展： dash 选中，可以启动 Dash 搜索开发文档 terminal: 复制相关代码时，就可以默认直接去终端执行了，可以设置为默认 iTerm2 bing alfred 这几个扩展，可以到这里下载：my-config-files/popclip 参考： popclip扩展官网 PockPock Mac 的 touchbar 增加一点用途，显示 Dock 的应用图标~推荐！ 双击 Ctrl 键在 Pock 和系统触控栏之间切换 PinPoint鼠标指针修改 Pixelmator图片处理软件 snap Snap-Mac平台下的快捷键设置App-在Mac下使用机械键盘！ SketchBookSketchBook 画图软件，需要配合手绘板等工具使用。在看教程时，看到老师用这个软件手写一些流程图啥的用到的。 The Unarchiver解压软件，在 App Store 中即可下载。 TyporaTypora：Markdown 编辑器。 Telegram Telegram使用指南 TinyPNG4Mackyleduo/TinyPNG4Mac 进行图片压缩的 1brew cask install tinypng4mac keycastr屏幕上显示你敲击的快捷键，或者也可以设置显示你敲击的任意字母。 How can I show typing keyboard in record screen 官宣-keycastr/keycastr brew cask install keycastr Mac 相关好文 推荐-Mac OS X 配置指南 | Mac OS X Setup Guide 你每天都能用上的 Mac 快捷键 少数派-macOS 上都有哪些既免费、又实用的工具？| 新手问号 柠檬精选]]></content>
      <categories>
        <category>ToolsDaily</category>
      </categories>
      <tags>
        <tag>Tools</tag>
        <tag>Mac</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Vim 基础]]></title>
    <url>%2F2018%2F12%2F02%2Ftools-vim-basic%2F</url>
    <content type="text"><![CDATA[Vim 学习系列： Vim 基础 Vim 插件及配置 neovim 安装及插键配置 主要分为三种模式： 一般模式 编辑模式 命令行模式 光标的移动单词级比单纯的逐个字符的移动，效率要高 w or W 向移动到下一单词开头 ★★ b or B 向左移动到单词开头 ★★ 块级 gg文档第一行，相当于1G ★★★ G文档最后一行,&lt;n&gt;G移动到你n行 ★★★ 0 or ^ orhome到行首（第1列） ★★ $ or end到行尾 ★★★ :&lt;N&gt; or &lt;N&gt;gg跳转到第 N 行 ★★ &lt;N&gt;j or &lt;N&gt;↓，向下移动 N 行，同理，也可以实现左右移动 ★★ v or V，字符选择或者行选择 ★★ ctrl-v 长方形选择，牛逼了 ★★ ctrl-f 屏幕向下移动一页 ctrl-b 屏幕向上移动一页 注意，所有命令都可以加一个数字N，表示对后面的命令执行N次，比如&lt;N&gt;G表示移动到第 N 行。 高级移动 &#39;. 跳到最后修改的那一行 gd 跳到当前变量在当前文件的定义处，其实是跳转到当前变量在此文件中第一次出现的地方，不过一般来说，第一次出现的地方也就是变量定义的地方 ★★★ ma 在当前位置做标记，用字母a标记当前光标所在位置，这里a可以是任意字母 :&#39;a 跳到标记a处 ★★ :&#39;. 跳转到最后一次修改的地方(.代表最后一次修改的地方) :&#39;&quot; 上一次编辑文件的地方 :&#39;&#39; 跳转到上次跳转之前的位置 打开文件、查找内容vim中打开文件 :e &lt;filename&gt;，在vim中打开名为filename的文件，如果没有，则创建； 文档内查找 * 向后查找光标当前所在单词 # 向前查找光标当前所在单词 ★★★ /&lt;search&gt; 向后查找指定字符 ?&lt;search&gt; 向后查找指定字符串 n 继续查找下一个 ★★★ N 继续查找上一个 匹配查找vim 中可以使用% 对 (和 )，[ 和 ]，{和 } 进行匹配查找，当光标位于其中一个 符号上时，按下%，光标会跳到与之匹配的另外一个符号上。 括号匹配，程序员必备 文档的修改与保存插入 ctrl-p 插入模式下进行单词补齐，比如有一个变量为michael，那么你只需要敲入部分名之后，就可以按下ctrl-p自动补全了。★★★ a 当前字符后插入 ★★★ I 行首插入 A 行尾插入 o 在下一行插入 ★★★ O 在上一行插入 ★★★ 删除 x 删除当前字符 X 向前删除一个字符，相当于键盘的Back Space。 dd 删除当前行，并将删除内容保存在vim剪贴板 ndd表示删除光标所在的向下n行。★★ dw 删除光标所在位置到下个字的第一个字母 daw 删除一个单词，包括词尾空格，实用，不用将光标移动到单词第一个字母，aw表示a word d&lt;X&gt; 删除指定内容，保存在剪贴板 c&lt;X&gt; 删除指定内容，保存在剪贴板，同时进入insert模式 说明，部分是对操作内容的描述，比如，删除一个单词，可以dw或者de，要复制当前位置到行尾内容，可以输入y$，要删除后面3个字符并插入，就输入c3l。 复制 yy 复制当前行到vim剪贴板 nyy复制光标向下n行 ★★★ y&lt;X&gt; 复制指定内容到剪贴板 粘贴 p 当前位置后粘贴 ★★★ P 在当前位置前粘贴 合并 J 当前行与下一行合并 替换 r&lt;X&gt; 将当前字符替换为X ★★★ :%s/search&gt;/&lt;replace&gt;/ 查找search内容并替换为replace内容，正则表达来替换，这个命令可以消除所有行位多余的空格：:%s/\s\+$// ★★★ &lt;n1&gt;,&lt;n2&gt;s/word1/word2/gc n1/n2都是数字，在n1行和n2行之间寻找word1，替换为word2。c代表confirm，替换前需要你确认，不加就默认全部替换。n2用$表示时，表示搜索到最后一行。★★★ 撤销、重做 u 撤销 ★★★ ctrl-r 重做 ★★★ . 重复前一个操作的意思 ★★★ 保存文件 :wq or ZZ 保存并退出 :x 保存退出 :q! or ZQ 强制推出，不保存 saveas &lt;newfilename&gt; 文件另存为 编辑 ctrl-n or ctrl-p Vim自带的补全（按照全文已有输入）★★★ d$ 从光标处删至当前行尾部 多窗口 :sp 切割窗口 ctrl-w-j或者ctrl-w-↓ 跳转窗口 :q或者ctrl-w-q 关闭当前窗口 重复上一次命令vim有一个特殊的命令.，你可以用它重复执行上一个命令。我感觉有点像EXCEL中的F4命令。 缩进 &gt;&gt; 向右缩进当前行 &lt;&lt; 向左缩进当前行 分屏与标签页分屏方式 :vsplit 缩写vs or ctrl-w v左右分屏 :split 缩写sp or ctrl-w s上下分屏 :diffsplit 缩写:diffs diff模式打开一个分屏，后面可以加上{filename} 窗口跳转 ctrl-w w 激活下一个窗口 ctrl-w j 激活下方窗口 ctrl-w k 激活上方窗口 ctrl-w h 激活左侧窗口 ctrl-w l 激活右侧窗口 关闭分屏12ctrl+w c # 关闭当前窗口 如果是最后一个窗口，无法关闭ctrl+w q # 关闭当前窗口 如果只剩最后一个，则退出Vim 参考： VIM的分屏功能 FAQQ:配置VIM，安装vim-plug插件之后，想要生效通过source ~/.vimrc命令生效配置，就会报错：E492: Not an editor command: Plug123[root@localhost ~]# source .vimrc-bash: .vimrc: line 2: syntax error near unexpected token `(&apos;-bash: .vimrc: line 2: `call plug#begin(&apos;~/.vim/plugged&apos;)&apos; error while running “source .vimrc”原因是，我们.vimrc本身并不是shell文件，而source ~/.vimrc等价于./.vimrc，当然后校验shell语法了。看了StackOverflow上的解答才清楚的。 可以通过输入$vim直接进入vim的命令模式，执行下面命令 1:source ~/.vimrc 注意，我这里.vimrc的位置就是位于~目录下，你可以:source /path/to/.vimrc 或者编辑完.vimrc文件，直接：1:so $MYVIMRC Q:从Win上复制文件时，常常因为换行符出错1:set fileformat=unix linux的文件换行符为\n，但windows却非要把\r\n作为换行符，所以，vim在解析从windows拷贝到linux的的vimrc时，因为遇到无法解析的\r，所以报错。 vim E492: Not an editor command: ^M(使用VIM打开文件一直提示错误) 最后周末放假好好折腾了一下，安装插键可以参考这篇文章： Vim 插键及配置 附上我的 Vim 配置文件链接 参考 wklken一些vim个性化配置 dofy-Github-Vim 实操教程（Learn Vim） 系列基础入门 wxnacy-Vim 练级手册 wxnacy-Vim 专辑 archlinux-Vim (简体中文)) kawabangga-Vim系列教程 进阶用法]]></content>
      <categories>
        <category>ToolsDev</category>
      </categories>
      <tags>
        <tag>Tools</tag>
        <tag>Vim</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Vim 插件及配置]]></title>
    <url>%2F2018%2F12%2F02%2Ftools-vim-plugin-config%2F</url>
    <content type="text"><![CDATA[编辑器之神 —— Vim Vim 学习系列： Vim 基础 Vim 插件及配置 neovim 安装及插键配置 平日使用 vim 经常编辑文件，想想使用时的痛点，决定研究一下插件的使用。 Vim的扩展通常也被成为bundle或插件。 软件版本： Mac OS X 10.14.1 vim 8.1 插件安装-Vundle众多文章中都提到Vundle，那我就选用它好了！ 有一个 Vim 的插键网站，专门有相关插键的配置介绍：VimAwesome 1.将Vundle下载到本地，后面下载的插件也将会下载到~/.vim/bundle路径下。1git clone https://github.com/gmarik/Vundle.vim.git ~/.vim/bundle/Vundle.vim 2.插件配置，将如下的内容粘贴到~/.vimrc的顶部(前提是，你本身.vimrc里一开始没有什么其他内容)。12345678910111213141516171819202122232425262728293031323334353637383940414243set nocompatible &quot; be iMproved, requiredfiletype off &quot; required&quot; set the runtime path to include Vundle and initializeset rtp+=~/.vim/bundle/Vundle.vimcall vundle#begin()&quot; alternatively, pass a path where Vundle should install plugins&quot;call vundle#begin(&apos;~/some/path/here&apos;)&quot; let Vundle manage Vundle, requiredPlugin &apos;VundleVim/Vundle.vim&apos;&quot; The following are examples of different formats supported.&quot; Keep Plugin commands between vundle#begin/end.&quot; plugin on GitHub repo&quot; Plugin &apos;tpope/vim-fugitive&apos;&quot; plugin from http://vim-scripts.org/vim/scripts.html&quot; Plugin &apos;L9&apos;&quot; Git plugin not hosted on GitHub&quot; Plugin &apos;git://git.wincent.com/command-t.git&apos;&quot; git repos on your local machine (i.e. when working on your own plugin)&quot; Plugin &apos;file:///home/gmarik/path/to/plugin&apos;&quot; The sparkup vim script is in a subdirectory of this repo called vim.&quot; Pass the path to set the runtimepath properly.&quot; Plugin &apos;rstacruz/sparkup&apos;, &#123;&apos;rtp&apos;: &apos;vim/&apos;&#125;&quot; Install L9 and avoid a Naming conflict if you&apos;ve already installed a&quot; different version somewhere else.&quot; Plugin &apos;ascenator/L9&apos;, &#123;&apos;name&apos;: &apos;newL9&apos;&#125;&quot; All of your Plugins must be added before the following linecall vundle#end() &quot; requiredfiletype plugin indent on &quot; required&quot; To ignore plugin indent changes, instead use:&quot;filetype plugin on&quot;&quot; Brief help&quot; :PluginList - lists configured plugins&quot; :PluginInstall - installs plugins; append `!` to update or just :PluginUpdate&quot; :PluginSearch foo - searches for foo; append `!` to refresh local cache&quot; :PluginClean - confirms removal of unused plugins; append `!` to auto-approve removal&quot;&quot; see :h vundle for more details or wiki for FAQ&quot; Put your non-Plugin stuff after this line 3.安装插件将需要安装的插键放入.vimrc文件中即可，例如：12Plugin &apos;scrooloose/nerdtree&apos;&quot;Plugin &apos;scrooloose/nerdtree&apos; &quot; 如果暂时不启用，就将该插件注释掉 打开vim，然后输入： 123vim # 打开 vim:PluginInstall:PluginList # 查看已安装插键列表 4.升级与卸载插件12# 注释下面这段话# Plugin &apos;Valloric/YouCompleteMe&apos; 然后 12:PluginUpdate # 这个命令本身可以一键升级所有插件:PlugginClean 参考： How to unInstall plugin? 5.帮助文档1:h vundle NERDTree1234567891011Plugin &apos;scrooloose/nerdtree&apos;&quot;F2开启和关闭树&quot;map &lt;F2&gt; :NERDTreeToggle&lt;CR&gt;let NERDTreeChDirMode=1&quot;显示书签&quot;let NERDTreeShowBookmarks=1&quot;设置忽略文件类型&quot;let NERDTreeIgnore=[&apos;\~$&apos;, &apos;\.pyc$&apos;, &apos;\.swp$&apos;]&quot;窗口大小&quot;let NERDTreeWinSize=25 python-mode1Plugin &apos;klen/python-mode&apos; &quot; https://vimawesome.com/plugin/python-mode 编写 Python 文件保存时，就会进行语法检查了：1234567let g:pymode_rope = 1let g:pymode_rope_completion = 1let g:pymode_rope_completion_bind = &apos;&lt;C-p&gt;&apos; &quot;为了自动补全有效，需要将 set paste 设置不启用let g:pymode_rope_goto_definition_bind = &apos;&lt;C-c&gt;g&apos;let g:pymode_python = &apos;python&apos; &quot; 默认检查 Python2&quot;Autofix PEP8 errorsnnoremap &lt;leader&gt;f :PymodeLintAuto&lt;CR&gt; 快捷键：12K 显示内置函数文档&lt;leader&gt;r 运行 python 文件 # let mapleader=&quot;, &quot; &quot; 设置 leader 为空格，那么`,+r`就可以运行 python 文件了 参考： 油管-python-mode Can’t get the jedi-vim plugin to work 解决了 python-mode 不自动补全的问题 python-mode/doc/pymode.txt vim-airline一个状态栏美化工具，颜控必备。附带功能可以一目了然的区分各种编辑状态。 12Plugin &apos;vim-airline/vim-airline&apos; &quot;https://github.com/vim-airlin e/vim-airlinePlugin &apos;vim-airline/vim-airline-themes&apos; &quot; https://github.com/v im-airline/vim-airline-themes https://github.com/vim-airline/vi m-airline/wiki/Screenshots 主题预览 To use solarized dark, set :AirlineTheme solarized and add the following to your .vimrc: let g:airline_solarized_bg=’dark’ 配置： 12345let g:airline_powerline_fonts = 1let g:airline_theme=&apos;deus&apos;let g:Powerline_symbols=&apos;fancy&apos;let Powerline_symbols=&apos;fancy&apos;set t_Co=256 &quot; 状态栏就有颜色了 Yggdroot/indentLine安装：1Plugin &apos;Yggdroot/indentLine&apos; 配置：12let g:indentLine_enabled = 1let g:indentLine_color_term = 239 为了这个插件能够有效果，也是折腾了半天。在 CentOS 平台是正常的，但是在 Mac 上的缩进线显示不正确，为何会这样呢？SOF-Why is apple vim compiled WITHOUT conceal feature?，原来 Mac 上自带的 Vim 版本虽然是8.0版本，但是没有concel这个 Feature ，而indentLine插件要显示对齐线依赖这个，坚线和星号在使用 conceal 功能。 那么该怎么添加这个特性呢？搜了一圈，可以重新安装 Vim，可以参考这篇文章安装 Vim。 经过安装设置之后，可以通过vim --version|grep con或者:echo has(&quot;conceal&quot;)查看是否已经具有 conceal 特性： rking/ag.vimag 的语法：1ag [FILE-TYPE] [OPTIONS] PATTERN [PATH] ag 这个 vim 插键主要是基于这个项目 ggreer/the_silver_searcher 1ag --list-file-types # 查看支持自定义哪些文件类型 安装了这个插键后，在 vim 的命令模式下，可以使用:Ag [options] {pattern} [{directory}]搜索了。 majutsushi/tagbar安装 vim 插键之前，机器本身需要ctags：123456# ubuntusudo apt-get install ctags# centossudo yum install ctags# macbrew install ctags 在这时使用 vim-tagbar 插件可以帮你快速了解当前文件中的类、方法等。1Plugin &apos;majutsushi/tagbar&apos; &quot; https://github.com/majutsushi/tagbar 配置：1nmap &lt;F8&gt; :TagbarToggle&lt;CR&gt; 关于 tagbar 的使用，看查看这篇文章 wklken-大纲式导航 YouCompleteMe目前主要涉及的是 Python 开发，所以，YCM 目前没有配置，如下仅供参考。1Plugin &apos;Valloric/YouCompleteMe&apos; 123456sudo apt-get install build-essential cmakesudo apt-get install python-dev python3-devcd ~/.vim/bundle/YouCompleteMe./install.py --allcp ~/.vim/bundle/YouCompleteMe/third_party/ycmd/examples/.ycm_extra_conf.py ~/.vim/ 123&quot;YouCompleteMe配置相关let g:ycm_server_python_interpreter=&apos;/usr/bin/python&apos;let g:ycm_global_ycm_extra_conf=&apos;~/.vim/.ycm_extra_conf.py&apos; 主题安装主题的方法比较简单，例如需要安装molokai主题，手动安装则按照如下步骤操作： 从 https://github.com/fatih/molokai 下载molokai.vim文件，放入~/.vim/colors中 然后在~/.vimrc文件中加入行colorscheme molokai即可。 因为我在 VSCode 和 Iterm2 中都采用了 Dracula 的主题，因此，vim 主题我也同样偏爱它，可以采用插键的方式安装：12Plugin &apos;dracula/vim&apos;:PluginInstall 然后在~/.vimrc文件中加入行colorscheme dracula即可。 主题相关的命令： 123:colorscheme &quot;查看当前主题:colorscheme space tab &quot;列出所有主题:colorscheme your-theme &quot;切换主题 设置vim为了让vim使用起来更加得心应手，先做一些简单的配置。 编辑VIM配置文件，可能一开始没有这个文件，不过没关系，直接vi ~/.vimrc保存这个文件即可。 今天学习到&lt;leader&gt; 这个概念，很强大，快捷键很方便！ nnoremap 将一个组合快捷键映射为另一个快捷键。 关于leader以及其他map知识，可以查看如下文章： 提高 Vim 使用效率的 12 个技巧 【Vim】使用map自定义快捷键 个人vim配置参考多人的配置，打造属于自己的Vim配置，这个配置不涉及插件的设置，因为常常生产环境是网络不通的，要迅速配置能用：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647let mapleader=&quot;,&quot; &quot; 设置 leaderlet g:mapleader = &apos;,&apos;&quot; 分屏窗口移动, Smart way to move between windowsmap &lt;C-j&gt; &lt;C-W&gt;jmap &lt;C-k&gt; &lt;C-W&gt;kmap &lt;C-h&gt; &lt;C-W&gt;hmap &lt;C-l&gt; &lt;C-W&gt;l&quot; Go to home and end using capitalized directions&quot; H和L跳转到行首行末, 实在不想按0和$, 太远noremap H ^noremap L $&quot; 命令行模式增强，ctrl - a到行首， -e 到行尾cnoremap &lt;C-a&gt; &lt;Home&gt;cnoremap &lt;C-e&gt; &lt;End&gt;&quot; 去掉搜索高亮noremap &lt;silent&gt;&lt;leader&gt;/ :nohls&lt;CR&gt;&quot; 快速保存和退出&quot; Quickly close the current windownnoremap &lt;leader&gt;q :q&lt;CR&gt;&quot; Quickly save the current filennoremap &lt;leader&gt;w :w&lt;CR&gt;syntax on &quot; 自动语法高亮set cursorline &quot; 突出显示当前行set encoding=utf-8set fileencoding=utf-8set fileformat=unix &quot;从Win上复制文件时，避免换行符错误set hlsearch &quot; 搜索时高亮显示被找到的文本set ignorecase smartcase &quot; 搜索时忽略大小写，但在有一个或以上大写字母时仍保持对大小写敏感set incsearch &quot; 输入搜索内容时就显示搜索结果set laststatus=2 &quot; 显示状态栏 (默认值为 1, 无法显示状态栏)set magic &quot; 设置魔术set nocompatible &quot; 关闭 vi 兼容模式set number &quot; 显示行号set paste &quot; 解决拷贝的时遇到注释会自动注释后续所有行的问题set ruler &quot; 打开状态栏标尺set shiftwidth=4 &quot; 设定 &lt;&lt; 和 &gt;&gt; 命令移动时的宽度为 4set softtabstop=4 &quot; 使得按退格键时可以一次删掉 4 个空格set smartindent &quot; 开启新行时使用智能自动缩进set tabstop=4 &quot; 设定 tab 长度为 4set ambiwidth=double &quot; 设置为双字宽显示，否则无法完整显示如:☆ vim配置文件中的注释，末尾用&quot;隔开即可。保留注释，对于了解配置内容有利。 vim配置参考 Michael728/my-config-files 个人总结的配置文件 wklken/k-vim Mac OS X 配置指南-vim 同时也有关于 macOS 介绍 强大的vim配置文件，让编程更随意 有vim配置的中文注释 FAQ1. github访问速度慢，下载插件失败 ubuntu上解决访问github慢的方法 2. mac上iterm2中, tmux里面鼠标复制, 无法选中一行内容然后你会发现你想复制terminal上的东西的时候，死活复制不了，这时按住 Option (Alt)键就行了。 ubuntu tmux复制粘贴总结 参考 pytlab-优雅的在终端中编写Python 同时介绍了 Tmux 和 Vim 的配置 那些离了就活不了的 VIM 插件 介绍了一些经典的插键 阮一峰-Vim 配置入门 YouCompleteMe 安装配置方法 知乎-Vim 8.0 正式发布 提到了 Vim 编译安装的一些好教程]]></content>
      <categories>
        <category>ToolsDev</category>
      </categories>
      <tags>
        <tag>Tools</tag>
        <tag>Vim</tag>
        <tag>Plugin</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git使用教程笔记]]></title>
    <url>%2F2018%2F11%2F24%2Fgit-advance%2F</url>
    <content type="text"><![CDATA[虽然之前写过一篇入门文章Git入门私房菜，但是工作中接触到的 Git 命令还有一些。有时候遇到一些小功能，就上网查一下，本文就针对用到的知识点做个全面的总结。 需要先在 Github 上创建个属于你的仓库，本文仓库名以 michalel-git 为例。 地址为： `git@github.com:Michael728/michael-git.git` Git 安装Git下载地址 Windows安装时需要注意在Configuring the line ending conversions界面，选择Checkout as-is,commit as -s，避免Windows的换行符问题。如果忘记设置，可以使用如下命令后期设置： 1git config --global core.autocrlf false 参考： GitHub 第一坑：换行符自动转换 Git 配置可以通过 git config -l 查看配置。 设置 Git 账号12git config --global user.name &quot;michael728&quot;git config --global user.email &quot;649168982@qq.com&quot; Git 配置别名git config文件来轻松为每一个命令设置别名。例如： 1234git config --global alias.co checkoutgit config --global alias.br branchgit config --global alias.ci commitgit config --global alias.st status 如果你想要执行外包命令，而不是一个 Git 子命令，可以在命令前面加 ！ 符号。 演示将git visual定义为gitk的别名： 1git config --global alias.visual &apos;!gitk&apos; 设置命令的别名，可以提高操作效率。查看.gitconfig文件vim ~/.gitconfig： 123456789101112131415161718192021222324[user] name = xxx email = xxx[i18n] commitencoding = utf-8 logoutputencoding = utf-8[core] quotepath = false[filter &quot;lfs&quot;] clean = git-lfs clean -- %f smudge = git-lfs smudge -- %f process = git-lfs filter-process required = true[alias] co = checkout br = branch c = commit s = status unstage = reset HEAD -- last = log -1 HEAD lg = log --graph --pretty=format:&apos;%Cred%h%Creset -%C(yellow)%d%Creset %s %Cgreen(%cr) %C(bold blue)&lt;%an&gt;%Creset&apos; --abbrev-commit --date=relative[color] ui = true 我们可以体验一个log的别名命令设置： 1lg = log --graph --pretty=format:&apos;%Cred%h%Creset -%C(yellow)%d%Creset %s %Cgreen(%cr) %C(bold blue)&lt;%an&gt;%Creset&apos; --abbrev-commit --date=relative 这是超厉害的别名缩写命令，试试现在的 git lg 有多酷炫吧！ Git 帮助文档授人以鱼不如授人以渔，先知道怎么通过帮助文档查看常用命令的说明吧： 12git helpgit help &lt;cmd&gt; 创建 Git 本地仓库已有远端仓库，创建本地仓库123456git clone git@github.com:Michael728/michael-git.gitcd michael-gittouch README.mdgit add README.mdgit commit -m &quot;add README&quot;git push -u origin master 已存在文件夹123456cd micahel-gitgit initgit remote add origin git@github.com:Michael728/michael-git.gitgit add .git commitgit push -u origin master 已存在 Git 仓库1234cd existing_repogit remote add origin git@github.com:Michael728/michael-git.gitgit push -u origin --all # --all 表示 Push all branches，-u 选项指定了一个默认主机git push -u origin --tags # --tags All refs under refs/tags are pushed 将本地的master分支推送到origin主机，同时指定origin为默认主机，后面就可以不加任何参数使用git push了。 参考： git push 的 -u 参数具体适合含义？ Git远程操作详解 git clone1git clone [-b br_name] url git@github.com:Michael728/michael-git.git 克隆的时候，可以指定下载远端的分支、自定义本地仓库的名字。如果不加分支名参数，git clone 命令会默认自动设置本地 master 分支跟踪克隆的远程仓库的 master 分支（其实是仓库的默认分支）。而且，默认远程仓库设置别名为 origin。 git add这是个多功能命令: 可以用它开始跟踪新文件 把已跟踪的文件放到暂存区 还能用于合并时把有冲突的文件标记为已解决状态，这个是在解决冲突时会用到的功能 git commit提交的操作，当你前面采用add命令将文件添加到暂存区跟踪后，需要通过commit将暂存区的内容提交到当前分支。 1git commit -m &quot;test&quot; 当一些已追踪的文件修改了，常常需要git add file，然后在git commit -m &quot;xxxx&quot;，其实这两个步骤可以合二为一：1git commit -am &quot;test&quot; 这么写个人觉得挺好，可以有效避免有些懒人git add .的方式，将一切文件都添加到了暂存区，导致最后多余文件提交入库。 git push语法： 1git push &lt;远程主机名&gt; &lt;本地分支名&gt;:&lt;远程分支名&gt; 如果省略远程分支名，则表示将本地分支推送与之存在”追踪关系”的远程分支（通常两者同名），如果该远程分支不存在，则会被新建。 当想要将master分支推送到origin服务器上： 1git push origin master 将本地分支test推送到远端时可以重命名： 1git push origin test:remote-test 利用该用法，还可以推送空分支到远端，实现远端分支的删除： 123git push origin :remote-test# 和如下命令等同git push origin --delete remote-test git rm从 Git 中移除某个文件，就必须从已跟踪的文件清单中删除（从暂存区域移除文件），然后提交。可以使用git rm命令完成此项工作，并连带从工作目录中删除指定的文件。 当我们先把某文件从 Git 库中删除（亦即从暂存区移除），但仍然希望保留在当前工作目录中。比如当你忘记在.gitignore文件中将一些文件忽略，但是却不小心把大的日志文件添加到暂存区域时，这一做法很有用： 12# --cached 将 README 文件从暂存区移除，但是工作区目录仍然保留git rm --cached README git checkout切换到某个历史版本： 1git checkout &lt;commit id&gt; 在 Git 中从当前分支创建并检出新分支的命令是： 1git checkout -b new-br 这个命令实际是： 1git checkout -b new-br current-br 在本地创建并切换到远端的分支： 12git branch -va # 查看本地+远程分支列表git checkout -b dev origin/dev 还可以可以在checkout命令中使用Hash值作为起点创建分支： 1git checkout -b name-of-branch &lt;commit id&gt; 除了有“切换”的意思，checkout还有一个撤销的作用。 举个例子，假设我们在一个分支开发一个小功能，刚写完一半，这时候需求变了，而且是大变化，之前写的代码完全用不了，好在你刚写，甚至都没有 git add 进暂存区，这个时候很简单的一个操作就直接把原文件还原： 1git checkout &lt;filename&gt; 参考：在git中checkout历史版本 git log1git log --pretty=oneline # 检查提交日志，都在一行：&lt;commit id&gt; &lt;message&gt; 查看某人的提交： 1git log --author=michael 一个常用的选项是-p，用来显示每次提交的内容差异，也可以加上-2或者-n2来仅显示最近两次提交： 12git log -p -2git log -n1 --format=format:%h # 查看当前分支最新的 commit id 缩略值 列出最近两周内的提交： 1git log --since=2.weeks git log命令全解析，打log还能这么随心所欲！ git-scm 2.3 Git 基础 - 查看提交历史 git diffgit diff本身只显示尚未暂存的改动，而不是自上次提交以来所做的所有改动。 若要查看已暂存的将要添加到下次提交里的内容和上次提交的内容的变化，可以用git diff --staged git branch新建develop分支：1git branch develop 切换分支：复习一下checkout的用法 1git checkout develop 新建并切换到develop分支：1git checkout -b develop 将分支develop推送到远程仓库origin：1git push origin develop 如果想给远程的分支取名为develop2，可以：1git push origin develop:develop2 不建议这么操作易混乱，还是本地分支名和远程分支名保持一致比较好。 关联本地分支和远程分支：创建本地分支并切换到分支：git checkout -b tools-dev 创建远程分支：git push origin tools-dev 本地分支推送到远程服务器时，远程分支自动创建，推送本地分支到远程： 1git push --set-upstream &lt;remote-name&gt; &lt;local-branch-name&gt;:&lt;remote-branch-name&gt; &lt;remote-name&gt;：远程 Git 服务器名称，一般为origin &lt;local-branch-name&gt;：本地分支名称 &lt;remote-branch-name&gt;：远程分支名称 一般情况下，本地分支和远程分支名称相同，所以可简化为： 1git push --set-upstream &lt;remote-name&gt; &lt;branch-name&gt; --set-upstream参数用来关联本地分支和远程分支 参考： Git创建远程分支 Git远程操作详解 查看本地分支：1git branch 查看远程分支：1git branch -r 删除本地分支：12git branch -d developgit branch -D develop（强制删除） 删除远程分支：123git push origin :remote-test# 和如下命令等同git push origin --delete remote-test 撤销操作1git commit --amend 如果已经提交完了（已经commit）了，发现漏掉几个文件没有添加，或者提交信息（-m)写错了，可以运行带有--amend选项的提交命令重新提交。 这个命令会将暂存区的文件提交。文本编辑器编辑后，会覆盖原来的提交信息。 取消暂存文件1git reset HEAD &lt;file&gt; 撤销对文件的修改1git checkout -- &lt;file&gt; 你需要知道 git checkout -- [file] 是一个危险的命令，这很重要. 远程仓库的使用查看远程仓库1git remote -v 如果想查看远程仓库更多的信息，可以使用git remote show &lt;remote-name&gt;命令。 远程仓库的移除与重命名 12git remote rename &lt;old-remote-name&gt; &lt;new-remote-name&gt;git remote rename pb paul 如果因为一些原因要移除一个远程仓库，可以使用git remote rm &lt;remote-name&gt;。 添加一个新的远程 Git 仓库，同时指定一个可以轻松引用的简写：1git remote add &lt;remote-name&gt; &lt;url&gt; 这里的remote-name常常取名为origin。所以，常见的origin其实是一个你 Git 仓库跟踪的远程仓库的简写。 拉取远端仓库有但你本地没有的信息：1git fetch &lt;remote-name&gt; 如果你使用clone命令克隆了一个仓库，命令会自动将其添加为远程仓库并默认以origin为缩写。 Tag列出标签12git tag # 列出所有标签git tag -l &apos;v1.8*&apos; # 列出以 v1.8 开头的所有标签 创建标签Git使用两种主要类型的标签： 附注（annotated）标签 轻量（ightweight）标签 前者会包括一些注释信息，来进一步解释这个 tag 的作用，而后者就仅仅只是一个 tag 的名字 附注标签1git tag -a v1.4 -m &apos;my version 1.4&apos; 通过git show &lt;tag-name&gt;命令可以看到标签信息 轻量标签1git tag v1.4 没用-a、-m的参数，只需要提供标签名字 删除标签1git tag -d &lt;tagname&gt; 补打标签假设忘记给项目打标签，可以在之后加上：基于某历史节点的commit id补打Tag： 1git tag -a v1.2 &lt;commit id&gt; 共享标签默认情况下，git push命令并不会传送标签到远程服务器上。在创建完标签后你必须显示地推送标签到共享服务器上。这个过程就像共享远程分支一样，可以运行git push origin [tagname] 如果想要一次性推送很多标签，也可以使用--tags选项的git push： 1git push origin --tags 检出标签1git checkout -b &lt;new-br&gt; &lt;tagname&gt; 参考： The Junior Git 6 Git 基础 - 打标签 使用场景新特性开发，创建临时分支，再合并到主干123456789#创建特性分支git checkout -b featureA……#提交之前，先checkout到master分支，更新一下git co mastergit pull#切到特性分支，在本地与最新的master分支合并git co featureAgit rebase -i master 参考： 聊下git rebase -i 本地仓库关联远程仓库：已有本地仓库，需要关联远端仓库，分两步：第一步，在Github上新建一个仓库test；第二步：将本地仓库与Github上的test项目进行关联，切换到本地仓库目录：git remote add origin git@github.com:xx/test.git什么意思？远程仓库的地址为：`git@github.com:xx/test.git`，而origin是给这项目的远程仓库起的名字，是的，名字你可以随便取，只不过大家公认的只有一个远程仓库时名字就是origin，为什么要给远程仓库取名字？因为我们可能一个项目有多个远程仓库，比如，Github一个，比如公司一个，这样的话，提交的时候可以提交到不同的远程仓库就需要指定不同的仓库名字了。 查看我们当前项目有哪些远程仓库可以执行如下命令： 1git remote -v 接下来，本地的仓库可以向远程仓库进行代码提交了： 1git push origin master 在代码提交之前，西安设置自己的用户名和邮箱，这些信息会出现在所有的commit记录里： 12git config --global user.name &quot;xxx&quot;git config --global user.email &quot;xx@mail.com&quot; 同时负责多个Bug的修改 更新远程仓库代码 1git fetch 以origin/master为基础创建分支 1git checkout -b fix/bug23 origin/master 修改完 1git commit 推送前更新一下代码，看看别人是否有修改 1git fetch 有修改的话rebase一下 1git rebase origin/master 生成patch 1git format-patch origin/master 发送patch或者也可以使用request pull 12send email OR Request pull[maintainer接收后] 分支使用已经完成，可以删除了 1git branch -D fix/bug23 想知道某行代码谁修改的阅读代码时，想知道某行代码是谁修改的？ 找到对应commit id 1git blame src/xxx.c 查看具体提交的内容 1git show &lt;commit id&gt; 远端仓库会退到历史版本 查找commit id通过git log查找想要会退到的历史版本的commit id 本地执行回退 1git reset --hard [commit id] 强制推送 1git push -f 参考：git 远程仓库版本的回退以及git reset 几种常用方式记录 突然插入bugifx，回退工作目录git stash保存所有工作内容 cherry-pick将某一提交点的修改拿到当前分支上：git cherry-pick 哈希值 基本的团队协作流程多人协作下的分支管理规范很重要，就跟代码规范一样重要。 以下就跟大家推荐一种我们内部在使用的一种分支管理流程 Git Flow。 Gti FlowGit Flow 是一种比较成熟的分支管理流程，我们先看一张图能清晰的描述他整个的工作流程： 大部分情况下都会拥有两个分支 master 和 develop，他们的职责分别是: master：永远处在即将发布(production-ready)状态 develop：最新的开发状态 确切的说 master、develop 分支大部分情况下都会保持一致，只有在上线前的测试阶段develop 比 master 的代码要多，一旦测试没问题，准备发布了，这时候会将 develop 合并到master 上。 但是，我们发布之后又会进行下一版本的功能开发，开发中间可能又会遇到需要紧急修复 bug，一个功能开发完成之后突然需求变动了等情况，所以 Git Flow 除了以上 master 和 develop两个主要分支以外，还提出了以下三个辅助分支： feature: 开发新功能的分支, 基于 develop, 完成后 merge 回 develop release: 准备要发布版本的分支, 用来修复 bug，基于 develop，完成后 merge 回develop 和 master hotfix: 修复 master 上的问题, 等不及 release 版本就必须马上上线. 基于 master, 完成后merge 回 master 和 develop 什么意思呢？举个例子，假设我们已经有 master 和 develop 两个分支了，这个时候我们准备做一个功能A，第一步我们要做的，就是基于 develop 分支新建个分支： 1git branch feature/A 看到了吧，其实就是一个规范，规定了所有开发的功能分支都以 feature 为前缀。但是这个时候做着做着发现线上有一个紧急的 bug 需要修复，那赶紧停下手头的工作，立刻切换到 master 分支，然后再此基础上新建一个分支： 1git branch hotfix/B 代表新建了一个紧急修复分支，修复完成之后直接合并到 develop 和 master ，然后发布。然后再切回我们的 feature/A 分支继续着我们的开发，如果开发完了，那么合并回 develop 分支，然后在 develop 分支属于测试环境，跟后端对接并且测试的差不多了，感觉可以发布到正式环境了，这个时候再新建一个 release 分支： 1git branch release/1.0 这个时候所有的 api、数据等都是正式环境，然后在这个分支上进行最后的测试，发现 bug 直接进行修改，直到测试 ok 达到了发布的标准，最后把该分支合并到 develop 和 master 然后进行发布。 以上就是 Git Flow 的概念与大概流程，看起来很复杂，但是对于人数比较多的团队协作现实开发中确实会遇到这么复杂的情况，是目前很流行的一套分支管理流程，但是有人会问每次都要各种操作，合并来合并去，有点麻烦，哈哈，这点 Git Flow 早就想到了，为此还专门推出了一个 Git Flow 的工具，并且是开源的： GitHub 开源地址： https://github.com/nvie/gitflow 简单点来说，就是这个工具帮我们省下了很多步骤，比如我们当前处于 master 分支，如果想要开发一个新的功能，第一步切换到 develop 分支，第二步新建一个以 feature 开头的分支名，有了 Git Flow 直接如下操作完成了： 1git flow feature start A 这个分支完成之后，需要合并到 develop 分支，然而直接进行如下操作就行： 1git flow feature finish A 如果是 hotfix 或者 release 分支甚至会自动帮你合并到 develop、master 两个分支。 想必大家已经了解了这个工具的具体作用，具体安装与用法我就不多提了，感兴趣的可以看我下我之前写过的一篇博客： http://stormzhang.com/git/2014/01/29/git-flow/ 详细演示下怎么给一个项目发起 Pull Request(PR)： 第一步，找到你想发起 PR 的项目，点击右上角的 Fork 按钮，然后该项目就出现在了你自己账号的 Repository 里。 第二步，把fork的项目 clone 到本地，然后修改的 bug 也好，想要新增的功能也好，总之把自己做的代码改动开发完，接着，把自己做的代码改动 push 到 你自己的 GitHub 上去。 第三步，点击你 Fork 过来的项目主页的 Pull requests 页面，点击右上角的New pull request。页面自动会比较该项目与原有项目的不同之处，最顶部声明了是源仓库的分支与你fork过来的分支的对比。同样的我写好标题和描述，然后我们点击中间的 Create pull request 按钮，至此我们就成功给该项目提交了一个 PR。然后就等着项目原作者 review 你的代码，并且决定会不会接受你的 PR，如果接受，那么恭喜你，你已经是该项目的贡献者之一了。 Git FAQgit merge和git rebase的区别12git checkout mastergit merge featureA 其实 rebase 命令也是合并的意思，上面的需求我们一样可以如下操作： 12git checkout mastergit rebase featureA rebase 跟 merge 的区别你们可以理解成有两个书架，你需要把两个书架的书整理到一起去，第一种做法是 merge ，比较粗鲁暴力，就直接腾出一块地方把另一个书架的书全部放进去，虽然暴力，但是这种做法你可以知道哪些书是来自另一个书架的；第二种做法就是rebase ，他会把两个书架的书先进行比较，按照购书的时间来给他重新排序，然后重新放置好，这样做的好处就是合并之后的书架看起来很有逻辑，但是你很难清晰的知道哪些书来自哪个书架的。 只能说各有好处的，不同的团队根据不同的需要以及不同的习惯来选择就好。 rebase 和 merge的另一个区别是rebase 的冲突是一个一个解决，如果有十个冲突，先解决第一个，然后用命令 12git add -ugit rebase --continue 继续后才会出现第二个冲突，直到所有冲突解决完，而merge 是所有的冲突都会显示出来。另外如果rebase过程中，你想中途退出，恢复rebase前的代码则可以用命令 1git rebase --abort 关于git rebase还有很多知识点： 聊下git rebase -i git merge 和 git rebase 小结 Git Community Book 中文版-rebase 压缩多个Commit 合并多个 Commit git branch -r与git branch -a的区别？ git branch -r只显示远端分支， git branch -a 显示本地分支和远程分支 发现好用的开源项目-GithubGitHub 其中一个最重要的作用就是发现全世界最优秀的开源项目，你没事的时候刷刷微博、知乎，人家没事的时候刷刷 GitHub ，看看最近有哪些流行的项目，久而久之，这差距就越来越大，那么如何发现优秀的开源项目呢？ 关注一些活跃的大牛 Explore菜单下的Trending，看到最近的一些热门开源项目，很多人主动获取开源项目的最好的途径，可以选择“当天热门”，“一周之内热门”和“一月之内热门”来查看，并且，可以分语言来查看。 Search，按照Most Stars来筛选。 除此之外，GitHub 的 Search 还有一些小技巧，比如你想搜索的结果中 star 数大于1000的，那么可以这样搜索：android http stars:&gt;1000 有些人如果习惯用 Google 进行搜索，那么想搜索 GitHub 上的结果，不妨前面加 GitHub 关键字就ok了，比如我在 google 里输入 GitHub android http ，每个关键字用空格隔开。 福利大放送GitHub 上影响力很大，同时又对你们很有用的项目： free-programming-books: 这个项目整理了所有跟编程相关的免费书籍，而且全球多国语言版的都有，中文版的在这里 free-programming-books-zh ob-my-zsh: 俗话说，不会用 shell 的程序员不是真正的程序员。oh-my-zsh 毫无疑问就是目前最流行，最酷炫的 shell awesome: GitHub 上有各种 awesome 系列，简单来说就是这个系列搜罗整理了 GitHub 上各领域的资源大汇总，比如有 awesome-android, awesome-ios, awesome-java, awesome-python 等等等，就不截图了，你们自行去感受。 github-cheat-sheet: GitHub 的使用有各种技巧，只不过基本的就够我们用了，但是如果你对 GitHub 超级感兴趣，想更多的了解 GitHub 的使用技巧，那么这个项目就刚好是你需要的，每个 GitHub 粉都应该知道这个项目。 LearningNotes：这是一份非常详细的面试资料，涉及 Android、Java、设计模式、算法等等等，你能想到的，你不能想到的基本都包含了，可以说是适应于任何准备面试的 Android 开发者，看完这个之后别说你还不知道怎么面试！ GitHub 上优秀开源项目真的是一大堆，就不一一推荐了，授人以鱼不如授人以渔，请大家自行主动发掘自己需要的开源项目吧，不管是应用在实际项目上，还是对源码的学习，都是提升自己工作效率与技能的很重要的一个渠道，总有一天，你会突然意识到，原来不知不觉你已经走了这么远！ 最后 Git使用教程笔记 Pro Git 中文 Git常用命令备忘]]></content>
      <categories>
        <category>ToolsDev</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【笔记】快速上手 Linux，玩转典型应用]]></title>
    <url>%2F2018%2F11%2F18%2Fnote-linux-basic-system%2F</url>
    <content type="text"><![CDATA[工作近1年多，真正转来开发这边还没7个月，很多基础都不扎实，看了个视频课程，做做笔记： 概要 详细链接]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Note</tag>
        <tag>Linux</tag>
        <tag>System</tag>
        <tag>Mooc</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【总结】写作、阅读、工作等日常习惯]]></title>
    <url>%2F2018%2F11%2F16%2Fhabit-writing-reading-working%2F</url>
    <content type="text"><![CDATA[习惯是在习惯中养成的。 本文主要介绍一些平日里在生活、工作当中一些看到的值得学习的习惯以及个人的一些经验想法总结等，会长期更新。 写作 写作的时候在中文和英文之间加空格，来源 除非是完整的英文句子，否则按照全局语言使用中文标点 中文各数字之间需要增加空格，来源 数字各单位之间需要增加空，例如SSD 一共有 20 TB 全形标点各其他字符之间不加空格，例如 我买了一部新 iPhone，还行 ✔️ 正确 我买了一部新 iPhone ，还行 ❎ 错误 千万不要同时用段首缩排和段间距 来源 目前大陆用的是弯引号，而台湾、香港用的是直角引号。对引号的使用使用方式也有所区别，大陆是先用双引号“ ”，内部如需再引用，再用单引号‘’，在香港和台湾都规定的是先用单引号「」，内部如需要引用，再用双引号『』 来源 对于技术文档中的参数等，[]：内的内容意思是：可写可不写; {}：那就必须要在{}内给出的选择里选一个; &lt;&gt;：表示必选 来源 排版好文： mzlogin/chinese-copywriting-guidelines 作者的文章 中文文案排版指北（简体中文版） 值得参考 阅读 学习不一定要一大段时间，可以挤时间。 碎片时间不能碎片学习，要碎片化时间系统化学习。 看书不一定要背住，不管记不记得住，要坚持看！无法清晰记住的，将来也会变成「隐性记忆」。 好书多读几遍，读纸质书，细度时做好笔记、划出重点；一个月后，扫读；半年后，忆读。 以上内容，参考自infoQ-佛系程序员的月薪五万指南 专注 有一个明确的目标、易于实现的小目标，将有助于专注的高效率的完成一件小事。 只设定一个「优先级最高德事」，其他所有事情不再重要，只集中精力做一件事！ 「2/8」原则，可能有80%的事情都没那么重要，只需投入20%的时间，而剩下的20%的重要事情，则需要投入80%的时间。 来源：如何集中精力 早起 要适应早起，首先要明确早起的目的，要知道第二天的行动清单，最重要的几件事 准备好一杯水，让你保持清醒，而不是回到床上 坚持每天同一时间起床，形成生物钟 早起，慢慢养成一个一个好的习惯]]></content>
      <categories>
        <category>Habit</category>
      </categories>
      <tags>
        <tag>习惯</tag>
        <tag>写作</tag>
        <tag>总结</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[那些做的不错的短视频]]></title>
    <url>%2F2018%2F11%2F11%2Fvideo-demo%2F</url>
    <content type="text"><![CDATA[需要做的仅仅是超越昨日的自己！ 20181111-【Nike - Dream Crazy】 20181227- 西方餐桌礼仪 How to improve your etiquette manners[doge] 一个将西方餐桌礼仪正确、错误行为对比的小视频]]></content>
      <categories>
        <category>Life</category>
      </categories>
      <tags>
        <tag>Video</tag>
        <tag>广告</tag>
        <tag>励志</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[打造性感好用的VS Code编辑器]]></title>
    <url>%2F2018%2F10%2F28%2Ftools-vscode%2F</url>
    <content type="text"><![CDATA[官网： https://code.visualstudio.com/ 主命令框F1或Ctrl+Shift+P: 打开命令面板。在打开的输入框内，可以输入任何命令，例如： 按一下 Backspace会进入到 Ctrl+P 模式 在Ctrl+P下输入&gt;可以进入Ctrl+Shift+P模式 在 Ctrl+P 窗口下还可以: 直接输入文件名，跳转到文件 ?列出当前可执行的动作 !显示 Errors或 Warnings，也可以Ctrl+Shift+M :跳转到行数，也可以 Ctrl+G 直接进入 @跳转到symbol（搜索变量或者函数），也可以 Ctrl+Shift+O 直接进入 @根据分类跳转symbol，查找属性或函数，也可以 Ctrl+Shift+O 后输入:进入 #根据名字查找 symbol，也可以 Ctrl+T 常用快捷键编辑器与窗口管理 打开一个新窗口： Ctrl+Shift+N 关闭窗口： Ctrl+Shift+W 同时打开多个编辑器（查看多个文件） 切出一个新的编辑器（最多 3 个） Ctrl+\，也可以按住 Ctrl 鼠标点击 Explorer 里的文件名 左中右 3 个编辑器的快捷键 Ctrl+1 Ctrl+2 Ctrl+3 编辑器换位置， Ctrl+k然后按 Left或 Right 代码编辑格式调整 对python文件进行代码格式化操作时，会提示安装autopep8 代码格式化： Shift+Alt+F，或 Ctrl+Shift+P 后输入 format code 代码行缩进: Ctrl+[ 、 Ctrl+] 在当前行下边插入一行 Ctrl+Enter 在当前行上方插入一行 Ctrl+Shift+Enter 上下移动一行： Alt+Up 或 Alt+Down 向上向下复制一行： Shift+Alt+Up 或 Shift+Alt+Down 光标相关 移动到定义处： F12 定义处缩略图：只看一眼而不跳转过去:Alt+F12 移动到文件结尾： Ctrl+End 移动到文件开头： Ctrl+Home 下面两个功能和alt+↑/↓配合，很方便的移动代码块： 选择从光标到行尾：Shift+End 选择从行首到光标处： Shift+Home 这两个功能很爽，可以同时编辑一些变量名： 多行编辑(列编辑)：Ctrl+Alt+Down/Up或者Alt+Shift+鼠标左键， 同时选中所有匹配： Ctrl+Shift+L Ctrl+D 下一个匹配的也被选中 (在 sublime 中是删除当前行，后面自定义快键键中，设置与 Ctrl+Shift+K 互换了) 回退上一个光标操作： Ctrl+U 删除光标右侧的所有字： Ctrl+Delete 扩展/缩小选取范围： Shift+Alt+Left 和 Shift+Alt+Right 移动到后半个括号： Ctrl+Shift+] 重构代码 查看函数引用和批量休修改函数名，好用： 重命名：比如要修改一个方法名，可以选中后按 F2，输入新的名字，回车，会发现所有的文件都修改了 找到所有的引用： Shift+F12 同时修改本文件中所有匹配的： Ctrl+F12 跳转到下一个 Error 或 Warning：当有多个错误时可以按 F8逐个跳转 查看 diff： 在 explorer 里选择文件右键 Set file to compare，然后需要对比的文件上右键选择 Compare with file_name_you_chose 查找替换 查找:Ctrl+F 查找替换:Ctrl+H 整个文件夹中查找:Ctrl+Shift+F 显示相关 全屏：F11 zoomIn/zoomOut：Ctrl +/- 侧边栏显/隐：Ctrl+B 显示资源管理器:Ctrl+Shift+E 显示搜索:Ctrl+Shift+F 显示 Git:Ctrl+Shift+G 显示 Debug:Ctrl+Shift+D 显示 Output:Ctrl+Shift+U 设置修改 VSCode 默认 terminal/终端在 vscode 设置中，搜索 terminal.integrated.shell.windows，点击在 settings.json 中编辑，将 git bash 终端路径设置进去即可 1D:\\Program Files\\Git\\bin\\bash.exe 其他自动保存：File -&gt; AutoSave ，或者 Ctrl+Shift+P，输入 auto VS Code 中文注释显示乱码怎么办？https://www.zhihu.com/question/34415763/answer/60444047将设置中的”files.autoGuessEncoding”项的值改为true即可。 我的配置12345678910111213141516171819202122232425262728&#123; &quot;workbench.iconTheme&quot;: &quot;vscode-icons&quot;, &quot;files.autoSave&quot;: &quot;onWindowChange&quot;, // 设置保存时，自动将Python代码的一些空格给trim掉； &quot;files.trimTrailingWhitespace&quot;: true, // 将一些编译后而不想在编辑器里看到的文件隐藏； &quot;files.exclude&quot;: &#123; &quot;.vs*&quot;: true, &quot;*.*~&quot;: true, &quot;*.pyc&quot;: true, &quot;*/*.pyc&quot;: true &#125;, &quot;terminal.integrated.rendererType&quot;: &quot;dom&quot;, &quot;terminal.integrated.shell.windows&quot;: &quot;C:\\Program Files\\Git\\bin\\bash.exe&quot;, &quot;python.formatting.autopep8Args&quot;: [ &quot;--max-line-length=100&quot; ], &quot;editor.formatOnSave&quot;: true, &quot;python.linting.pylintEnabled&quot;: true, &quot;python.linting.pylintArgs&quot;: [ &quot;--include-naming-hint=n&quot;, &quot;--disable=W0311&quot;, &quot;--disable=C0103&quot;, &quot;--disable=E1101&quot; ], &quot;files.eol&quot;: &quot;\n&quot;, &quot;editor.wordWrap&quot;: &quot;on&quot;&#125; 常用扩展VS Code扩展商店：https://marketplace.visualstudio.com/vscode 主题可以来主题商城选择： 切换主题的快捷键：ctrl+k,ctrl+t One Dark Pro Atom One Dark FlatUI Material Icon Theme: 图标主题 vscode-icons VSCode Great Icons Dracula Official：主题，推荐 bookmarks：ctrl+alt+l快速跳转，图标设置 开发扩展 AutoFileNmae:auto complete file name，自动补全文件的名字 code runner:ctrl+alt+n Remote - SSH：远端连接 VM 编辑的利器！ Guides:显示代码对其辅助线 gitlens:显示代码每一行的最新修改人 Beautify:显示js/json/css美化，按F1 Rainbow Brackets：有颜色的显示括号匹配 Prettier - Code formatter Path Intellisense: 路径匹配 Auto Rename Tag：自动修改标签 leetcode 在 VS Code 中刷算法的插键，强烈安利，为此还录制了一期 B 站视频 Color Highlight:写csss时，颜色值会增加对应的颜色背景显示 Vetur：VUE扩展 open in browser:alt+b选择浏览器预览文件 Settings Sync: 同步配置 下面介绍一下怎么设置同步：ctrl+shift+p，输入sync，会看到相关选项，选择update/upload settings，然后会输入https://github.com/settings/tokens中设置的key。具体的用法，Settings Sync的扩展主页介绍的很详细了：https://marketplace.visualstudio.com/items?itemName=Shan.code-settings-sync FAQ如何设置中文界面 设置中文界面 Microsoft/vscode-tips-and-tricks language-pack 参考 Visual Studio Code 简明使用教程-w3cschool Microsoft Visual Studio Code 中文手册 VS Code 配置 VSCode配置备忘 Getting Started with Python in VS Code Visual Studio Code初探 使用Python virtualenv时如何设置VS code 学会用好 Visual Studio Code]]></content>
      <categories>
        <category>ToolsDev</category>
      </categories>
      <tags>
        <tag>Tools</tag>
        <tag>IDE</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS 安装 CICD 利器 Jenkins]]></title>
    <url>%2F2018%2F10%2F11%2Fcicd-jenkins-01%2F</url>
    <content type="text"><![CDATA[环境准备安装JDK安装Oracle JDK Jenkins 自身采用 Java 开发，所以要必须安装 JDK； 博客园-Linux安装JDK 1234export JAVA_HOME=/usr/java/jdk1.8.0_171export JRE_HOME=$&#123;JAVA_HOME&#125;/jreexport CLASSPATH=.:$&#123;JAVA_HOME&#125;/lib:$&#123;JRE_HOME&#125;/libexport PATH=$&#123;JAVA_HOME&#125;/bin:$PATH 创建软连接： 1ln -s /usr/local/java/jdk1.8.0_171/bin/java /usr/bin/java 注意：Java版本不能是gcj，会导致Jenkins有问题，centos7搭建jenkins小记文章中提到的java版本问题导致CentOS下的Jenkins有问题。 安装openjdk的方法1yum -y install java-1.8.0-openjdk java-1.8.0-openjdk-devel 参考： Centos7安装OpenJDK8 OpenJDK官网 安装Git1yum install git 规避磁盘过满问题1.方法1：创建软连接，准备较大空间 /data挂在了较大空间，然后在其中创建相关目录： 12mkdir -p /data/jenkinsln -s /data/jenkins/ /var/lib/jenkins 2.方法2：丢弃构建 设置构建最大保留天数或者保留个数，实现自动删除构建结果。 参考： Jenkins服务器磁盘空间管理策略 CentOS离线安装-推荐1234## http://pkg.jenkins-ci.org/redhat-stable/wget http://pkg.jenkins-ci.org/redhat/jenkins-2.39-1.1.noarch.rpm ## 下载(也可以Windows下载再转过来)sudo rpm --import https://pkg.jenkins.io/redhat-stable/jenkins.io.key ## 导入公钥，发现离线安装，不需要导入公钥就能安装rpm -ih jenkins-2.7.2-1.1.noarch.rpm 自动安装完成之后： /usr/lib/jenkins/jenkins.war WAR包 /etc/sysconfig/jenkins 配置文件 /var/lib/jenkins/ 默认的JENKINS_HOME目录 /var/log/jenkins/jenkins.log Jenkins日志文件 启动Jenkins: 12sudo systemctl enable jenkins # 开机自启动Jenkinssudo systemctl start jenkins # 启动Jenkins 查看服务细节： 1systemctl status jenkins.service 验证Jenkins Server访问链接： 1telnet &lt;ip&gt; 8080 如果访问有问题，需要把防火墙关了： 12systemctl stop firewalldsystemctl disable firewalld.service #重启不自动开启 通过如下两个命令查看防火墙是否关闭： 12systemctl list-unit-files|grep firewalld.serviceiptables -t nat -S 在线安装1234567# 添加Jenkins源sudo wget -O /etc/yum.repos.d/jenkins.repo https://pkg.jenkins.io/redhat-stable/jenkins.reposudo rpm --import https://pkg.jenkins.io/redhat-stable/jenkins.io.keyyum repolist # Update your package manager list to get the latest packages# 安装yum install java-1.8.0-openjdk jenkinsservice jenkins start # 启动 基于Tomcat安装 在Tomcat官网下载tar包 将tar包拷贝至/usr/local目录并解压：cd /usr/local/ &amp;&amp; tar zxvf apache-tomcat-9.0.12.tar.gz 访问jenkins官网下载长期维护版本的jenkins.war拷贝至/usr/local/apache-tomcat-9.0.12/webapps，启动tomcat：cd /usr/local/apache-tomcat-9.0.12 访问：http://ip:8080/jenkins 管理员密码访问：1cat /root/.jenkins/secrets/initialAdminPassword 基于这种方式安装的Jenkins位置处于/root/.jenkins，因此，为了避免Job占用空间过大，需要执行如下命令创建软连接： 1ln -s /data/jenkins_jobs/ /root/.jenkins/jobs Jenkins设置为了不因为权限出现各种问题，这里直接使用root 123## sudo vim /etc/sysconfig/jenkinsJENKINS_USER=&quot;root&quot; ## 原值 &quot;jenkins&quot; 必须修改，否则权限不足JENKINS_PORT=&quot;8080&quot; ## 原值 &quot;8080&quot; 可以不修改 修改目录权限 123chown -R root:root /var/lib/jenkinschown -R root:root /var/cache/jenkinschown -R root:root /var/log/jenkins Centos安装参考： How to install Jenkins on CentOS 7 Jenkins 持续集成综合实战 CentOS 7 安装 Jenkins-提到配置权限 以root用户运行jenkins中shell命令 CentOS 安装 Jenkins ken的杂谈-CentOS 7 下Jenkins安装部署教程 Ubuntu 下载https://pkg.jenkins.io/debian/jenkins.io.key apt-key add jenkins.io.key 以上两步，可以合二为一： 1wget -q -O - https://pkg.jenkins.io/debian/jenkins-ci.org.key | sudo apt-key add - sh -c &#39;echo deb http://pkg.jenkins.io/debian-stable binary/ &gt; /etc/apt/sources.list.d/jenkins.list&#39; apt-get update apt-get install jenkins /etc/init.d/jenkins start。或者service start jenkins。启动Jenkins。 通过：http://{ip}:8080 访问jenkins。 cat /var/lib/jenkins/secrets/initialAdminPassword得到默认密码填入下面的密码框中 安装好之后，可以修改相关配置改变默认端口： /etc/default/jenkins Ubuntu安装参考： how to change port number for Jenkins installation In Ubuntu 12.04 How to install Jenkins on Ubuntu 16.04 Jenkins master优化增加同时打开文件句柄数增加同时打开文件句柄数，linux默认一个进程能同时打开的文件句柄是1024个，在jenkins master肯定是不够的，需要调整成65535 CentOS系统，修改/etc/security/limits.conf，在文件最后增加一行: 1root - nofile 65535 重启后生效，可以通过命令ulimit -a查看 设置tomcat 日志循环，限制日志的大小https://stackoverflow.com/questions/8342336/how-to-set-maximum-number-of-rolls-and-maximum-log-size-for-tomcat Jenkisn配置Jenkins用户admin账号初始密码： 1cat /var/lib/jenkins/secrets/initialAdminPassword Jenkins使用 – 用户设置 Jenkins使用Jenkins关闭、重启、重载http://localhost:8080/[exit/restart/reload] 参考： Jenkins的关闭、重启 Ubuntu 16安装、配置Jenkins实践 Jenkins Job指定执行节点 关联job，进入job的配置页面，勾选Restrict where this project can be run 利用了标签的功能 参考： Jenkins使用教程之管理节点 Jenkins升级可以通过系统管理(System management)–&gt; 系统信息(System Info)查找.war的文件 1executable-war /usr/lib/jenkins/jenkins.war 先列出官网地址：https://jenkins.io/download/ 升级之前，停止Jenkins服务（记得备份原来的jenkins.war，以防万一） 1http://jenkinsIP:port/exit 从官网下载最新的war包，然后替换掉上面路径下的war。 替换完成后，重启： 12systecmctl start jenkins # centosservice jenkins start # ubunutu 参考： Jenkins技巧：如何更新Jenkins到最新版本 Jenkins插件 dashboard view：Dashboard-view自定义jenkins任务集视图 Workspace Cleanup Plugin：这个插件可以再每次build之前清空workspace Monitoring：监控一些机器的状态信息了 Folders View：新建任务时，支持创建文件夹。 SSH Slaves：添加节点时，可以采用SSH方式链接； PostBuildScript：根据 Build 状态执行脚本 Post Build Task Pipeline：必须 【请勾选】 Build Pipeline Plugin：用于创建pipline视图 Configuration Slicing：主要功能是可以批量设置job的属性，比如设置保留多少天的构建记录，神器之一，有效解决Jenkins磁盘过满的问题 Multijob plugin：配置Multijob必备的插件； Timestamper Build Timeout plugin：构建超时插件 Folders：可嵌套地定义文件夹来级别 views / jobs Custom Tools Plugin Git plugin：Git插件 【请勾选】 Git Parameter GitLab Gitlab Hook Plugin Gitlab Authentication plugin Node and Label parameter plugin Publish Over SSH Groovy plugins：并发任务解决 Windows Slaves Plugin：连接Windows Slaves，默认安装了 Matrix Authorization Strategy Plugin：矩阵形式认证策略插件，默认安装了 插件使用参考： jenkins常用一些插件 thoughtworks-第二话：Jenkins必备插件安装 Jenkins常用插件介绍 小团队持续集成之实践【6】 - Jenkins - 安装与插件篇 Jenkins持续集成平台搭建 Jenkins SlaveSlave机器上需要安装好git、配置好Java环境（尤其是一些类似JAVA_HOME的变量）。 通过SSH连接node–推荐 先安装SSH Slaves插件，这样在新增节点时，ssh配置将更加友好。 点击 Credentials， 点击 Jenkins -&gt; Global credentials -&gt; Add Credentials，Username 和 Password 表示执行机的账号和密码。 新建节点，「启动方式」 选择 Launch slave agents via SSH。Credentials 选择刚刚新建的钥匙，Host Key Verification Strategy 选择 Manually trusted Key Verification Stragegy。 最后Launch agent即可； 通过JNLP连接node该方法比较麻烦，不详细介绍了。 注意：需要下载两个文件到agent机器上： agent.jar slave-agent.jnlp 参考： 两种常见挂载Jenkins slave节点的方法 Jenkins : 安装 master 和 slave Jenkins FAQQ1: 忽略Jenkins升级提醒对于轻微强迫症的我来说，看着升级提醒，还不能叉掉，实在忍不了，Google之后，有解决方法： 1234Manage Jenkins =&gt; Configure System =&gt; Administrative monitors configuration系统管理-》系统设置-》管理监控配置去掉“Jenkins更新通知”UnCheck &quot;Jenkins Update Notification&quot; and apply How to disable displaying “New version of Jenkins (2.62) is available for download (changelog)”? Q2: Cannot run program “java”: error=2, No such file or directory虽然登录到master机器或者执行机上，java都配置好了，但是仍然遇到了错误，后来看到一篇博客中提到的方法，在usr/bin下创建了一个Java的软连接，就解决了。 1ln -s /usr/java/jdk1.8.0_171/bin/java /usr/bin enkins cannot run program mvn error 2 - No such file or directory Posted by Echo Yuan on July 2 Q3: jenkins.JenkinsException: Error in request. Possibly authentication failed [500]: Internal Server Error在JJB项目中，发生了上面的错误，定位问题了半天，发现可能是Jenkins本身出问题了，而不是项目出问题。以前运行OK的Jenkins怎么突然发生这个问题了呢？可能是如下原因造成： var/lib/jenkins/jobs：目录下Job占据过多空间。在Jenkins中的节点管理里查看master机器的剩余磁盘空间`也可以观察到。 1du -ah --max-depth=1 /etc/rc.local是啥？ 参考： 【Jenkins学习 】解决jenkins运行磁盘满的问题 Q4: starting jenkins bash /usr/bin/java permission denied解决办法主要分了两步： 将原本位于/root/buildbox/javaxxx/下的目录移到了/usr/java/下，重新配置java环境； 在vim /etc/init.d/jenkins中的candidates字段补充上java路径/usr/java/jdk1.8.0_151/bin/java。 参考： Jenkins在Linux下的安装与配置 启动jenkins服务错误 Jenkins fails when running “service start jenkins” Q5: 执行Jenkins服务器界面运行一段时间后就会卡死，界面显示空白原因：tomcat的日志（/home/apache-tomcat-8.0.30/logs）查看catalina.out日志，得知是java虚拟机内存空间溢出。解决：到后台tomcat的bin目录下，修改 tomcat的启动脚本：startup.sh，在最上面添加 export JAVA_OPTS=“-XX:MaxPermSize=1024m -Xms1024m -Xmx3096m” Q6: 构建完成后需要清除workspace需要安装“Workspace Cleanup Plugin插件”，在构建任务配置时，可以在“增加构建后操作步骤”中选择Delete workspace when build is done Q7: Linux环境变量问题，没有加载/etc/profile文件，获取不到需要的环境变量。添加节点时，Prefix Start Slave Command 选择输入 source /etc/profile &amp;&amp; 加一个前置动作。注意&amp;&amp;之后要有空格！！！ Q8：Jenkins定时构建用法Jenkins定时构建 原文链接 CICD-Jenkins搭建笔记一]]></content>
      <categories>
        <category>DevOps</category>
      </categories>
      <tags>
        <tag>DevOps</tag>
        <tag>Jenkins</tag>
        <tag>CICD</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[那些有趣的博客]]></title>
    <url>%2F2018%2F09%2F16%2Fblog-interesting%2F</url>
    <content type="text"><![CDATA[总有一些博主是勤奋总结的，比公众号要有营养的多，这里列个清单吧： Python国内 TaoBeier-moelove CICD wklken 刘江的博客 David Dai 小戴，扇贝网后端工程师，Python 和 Go 栖迟于一丘 对 Python 相关源码进行了分析 忘归 Python 和 Go 美图 莫凡Python 除了机器学习方面，还有 Linux 方面总结 国外 kennethreitz requests 库的作者 RealPython 一个国外的 Python 学习网站，分享一下有趣的 Tricks lepture-Japan Full Stack Python life is short - you need Python 主要介绍了 Python 一些小技巧，卡片式展示 doughellmann 知名python程序员，博客涵盖大量库 [The Invent with Python Blog](https://inventwithpython.com/blog/ Paul Ganssle python-dateutil 的作者 JamesDjango 核心团队的成员 The Standard Python Library Python 标准模块的介绍 安卓 刘望舒的博客 DevOps Vnimos’s blog-OpenStack DevOps 博主介绍了很多这方面的文章 Web geekplux 后端开发 Nicol 一个喜欢总结，朝架构师方向努力的开发者 Linux 骏马金龙 LINUX大棚 海底苍鹰(tank) 金步国作品集 这个博主记载了一些 Linux 的文章，算比较老，但是比较经典 安全 安全-nMask 数学 Matrix67-数学爱好者 ML 谭升-AI pytlab-计算化学 运维 海底苍鹰 张文兵博客 运维之美 设计 丁宇 一个在日本工作的中国设计师，博客挺有趣 综合 dirtysalt Netkiller 系列电子书 —— 手札 D大 龙哥盟 图拉鼎 无聊小博 心理学 刘未鹏-mindhacks 艺术 易 象 辞 道卬 参考 timqian/chinese-independent-blogs 中文独立博客列表 栖迟于一丘-整理、分享]]></content>
      <categories>
        <category>阅读</category>
      </categories>
      <tags>
        <tag>资源</tag>
        <tag>Blog</tag>
        <tag>博客</tag>
        <tag>List</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用GitBook+Github编写文档书籍]]></title>
    <url>%2F2018%2F09%2F08%2Ftools-gitbook-hackpythonista-notebook%2F</url>
    <content type="text"><![CDATA[Books are to mankind what memory is to the individuanl. 书之于人类，犹如记忆于之个人。 最近看到了python-web-guide这样的文档以及explore python，觉得知识体系还是用这种方式全面组织比较系统一点，因此，放假在家也搞一下gitbook吧！ 欢迎访问我的第一本GitBook-HackPythonista，目前内容有待丰富，囧 鉴于已有相当多的文档介绍了Git，本文仅做简要笔记，同时记录一下遇到的坑。 gitbook基本使用 全局安装 gitbook 1sudo npm install gitbook-cli -g 安装完成，执行gitbook -V查看版本信息； gitbook常用命令 12345678910111213gitbook init //初始化目录文件gitbook help //列出gitbook所有的命令gitbook --help //输出gitbook-cli的帮助信息gitbook build //生成静态网页gitbook serve //生成静态网页并运行服务器gitbook build --gitbook=2.0.1 //生成时指定gitbook的版本, 本地没有会先下载gitbook ls //列出本地所有的gitbook版本gitbook ls-remote //列出远程可用的gitbook版本gitbook fetch 标签/版本号 //安装对应的gitbook版本gitbook update //更新到gitbook的最新版本gitbook uninstall 2.0.1 //卸载对应的gitbook版本gitbook build --log=debug //指定log的级别gitbook builid --debug //输出错误信息 与github集成，参考文章chengweiBlog-GitHub 集成 安装gitbook插键，参考文章chengweiBlog-book.json 在书籍根目录创建book.json。 book.json 示例：1234567891011121314151617181920212223&#123; &quot;gitbook&quot;: &quot;3.2.3&quot;, &quot;language&quot;: &quot;zh&quot;, &quot;description&quot;: &quot;Michael翔技术栈NoteBook&quot;, &quot;plugins&quot;: [ &quot;disqus@0.1.0&quot;, &quot;anchor-navigation-ex&quot;, &quot;-lunr&quot;, &quot;-search&quot;, &quot;search-pro-kui&quot; ], &quot;pluginsConfig&quot;: &#123; &quot;disqus&quot;: &#123; &quot;shortName&quot;: &quot;HackPythonista&quot; &#125;, &quot;anchor-navigation-ex&quot;: &#123; &quot;isShowTocTitleIcon&quot;: true, &quot;tocLevel1Icon&quot;: &quot;fa fa-hand-o-right&quot;, &quot;tocLevel2Icon&quot;: &quot;fa fa-hand-o-right&quot;, &quot;tocLevel3Icon&quot;: &quot;fa fa-hand-o-right&quot; &#125; &#125;&#125; gitbook插键disqus插键按照前面参考文章安装disqus插键时，使用命令npm install gitbook-plugin-disqus会默认安装disqus的最新版本，然后gitbook serve时，就会报错： 123info: loading plugin &quot;disqus&quot;... ERRORError: GitBook doesn&apos;t satisfy the requirements of this plugin: &gt;=4.0.0-alpha 想要尝试升级gitbook的版本，通过gitbook ls-remote查看可以安装的版本，然后利用gitbook fetch 4.0.0-alpha.6安装，尽管我用gitbook uninstall 3.2.3卸载了旧版本，安装之后不明白为何还是使用的3.2.3的稳定版本，后来用尝试创建软连接解决依然存在问题，没继续升级gitbook版本； 查看disqus-plugin文档没有解决，查看disqus项目issue，有人给出了答案，“1.0.1”版本需要gitbook的版本”&gt;=4.0.0-alpha”，可以通过&quot;plugins&quot;: [&quot;disqus@0.1.0&quot;]的方式，指定安装旧版本的disqus插键解决这个问题。 后来看到disqus插键官网文档，发现明明有写这些的，自己没注意到，文档多重要. 我们也可以通过@符号来指定插件的版本号，如：”plugins1@0.1.1“, 这个特性在使用一个旧版本的 gitbook 时是非常有用的 PSnpm安装指定版本：1npm install jquery@3.0.0 如果加上-g参数，表示安装到全局目录中 更新 20200731：gitbook 已经该版本了，不支持上面介绍的这种方式了，登录他们官网可以查看如何使用。 参考 gitbook的使用和常用插件 博客园/GitBook插件整理 - book.json配置 简书/GitBook插件整理 npm 安装指定版本 用github写开源书籍 zhangjikai-更多插件介绍]]></content>
      <categories>
        <category>ToolsDev</category>
      </categories>
      <tags>
        <tag>Tools</tag>
        <tag>Gitbook</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[工作中常用的 Linux 命令]]></title>
    <url>%2F2018%2F07%2F05%2Flinux-useful-commands-in-work%2F</url>
    <content type="text"><![CDATA[awk示例： env变量值如下，需要获得pkg_url的链接值： 1&#123;&quot;name&quot;: &quot;michael&quot;, &quot;sex&quot;: &quot;male&quot;, &quot;pkg_url&quot;: &quot;www.github.com&quot;, &quot;number&quot;: &quot;888&quot;&#125; 123pkg_url=$(echo $env | awk -F &quot;pkg_url\&quot;: \&quot;&quot; &apos;&#123;print $2&#125;&apos; | awk -F &quot;\&quot;,&quot; &apos;&#123;print $1&#125;&apos;)echo $pkg_urlwww.github.com -F 指定分隔规则，因为分隔规则中包含了双引号，所以需要用转义符号。 1234567# 格式$ awk 动作 文件名# 示例$ awk &apos;&#123;print $0&#125;&apos; demo.txtecho &apos;hello:michael:xiang&apos;|awk -F &apos;:&apos; &apos;&#123;print $1&#125;&apos; awk print函数 printf+awk完美结合 AWK 简明教程 awk 入门教程 basenamebasename命令用于打印目录或者文件的基本名称 1234[root@HGH1000059721 test]# basename a.tar .tar #后缀：可选参数，指定要去除的文件后缀字符串。a[root@HGH1000059721 test]# basename /tmp/test/a.tar #不带后缀，获取文件名a.tar 参考： basename cp将目录src复制到dest目录下，复制好后，dest/src: 1cp -r src dest 将目录src下的内容复制到dest目录下： 1cp -r src/* dest 复制文件，覆盖不询问： 1cp -nrf a.txt b.txt 系统默认给cp命令设置了别名cp -i，所以，复制时有冲突需要确认，使用如下方式实现默认覆盖：1/bin/cp xx yy 参考： Linux命令详解之—cp命令 Linux命令命令大全-cp命令 Linux 使用 cp 命令强制覆盖功能 curl发出 Get 请求，服务器返回的内容会在命令行输出： 1curl https://www.example.com -o 将服务器的回应保存成文件，等同于 wget 命令； -O 将服务器的回应保存成文件，并将 URL 的最后部分当作文件名； -i 显示 HTTP Response 的头信息，连同网页代码一起； -A 指定 User-Agent； -H 添加 HTTP 请求的标头； -d 发送 POST 请求的数据体； -F 用来向服务器上传二进制文件； -k 指定跳过 SSL 检测； -u 指定服务器认证的用户名和密码； -x 指定 HTTP 请求的代理； -X 支持其他动词，比如 POST，发送表单信息，curl -X POST --data &quot;data=xxx&quot; example.com/form.cgi -v 显示一次 HTTP 通信的整个过程，包括端口连接和 HTTP Request 头信息； Tips: FireFox/Chrome的Dev Tools可以直接把请求复制成 curl 的命令，然后可以直接在 shell 里运行 Postman 也可以把保存的请求复制成 curl 命令，方便在服务器中调试； 参考： 阮一峰 - curl 的用法指南 阮一峰 - curl网站开发指南 crontab12345678910# For details see man 4 crontabs# Example of job definition:# .---------------- minute (0 - 59)# | .------------- hour (0 - 23)# | | .---------- day of month (1 - 31)# | | | .------- month (1 - 12) OR jan,feb,mar,apr ...# | | | | .---- day of week (0 - 6) (Sunday=0 or 7) OR sun,mon,tue,wed,thu,fri,sat# | | | | |# * * * * * user-name command to be executed 在以上各个字段中，还可以使用以下特殊字符： 星号（*）：代表所有可能的值，例如month字段如果是星号，则表示在满足其它字段的制约条件后每月都执行该命令操作。 逗号（,）：可以用逗号隔开的值指定一个列表范围，例如，“1,2,5,7,8,9” 中杠（-）：可以用整数之间的中杠表示一个整数范围，例如“2-6”表示“2,3,4,5,6” 正斜线（/）：可以用正斜线指定时间的间隔频率，例如“0-23/2”表示每两小时执行一次。同时正斜线可以和星号一起使用，例如*/10，如果用在minute字段，表示每十分钟执行一次。 任务执行文件所在位置：1/var/spool/cron/crontabs 命令参数： -u user：用来设定某个用户的crontab服务；file：file是命令文件的名字,表示将file做为crontab的任务列表文件并载入 -e：编辑某个用户的crontab文件内容。如果不指定用户，则表示编辑当前用户的crontab文件。 -l：显示某个用户的crontab文件内容，如果不指定用户，则表示显示当前用户的crontab文件内容。 -r：从/var/spool/cron目录中删除某个用户的crontab文件，如果不指定用户，则默认删除当前用户的crontab文件。 -i：在删除用户的crontab文件时给确认提示 推荐一个有趣的网站，可以查看 crontab 语法含义： https://crontab.guru/ 每隔2分钟执行/tmp/test.sh脚本：12crontab -e # 使用crontab -e命令，编辑的是/var/spool/cron下对应用户的 cron 文件*/2 * * * * /tmp/test.sh 第星期六、星期日的时10分重启smb-也就是每周六、周日：110 1 * * 6,0 /etc/init.d/smb restart &gt;&gt; /tmp/run.log 2&gt;&amp;1 实例4：每隔两天的上午8点到11点的第3和第15分钟执行：13,15 8-11 */2 * * myCommand 实例5：清理httpd服务日志超过3天的内容：10 5 * * * /usr/bin/find /var/log/httpd/ -type f -mtime +3 -exec rm -rf &#123;&#125; \; 实例6：通过正则清理指定文件夹的内容12#update-20181122: clean dir +120 days0 6 * * * find /data/michael -maxdepth 7 -type d -mtime +120 -regextype posix-egrep -regex &apos;.*/[0-9]&#123;2&#125;/[0-9]&#123;6&#125;$&apos; -exec rm -rf &#123;&#125; \; 启动 / 停止 / 重启 crontab 123$ /etc/init.d/crond start$ /etc/init.d/crond stop$ /etc/init.d/crond restart 查看日志 1$ tail -f /var/log/cron 参考： 如何查看crontab的日志记录 runoob-Linux Crontab 定时任务 LinuxTools-crontab 定时任务 推荐 每天一个linux命令（50）：crontab命令 date选项：不加: 显示当前的时间.-d &lt;字符串&gt;：显示字符串所指的日期与时间。字符串前后必须加上双引号；-s &lt;字符串&gt;：根据字符串来设置日期与时间。字符串前后必须加上双引号；-u：显示GMT；–help：在线帮助；–version：显示版本信息。 参数 &lt;+时间日期格式&gt;：指定显示时使用的日期时间格式。就是格式化字符串处理.当需要用到空格时要使用双引号,如&quot;+%Y-%m-%d %H:%M:%S&quot;. 一般,%Y %m %d %H %M %S 是最基本的. 使用星期月份时也会用到%a %b 示例1234VERSION=$(date +%Y%m%d%H%M%S) #20180410192702 #date后面有空格time=$(date &quot;+%Y-%m-%d %H:%M:%S&quot;) #时间格式中有空格，需要加引号» date &quot;+%Y-%m-%d %T %a %A&quot;2018-06-04 11:31:25 Mon Monday 参考： Shell中date命令用法 df通过df命令很容易发现那个磁盘的存储空间快没了。查看挂载状态和硬盘使用量信息：1df -hT digdig 和 nslookup 作用有些类似，都是DNS查询工具。dig，其实是一个缩写，即 Domain Information Groper。 查看域名的信息。一般一个域名都会绑定到多个 IP 上，ping 命令只能一次看到一个 ip，这个可以看到域名解析的信息。1dig baidu.com 可能机器上没有这个命令，可以如下方式安装：1yum install -y bind-utils 参考： 《dig挖出DNS的秘密》-linux命令五分钟系列之三十四 Linux 大棚 xindoo-csdn-我常用的一些linux命令 dudu命令可以显示某个特定目录（默认情况下是当前目录）的磁盘使用情况。这一方法可以判断系统上某个目录下是不是有超大的文件。 查看当前文件夹的文件大小：12du -sh *du -sh /usr/* | sort -rn # 按M大小排序 env查看环境变量值，例：查看带有SVN的环境变量值：1env|grep SVN find实例：定时清理httpd服务日志超过3天的内容： 10 5 * * * /usr/bin/find /var/log/httpd/ -type f -mtime +3 -exec rm -rf &#123;&#125; \; 实例： 通过正则清理指定文件夹的内容12#update-20181122: clean dir +120 days0 6 * * * find /data/michael -maxdepth 7 -type d -mtime +120 -regextype posix-egrep -regex &apos;.*/[0-9]&#123;2&#125;/[0-9]&#123;6&#125;$&apos; -exec rm -rf &#123;&#125; \; 实例：搜索/etc目录下第一层的conf配置文件，文件夹下层的不需要1find /etc/ -maxdepth 1 -name &quot;*.conf&quot; # 最好加上引号 实例：只搜索当前目录，但是不包括.git目录，统计目录数1find . -maxdepth 1 -mindepth 1 -type d | grep -v .git |wc -l 实例：仅列出目录1find . -type d -maxdepth 1 参考： Linux中find常见用法示例 FIND中正则表达式的使用-Linux中find命令基本使用方法 fdiskfdisk -l看到目前系统中所有分区的信息https://blog.csdn.net/cc_net/article/details/2894510 freefree命令可以显示Linux系统中空闲的、已用的物理内存及swap内存,及被内核使用的buffer。在Linux系统监控的工具中，free命令是最经常使用的命令之一。 1free -h -s 2 -t -h 单位会更人性化 -s 每2秒，显示内存使用信息 -t 显示内存总和 12345# 结果 total used free shared buff/cache availableMem: 7.6G 935M 6.1G 9.7M 631M 6.4GSwap: 7.5G 0B 7.5GTotal: 15G 935M 13G total:总计物理内存的大小。 used:已使用多大。 free:可用有多少。 Shared:多个进程共享的内存总额。 Buffers/cached:磁盘缓存的大小 交换分区SWAP，也就是我们通常所说的虚拟内存 从应用程序角度来看，对于应用程序来说，buffers/cached 是等于可用的，因为buffer/cached 是为了提高文件读取的性能，当应用程序需在用到内存的时候，buffer/cached 会很快地被回收。 所以从应用程序的角度来说 可用内存=系统free memory+buffers+cached 我们看linux,只要不用swap的交换空间,就不用担心自己的内存太少.如果常常swap用很多,可能你就要考虑加物理内存了.这也是linux看内存是否够用的标准. +buffers/cache,即对应用程序来说free的内存太少了，也是该考虑优化程序或加内存了 参考： 每天一个linux命令（45）：free 命令 fuserfuser通常被用在诊断系统的“resource busy”问题，通常是在你希望umount指定的挂载点得时候遇到。 如果你希望kill所有正在使用某一指定的file, file system or sockets的进程的时候，你可以使用 -k option 1fuser –k –i /path/to/your/filename # 加上-i 表示杀死之前，需确认 fuser命令 fuser 命令小结 groups12whoami # 查看用户名groups # 查看当前用户所属组 grep语法：1grep [options] pattern [file] 12# 递归、显示行号、忽略大小写、显示搜到的匹配内容上下2行 搜索范围是当前目录下grep -rni 'github.com' -C 2 . 12grep 'shopbase' /home/admin -r -n --include *.&#123;vm,java&#125; #指定文件后缀grep 'shopbase' /home/admin -r -n --exclude *.&#123;vm,java&#125; #反匹配 参考： man-grep Linux查找文件内容（grep） 每天一个linux命令（39）：grep 命令 我的java问题排查工具单 gzipgzip是GNU项目的产物。这个软件下买呢含有下面的工具： gzip ：用来压缩文件 gzcat：用来查看压缩过的文本文件的内容 gunzip:用来解压文件。 12gzip xxxgzip -l &lt;filename&gt; # list compressed file contents head显示前n行内容： 1head -n https://www.linuxdaxue.com/linux-command-intro-head.html less在more的时候，我们并没有办法向前面翻，只能往后面看，但若使用了less时，就可以使用 [pageup] [pagedown] 等按键的功能来往前往后翻看文件。 locate12locate GPG-KEY# find /etc -name &apos;*GPG-KEY*&apos; 等同 可能系统没有自带locate命令，可以使用yum install mlocate -y安装，安装结束执行updatedb命令。 ls仅显示目录： 1ll -d ls命令显示文件大小，会根据文件大小自己决定单位，M或者Kb或者G 1ll -h mountmount可以显示全部挂载情况。 将分区挂载到目录： 1mount /dev/xvde /data Linux mount命令 mkdirmkdir sysadmin/admim_{1,2,3,4,5} 参考： 在Linux中用chattr和lsattr命令管理文件和目录属性 netstat检查端口占用 1netstat -anp|grep 80 linux(redhat,centos)释放被占用端口 pingping baidu.com 生活在宁静的角落——PING命令的各类反馈信息 rm只删除当前文件夹下的隐藏文件和隐藏文件夹：1rm -rf .* https://blog.csdn.net/ficksong/article/details/52447729 rpm我的系统中安装了那些rpm软件包1rpm -qa 如果要查找所有安装过的包含某个字符串sql的软件包1rpm -qa | grep sql 一个rpm包中的文件安装到那里去了？1rpm -ql 包名 软件包的卸载1rpm -e 参考：http://man.linuxde.net/rpm rpm2cpioRPM 包解压缩：12# 注意，要加上 cpio -div，否则终端会打印多余的内容出来rpm2cpio xxxx.rpm | cpio -div 你的 Linux 下可能没有rpm2cpio这个命令，用过简单指令安装即可： 12sudo apt-get install rpm2cpiosudo yum install rpm2cpio sedeg1：截取日志中的两行之间的内容，同时去掉匹配的首尾行：1cat mock.log |sed -n &apos;/tee/,/find/p&apos; mock.log|sed -n &apos;1!p&apos;|sed -n &apos;$!p&apos;|awk &apos;&#123;print $2,$3&#125;&apos; eg2:1nl passwd|sed &quot;1d;10d&quot; #删除第1行，第10行 eg3:12sed -i -e &quot;1i%define upstream_version $UPSTREAMVERSION\\&quot; *.spec #第一行插入sed -i -e &quot;s/UPSTREAMVERSION/$UPSTREAMVERSION/g&quot; *.spec #替换 参考： SED 简明教程 sed、awk——运维必须掌握的两个工具 看例子学sed 三十分钟学会SED sed命令筛选指定字符串之间的行 SELinux12sestatus [-v] # 查看selinux开启状态getenforce # 查看当前selinux的状态 selinux开启常常影响其他一些服务，比如httpd等，所以，运维往往一般拿到机器就会默认将其关闭。 12setenforce 1 # 设置SELinux 成为enforcing模式setenforce 0 # 设置SELinux 成为permissive模式 不重启关闭selinux的解决办法 开机重启后，上面利用setenforce方式修改的值会失效，所以，开机重启也有效的话，需要修改如下文件： 1/etc/selinux/config # 文件的软链接是/etc/sysconfig/selinux 是 wiki-SELinux Linux 下为何要关闭 SELinux？ 如何开启或关闭SELinux SELinux开启与关闭各参数说明 sort对之前提到的密码文件/etc/passwd根据用户ID进行数值排序。-k和-t参数在对安字段分割的数据进行排序时非常有用。 1sort -t &quot;:&quot; -k 3 -n /etc/passwd systemctl 任务 旧指令 新指令 使某服务自动启动 chkconfig –level 3 httpd on systemctl enable httpd.service 使某服务不自动启动 chkconfig –level 3 httpd off systemctl disable httpd.service 检查服务状态 service httpd status systemctl status httpd.service 显示所有已启动的服务 chkconfig –list systemctl list-units –type=service 启动某服务 service httpd start systemctl start httpd.service 停止某服务 service httpd stop systemctl stop httpd.service 重启某服务 service httpd restart systemctl restart httpd.service Linux 设置程序开机自启动 （命令systemctl 和 chkconfig用法区别比较） sha256sum生成文件对应的sha256值： 12sha256sum FusionSphere_Upgrade_6.2.50.4001.tar.gz &gt; a.sha256sum # 校验sha256sum -c &lt;(grep FusionSphere_Upgrade_6.2.50.4001.tar.gz a.sha256sum) # 校验 参考： linux下生成sha256校验文件、使用sha256校验某个文件 tar目前Unix和Linux上最广泛使用的归档工具是 tar 命令。 1tar function [options] object1 object2 …… 首先，创建一个归档文件： 1tar -cvf test.tar test/ test2/ 创建了名为test.tar归档文件，含有 test 和 test2 目录内容。 接着，列出 tar 文件 test.tar 内容（但并不提取文件）： 1tar -tf test.tar 最后用命令提取文件： 1tar -xvzf test.tar tar命令是给整个目录创建归档文件的简便方法 窍门：下载开源软件之后，经常会看到文件名以.tgz结尾。这些事gzip压缩过的tar文件，可以用tar -zxvf filename.tgz来解压 teetee命令用于将数据重定向到文件，另一方面还可以提供一份重定向数据的副本作为后续命令的stdin。简单的说就是把数据重定向到给定文件和屏幕上。 eg1 在终端打印stdout同时重定向到文件中： 1ls | tee out.txt | cat -n eg2 创建daemon.json文件，EOF之间内容作为stdin： 12345tee /etc/docker/daemon.json &lt;&lt; EOF&#123; &quot;insecure-registries&quot; : [ &quot;&quot;, &quot;&quot;]&#125;EOF &lt;&lt; EOF …… EOF的作用是在命令执行过程中用户自定义输入，它类似于起到一个临时文件的作用，只是比使用文件更方便灵活。 EOF妙用： 它的作用就是将两个delimiter之间的内容(Here Document Content 部分) 传递给cmd 作为输入参数。 123cmd &lt;&lt; delimiter Here Document Contentdelimiter 12345[root@ecs-6b86 tmp]# cat &lt;&lt; EOF &gt;tt.sh123123123345345asdfasdsEOF 自定义EOF，比如自定义为michael[root@slave-server opt]# cat &lt;&lt; michael &gt; haha.txt ggggggg44444446666666michael &lt;&lt; 变为 &lt;&lt;-。 使用 &lt;&lt;- 的唯一变化就是Here Document 的内容部分每行前面的 tab (制表符)将会被删除掉，这种用法是为了编写Here Document的时候可以将内容部分进行缩进，方便阅读代码。 有时脚本内容里变量不想被系统环境变量替换掉，可以通过在起始的 delimiter的前后添加 “ 来实现 参考： linux shell 的here document 用法 (cat &lt;&lt; EOF) EOF是什么？ linux shell脚本EOF妙用 tree1tree -FCL 2 FusionUpgrade linux tree命令–显示目录的树形结构 time12345678time nslookup michael.comnslookup: can&apos;t resolve &apos;(null)&apos;: Name does not resolveName: micahel.comAddress 1: 10.248.250.158real 0m 5.00suser 0m 0.00ssys 0m 0.00s time test 判断字符串是否为空，可以通过help test查看 1234-z STRING True if string is empty.-n STRING STRING True if string is not empty. 示例： 12345678910111213#!/bin/shSTRING=&quot;&quot;# -zif [ -z &quot;$STRING&quot; ]; then echo &quot;STRING is empty&quot;fiif [ -n &quot;$STRING&quot; ]; then echo &quot;STRING is not empty&quot;fi# STRING is empty linux shell 中判断字符串为空的正确方法：有趣的示例，强调了需要加引号的重要性 Linux shell 编程 字符串null值 的 条件判断?：解释了，为何加引号，bash的内建命令test在只有一个参数的情况下，只要参数不为空就返回真 tcpdump首先，先用 tcpdump -D 命令列出可以抓包的网络接口： 123456789101112$ tcpdump -D1.virbr02.docker03.bluetooth0 (Bluetooth adapter number 0)4.nflog (Linux netfilter log (NFLOG) interface)5.nfqueue (Linux netfilter queue (NFQUEUE) interface)6.usbmon1 (USB bus number 1)7.usbmon2 (USB bus number 2)8.wlp3s09.enp5s010.any (Pseudo-device that captures on all interfaces)11.lo [Loopback] 其中， lo 就是 localhost 。其中特殊接口 any 可用于抓取所有活动的网络接口的数据包。 123456789101112$ sudo tcpdump -i any -c5 -nn icmp port 80 -A -w webserver.pcaptcpdump: verbose output suppressed, use -v or -vv for full protocol decodelistening on any, link-type LINUX_SLL (Linux cooked), capture size 262144 bytes22:10:51.809330 IP 192.168.3.43.22 &gt; 192.168.3.66.50051: Flags [P.], seq 2040167007:2040167203, ack 59350146, win 1432, options [nop,nop,TS val 89942170 ecr 111122685], length 19622:10:51.812472 IP 192.168.3.43.22 &gt; 192.168.3.66.50051: Flags [P.], seq 196:416, ack 1, win 1432, options [nop,nop,TS val 89942173 ecr 111122685], length 22022:10:51.833093 IP 192.168.3.66.50051 &gt; 192.168.3.43.22: Flags [.], ack 0, win 23490, options [nop,nop,TS val 111123121 ecr 89942122], length 022:10:51.833193 IP 192.168.3.43.22 &gt; 192.168.3.66.50051: Flags [P.], seq 416:612, ack 1, win 1432, options [nop,nop,TS val 89942194 ecr 111123121], length 19622:10:51.835541 IP 192.168.3.66.50051 &gt; 192.168.3.43.22: Flags [.], ack 196, win 23487, options [nop,nop,TS val 111123121 ecr 89942170], length 05 packets captured7 packets received by filter0 packets dropped by kernel -c 选项可以用于限制 tcpdump 抓包的数量 用 -n 选项显示 IP 地址，-nn 选项显示端口号 icmp 这里用作过滤条件，只要抓取 ICMP 报文 port 指定端口号，根据端口号来筛选数据包 tcpdump 提供了两个选项可以查看数据包内容，-X 以十六进制打印出数据报文内容，-A 打印数据报文的 ASCII 值 使用 -w 选项来保存数据包而不是在屏幕上显示出抓取的数据包 tcpdump 将数据包保存在二进制文件中，所以不能简单的用文本编辑器去打开它。使用 -r 选项参数来阅读该文件中的报文内容：1tcpdump -nn -r webserver.pcap 用 host 参数只抓取和特定主机相关的数据包：1sudo tcpdump -i any -c5 -nn host 54.204.39.132 可以使用括号来创建更为复杂的过滤规则，但在 shell 中请用引号包含你的过滤规则以防止被识别为 shell 表达式：1$ sudo tcpdump -i any -c5 -nn &quot;port 80 and (src 192.168.122.98 or src 54.204.39.132)&quot; src 抓取源 IP 地址 使用 dst 就是按目的 IP/主机名来筛选数据包 使用 and 以及 or 逻辑操作符来创建过滤规则 参考： 伯乐在线-在 Linux 命令行中使用 tcpdump 抓包 运维之路-NAS存储抓包分析 Huang-tcpdump 常用操作 Tcpdump入门教程示例 9个tcpdump使用实例 toptop 命令是 Linux 下常用的性能分析工具，能够实时显示系统中各个进程的资源占用状况。 load average: 0.02, 0.04, 0.00： 系统1分钟、5分钟、15分钟的CPU负载信息 top 默认按 cpu 占用排序，这也是可以修改的，按 F(大写)即可选择相应排序，之后任意键退出即可。 进程信息： PID：进程的ID USER：进程所有者 PR：进程的优先级别，越小越优先被执行 NInice：值 VIRT：进程占用的虚拟内存 RES：进程占用的物理内存 SHR：进程使用的共享内存 S：进程的状态。S表示休眠，R表示正在运行，Z表示僵死状态，N表示该进程优先值为负数 %CPU：进程占用CPU的使用率 %MEM：进程使用的物理内存和总内存的百分比 TIME+：该进程启动后占用的总的CPU时间，即占用CPU使用时间的累加值。 COMMAND：进程启动命令名称 交互操作： c:显示进程命令的全路径与参数 f:可以指定top显示的内容，如ppid、swap等都可以选择显示 k:输入k之后可以kill掉指定的进程 A:分类显示各种系统资源高的进程。可用于快速识别系统上的性能要求极高的任务，推荐使用 h:获取top的命令帮助 H:显示线程，默认只显示进程 W[大写]:将当前设置写入~/.toprc文件中。这是写top配置文件的推荐方法 参考： Top实践小技巧 useradd/groupaddLinux 系统的用户、群组添加、管理 12345678910# 添加一个用户为 michael，属于基本组(主组) root。如果不加 -g，则默认会属于和用户名同名的主组useradd -g root michael# 修改密码passwd michael# 新增一个 michael 的组groupadd michael# 修改用户名的主组为 michaelusermod -g michael michael# 删除用户 michaeluserdel michael 参考： 博客园-Linux用户和组管理，添加修改用户，添加修改组，加入组，移除组 unzip1unzip -l demo1-0.1-py2.7.egg 1unzip -o -d /home/sunny myfile.zip 把myfile.zip文件解压到 /home/sunny/-o:不提示的情况下覆盖文件；-d:-d /home/sunny 指明将文件解压缩到/home/sunny目录下； 参考： Linux下的压缩（zip）解压(unzip)缩命令 unzip命令 wc1wc [-clw][--help][--version][文件...] 参数：12345-c或--bytes或--chars 只显示Bytes数。-l或--lines 只显示行数。-w或--words 只显示字数。--help 在线帮助。--version 显示版本信息。 whowho //显示当前登录系统的用户显示标题栏1# who -H 只显示当前用户1# who -m -H wget将远程目录下的全部内容下载到save目录下。-nd参数表示，如果远程目录下也有子目录，会将子目录中的文件下载下来而不创建多余目录。 1wget -r -np -nd -R &quot;index.html*&quot; -P test http://xxx/FusionUpgrade/master/euler/20181101130551/ # 注意，URL末尾需要有/，否则会递归下载的 -r：递归下载，下载指定网页某一目录下（包括子目录）的所有文件 -nd:–-no-directories 不创建目录 -np：–-no-parent 不要追溯到父目录 P:指定下载下来的存放目录，没有会自动创建 -nH:–-no-host-directories 不创建主机目录 示例2： 将远程文件夹原封不动下载下来，并且下载下来的本地路径也是远程目录，而不会创建多级目录。-nH表示不会创建xxx.com目录，--cut-dirs将其余多余层级目录不下载，实现效果下载到本地就只是DLRN_RPMS目录。 1wget -r -p -k -np -nH --cut-dirs=4 http://xxx.com/cps/FusionNetwork-for-fc/master/suse/DLRN_RPMS/ 参考： wget 文件下载 wget wget递归下载文件 watch123watch -d &apos;ls -l|grep scf&apos; # 监测当前目录中 scf&apos; 的文件的变化watch -n 10 &apos;cat /proc/loadavg&apos; # 10秒一次输出系统的平均负载watch -n 1 -d netstat -ant # 命令：每隔一秒高亮显示网络链接数的变化情况 参考： watch-命令 systemd service服务 Systemd 入门教程：命令篇 xargs为了快速修改后缀名字 源文件夹下： 12CentOS-base.repo.repo.bakepel.repo.repo.bak 方法一： 1ls *.bak|awk -F. '&#123;print $1&#125;'|xargs -t -i mv &#123;&#125;.repo.repo.bak &#123;&#125;.repo 参考： 阮一峰——xargs 命令教程]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zsh+on-my-zsh配置教程指南（程序员必备）]]></title>
    <url>%2F2018%2F03%2F11%2Ftools-zsh-tutorial%2F</url>
    <content type="text"><![CDATA[本文以CentOS 7/Mac 为例，介绍zsh的配置使用教程。 准备查看当前环境shell1echo $SHELL 查看系统自带哪些shell1cat /etc/shells 安装zsh12yum install zsh # CentOSbrew install zsh # mac安装 将zsh设置为默认shell1chsh -s /bin/zsh # CentOS 12345# Mac如下# 在 /etc/shells 文件中加入如下一行/usr/local/bin/zsh# 接着运行chsh -s /usr/local/bin/zsh 可以通过echo $SHELL查看当前默认的shell，如果没有改为/bin/zsh，那么需要重启shell。 oh-my-zsh配置zsh是一件麻烦的事儿，爱折腾的程序猿怎么可能忍受？！于是，oh-my-zsh出现了，有了这个东东，zsh配置起来就方便多了！ 安装oh-my-zsh有若干安装方式，介绍三种：1.自动安装 1wget https://github.com/robbyrussell/oh-my-zsh/raw/master/tools/install.sh -O - | sh 2.手动安装 12git clone git://github.com/robbyrussell/oh-my-zsh.git ~/.oh-my-zshcp ~/.oh-my-zsh/templates/zshrc.zsh-template ~/.zshrc 3.真-手动安装 在oh-my-zsh的github主页，手动将zip包下载下来。 将zip包解压，拷贝至~/.oh-my-zsh目录。此处省略拷贝的操作步骤。 执行cp ~/.oh-my-zsh/templates/zshrc.zsh-template ~/.zshrc 三选一即可，适合各种环境下的安装，然后需要source ~./.zshrc将配置生效。以下修改了.zshrc文件之后，都执行一下这个命令。 zsh主题通过如下命令可以查看可用的Theme： 1# ls ~/.oh-my-zsh/themes 如何修改zsh主题呢？ 编辑~/.zshrc文件，将ZSH_THEME=&quot;candy&quot;,即将主题修改为candy。我采用的ys。 其他好玩的主题： romkatv/powerlevel10k 比较强大酷炫的主题，使用方法看 README zsh扩展在~/.zshrc中找到plugins关键字，就可以自定义启用的插件了，系统默认加载git。 git插件命令内容可以参考cat ~/.oh-my-zsh/plugins/git/git.plugin.zsh。 常用的： 12345678910111213gapa git add --patchgc! git commit -v --amendgcl git clone --recursivegclean git reset --hard &amp;&amp; git clean -dfxgcm git checkout mastergcmsg git commit -mgco git checkoutgd git diffgdca git diff --cachedgp git pushgrbc git rebase --continuegst git statusgup git pull --rebase 完整列表：https://github.com/robbyrussell/oh-my-zsh/wiki/Plugin:git extract解压文件用的，所有的压缩文件，都可以直接x filename，不用记忆参数 当然，如果你想要用tar命令，可以使用tar -加tab键，zsh会列出参数的含义。 autojump按照官方文档介绍，需要使用如下命令安装，而不是一些博客中的介绍： 12yum install autojump-zsh # CentOSbrew install autojump # Mac CentOS安装好之后，需要在~/.zshrc中配置一下，除了在plugins中增加autojump之外，还需要添加一行： 1[[ -s ~/.autojump/etc/profile.d/autojump.sh ]] &amp;&amp; . ~/.autojump/etc/profile.d/autojump.sh 安装好之后，记得source ~/.zshrc，然后你就可以通过j+目录名快速进行目录跳转。支持目录名的模糊匹配和自动补全。 j -stat：可以查看历史路径库 zsh-autosuggestionszsh-autosuggestions 1git clone https://github.com/zsh-users/zsh-autosuggestions $&#123;ZSH_CUSTOM:-~/.oh-my-zsh/custom&#125;/plugins/zsh-autosuggestions 在 ~/.zshrc 中配置 1plugins=(其他的插件 zsh-autosuggestions) 因为箭头→不太方便，在.zshrc中自定义补全快捷键为逗号，但是又一次遇到了需要输入逗号的情况，所以，并不太推荐如下修改： 1bindkey ',' autosuggest-accept zsh-syntax-highlightingzsh-syntax-highlighting 1git clone https://github.com/zsh-users/zsh-syntax-highlighting.git $&#123;ZSH_CUSTOM:-~/.oh-my-zsh/custom&#125;/plugins/zsh-syntax-highlighting ~/.zshrc文件中配置： 1plugins=(其他的插件 zsh-syntax-highlighting) git-opengit-open插件可以在你git项目下打开远程仓库浏览项目。 1git clone https://github.com/paulirish/git-open.git $ZSH_CUSTOM/plugins/git-open batbat 代替 catcat 某个文件，可以在终端直接输出文件内容，bat 相比 cat 增加了行号和颜色高亮 👍 1brew install bat 常用快捷键 命令历史记录 一旦在 shell 敲入正确命令并能执行后，shell 就会存储你所敲入命令的历史记录（存放在~/.zsh_history 文件中），方便再次运行之前的命令。可以按方向键↑和↓来查看之前执行过的命令 可以用 r来执行上一条命令 使用 ctrl-r 来搜索命令历史记录 命令别名 可以简化命令输入，在 .zshrc 中添加 alias shortcut=&#39;this is the origin command&#39; 一行就相当于添加了别名 在命令行中输入 alias 可以查看所有的命令别名 使用技巧 连按两次Tab会列出所有的补全列表并直接开始选择，补全项可以使用 ctrl+n/p/f/b上下左右切换 智能跳转，安装了 autojump 之后，zsh 会自动记录你访问过的目录，通过 j 目录名 可以直接进行目录跳转，而且目录名支持模糊匹配和自动补全，例如你访问过 hadoop-1.0.0 目录，输入j hado 即可正确跳转。j –stat 可以看你的历史路径库。 命令选项补全。在zsh中只需要键入 tar - 就会列出所有的选项和帮助说明 在当前目录下输入 .. 或 … ，或直接输入当前目录名都可以跳转，你甚至不再需要输入 cd 命令了。在你知道路径的情况下，比如 /usr/local/bin 你可以输入cd /u/l/b 然后按进行补全快速输入 目录浏览和跳转：输入 d，即可列出你在这个会话里访问的目录列表，输入列表前的序号，即可直接跳转。 命令参数补全。键入kill &lt;tab&gt; 就会列出所有的进程名和对应的进程号 更智能的历史命令。在用或者方向上键查找历史命令时，zsh支持限制查找。比如，输入ls,然后再按方向上键，则只会查找用过的ls命令。而此时使用则会仍然按之前的方式查找，忽略 ls 多个终端会话共享历史记录 通配符搜索：ls -l **/*.sh，可以递归显示当前目录下的 shell 文件，文件少时可以代替 find。使用 **/ 来递归搜索 扩展环境变量，输入环境变量然后按 就可以转换成表达的值 在 .zshrc 中添加 setopt HIST_IGNORE_DUPS 可以消除重复记录，也可以利用sort -t &quot;;&quot; -k 2 -u ~/.zsh_history | sort -o ~/.zsh_history手动清除 其他安装 zplug 插件管理器12# https://github.com/zplug/zplugcurl -sL --proto-redir -all,https https://raw.githubusercontent.com/zplug/installer/master/installer.zsh | zsh 参考 wting/autojump–官方文档 powerline/fonts Linux 终极 Shell Ubuntu 16.04下安装zsh和oh-my-zsh Ubuntu 下安装oh-my-zsh 掘金-Shell 中的极品– Zsh CentOS 7下autojump无法使用的可能原因 oh-my-zsh配置你的zsh提高shell逼格终极选择 Mac zsh oh-my-zsh 插件推荐 zsh 全程指南-推荐 iterm主题下载 程序员内功系列–iTerm与Zsh篇 Mac 下配置终端环境 iTerm2 + Zsh + Oh My Zsh + tmux 手把手一起安装 oh-my-zsh 炫酷主题 一位 UP 主上传的教程，对应文章 最后 Github-Michael728/my-config-files 附上我的配置文件地址； zsh+on-my-zsh配置教程指南 本文地址]]></content>
      <categories>
        <category>ToolsDev</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Tools</tag>
        <tag>Mac</tag>
        <tag>zsh</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[观影-完美陌生人-家庭-人性]]></title>
    <url>%2F2017%2F05%2F05%2Fmovie-Perfect-Strangers%2F</url>
    <content type="text"><![CDATA[豆瓣链接-完美陌生人 虽然过于巧合，但是，电影毕竟是电影，这里无需都要那么真实，因为，他的目的对人性的讽刺，夫妻间、朋友间的关系原来那么微妙，充满秘密……就连最后的结局也是精彩，值得推敲，并不是有些评价所说的，“闹掰的怎么和好的那么快”，因为，结尾展示的是平行时空下是什么样的结局！ 这是那一天第一次看这部电影时，我在豆瓣留下的评论，虽然这段时间一直为论文的事情而忙碌，但是，忙里偷闲，把这部之前一直想看的电影看完了，时间不是很长，它却给我留下了极深的印象。尽管是一部意大利的小成本电影，所有的场景基本都是在男主家里，但是，大家通过打来的各种电话，却足以让观众想象到了背后的故事…… 几个家庭的正常聚餐，却因为一个把手机交出来共享电话信息的游戏额支离破碎。以为坚强可靠的友情，也只是你以为的坚强可靠！比如，男主的妻子和男主从小长到大的小伙伴有了私情，甚至还要为此去隆胸；比如，当知道好兄弟是gay时，有人就控制不住的开始接受不了。结局也挺有意思，展示的是如果不玩游戏，是个什么完美的聚餐结局，一片祥和温馨，各回各家，手机里也是传达着各自的秘密…… “不要去可以考验人性，它会让你失望的！”如果可以，给彼此一定的空间，每个人都不是圣人，都会有可能犯错，然而，留给的空间是基于彼此的信任，是彼此都珍视彼此的情况。 人和人之间的关系是脆弱的 这句话真不假，有时候你自以为牢固的关系，可能并不真的像你想象的那样牢固。 男主对他刚刚成年的女儿说的话，令我印象深刻，是一个足够成熟冷静的父亲，在女儿私下打电话给他时（并没有选择打给她的妈妈），女儿询问他关于她要不要去他男友家时，父亲只是告诉了她，去还是不去，是她自己的决定，这可能是她人生中一个重要的时刻！（PS：男主还给她女儿准备了一盒tt），不管现实中是否有这样足够冷静的父亲，至少，电影里这样的一位父亲的做法是值得学习的，作为父亲，其实并不能左右子女的想法，因为他们已经是一个独立的人了，应该尊重，并告知选择可能带来的结果，至于做还是不做，还是要看他们怎么去选择。 Mark一下，不知道这部作品会不会成为我今年的最佳影片了。]]></content>
      <categories>
        <category>电影</category>
      </categories>
      <tags>
        <tag>电影</tag>
        <tag>人性</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Windows下利用批命令修改IP设置]]></title>
    <url>%2F2016%2F11%2F14%2Ftools-batch-file-set-ip-mask-gateway%2F</url>
    <content type="text"><![CDATA[因为在实验室需要将网络设置为自动获取IP地址和DNS服务器地址，然而，在宿舍想要登录成功6维BT站，却需要配置静态IP地址。每次切换IP需要输入一串参数，打开网络适配器去设置，很麻烦，下午就花时间解决了一下。 设置静态IP/DNS地址12netsh int ipv4 set address name="以太网" source=static address=222.26.218.27 mask=255.255.255.40 gateway=222.26.218.254netsh int ipv4 set dns name="以太网" source=static address=202.118.66.66 register=primary validate=no 这里需要注意的是，name这个值，是你电脑网络连接的名称，需要到网络适配器中去查看，示意图如下： 大部分name值都是”本地连接”，需要根据你自己的配置修改名称。 ipv4 address:IP地址 mask:子网掩码 gateway:默认网关 dns address:首选DNS服务器 设置动态IP/DNS地址12netsh interface ipv4 set address name="以太网" source=dhcpnetsh interface ipv4 set dnsservers name="以太网" source=dhcp 命令升级版将设置静态IP和动态IP集成到一个bat文件中，方便执行。 注意：执行时，需要管理员权限。 123456789101112131415161718192021222324252627282930@echo offtitle 一件切换IP地址--Michael翔color 0a:beginecho 一键切换IP地址echo 1.切换成静态IP（宿舍）echo 2.切换成动态IPecho.@rem echo. 紧跟着一点，效果是空了一行set /p op=Type optionif "%op%"=="1" goto op1if "%op%"=="2" goto op2:op1echo "你选择了选项1"netsh int ipv4 set address name="以太网" source=static address=222.26.218.16 mask=255.255.255.0 gateway=222.26.218.254netsh int ipv4 set dns name="以太网" source=static address=202.118.66.6 register=primary validate=nogoto exit@rem 这里的go to begin不能少，不然，执行选项1之后，会继续向下执行:op2echo "你选择了选项2"netsh interface ipv4 set address name="以太网" source=dhcpnetsh interface ipv4 set dnsservers name="以太网" source=dhcpgoto exit:Exitpasue 注解：在 SET 命令中添加了两个新命令行开关: 12SET /A expressionSET /P variable=[promptString] /A 命令行开关指定等号右边的字符串为被评估的数字表达式。 /P 命令行开关允许将变量数值设成用户输入的一行输入。读取输入 行之前，显示指定的 promptString。promptString (提示词)可以是空的 命令简介 echo+message如果，要在执行bat命令时，让cmd窗口不一闪而过，在文件末尾添加pause就可以了！例如：echo “hello michael翔” @echo off这个效果是不显示后面的执行命令，关闭回显功能； rem注释命令，类似于在C语言中的/——–/，它并不会被执行，只是起一个注释的作用例如：rem 这里是注释哈！不会执行，但是，会显示此行，如果要关闭回显，加符号@； pause暂停命令。 goto跳转命令。程序指针跳转到指定的标签，从标签后的第一条命令开始继续执行批处理程序。例如：123:1startgoto 1 这里就会循环执行，打卡很多窗口。 set显示、设置或删除变量例如： 12345set a=2set b=aecho %a%echo %b%pasue 这里是设置b为字符串a，如果要将a值赋值给b，应该b=%a%。set a=删除变量 符号简介 @回显关闭，表示不显示@后面的命令。 命令释义文件夹管理 cd 显示当前目录名或改变当前目录。 md 创建目录。 rd 删除一个目录。 dir 显示目录中的文件和子目录列表。 tree 以图形显示驱动器或路径的文件夹结构。 path 为可执行文件显示或设置一个搜索路径。 copy 复制文件和目录树。 文件管理 type 显示文本文件的内容。 copy 将一份或多份文件复制到另一个位置。 del 删除一个或数个文件。 move 移动文件并重命名文件和目录。（Windows XP Home Edition中没有) ren重命名文件。 replace 替换文件。 attrib 显示或更改文件属性。 find 搜索字符串。 fc 比较两个文件或两个文件集并显示它们之间的不同 参考 百科-批处理 How to script a change to a static IP address or DHCP IP address in Windows using a batch file 批处理常用命令总结和WindowsXP下运行命令使用大全及优化 BAT 批处理脚本 教程 Multiple choices menu on batch file? 知道-批处理中set /a和set /p有什么区别，一般怎么用？谢谢回答！ 贴吧-简述一下怎么自己写批处理吧]]></content>
      <categories>
        <category>ToolsDev</category>
      </categories>
      <tags>
        <tag>Tools</tag>
        <tag>小程序</tag>
        <tag>batch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[博客建站日志]]></title>
    <url>%2F2016%2F09%2F03%2Fblog-logfile%2F</url>
    <content type="text"><![CDATA[建站笔记 Hexo 搭建 Blog 精简笔记 站点管理 百度统计 资源索引 那些年我剁手的极客时间课程 有极客时间课程返利链接 那些做的不错的短视频 那些有趣的博客 【总结】写作、阅读、工作等日常习惯 建站日志 2019-09-08: 在 Gandi 上购买了一个域名，值得纪念！2019-06-15: 博客使用 Travis CI 部署2019-05-18: 博客增加了「阅读」、「观影」、「一言」页面2019-05-11：博客增加了萌萌的「看板娘」，同时，评论系统改为 Valine2018-11-11：Github搭建的博客，启用https了，做了适配修改，同时升级了Next主题版本。2019-03-03：评论系统从 Disqus 改为了「来必力」2017-04-22：将博客评论由多说变为disqus，尽管需要FQ才能看到，但是没办法，多说要关闭了……2017-04-03：修改了工具总结，添加了几个这段时间发现的好软件2016-09-03：优化了sitemap 、添加了博客内搜索2016-09-03：增加了工具页面http://michaelxiang.me/tools/，激动人心]]></content>
      <categories>
        <category>ToolsDaily</category>
      </categories>
      <tags>
        <tag>Blog</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python正则表达式学习摘要及资料]]></title>
    <url>%2F2016%2F07%2F28%2Fpython-regx%2F</url>
    <content type="text"><![CDATA[摘要 在正则表达式中，如果直接给出字符，就是精确匹配。 {m,n}? 对于前一个字符重复 m到 n 次，并且取尽可能少的情况 在字符串&#39;aaaaaa&#39;中，a{2,4} 会匹配 4 个 a，但 a{2,4}? 只匹配 2 个 a。^表示行的开头，^\d表示必须以数字开头。 $表示行的结束，\d$表示必须以数字结束。 你可能注意到了，py也可以匹配&#39;python&#39;–&gt;py;但是加上^py$就变成了整行匹配，就只能匹配’py’了,匹配&#39;python&#39;时，就什么也得不到。 参考表正则表达式特殊序列 re模块re.compile(pattern[, flags])把正则表达式的模式和标识转化成正则表达式对象，供match() 和search() 这两个函数使用。 re 所定义的 flag 包括：123456re.I 忽略大小写re.L 表示特殊字符集 \w, \W, \b, \B, \s, \S 依赖于当前环境re.M 多行模式re.S 即为’ . ’并且包括换行符在内的任意字符（’ . ’不包括换行符）re.U 表示特殊字符集 \w, \W, \b, \B, \d, \D, \s, \S 依赖于 Unicode 字符属性数据库re.X 为了增加可读性，忽略空格和’ # ’后面的注释 以下两种用法结果相同：(A)12compiled_pattern = re.compile(pattern) result = compiled_pattern.match(string) (B)1result = re.match(pattern, string) 由于Python的字符串本身也用\转义，所以要特别注意：123s = &apos;ABC\\-001&apos; # Python的字符串 #对应的正则表达式字符串变成： #&apos;ABC\-001&apos; 因此我们强烈建议使用Python的r前缀，就不用考虑转义的问题了123s = r&apos;ABC\-001&apos; # Python的字符串# 对应的正则表达式字符串不变：# &apos;ABC\-001&apos; searchre.search(pattern, string[, flags])在字符串中查找匹配正则表达式模式的位置，返回 MatchObject 的实例，如果没有找到匹配的位置，则返回None。 对于已编译的正则表达式对象来说（re.RegexObject），有以下search 的方法：search (string[, pos[, endpos]])若 regex 是已编译好的正则表达式对象，regex.search(string, 0, 50) 等同于regex.search(string[:50], 0)`。123&gt;&gt;&gt; pattern = re.compile(&quot;a&quot;) &gt;&gt;&gt; pattern.search(&quot;abcde&quot;) # Match at index 0 &gt;&gt;&gt; pattern.search(&quot;abcde&quot;, 1) # No match; matchre.match(pattern, string[, flags])判断 pattern 是否在字符串开头位置匹配。对于 RegexObject，有：match(string[, pos[, endpos]])match() 函数只在字符串的开始位置尝试匹配正则表达式，也就是只报告从位置 0 开始的匹配情况，而 search() 函数是扫描整个字符串来查找匹配。如果想要搜索整个字符串来寻找匹配，应当用 search()。12&gt;&gt;&gt; pattern.match(&apos;bca&apos;,2).group()&apos;a&apos; 虽然，match默认是从开头匹配，但是，如果指定位置，仍然能成功；但是！match也是从指定位置开始匹配，不匹配仍然会失败，这一点就和search有区别啦。 match()方法判断是否匹配，如果匹配成功，返回一个Match对象，否则返回None。12345test = &apos;用户输入的字符串&apos;if re.match(r&apos;正则表达式&apos;, test): print(&apos;ok&apos;)else: print(&apos;failed&apos;) splitre.split(pattern, string[, maxsplit=0, flags=0])此功能很常用，可以将将字符串匹配正则表达式的部分割开并返回一个列表。对 RegexObject，有函数：split(string[, maxsplit=0]) 对于一个找不到匹配的字符串而言，split 不会对其作出分割 12&gt;&gt;&gt; &apos;a b c&apos;.split(&apos; &apos;)[&apos;a&apos;, &apos;b&apos;, &apos;&apos;, &apos;&apos;, &apos;c&apos;] 这里用字符串自带的split方法就很不灵活。12&gt;&gt;&gt; re.split(r&apos;\s+&apos;, &apos;a b c&apos;)[&apos;a&apos;, &apos;b&apos;, &apos;c&apos;] 看出差别了吧，很强大！再来一个终极的：12&gt;&gt;&gt; re.split(r&apos;[\s\,\;]+&apos;, &apos;a,b;; c d&apos;)[&apos;a&apos;, &apos;b&apos;, &apos;c&apos;, &apos;d&apos;] r&#39;[\s\,\;]+&#39;的正则表达式意思为：空格或者,或者;`出现1次或1次以上都是满足条件的分割符号！所以，最后结果还是很干净。 findallre.findall(pattern, string[, flags]) 在字符串中找到正则表达式所匹配的所有子串，并组成一个列表返回。同样 RegexObject有：findall(string[, pos[, endpos]])1234 #get all content enclosed with [], and return a list &gt;&gt;&gt; pattern=re.compile(r&apos;hh&apos;)&gt;&gt;&gt; pattern.findall(&apos;hhmichaelhh&apos;)[&apos;hh&apos;, &apos;hh&apos;] finditerre.finditer(pattern, string[, flags])和 findall 类似，在字符串中找到正则表达式所匹配的所有子串，并组成一个迭代器返回。同样 RegexObject 有：finditer(string[, pos[, endpos]]) subre.sub(pattern, repl, string[, count, flags])在字符串 string 中找到匹配正则表达式pattern的所有子串，用另一个字符串 repl进行替换。如果没有找到匹配 pattern 的串，则返回未被修改的 string。Repl 既可以是字符串也可以是一个函数。 返回值是替换后的新字符串。 对于 RegexObject有：sub(repl, string[, count=0])123456789&gt;&gt;&gt; pattern=re.compile(r&apos;\d&apos;)&gt;&gt;&gt; pattern.sub(&apos;no&apos;,&apos;12hh34hh&apos;)&apos;nonohhnonohh&apos;&gt;&gt;&gt; pattern.sub(&apos;no&apos;,&apos;12hh34hh&apos;,0)&apos;nonohhnonohh&apos;&gt;&gt;&gt; pattern.sub(&apos;no&apos;,&apos;12hh34hh&apos;,count=0)&apos;nonohhnonohh&apos;&gt;&gt;&gt; pattern.sub(&apos;no&apos;,&apos;12hh34hh&apos;,1)&apos;no2hh34hh&apos; 通过上面的例子，可以看出,count是可以缺省的，同时，默认值是0，表示全部替换；否则，就是指定替换几个。 subnre.subn(pattern, repl, string[, count, flags])该函数的功能和 sub() 相同，但它还返回新的字符串以及替换的次数。同样RegexObject有：subn(repl, string[, count=0])12&gt;&gt;&gt; pattern.subn(&apos;no&apos;,&apos;12hh34hh&apos;,count=0)(&apos;nonohhnonohh&apos;, 4) 分组除了简单地判断是否匹配之外，正则表达式还有提取子串的强大功能。用()表示的就是要提取的分组（Group）。比如： ^(\d{3})-(\d{3,8})$分别定义了两个组，可以直接从匹配的字符串中提取出区号和本地号码：1234567891011&gt;&gt;&gt; m = re.match(r&apos;^(\d&#123;3&#125;)-(\d&#123;3,8&#125;)$&apos;, &apos;010-12345&apos;)&gt;&gt;&gt; m&lt;_sre.SRE_Match object; span=(0, 9), match=&apos;010-12345&apos;&gt;&gt;&gt;&gt; m.group(0)&apos;010-12345&apos;&gt;&gt;&gt; m.group(1)&apos;010&apos;&gt;&gt;&gt; m.group(2)&apos;12345&apos;&gt;&gt;&gt; m.groups()(&apos;010&apos;, &apos;12345&apos;) 通过实验，如果不用括号，得到的Match对象课可以使用例如a.group(0)或者a.group()但是，使用a.group(1)就会报错的。 贪婪匹配正则匹配默认是贪婪匹配，也就是匹配尽可能多的字符。举例如下，匹配出数字后面的0：12&gt;&gt;&gt; re.match(r&apos;^(\d+)(0*)$&apos;, &apos;102300&apos;).groups()(&apos;102300&apos;, &apos;&apos;) 由于\d+采用贪婪匹配，直接把后面的0全部匹配了，结果0*只能匹配空字符串了。 必须让\d+采用非贪婪匹配（也就是尽可能少匹配），才能把后面的0匹配出来，加个?就可以让\d+采用非贪婪匹配：12&gt;&gt;&gt; re.match(r&apos;^(\d+?)(0*)$&apos;, &apos;102300&apos;).groups()(&apos;1023&apos;, &apos;00&apos;) SF-正则表达式的贪婪\非贪婪模式怎么理解？ Python正则表达式学习资源 廖雪峰-正则表达式 IBM-使用 Python 模块 re 实现解析小工具 deerchao-则表达式30分钟入门教程 deerchao-正则表达式30分钟入门教程 静觅-爬虫入门七之正则表达式]]></content>
      <categories>
        <category>正则</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>正则</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[在魔都实习生活]]></title>
    <url>%2F2016%2F07%2F25%2Flife-about-intern-in-Shanghai%2F</url>
    <content type="text"><![CDATA[不知不觉，来传说中的“魔都”已经一个多月了，然而，我并没有感受到他的魔力，可能是我还没去发现吧……应该是我还没有动力去发现！ 文章开头的图片拍摄于我和媳妇儿2014年“南游”的时候，当时在外滩附近大楼拍的，现在想想，仿佛过去没多久，事实，白驹过隙，已2年多了:) 记录一下在银联这段时间的生活： 灯火通明的开发中心大楼 园区风景 伙食真是没话说啊，减肥太难，囧 我们小组现在的办公室，据说马上要搬了，不知道那时候我还在不在 来张我的小窝 陪别人去逛的徐家汇那边的恒隆，确实很繁华！ 希望一切安好，珍惜拥有的一切，努力变得更好！]]></content>
      <categories>
        <category>Life</category>
      </categories>
      <tags>
        <tag>Life</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python--matplotlib绘图可视化知识点整理]]></title>
    <url>%2F2016%2F05%2F14%2Fpython-matplotlib-basic%2F</url>
    <content type="text"><![CDATA[强烈推荐ipython无论你工作在什么项目上，IPython都是值得推荐的。利用ipython --pylab，可以进入PyLab模式，已经导入了matplotlib库与相关软件包（例如Numpy和Scipy)，额可以直接使用相关库的功能。 本文作为学习过程中对matplotlib一些常用知识点的整理，方便查找。 这样IPython配置为使用你所指定的matplotlib GUI后端（TK/wxPython/PyQt/Mac OS X native/GTK)。对于大部分用户而言，默认的后端就已经够用了。Pylab模式还会向IPython引入一大堆模块和函数以提供一种更接近MATLAB的界面。 参考 matplotlib-绘制精美的图表 matplotlib.pyplot.plt参数介绍 12345678import matplotlib.pyplot as pltlabels=&apos;frogs&apos;,&apos;hogs&apos;,&apos;dogs&apos;,&apos;logs&apos;sizes=15,20,45,10colors=&apos;yellowgreen&apos;,&apos;gold&apos;,&apos;lightskyblue&apos;,&apos;lightcoral&apos;explode=0,0.1,0,0plt.pie(sizes,explode=explode,labels=labels,colors=colors,autopct=&apos;%1.1f%%&apos;,shadow=True,startangle=50)plt.axis(&apos;equal&apos;)plt.show() matplotlib图标正常显示中文为了在图表中能够显示中文和负号等，需要下面一段设置：123import matplotlib.pyplot as pltplt.rcParams[&apos;font.sas-serig&apos;]=[&apos;SimHei&apos;] #用来正常显示中文标签plt.rcParams[&apos;axes.unicode_minus&apos;]=False #用来正常显示负号 matplotlib inline和pylab inline可以使用ipython --pylab打开ipython命名窗口。 12%matplotlib inline #notebook模式下%pylab inline #ipython模式下 这两个命令都可以在绘图时，将图片内嵌在交互窗口，而不是弹出一个图片窗口，但是，有一个缺陷：除非将代码一次执行，否则，无法叠加绘图，因为在这两种模式下，是要有plt出现，图片会立马show出来，因此： 推荐在ipython notebook时使用，这样就能很方便的一次编辑完代码，绘图。 为项目设置matplotlib参数在代码执行过程中，有两种方式更改参数： 使用参数字典(rcParams) 调用matplotlib.rc()命令 通过传入关键字元祖，修改参数 如果不想每次使用matplotlib时都在代码部分进行配置，可以修改matplotlib的文件参数。可以用matplot.get_config()命令来找到当前用户的配置文件目录。 配置文件包括以下配置项： axex: 设置坐标轴边界和表面的颜色、坐标刻度值大小和网格的显示backend: 设置目标暑促TkAgg和GTKAggfigure: 控制dpi、边界颜色、图形大小、和子区( subplot)设置font: 字体集（font family）、字体大小和样式设置grid: 设置网格颜色和线性legend: 设置图例和其中的文本的显示line: 设置线条（颜色、线型、宽度等）和标记patch: 是填充2D空间的图形对象，如多边形和圆。控制线宽、颜色和抗锯齿设置等。savefig: 可以对保存的图形进行单独设置。例如，设置渲染的文件的背景为白色。verbose: 设置matplotlib在执行期间信息输出，如silent、helpful、debug和debug-annoying。xticks和yticks: 为x,y轴的主刻度和次刻度设置颜色、大小、方向，以及标签大小。 线条相关属性标记设置用来该表线条的属性 线条风格linestyle或ls 描述 线条风格linestyle或ls 描述 ‘-‘ 实线 ‘:’ 虚线 ‘–’ 破折线 ‘None’,’ ‘,’’ 什么都不画 ‘-.’ 点划线 线条标记 标记maker 描述 标记 描述 ‘o’ 圆圈 ‘.’ 点 ‘D’ 菱形 ‘s’ 正方形 ‘h’ 六边形1 ‘*’ 星号 ‘H’ 六边形2 ‘d’ 小菱形 ‘_’ 水平线 ‘v’ 一角朝下的三角形 ‘8’ 八边形 ‘&lt;’ 一角朝左的三角形 ‘p’ 五边形 ‘&gt;’ 一角朝右的三角形 ‘,’ 像素 ‘^’ 一角朝上的三角形 ‘+’ 加号 ‘\ ‘ 竖线 ‘None’,’’,’ ‘ 无 ‘x’ X 颜色可以通过调用matplotlib.pyplot.colors()得到matplotlib支持的所有颜色。 别名 颜色 别名 颜色 b 蓝色 g 绿色 r 红色 y 黄色 c 青色 k 黑色 m 洋红色 w 白色 如果这两种颜色不够用，还可以通过两种其他方式来定义颜色值： 使用HTML十六进制字符串 color=&#39;eeefff&#39; 使用合法的HTML颜色名字（’red’,’chartreuse’等）。 也可以传入一个归一化到[0,1]的RGB元祖。 color=(0.3,0.3,0.4) 很多方法可以介绍颜色参数，如title()。plt.tilte(&#39;Title in a custom color&#39;,color=&#39;#123456&#39;） 背景色通过向如matplotlib.pyplot.axes()或者matplotlib.pyplot.subplot()这样的方法提供一个axisbg参数，可以指定坐标这的背景色。 subplot(111,axisbg=(0.1843,0.3098,0.3098) 基础如果你向plot()指令提供了一维的数组或列表，那么matplotlib将默认它是一系列的y值，并自动为你生成x的值。默认的x向量从0开始并且具有和y同样的长度，因此x的数据是[0,1,2,3]. 图片来自:绘图: matplotlib核心剖析 确定坐标范围 plt.axis([xmin, xmax, ymin, ymax])上面例子里的axis()命令给定了坐标范围。 xlim(xmin, xmax)和ylim(ymin, ymax)来调整x,y坐标范围123456789101112131415161718%matplotlib inlineimport numpy as npimport matplotlib.pyplot as pltfrom pylab import *x = np.arange(-5.0, 5.0, 0.02)y1 = np.sin(x)plt.figure(1)plt.subplot(211)plt.plot(x, y1)plt.subplot(212)#设置x轴范围xlim(-2.5, 2.5)#设置y轴范围ylim(-1, 1)plt.plot(x, y1) 叠加图用一条指令画多条不同格式的线。123456789import numpy as npimport matplotlib.pyplot as plt# evenly sampled time at 200ms intervalst = np.arange(0., 5., 0.2)# red dashes, blue squares and green trianglesplt.plot(t, t, &apos;r--&apos;, t, t**2, &apos;bs&apos;, t, t**3, &apos;g^&apos;)plt.show() plt.figure()你可以多次使用figure命令来产生多个图，其中，图片号按顺序增加。这里，要注意一个概念当前图和当前坐标。所有绘图操作仅对当前图和当前坐标有效。通常，你并不需要考虑这些事，下面的这个例子为大家演示这一细节。1234567891011121314import matplotlib.pyplot as pltplt.figure(1) # 第一张图plt.subplot(211) # 第一张图中的第一张子图plt.plot([1,2,3])plt.subplot(212) # 第一张图中的第二张子图plt.plot([4,5,6])plt.figure(2) # 第二张图plt.plot([4,5,6]) # 默认创建子图subplot(111)plt.figure(1) # 切换到figure 1 ; 子图subplot(212)仍旧是当前图plt.subplot(211) # 令子图subplot(211)成为figure1的当前图plt.title(&apos;Easy as 1,2,3&apos;) # 添加subplot 211 的标题 figure感觉就是给图像ID，之后可以索引定位到它。 plt.text()添加文字说明 text()可以在图中的任意位置添加文字，并支持LaTex语法 xlable(), ylable()用于添加x轴和y轴标签 title()用于添加图的题目 12345678910111213141516171819import numpy as npimport matplotlib.pyplot as pltmu, sigma = 100, 15x = mu + sigma * np.random.randn(10000)# 数据的直方图n, bins, patches = plt.hist(x, 50, normed=1, facecolor=&apos;g&apos;, alpha=0.75)plt.xlabel(&apos;Smarts&apos;)plt.ylabel(&apos;Probability&apos;)#添加标题plt.title(&apos;Histogram of IQ&apos;)#添加文字plt.text(60, .025, r&apos;$\mu=100,\ \sigma=15$&apos;)plt.axis([40, 160, 0, 0.03])plt.grid(True)plt.show() text中前两个参数感觉应该是文本出现的坐标位置。 plt.annotate()文本注释在数据可视化的过程中，图片中的文字经常被用来注释图中的一些特征。使用annotate()方法可以很方便地添加此类注释。在使用annotate时，要考虑两个点的坐标：被注释的地方xy(x, y)和插入文本的地方xytext(x, y)。[^1] 123456789101112131415import numpy as npimport matplotlib.pyplot as pltax = plt.subplot(111)t = np.arange(0.0, 5.0, 0.01)s = np.cos(2*np.pi*t)line, = plt.plot(t, s, lw=2)plt.annotate(&apos;local max&apos;, xy=(2, 1), xytext=(3, 1.5), arrowprops=dict(facecolor=&apos;black&apos;, shrink=0.05), )plt.ylim(-2,2)plt.show() [^1]:DataHub-Python 数据可视化入门1 plt.xticks()/plt.yticks()设置轴记号现在是明白干嘛用的了，就是人为设置坐标轴的刻度显示的值。 12345678910111213141516171819202122232425262728# 导入 matplotlib 的所有内容（nympy 可以用 np 这个名字来使用）from pylab import *# 创建一个 8 * 6 点（point）的图，并设置分辨率为 80figure(figsize=(8,6), dpi=80)# 创建一个新的 1 * 1 的子图，接下来的图样绘制在其中的第 1 块（也是唯一的一块）subplot(1,1,1)X = np.linspace(-np.pi, np.pi, 256,endpoint=True)C,S = np.cos(X), np.sin(X)# 绘制余弦曲线，使用蓝色的、连续的、宽度为 1 （像素）的线条plot(X, C, color=&quot;blue&quot;, linewidth=1.0, linestyle=&quot;-&quot;)# 绘制正弦曲线，使用绿色的、连续的、宽度为 1 （像素）的线条plot(X, S, color=&quot;r&quot;, lw=4.0, linestyle=&quot;-&quot;)plt.axis([-4,4,-1.2,1.2])# 设置轴记号xticks([-np.pi, -np.pi/2, 0, np.pi/2, np.pi], [r&apos;$-\pi$&apos;, r&apos;$-\pi/2$&apos;, r&apos;$0$&apos;, r&apos;$+\pi/2$&apos;, r&apos;$+\pi$&apos;])yticks([-1, 0, +1], [r&apos;$-1$&apos;, r&apos;$0$&apos;, r&apos;$+1$&apos;])# 在屏幕上显示show() 当我们设置记号的时候，我们可以同时设置记号的标签。注意这里使用了 LaTeX。[^2] [^2]:Matplotlib 教程 移动脊柱 坐标系1234567ax = gca()ax.spines[&apos;right&apos;].set_color(&apos;none&apos;)ax.spines[&apos;top&apos;].set_color(&apos;none&apos;)ax.xaxis.set_ticks_position(&apos;bottom&apos;)ax.spines[&apos;bottom&apos;].set_position((&apos;data&apos;,0))ax.yaxis.set_ticks_position(&apos;left&apos;)ax.spines[&apos;left&apos;].set_position((&apos;data&apos;,0)) 这个地方确实没看懂，囧，以后再说吧，感觉就是移动了坐标轴的位置。 plt.legend()添加图例1234plot(X, C, color=&quot;blue&quot;, linewidth=2.5, linestyle=&quot;-&quot;, label=&quot;cosine&quot;)plot(X, S, color=&quot;red&quot;, linewidth=2.5, linestyle=&quot;-&quot;, label=&quot;sine&quot;)legend(loc=&apos;upper left&apos;) matplotlib.pyplot使用plt.style.use(&#39;ggplot&#39;)命令，可以作出ggplot风格的图片。 12345678910111213141516171819202122232425# Import necessary packagesimport pandas as pd%matplotlib inlineimport matplotlib.pyplot as pltplt.style.use(&apos;ggplot&apos;)from sklearn import datasetsfrom sklearn import linear_modelimport numpy as np# Load databoston = datasets.load_boston()yb = boston.target.reshape(-1, 1)Xb = boston[&apos;data&apos;][:,5].reshape(-1, 1)# Plot dataplt.scatter(Xb,yb)plt.ylabel(&apos;value of house /1000 ($)&apos;)plt.xlabel(&apos;number of rooms&apos;)# Create linear regression objectregr = linear_model.LinearRegression()# Train the model using the training setsregr.fit( Xb, yb)# Plot outputsplt.scatter(Xb, yb, color=&apos;black&apos;)plt.plot(Xb, regr.predict(Xb), color=&apos;blue&apos;, linewidth=3)plt.show() 给特殊点做注释好吧，又是注释，多个例子参考一下！ 我们希望在 2π/32π/3 的位置给两条函数曲线加上一个注释。首先，我们在对应的函数图像位置上画一个点；然后，向横轴引一条垂线，以虚线标记；最后，写上标签。1234567891011121314151617t = 2*np.pi/3# 作一条垂直于x轴的线段，由数学知识可知，横坐标一致的两个点就在垂直于坐标轴的直线上了。这两个点是起始点。plot([t,t],[0,np.cos(t)], color =&apos;blue&apos;, linewidth=2.5, linestyle=&quot;--&quot;)scatter([t,],[np.cos(t),], 50, color =&apos;blue&apos;)annotate(r&apos;$\sin(\frac&#123;2\pi&#125;&#123;3&#125;)=\frac&#123;\sqrt&#123;3&#125;&#125;&#123;2&#125;$&apos;, xy=(t, np.sin(t)), xycoords=&apos;data&apos;, xytext=(+10, +30), textcoords=&apos;offset points&apos;, fontsize=16, arrowprops=dict(arrowstyle=&quot;-&gt;&quot;, connectionstyle=&quot;arc3,rad=.2&quot;))plot([t,t],[0,np.sin(t)], color =&apos;red&apos;, linewidth=2.5, linestyle=&quot;--&quot;)scatter([t,],[np.sin(t),], 50, color =&apos;red&apos;)annotate(r&apos;$\cos(\frac&#123;2\pi&#125;&#123;3&#125;)=-\frac&#123;1&#125;&#123;2&#125;$&apos;, xy=(t, np.cos(t)), xycoords=&apos;data&apos;, xytext=(-90, -50), textcoords=&apos;offset points&apos;, fontsize=16, arrowprops=dict(arrowstyle=&quot;-&gt;&quot;, connectionstyle=&quot;arc3,rad=.2&quot;)) plt.subplot()plt.subplot(2,3,1)表示把图标分割成2*3的网格。也可以简写plt.subplot(231)。其中，第一个参数是行数，第二个参数是列数，第三个参数表示图形的标号。 plt.axes()我们先来看什么是Figure和Axes对象。在matplotlib中，整个图像为一个Figure对象。在Figure对象中可以包含一个，或者多个Axes对象。每个Axes对象都是一个拥有自己坐标系统的绘图区域。其逻辑关系如下[^3][^4]： plt.axes-官方文档 axes() by itself creates a default full subplot(111) window axis. axes(rect, axisbg=’w’) where rect = [left, bottom, width, height] in normalized (0, 1) units. axisbg is the background color for the axis, default white. axes(h) where h is an axes instance makes h the current axis. An Axes instance is returned. rect=[左, 下, 宽, 高] 规定的矩形区域,rect矩形简写，这里的数值都是以figure大小为比例，因此，若是要两个axes并排显示，那么axes[2]的左=axes[1].左+axes[1].宽，这样axes[2]才不会和axes[1]重叠。 show code:1234567891011121314151617181920212223242526272829303132333435http://matplotlib.org/examples/pylab_examples/axes_demo.htmlimport matplotlib.pyplot as pltimport numpy as np# create some data to use for the plotdt = 0.001t = np.arange(0.0, 10.0, dt)r = np.exp(-t[:1000]/0.05) # impulse responsex = np.random.randn(len(t))s = np.convolve(x, r)[:len(x)]*dt # colored noise# the main axes is subplot(111) by defaultplt.plot(t, s)plt.axis([0, 1, 1.1*np.amin(s), 2*np.amax(s)])plt.xlabel(&apos;time (s)&apos;)plt.ylabel(&apos;current (nA)&apos;)plt.title(&apos;Gaussian colored noise&apos;)# this is an inset axes over the main axesa = plt.axes([.65, .6, .2, .2], axisbg=&apos;y&apos;)n, bins, patches = plt.hist(s, 400, normed=1)plt.title(&apos;Probability&apos;)plt.xticks([])plt.yticks([])# this is another inset axes over the main axesa = plt.axes([0.2, 0.6, .2, .2], axisbg=&apos;y&apos;)plt.plot(t[:len(r)], r)plt.title(&apos;Impulse response&apos;)plt.xlim(0, 0.2)plt.xticks([])plt.yticks([])plt.show() [^3]:绘图: matplotlib核心剖析[^4]:python如何调整子图的大小？ pyplot.pie参数 matplotlib.pyplot.pie colors颜色找出matpltlib.pyplot.plot中的colors可以取哪些值？ so-Named colors in matplotlib CSDN-matplotlib学习之（四）设置线条颜色、形状12for name,hex in matplotlib.colors.cnames.iteritems(): print name,hex 打印颜色值和对应的RGB值。 plt.axis(&#39;equal&#39;)避免比例压缩为椭圆 autopct How do I use matplotlib autopct?1autopct enables you to display the percent value using Python string formatting. For example, if autopct=&apos;%.2f&apos;, then for each pie wedge, the format string is &apos;%.2f&apos; and the numerical percent value for that wedge is pct, so the wedge label is set to the string &apos;%.2f&apos;%pct.]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Matplotlib</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SQL基础语法笔记教程整理]]></title>
    <url>%2F2016%2F05%2F03%2FSQL%2F</url>
    <content type="text"><![CDATA[最近从图书馆借了本介绍SQL的书，打算复习一下基本语法，记录一下笔记，整理一下思路，以备日后复习之用。 PS：本文适用SQL Server2008语法。 一、关系型数据库和SQL实际上准确的讲，SQL是一门语言，而不是一个数据库。 什么是SQL呢？简而言之，SQL就是维护和使用关系型数据库中的的数据的一种标准的计算机语言。 1.1 SQL语言主要有3个主要的组成部分。 DML(Data Manipulation Language)数据操纵语言。这个模块可以让我们检索、修改、增加、删除数据库中的数据。 DDL(Data Definition Language)数据定义语言。是的我们能够创建和修改数据库本身。如：DDL提供ALTER语句，他让我们可以修改数据库中表的设计。 DCL(Data Control Language)数据控制语言，用于维护数据库的安全。 在SQL术语中，记录(record)和字段(field)实际上就称为行(row)和列(column)。 1.2 主键和外键主键之所以有必要： 首先使你唯一标识表中单独的一行。主键确保了唯一性。 可以很容易的将一个表和另一个表关联。 主键一般就会自动默认创建索引，提高了查询速度。 外键就是说A表中的某个字段，同时是B中的主键，那么这个字段就是A表中的外键。希望A表中的这个外键的值必须是B中已经存在的值。 1.3 数据类型一般来讲，有3中重要的数据类型： 数字(Numeric) 字符(Character) 以及日期/时间(Date/Time) bit是数字型，它只允许两个值，0和1。 字符类型区别[^1]：[^1]:varchar和Nvarchar区别 类型 长度 说明 char 固定长度 nchar 固定长度 处理unicode数据类型(所有的字符使用两个字节表示) varchar 可变长度 效率没char高 灵活 nvarchar 可变长度 处理unicode数据类型(所有的字符使用两个字节表示) 1字节=8位 bit就是位，也叫比特位，是计算机表示数据最小的单位。 byte就是字节，1byte=8bit，1byte就是1B； 一个字符=2字节； 1.3 空值空值不等于空格或空白。使用NULL表示空值。 二、简单增删改查2.1 查（列名有空格的情况）12SELECT [ last name]FROM Customers 用方括号将有空格的列名括起来。PS: MySql中用重音符`（~）按键。Oracle用双引号。 查询顺序,SQL执行顺序^2：123456Select -1&gt;选择列,-2&gt;distinct,-3&gt;top 1&gt;…From 表 2&gt;…Where 条件 3&gt;…Group by 列 4&gt;…Having 筛选条件 6&gt;…Order by 列 2.2 增123456INSERT INTO tablename(columnlist)VALUES(RowValues1)(RowValues2)(repeat any number of times) 2.3 改123UPDATE tableSET column1=expression1,column2=expression2(repeat any number of times)WHERE condition 2.4 删123DELETEFROM tableWHERE condition 删除前可以验证一下：1234SELECT COUNT（*）FROM tableWHERE condition 如果想要删除所有的行，可以：1DELETE FROM table 或者1TRUNCATE TABLE table TRUNCATE TABLE优势在于速度更快，但是不提供记录事务的结果。另外一个不同点是，TRUNCATE TABLE重新设置了用于自增型的列的当前值，DELETE不会。 三、别名关键字：AS 3.1 计算字段使用计算字段可以做如下的事情： 选择特定的单词或者数值 对单个或者多个列进行计算 把列和直接量组合在一起。 3.2 直接量这个直接量和表中的数据没有任何关系，就是为了说明所用，下面这种类型的表达式就叫做直接量(literal value)。 12SELECT &apos;直接量&apos; AS `类型`,firstname,lastname FROM `customers` ; 如图，结果中直接量就在一列中了。 3.3 算数运算例子1：12SELECT num*price AS totalFROM orders 例子2：12SELECT firstname+&apos; &apos;+lastname AS &apos;fullname&apos;FROM users 在MySql中连接要是用CONCAT函数：123SELECT OrderID,FirstName,LastName,CONCAT(FirstName,&apos; &apos;,LastName) AS &apos;fullname&apos;FROM orders 3.4 别名1）列的别名12SELECT firstname AS fnFROM customers 2） 表的别名12SELECT firstname FROM customers AS cu 说明： 列的别名是为了显示用的，别名会作为查询结果的表头，不能在WHERE中使用列的别名，会出错！！！ 表的别名确实是为了方便操作用的，可以在WHERE中使用列的别名进行！ 四、使用函数函数要有一组圆括号跟在关键字后边，圆括号告诉我们，这是一个函数！ 4.1 字符函数LEFT&amp;RIGHT LEFT(CharacterValue,NumberOfCharacters)含义：选择CharacterValue字段的左边NumberOfCharacters几个字符。ps:RIGHT是右边几个字符。 LTRIM&amp;RTRIM LTRIM(CharacterValue) 可以删除左边开始的空格。RTRIM作用类似。 SUBSTRINGSUBSTRING(CharacterValue,StartPositon,NumberOfCharacters)含义：选择从开始位置（包括），N个长度的字符。12SELECT SUBSTRING(&apos;thewhitegoat&apos;,4,5) AS &apos;The Answer&apos; 返回：white 4.2 日期/时间函数GETDATE1SELECT GETDATE() 返回当前日期和时间。PS：在MySql中，等价函数是NOW，在Oracle中是CURRENT_DATE。 DATEPART能够分析具体的日期，并且返回诸如该日期是该月中的第几天，或者该年份中的第几周等信息。1DATEPART(datepart,DateValue) datepart可以是许多不同的值，如下都是有效值： year quarter month dayofyear day week weekday hour minute second DATEDIFF可以让我们得到任意两个日期之间相差的天数（或周数、月数等）。1DATEDIFF(datepart1,startdate1,startdate2) DATEDIFF Function Expression Resulting Value DATEDIFF(day,’7/8/2009’,’8/14/2009’) 37 DATEDIFF(week,’7/8/2009’,’8/14/2009’) 5 DATEDIFF(month,’7/8/2009’,’8/14/2009’) 1 DATEDIFF(year,’7/8/2009’,’8/14/2009’) 0 PS:MySql中，DATEDIFF函数只允许我们计算两个日期之间的天数，如果想要得到一个正数，结束的日期通常要作为第一个参数:1DATEDIFF(enddate,startdate) Oracle中没有等价函数 4.3 数值函数ROUND允许我们四舍五入。1ROUND(numericvalue,decimalpalaces) RAND用来产生随机数1RAND([seed]) 没有参数时，它会返回0-1之间的一个随机数。1SELECT RAND() AS &apos;Random Value&apos; 可选参数seed有的情况下，每次将返回相同的值。这让我想起了Python中的Random包。看来很多时候，一些东西是共通的啊。 PIPI()函数如果想要对它保留两位小数，可以通过复合函数进行：1SELECT ROUND(PI(),2) 将会返回：3.14 4.4 转换函数CAST函数允许我们把数据从一种类型转换成另一种类型。1CAST(expression AS DateType) 例子：123SELECT &apos;2009-04-11&apos; AS &apos;Original Date&apos;,CAST(&apos;2009--04-11&apos; AS DATETIME) AS &apos;Converted Date&apos; ISNULL函数，很有用可以把NULL值转换成一个有意义的值。123SELECT Description,ISNULL(Color,&apos;Unknown&apos;) AS &apos;Color&apos;FROM Products 五、排序函数5.1 添加排序123SELECT columnlistFROM tablelistORDER BY columnlist 默认是升序，ASC，因此，上面等价于：123SELECT columnlistFROM tablelistORDER BY columnlist ASC 5.2 降序使用DESC关键字：123SELECT columnlistFROM tablelistORDER BY columnlist DESC 5.3 根据多列12345SELECT FirstName,LastNameFROM CustomersORDER BY LastName, FirstName 注意：列的顺序很重要，首先按照LastName排序，然后按照FirstName排序。 5.4 根据计算字段123SELECT LastName+&apos;,&apos;+FirstName AS &apos;Name&apos;FROM CustomersORDER BY Name 因此，从这儿可以知道，列别名不可以用在WHERE中，但可以用在ORDER BY中。例子123SELECT FirstName,LastNameFROM CustomersORDER BY LastName+FirstName AS &apos;Name&apos; 5.5 排序补充内容当数据升序时，出现顺序是如下： NULL-&gt;数字-&gt;字符注意：此时，该列中的数字其实是按照字符来算的，因此，升序时，23也是排在5之前的。 六、基于列的逻辑-CASE6.1 IF-THEN-ELSE逻辑包含列和CASE表达式的SELECT语句，大概如下：12345SELECT column1,column2,CaseExpressionFROM table 6.2 CASE-简单格式1234567SELECT CASE ColumnOrExpressionWHEN value1 THEN result1WHEN value2 THEN result2(repeat WHEN-THEN any number of times)[ELSE DefaultResult]END CASE表达式对于把不好理解的值转换成有意义的描述是很有用的。12345678SELECT CASE CategoryCodeWHEN &apos;F&apos; THEN &apos;Fruit&apos;WHEN &apos;V&apos; THEN &apos;Vegetable&apos;ELSE &apos;other&apos;END AS &apos;Category&apos;,ProductDescription As &apos;Description&apos;FROM Products 6.3 CASE-查询格式1234567SELECT CASE WHEN condition1 THEN result1WHEN condition2 THEN result2(repeat WHEN-THEN any number of times)[ELSE DefaultResult]END 这种格式允许在关键字WHEN后边放置较为复杂的条件表达式。 相关问题： StackOverFlow-SQL Server: CASE WHEN OR THEN ELSE END =&gt; the OR is not supported 七、基于行的逻辑7.1 应用查询条件终于派到WHERE出场了，注意写法顺序，再写一遍：123456Select -1&gt;选择列,-2&gt;distinct,-3&gt;top 1&gt;…From 表 2&gt;…Where 条件 3&gt;…Group by 列 4&gt;…Having 筛选条件 6&gt;…Order by 列 7.2 限制行-TOP1234SELECT TOP Number ColumnlistFROM table 7.3 TOP和ORDER BY结合关键字TOP的另一个用途是，把它和ORDER BY子句结合起来，基于特定分类，得到带有最大值的一定数量的行。 假设你想看到Shakespeare所著的销量最多的书。1234567SELECT TOP1Title AS &apos;Book Title&apos;,CurrentMonthSales AS &apos;Quantuty Sold&apos;FROM BooksWHERE Author=&apos;Shakespeare&apos;ORDER BY CurrentMonthSales DESC ps: 学会利用google搜索，例如，我想要知道oracle中类似top作用的关键字是什么，可以： 八、布尔逻辑关键字：AND/OR/NOT/BETWEEN/IN/IS/NULL 8.1 OROR子句意味着，如果确定任意条件为真，那么就该选中该行。1234SELECT userid,name,phoneFROM usersWHERE age&lt;18OR age&gt;60 8.2 使用圆括号1234567SELECT CustomerName,Sate,QuantityPurchasedFROM OrdersWHERE State =&apos;IL&apos;OR State=&apos;CA&apos;AND QuantityPurchased&gt;8 本来想要的结果是对来自IL或者CA的客户，同时，只看数量大于8的订单。但是上面执行的结果不是这样的，因为，SQL总是会先处理AND操作符！！！然后才会处理OR操作符。所以，上述语句中，先看到AND并执行如下的条件12State= &apos;CA&apos;AND QuantityPurchased&gt;8 因此，要用括号来规定顺序：1234567SELECT CustomerName,Sate,QuantityPurchasedFROM OrdersWHERE (State =&apos;IL&apos;OR State=&apos;CA&apos;)AND QuantityPurchased&gt;8 8.3 NOT操作符NOT操作符表示对后边的内容否定或者取反。123SELECT CustomerName,StateFROM OrdersWHERE NOT (State=&apos;IL&apos; OR Sate=&apos;NY&apos;) 这个其实可以用AND改写的！！！NOT操作符在逻辑上不是必须的。 8.4 BETWEEN操作符12345SELECT CustomerName,Sate,QuantityPurchasedFROM OrdersWHERE QuantityPurchased BETWEEN 8 AND 10 8.5 IN操作符假设你想看到IL或者NY的行：1234SELECT *FROM OrdersWHERE State=&apos;IL&apos;OR State=&apos;CA&apos; 可以改写成：123SELECT *FROM OrdersWHERE State IN (&apos;IL&apos;,&apos;CA&apos;) 8.9 布尔逻辑-IS NULL为了将某字段NULL值的行或0的行包括进来：1234SELECT *FROM ProductsWHERE weight=0OR weight IS NULL 或者123SELECT *FROM ProductsWHERE ISNULL(weight,0)=0 九、模糊匹配9.1 LIKE和%搭配%通配符可以表示任意的字符，它可以表示0个，1个，任意多个字符。 9.2 通配符除了%以外，还有下划线（_）、方括号起来的characterlist，以及用方括号括起来的脱字符号（^）加上characterlist。 下划线表示一个字符 [characterlist]表示括号中字符的任意一个 [^characterlist]表示不能是括号中字符的任意一个例子：12345SELECT FirstName,LastNameFROM ActorsWHERE FirstName LIKE &apos;[CM]ARY&apos; 检索以C或者M开头并以ARY结尾的所有行。 9.3 按照读音匹配SOUNDEX和DIFFERENCE 十、汇总数据10.1消除重复使用DISTINCT12SELECT DISTINCE name,ageFROM users 如果age不同，即使name相同，那么这一行就不会被删除重复。 10.2 聚合函数COUNT\SUM\AVG\MIN\MAX，他们提供了对分组数据进行计数、求和、取平均值、取最小值和最大值等方法。12345SELECT AVG(Grade) AS &apos;Average Quiz Score&apos;MIN(Grade) AS &apos;Minimum Quiz Score&apos;FROM GradesWHERE GradeType=&apos;Quiz&apos; COUNT函数可以有3中不同方式使用它。1.COUNT函数可以用来返回所有选中行的数目，而不管任何特定列的值。例如：下面语句返回GradeType为’HomeWork’的所有行的数目：1234SELECT COUNT(*) AS &apos;Count of Homework Rows&apos;FROM GradesWHERE GradeType=&apos;HomeWork&apos; 这种*方式，会计数所有行的个数，即使其中有NULL。 2.第二种方式指定具体的列1234SELECT COUNT(Grades) AS &apos;Count of Homework Rows&apos;FROM GradesWHERE GradeType=&apos;HomeWork&apos; 第一种方式返回3，这一种方式返回2，为什么？？？因为，这种方式要满足Grades这一列有值，NULL值的行不会计数。 3.使用关键字DISTINCT。123SELECT COUNT(DISTINCT FeeType) AS &apos;Number of Fee Types&apos;FROM Fees 这条语句计数了FeeType列唯一值的个数。 10.3 分组数据-GROUP BY123456SELECTGradeType AS &apos;Grade Type&apos;,AVG(Grade)AS &apos;Average Grade&apos;FROM GradesGROUP BY GradeTypeORDER BY GradeType 感觉像EXCEL中的分类汇总功能。如果想把Grade为NULL值的当做0，那么可以用：123456SELECTGradeType AS &apos;Grade Type&apos;,AVG(ISNULL(Grade,0))AS &apos;Average Grade&apos;FROM GradesGROUP BY GradeTypeORDER BY GradeType GROUP BY子句中的列的顺序是没有意义的； ORDER BY子句中的列的顺序是有意义的。 10.4 基于聚合查询条件-HAVING当针对带GROUP BY的一条SELECT语句应用任何查询条件时，人们必须要问查询条件是应用于单独的行还是整个组。 实际上，WHERE子句是单独的执行查询条件。SQL提供了一个名为HAVING的关键字，它允许对组级别使用查询条件。例子：查看选修了类型为选修“A”，平均成绩在70分以上的学生姓名，平均成绩。12345678SELECT Name,AVG(ISNULL(Grades,0)) AS &apos;Average Grades&apos;FROM GradesWHERE GradeType=&apos;A&apos;GROUP BY NameHAVING AVG(ISNULL(Grades,0))&gt;70ORDER BY Name 修要修类型为A，那么，这是这对行的查询，因此这里要用WHERE。但是，还要筛选平均成绩，那么，这是一个平均值，建立在聚合函数上的，并不是单独的行，这就需要用到关键字HAVING。需要先将Student分组，然后把查询结果应用到基于全组的一个聚合统计上。 WHERE只保证我们选择了GradeType是A的行，HAVING保证平均成绩至少70分以上。 注意：如果想要在结果中添加GradeType的值，如果直接在SELECT后边添加这个列，将会出错。这是因为，所有列都必须要么出现在GROUP BY中，要么包含在一个聚合函数中。123456789SELECT Name,GradeType,AVG(ISNULL(Grades,0)) AS &apos;Average Grades&apos;FROM GradesWHERE GradeType=&apos;A&apos;GROUP BY Name,GradeTypeHAVING AVG(ISNULL(Grades,0))&gt;70ORDER BY Name 十一、组合表11.1 内连接来组合表-Inner Join通过书中的描述，我感觉内连接更像是用来将主键表、外键表连接起来的工具。例如：A表： userid name age 1 michael 26 2 hhh 25 3 xiang 20 B表： orderid userid num price 1 1 2 3 2 2 6 6 3 1 5 5 如上表格，那么要连接这两个表格，查询订单1的客户姓名，年龄，订单号：方式一：1234SELECT name,age,orderidFROM A,BWHERE A.userid=B.useridAND orderid=1 方式二，使用现在的内连接实现：12345SELECT name,age,orderidFROM AINNER JOIN BON A.userid=B.useridAND orderid=1 ON关键字指定两个表如何准确的连接。 内连接中表的顺序：FROM 子句指定了A表，INNER JOIN 子句指定B表，我们调换A,B顺序，所得到的结果相同的!只是显示列的顺序可能会不同而已。 不建议使用方式一的格式。关键字INNER JOIN ON的优点在于显示地表示了连接的逻辑，那是它们唯一的用途。WEHERE的含义不够明显。因为它是条件的意思啊，不是连接的！ 11.2 外连接外连接分为左连接（LEFT OUTER JOIN)、右连接(RIGHT OUTER JOIN)、全连接（FULL OUTER JOIN)。 OUTER是可以省略的。 左连接（LEFT JOIN)12345SELECT name,age,orderidFROM ALEFT JOIN BON A.userid=B.useridAND orderid=1 外连接的强大之处在于，主表中的数据必然都会保留，从表中列没有值的情况，用NULL补充。 LEFT JOIN 左边的表为主表，右边的表为从表。 11.3 自连接自连接必然用到表的别名。1234SELECT A.name,B.name as ManagerNameFROM worker as ALEFT JOIN worker as BON A.managerid=B.id 11.4 创建视图123CREATE VIEW ViewName ASSelectStatement[WITH CHECK OPTION] 视图中不能包含ORDER BY子句。 [WITH CHECK OPTION]表示对视图进行UPDATE,INSERT,DELETE操作时任然保证了视图定义时的条件表达式。 删除视图：1DROP VIEW ViewName 修改视图：12ALTER VIEW ViewName ASSelectStatement 视图的优点 简化用户的操作 使用户以多角度看待同一数据 对重构数据库提供了一定程度的逻辑独立性 对机密数据提供安全保护 十二、补充12.1 子查询可以用3种主要的方式来指定子查询，总结如下： 当子查询是tablelist的一部分时，它指定了一个数据源。 当子查询是condition的一部分时，它成为查询条件的一部分。 当子查询是columnlist的一部分时，它创建了一个单个的计算的列。 12.2 索引索引是一种物理结构，可以为数据库表中任意的列添加索引。 索引的目的是，当SQL语句中包含该列的是偶，可以加速数据的检索。 索引的缺点是，在数据库中，索引需要更多的存储硬盘。另一个负面因素是，索引通常会降低相关的列数据更新速度。这是因为，任何时候插入或者修改一行记录时，索引都必须重新计算该列中的值的正确的排列顺序。 可以对任意的列进行索引，但是只能指定一个列作为主键。指定一个列作为主键意味着两件事情：首先这个列成为了索引，其次保证这列包含唯一的值。12CREATE INDEX Index2ON MyTable (ColumnFour) 删除一个索引：12DROP INDX Index2ON MyTable 参考： SQL总结（一）基本查询 SQL Server 常用高级语法笔记 史上最全的SQL Server复习笔记一]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>数据库</tag>
        <tag>SQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[搜狗输入法使用技巧整理]]></title>
    <url>%2F2015%2F12%2F28%2Ftools-sougoupinyin%2F</url>
    <content type="text"><![CDATA[现在的输入法有很多，但是，哪个最好呢？不必纠结，自己用着顺手的才是最好！ 自己选择搜狗输入法的原因很简单，因为，它支持的平台多，同时，各个平台更新也很积极。从兼容性的角度考虑，还是最后选择了搜狗。至于搜狗启动的广告之类，其实不怕麻烦，是可以在设置里选择不弹出的。 作为每天使用最多的输入法，我觉得，花点时间了解它一下还是值得的，你说呢？毕竟是与我们共同作战的小伙伴啊！ 输入罗马数字+计算器属性设置-&gt;高级 需要输入罗马数字时，采用：v+”数字”，然后可以看见候选数字中有罗马数字了。 v+计算式子 就能直接获得结果 输入法截图右击输入法进入搜狗工具箱。按键-&gt;扩展功能快捷键 设置截图快捷键之后，就可以通过快捷键快速截图了！这样需要截图的时候就不需要开qq！足以应付日常的截图功能了，至于专业的，还是找专业截图的工具好了…… 自定义短语属性设置-&gt;高级-&gt;自定义短语如图，可以通过设置自定义短语，从而达到快速输入一些短语的功能。例如：设置缩写qq对应短语’你的qq邮箱’,那么下次在你需要输入QQ邮箱的时候，只需要输入qq就能显示邮箱候选了。 鼠标手势没想到，搜狗输入法鼠标手势也有，再方便不过了。可以通过扩展箱安装。如果担心鼠标手势和某些应用程序内的手势冲突，可以通过设置来定义在某些程序里边不启用鼠标手势。PS：现在已经喜欢上搜狗鼠标手势的全局缩小，全局最大化的功能了。浏览器一下子可以快速最小化和最大化呢。防止boss突袭。 手写输入通过扩展工具箱里的首席输入扩展，可以在遇到陌生字时，手写输入。 Tab拆字辅助码笔画笔画筛选用于输入单字时，用笔顺来快速定位该字。使用方法是输入一个字或多个字后，按下tab键（tab键如果是翻页的话也不受影响），然后用h横、s 竖、p撇、n捺、z折依次输入第一个字的笔顺，一直找到该字为止。五个笔顺的规则同上面的笔画输入的规则。要退出笔画筛选模式，只需删掉已经输入的笔画辅助码即可。 例如，快速定位【珍】字，输入了zhen后，按下【tab】，然后输入珍的前两笔【hh】，就可定位该字。 或者输入一个不怎么用的词：威赫（wei he），这个词不在第一页，这种情况下不要翻页。输入weihe，然后按tab键，会进入一个笔画模式，你可以用横撇竖点（hpsd）定位到字。这里，“威”字笔顺是横、撇、横、撇点、撇、横、斜钩、撇、点，所以你输入weihe之后，按一下tab，然后输入hp，看看是不是把第一个字是威的提到前 面了？如果还不够精确，可以继续输入下面的笔画，一般输入3笔左右就够了，然后按0只显示单字，选中威之后再选下一个。 Tab拆字辅助码拼音拆字辅助码让你快速的定位到一个单字，使用方法如下：想输入一个汉字【娴】，但是非常靠后，找不到，那么输入【xian】，然后按下【tab】键，在输入【娴】的两部分【女】【闲】的首字母nx，就可以看到只剩下【娴】字了。输入的顺序为xian+tab+nx。 难字按u键进行偏旁和笔画输入U模式是专门为输入不会读的字所设计的。在输入u键后，然后依次输入一个字的笔顺，笔顺为：h横、s竖、p撇、n捺、z折，就可以得到该字，同时小键盘上的1、2、3、4、5也代表h、s、p、n、z。这里的笔顺规则与普通手机上的五笔画输入是完全一样的。其中点也可以用d来输入。由于双拼占用了u键，智能ABC的笔画规则不是五笔画，所以双拼和智能ABC下都没有u键模式。 对于只认识偏旁部首，不清楚字音的字，像“黏”、“亓”等，我们可以这样输入：u+偏旁部首的读音，或者u+字的顺序笔画。对于即清楚字形，又清楚字音的，只是候选位置比较靠后的字，比如“幂”、“祎”等，我们可以这样输入： 读音+tab键+偏旁的读音首字母，例如“幂”字的偏旁是“秃宝盖”，对应的字母就是“t”，“祎”字的偏旁部首对应的读音分别是“s”（示补旁）、“w”（韦）。对于只知道读音，不清楚怎么写的字，我们可以这样输入： 比如“耄”，我们知道它是“耄耋”中的一个字，可以输入maodie，然后按“[”键，上屏当前候选第一个字； 比如“餮”，我们知道它是“饕餮”中的一个字，可以输入taotie，然后按“]”键，上屏当前候选第二个字； 生活小技巧（农历，诗句等） 键入rq选择1得到××××年××月××日格式时间，选择2得到××××-××-××格式时间，选择3得到例如二〇〇八年三月三十一日的时间 键入llysc选择2得到：离离原上草，一岁一枯荣。野火烧不尽，春风吹又生。远芳侵古道，晴翠接荒城。又送王孙去，萋萋满别情。 比较常用的特殊符号，如↑之类 键入pai选择3得到π 键入aerfa选择2得到希腊字母α，依此类推 键入wjx选择3、4分别得到☆和★ 键入sjt、xjt、zjt、yjt分别得到↑、↓、←和→ 键入sjx选择3、4分别得到△和▲ 参考： 搜狗输入法使用实用技巧分享 拼音输入法有哪些鲜为人知的技巧？]]></content>
      <categories>
        <category>ToolsDaily</category>
      </categories>
      <tags>
        <tag>Tools</tag>
        <tag>输入法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[遗传算法GA(Genetic Algorithm)入门知识梳理]]></title>
    <url>%2F2015%2F12%2F24%2Falgorithm-GA-basic%2F</url>
    <content type="text"><![CDATA[一、遗传算法进化论背景知识作为遗传算法生物背景的介绍，下面内容了解即可： 种群(Population)：生物的进化以群体的形式进行，这样的一个群体称为种群。 个体：组成种群的单个生物。 基因 ( Gene ) ：一个遗传因子。 染色体 ( Chromosome ) ：包含一组的基因。 生存竞争，适者生存：对环境适应度高的、牛B的个体参与繁殖的机会比较多，后代就会越来越多。适应度低的个体参与繁殖的机会比较少，后代就会越来越少。 遗传与变异：新个体会遗传父母双方各一部分的基因，同时有一定的概率发生基因变异。 简单说来就是：繁殖过程，会发生基因交叉( Crossover ) ，基因突变 ( Mutation ) ，适应度( Fitness )低的个体会被逐步淘汰，而适应度高的个体会越来越多。那么经过N代的自然选择后，保存下来的个体都是适应度很高的，其中很可能包含史上产生的适应度最高的那个个体。 二、遗传算法思想GA的组成: 编码（产生初始种群） 适应度函数 遗传算子（选择、交叉、变异） 运行参数 借鉴生物进化论，遗传算法将要解决的问题模拟成一个生物进化的过程，通过复制、交叉、突变等操作产生下一代的解，并逐步淘汰掉适应度函数值低的解，增加适应度函数值高的解。这样进化N代后就很有可能会进化出适应度函数值很高的个体。 举个例子，使用遗传算法解决“0-1背包问题”的思路：0-1背包的解可以编码为一串0-1字符串（0：不取，1：取） ；首先，随机产生M个0-1字符串，然后评价这些0-1字符串作为0-1背包问题的解的优劣；然后，随机选择一些字符串通过交叉、突变等操作产生下一代的M个字符串，而且较优的解被选中的概率要比较高。这样经过G代的进化后就可能会产生出0-1背包问题的一个“近似最优解”。 2.1 编码需要将问题的解编码成字符串的形式才能使用遗传算法。最简单的一种编码方式是二进制编码，即将问题的解编码成二进制位数组的形式。例如，问题的解是整数，那么可以将其编码成二进制位数组的形式。将0-1字符串作为0-1背包问题的解就属于二进制编码。 基因在一定能够意义上包含了它所代表的问题的解。基因的编码方式有很多，这也取决于要解决的问题本身。常见的编码方式有： 二进制编码，基因用0或1表示（常用于解决01背包问题） 如：基因A：00100011010 (代表一个个体的染色体) 互换编码（用于解决排序问题，如旅行商问题和调度问题） 如旅行商问题中，一串基因编码用来表示遍历的城市顺序，如：234517986，表示九个城市中，先经过城市2，再经过城市3，依此类推。 树形编码（用于遗传规划中的演化编程或者表示） 如,问题：给定了很多组输入和输出。请你为这些输入输出选择一个函数，使得这个函数把每个输入尽可能近地映射为输出。 编码方法：基因就是树形结构中的一些函数。 值编码 （二进制编码不好用时，解决复杂的数值问题） 在值编码中，每个基因就是一串取值。这些取值可以是与问题有关任何值：整数，实数，字符或者其他一些更复杂的东西。 2.2 适应度函数适应度函数 ( Fitness Function )：用于评价某个染色体的适应度，用f(x)表示。有时需要区分染色体的适应度函数与问题的目标函数。例如：0-1背包问题的目标函数是所取得物品价值，但将物品价值作为染色体的适应度函数可能并不一定适合。适应度函数与目标函数是正相关的，可对目标函数作一些变形来得到适应度函数。 遗传算子：遗传算法有3个最基本的操作：选择，交叉，变异。 2.3 选择选择一些染色体来产生下一代。一种常用的选择策略是 “比例选择”，也就是个体被选中的概率与其适应度函数值成正比。假设群体的个体总数是M，那么那么一个体Xi被选中的概率为f(Xi)/( f(X1) + f(X2) + …….. + f(Xn) ) 。比例选择实现算法就是所谓的“轮盘赌算法”( Roulette Wheel Selection )。 123456789101112131415161718192021222324252627282930313233轮盘赌算法/** 按设定的概率，随机选中一个个体* P[i]表示第i个个体被选中的概率*/int RWS()&#123;m =0;r =Random(0,1); //r为0至1的随机数for(i=1;i&lt;=N; i++)&#123;/* 产生的随机数在m~m+P[i]间则认为选中了i* 因此i被选中的概率是P[i]*/m = m + P[i];if(r&lt;=m) return i; 2.4 交叉所谓交叉运算，是指对两个相互配对的染色体依据交叉概率按某种方式相互交换其部分基因，从而形成两个新的个体。交叉运算在GA中起关键作用，是产生新个体的主要方法。 2.4.1 2条染色体交换部分基因，来构造下一代的2条新的染色体。例如：交叉前： 00000|011100000000|10000 11100|000001111110|00101 交叉后： 00000|000001111110|10000 11100|011100000000|00101 染色体交叉是以一定的概率发生的，这个概率记为Pc 。 2.4.2 双交叉点法 （用于二进制编码）选择两个交叉点,子代基因在两个交叉点间部分来自一个父代基因,其余部分来自于另外一个父代基因. 如： 交叉前： 01 |0010| 11 11 |0111| 01 交叉后： 11 |0010| 01 01 |0111| 11 2.4.3. 基于“ 与/或 ”交叉法 （用于二进制编码）对父代按位”与”逻辑运算产生一子代A;按位”或”逻辑运算产生另一子代B。该交叉策略在解背包问题中效果较好 . 如： 交叉前： 01001011 11011101 交叉后： 01001001 11011111 还有其他交叉方法，参考遗传算法学习心得 2.5 变异变异是指依据变异概率将个体编码串中的某些基因值用其它基因值来替换，从而形成一个新的个体。GA中的变异运算是产生新个体的辅助方法，它决定了GA的局部搜索能力，同时保持种群的多样性。交叉运算和变异运算的相互配合，共同完成对搜索空间的全局搜索和局部搜索。 注：变异概率Pm不能太小，这样降低全局搜索能力；也不能太大，Pm &gt; 0.5，这时GA退化为随机搜索。 在繁殖过程，新产生的染色体中的基因会以一定的概率出错，称为变异。变异发生的概率记为Pm 。 2.5.1. 基本位变异算子 （用于二进制编码）基本位变异算子是指对个体编码串随机指定的某一位或某几位基因作变异运算。对于基本遗传算法中用二进制编码符号串所表示的个体，若需要进行变异操作的某一基因座上的原有基因值为0，则变异操作将其变为1；反之，若原有基因值为1，则变异操作将其变为0。 变异前： 000001110000000010000 变异后： 000001110000100010000 2.5.2. 逆转变异算子（用于互换编码）在个体中随机挑选两个逆转点，再将两个逆转点间的基因交换。 如： 变异前： 1346798205 变异后： 1246798305 2.6 运行参数GA运行时选择的参数应该视解决的具体问题而定，到目前为止，还没有一个适用于GA所有应用领域的关于算法参数的理论。下面是一般情况下使用GA时推荐的参数： 2.6.1 交叉率交叉率一般来说应该比较大，推荐使用80％-95％。 2.6.2 变异率变异率一般来说应该比较小，一般使用0.5％-1％最好。 2.6.3 种群的规模种群规模指的是群体中个体的个数。实验发现，比较大的种群的规模并不能优化遗传算法的结果。种群的大小推荐使用20-30，一些研究表明，种群规模 的大小取决于编码的方法，具体的说就是编码串（Encoded String）的大小。也就是说，如果说采用32位为基因编码的时候种群的规模大小最好为32的话，那么当采用16位为基因编码时种群的规模相应应变为原 来的两倍。 2.6.4 遗传运算的终止进化代数个人的想法是，设定一个计数器，如果连续N代出现的最优个体的适应度都一样时，（严格的说应该是，连续N代子代种群的最优个体适应度都&lt;=父代最优个性的适应度）可以终止运算。 三、SGA（基本遗传算法）的伪代码SGA（基本遗传算法）中采用轮盘赌选择方法 3.1算法流程图 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960基本遗传算法伪代码/** Pc：交叉发生的概率* Pm：变异发生的概率* M：种群规模* G：终止进化的代数* Tf：进化产生的任何一个个体的适应度函数超过Tf，则可以终止进化过程*/初始化Pm，Pc，M，G，Tf等参数。随机产生第一代种群Popdo&#123; 计算种群Pop中每一个体的适应度F(i)。 初始化空种群newPop do &#123; 根据适应度以比例选择算法从种群Pop中选出2个个体 if ( random ( 0 , 1 ) &lt; Pc ) &#123; 对2个个体按交叉概率Pc执行交叉操作 &#125; if ( random ( 0 , 1 ) &lt; Pm ) &#123; 对2个个体按变异概率Pm执行变异操作 &#125;将2个新个体加入种群newPop中&#125; until ( M个子代被创建 )用newPop取代Pop&#125;until ( 任何染色体得分超过Tf， 或繁殖代数超过G ) 四、基本遗传算法的优化下面的方法可优化遗传算法的性能。 4.1 灾变遗传算法的局部搜索能力较强，但是很容易陷入局部极值。引用网上的一段原话: “那么如何解决遗传算法容易陷入局部极值的问题呢？让我们来看看大自然提供的方案。 六千五百万年以前，恐龙和灵长类动物并存，恐龙在地球上占绝对统 治地位，如果恐龙没有灭绝灵长类动物是绝没有可能统治地球的。正是恐龙的灭绝才使灵长类动物有了充分进化的余地，事实上地球至少经历了5次物种大灭绝，每 次物种灭绝都给更加高级的生物提供了充分进化的余地。所以要跳出局部极值就必须杀死当前所有的优秀个体，从而让远离当前极值的点有充分的进化余地。这就是灾变的思想。” 灾变就是杀掉最优秀的个体，这样才可能产生更优秀的物种。那何时进行灾变，灾变次数又如何设定？ 何时进行灾变，可以采用灾变倒计数的方式。如果n代还没有出现比之前更优秀的个体时，可以发生灾变。灾变次数可以这样来确定，如果若干次灾变后产生的个体的适应度与没灾变前的一样，可停止灾变。 4.2 精英主义(Elitist Strategy)选择：当利用交叉和变异产生新的一代时，我们有很大的可能把在某个中间步骤中得到的最优解丢失。 精英主义的思想是,在每一次产生新的一代时，首先把当前最优解原封不动的复制到新的一代中。然后按照前面所说的那样做就行。精英主义方法可以大幅提高运算速度，因为它可以防止丢失掉找到的最好的解。 精英主义是基本遗传算法的一种优化。为了防止进化过程中产生的最优解被交叉和变异所破坏，可以将每一代中的最优解原封不动的复制到下一代中。 4.3 矛盾由上面看来,灾变与精英主义之间似乎存在着矛盾.前者是将产生的最优个体杀掉,而后者是将最优秀个体基因直接保存到下一代. 应该辩证地看待它们之间的矛盾,两者其实是可以共存的.我们在每一代进行交叉运算时,均直接把最优秀的个体复制到下一代;但当连续N代,都没有更优 秀的个体出现时,便可以猜想可能陷入局部最优解了,这样可以采用灾变的手段.可以说,精英主义是伴随的每一代的,但灾变却不需要经常发生,否则算法可能下 降为随机搜索了. 当然,每个算法中不一定要用精英主义和灾变的手段,应该根据具体的问题而定 4.4 插入操作：可在3个基本操作的基础上增加一个插入操作。插入操作将染色体中的某个随机的片段移位到另一个随机的位置。 五、GA算法特点5.1 遗传算法的优点: 群体搜索，易于并行化处理； 不是盲目穷举，而是启发式搜索； 适应度函数不受连续、可微等条件的约束，适用范围很广。 容易实现。一旦有了一个遗传算法的程序，如果想解决一个新的问题，只需针对新的问题重新进行基因编码就行；如果编码方法也相同，那只需要改变一下适应度函数就可以了。 5.2 遗传算法的缺点: 全局搜索能力不强,很容易陷入局部最优解跳不出来；(可结合SA进行改进,因为SA在理率上是100%得到全局最优的,但搜索代价高) 将遗传算法用于解决各种实际问题后，人们发现遣传算法也会由于各种原因过早向目标函数的局部最优解收敛，从而很难找到全局最优解。其中有些是由于目标函数的特性造成的，例如函数具有欺骗性，不满足构造模块假说等等；另外一些则是由于算法设计不当。为此，不断有人对遗传算法提出各种各样的改进方案。例如：针对原先的定长二进制编码方案；提出了动态编码、实数编码等改进方案；针对按比例的选择机制，提出了竞争选择、按续挑选等改进方案；针对原先的一点交算子，提出了两点交、多点交、均匀交等算子；针对原先遗传算法各控制参数在进化过程中不变的情况，提出了退化遗传算法、自适应遗传算法等。另外，针对不同问题还出现了分布式遗传算法、并行遗传算法等等。 六、遗传算法的实例参考：参考文献都是干货！！！参考文献都是干货！！！参考文献都是干货！！！ 遗传算法入门-博客园-苍梧本文主要参考，推荐！感谢作者~ 经典算法研究系列：七、深入浅出遗传算法July大神写的，通俗易懂，推荐！！！ HELLO，遗传算法！博主语言轻松，用python描述了遗传算法求解一个函数最大值的例子。 遗传算法理论基础与简单应用实例博主总结整理的内容，挺不错的，文中的链接有实例应用。 遗传算法入门到掌握（一） CSDN-GA代码下载袋鼠跳的例子来描述了GA算法，帮助理解GA。 非常好的理解遗传算法的例子求下述二元函数的最大值的例子 遗传算法学习心得 本文由 Michael翔 创作，采用 知识共享署名 3.0 中国大陆许可协议 进行许可。可自由转载、引用，但需署名作者且注明文章出处。]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python数据分析入门之pandas总结基础]]></title>
    <url>%2F2015%2F12%2F23%2Fpython-pandas-basic%2F</url>
    <content type="text"><![CDATA[Pandas–“大熊猫”基础SeriesSeries: pandas的长枪(数据表中的一列或一行,观测向量,一维数组…) 12345678Series1 = pd.Series(np.random.randn(4))print Series1,type(Series1) print Series1.indexprint Series1.values 输出结果： 12345678910111213140 -0.6762561 0.5330142 -0.9352123 -0.940822dtype: float64 &lt;class &apos;pandas.core.series.Series&apos;&gt;Int64Index([0, 1, 2, 3], dtype=&apos;int64&apos;)[-0.67625578 0.53301431 -0.93521212 -0.94082195] np.random.randn() 正态分布相关。函数说明 Series⽀持过滤的原理就如同NumPy1234print Series1&gt;0 print Series1[Series1&gt;0] 输出结果如下： 12345678910111213140 0.0304801 0.0727462 -0.1866073 -1.412244dtype: float64 &lt;class &apos;pandas.core.series.Series&apos;&gt;Int64Index([0, 1, 2, 3], dtype=&apos;int64&apos;)[ 0.03048042 0.07274621 -0.18660749 -1.41224432] 我发现，逻辑表达式，获得的值就是True或者False。要先取得值，还是要X[y]的形式。 当然也支持广播Broadcasting什么是broadcasting,暂时我也不太清楚，看个栗子： 1234print Series1*2 print Series1+5 输出结果如下： 123456789101112131415161718190 0.060961 1 0.145492 2 -0.373215 3 -2.824489 dtype: float64 0 5.030480 1 5.072746 2 4.813393 3 3.587756 dtype: float64 以及Universal Functionnumpy.frompyfunc(out,nin,nout) 返回的是一个函数，nin是输入的参数个数，nout是函数返回的对象的个数函数说明 在序列上就使用行标，而不是创建1个2列的数据表，能够轻松辨别哪是数据，哪是元数据这句话的意思，我的理解是序列尽量是一列，不用去创建2列，这样子，使用index就能指定数据了 12345678910Series2 = pd.Series(Series1.values,index=[&apos;norm_&apos;+unicode(i) for i in xrange(4)])print Series2,type(Series2)print Series2.indexprint type(Series2.index)print Series2.values 输出结果如下，可以看到，它是通过修改了index值的样式，并没有创建2列。 12345678910111213141516norm_0 -0.676256norm_1 0.533014norm_2 -0.935212norm_3 -0.940822dtype: float64 &lt;class &apos;pandas.core.series.Series&apos;&gt;Index([u&apos;norm_0&apos;, u&apos;norm_1&apos;, u&apos;norm_2&apos;, u&apos;norm_3&apos;], dtype=&apos;object&apos;)&lt;class &apos;pandas.core.index.Index&apos;&gt;[-0.67625578 0.53301431 -0.93521212 -0.94082195] 虽然行是有顺序的，但是仍然能够通过行级的index来访问到数据： （当然也不尽然像Ordered Dict，因为⾏索引甚⾄可以重复，不推荐重复的行索引不代表不能用） 12print Series2[[&apos;norm_0&apos;,&apos;norm_3&apos;]] 可以看到，读取数据时，确实要采用X[y]的格式。这里X[[y]]是因为，它要读取两个数据，指定的是这两个数据的index值，将index值存放进list中，然后读取。输出结果如下： 123456norm_0 -0.676256norm_3 -0.940822dtype: float64 再比如： 1234print &apos;norm_0&apos; in Series2print &apos;norm_6&apos; in Series2 输出结果： 1234TrueFalse 逻辑表达式的输出结果，布尔型值。 从Key不重复的Ordered Dict或者从Dict来定义Series就不需要担心行索引重复：12345678910Series3_Dict = &#123;&quot;Japan&quot;:&quot;Tokyo&quot;,&quot;S.Korea&quot;:&quot;Seoul&quot;,&quot;China&quot;:&quot;Beijing&quot;&#125;Series3_pdSeries = pd.Series(Series3_Dict)print Series3_pdSeriesprint Series3_pdSeries.valuesprint Series3_pdSeries.index 输出结果： 123456789101112China BeijingJapan TokyoS.Korea Seouldtype: object[&apos;Beijing&apos; &apos;Tokyo&apos; &apos;Seoul&apos;]Index([u&apos;China&apos;, u&apos;Japan&apos;, u&apos;S.Korea&apos;], dtype=&apos;object&apos;) 通过上面的输出结果就知道了，输出结果是无序的，和输入顺序无关。 想让序列按你的排序⽅式保存？就算有缺失值都毫无问题 1234567891011121314Series4_IndexList = [&quot;Japan&quot;,&quot;China&quot;,&quot;Singapore&quot;,&quot;S.Korea&quot;]Series4_pdSeries = pd.Series( Series3_Dict ,index = Series4_IndexList)print Series4_pdSeriesprint Series4_pdSeries.valuesprint Series4_pdSeries.indexprint Series4_pdSeries.isnull()print Series4_pdSeries.notnull() 上面这样的输出就会按照list中定义的顺序输出结果。 整个序列级别的元数据信息：name 当数据序列以及index本身有了名字，就可以更方便的进行后续的数据关联啦！ 这里我感觉就是列名的作用。下面举例： 1234print Series4_pdSeries.nameprint Series4_pdSeries.index.name 很显然，输出的结果都是None，因为我们还没指定name嘛！ 123456Series4_pdSeries.name = &quot;Capital Series&quot;Series4_pdSeries.index.name = &quot;Nation&quot;print Series4_pdSeries 输出结果： 123456789101112NationJapan TokyoChina BeijingSingapore NaNS.Korea SeoulName: Capital Series, dtype: object “字典”？不是的，⾏index可以重复，尽管不推荐。 12345678Series5_IndexList = [&apos;A&apos;,&apos;B&apos;,&apos;B&apos;,&apos;C&apos;]Series5 = pd.Series(Series1.values,index = Series5_IndexList)print Series5print Series5[[&apos;B&apos;,&apos;A&apos;]] 输出结果： 123456789101112131415161718A 0.030480B 0.072746B -0.186607C -1.412244dtype: float64B 0.072746B -0.186607A 0.030480dtype: float64 我们可以看出，Series[‘B’]输出了两个值，所以index值尽量不要重复呀！ DataFrameDataFrame：pandas的战锤(数据表，⼆维数组) Series的有序集合，就像R的DataFrame一样方便。 仔细想想，绝大部分的数据形式都可以表现为DataFrame。 从NumPy二维数组、从文件或者从数据库定义：数据虽好，勿忘列名123456dataNumPy = np.asarray([(&apos;Japan&apos;,&apos;Tokyo&apos;,4000),(&apos;S.Korea&apos;,&apos;Seoul&apos;,1300),(&apos;China&apos;,&apos;Beijing&apos;,9100)])DF1 = pd.DataFrame(dataNumPy,columns=[&apos;nation&apos;,&apos;capital&apos;,&apos;GDP&apos;])DF1 这里DataFrame中的columns应该就是列名的意思。现在看print的结果，是不是很舒服啊！Excel的样式嘛 等长的列数据保存在一个字典里（JSON）：很不幸，字典key是无序的123456dataDict = &#123;&apos;nation&apos;:[&apos;Japan&apos;,&apos;S.Korea&apos;,&apos;China&apos;],&apos;capital&apos;:[&apos;Tokyo&apos;,&apos;Seoul&apos;,&apos;Beijing&apos;],&apos;GDP&apos;:[4900,1300,9100]&#125;DF2 = pd.DataFrame(dataDict)DF2 输出结果可以发现，无序的！ 1234567 GDP capital nation0 4900 Tokyo Japan1 1300 Seoul S.Korea2 9100 Beijing China PS:由于懒得截图放过来，这里没有了边框线。 从另一个DataFrame定义DataFrame：啊，强迫症犯了！1234DF21 = pd.DataFrame(DF2,columns=[&apos;nation&apos;,&apos;capital&apos;,&apos;GDP&apos;])DF21 很明显，这里是利用DF2定义DF21，还通过指定cloumns改变了列名的顺序。 1234DF22 = pd.DataFrame(DF2,columns=[&apos;nation&apos;,&apos;capital&apos;,&apos;GDP&apos;],index = [2,0,1])DF22 很明显，这里定义了columns的顺序，还定义了index的顺序。 12345678nation capital GDP2 China Beijing 91000 Japan Tokyo 49001 S.Korea Seoul 1300 从DataFrame中取出列？两种方法（与JavaScript完全一致！）OMG，囧，我竟然都快忘了js语法了，现在想起了，但是对象的属性既可以obj.x也可以obj[x]。 ‘.’的写法容易与其他预留关键字产生冲突 ‘[ ]’的写法最安全。 从DataFrame中取出行？（至少）两种⽅法： 方法1和方法2： 1234print DF22[0:1] #给出的实际是DataFrameprint DF22.ix[0] #通过对应Index给出⾏,**ix**好爽。 输出结果： 123456789101112 nation capital GDP2 China Beijing 9100nation Japancapital TokyoGDP 4900Name: 0, dtype: object 方法3 像NumPy切片一样的终极招式：iloc ： 1234print DF22.iloc[0,:] #第一个参数是第几行，第二个参数是列。这里呢，就是第0行，全部列print DF22.iloc[:,0] #根据上面的描述，这里是全部行，第0列 输出结果，验证一下： 12345678910111213141516nation Chinacapital BeijingGDP 9100Name: 2, dtype: object2 China0 Japan1 S.KoreaName: nation, dtype: object 动态增加列列，但是无法用”.”的方式，只能用”[]”举个栗子说明一下就明白了： 1234DF22[&apos;population&apos;] = [1600,130,55]DF22 输出结果： 12345678nation capital GDP population2 China Beijing 9100 16000 Japan Tokyo 4900 1301 S.Korea Seoul 1300 55 Index：行级索引Index：pandas进⾏数据操纵的鬼牌（行级索引） ⾏级索引是： 元数据 可能由真实数据产生，因此可以视作数据 可以由多重索引也就是多个列组合而成 可以和列名进行交换，也可以进行堆叠和展开，达到Excel透视表效果 Index有四种…哦不，很多种写法，⼀些重要的索引类型包括： pd.Index（普通） Int64Index（数值型索引） MultiIndex（多重索引，在数据操纵中更详细描述） DatetimeIndex（以时间格式作为索引） PeriodIndex （含周期的时间格式作为索引） 直接定义普通索引，长得就和普通的Series⼀样12345678index_names = [&apos;a&apos;,&apos;b&apos;,&apos;c&apos;]Series_for_Index = pd.Series(index_names)print pd.Index(index_names)print pd.Index(Series_for_Index) 输出结果： 1234Index([u&apos;a&apos;, u&apos;b&apos;, u&apos;c&apos;], dtype=&apos;object&apos;)Index([u&apos;a&apos;, u&apos;b&apos;, u&apos;c&apos;], dtype=&apos;object&apos;) 可惜Immutable，牢记！ 不可变！举例如下：此处挖坑啊。不明白…… 12345678index_names = [&apos;a&apos;,&apos;b&apos;,&apos;c&apos;] index0 = pd.Index(index_names) print index0.get_values() index0[2] = &apos;d&apos; 输出结果如下： 1234567891011121314151617181920212223242526272829303132[&apos;a&apos; &apos;b&apos; &apos;c&apos;]---------------------------------------------------------------------------TypeError Traceback (most recent call last)&lt;ipython-input-36-f34da0a8623c&gt; in &lt;module&gt;() 2 index0 = pd.Index(index_names) 3 print index0.get_values()----&gt; 4 index0[2] = &apos;d&apos;C:\Anaconda\lib\site-packages\pandas\core\index.pyc in __setitem__(self, key, value) 1055 1056 def __setitem__(self, key, value):-&gt; 1057 raise TypeError(&quot;Indexes does not support mutable operations&quot;) 1058 1059 def __getitem__(self, key):TypeError: Indexes does not support mutable operations 扔进去一个含有多元组的List，就有了MultiIndex可惜，如果这个List Comprehension改成小括号，就不对了。 123456multi1 = pd.Index([(&apos;Row_&apos;+str(x+1),&apos;Col_&apos;+str(y+1)) for x in xrange(4) for y in xrange(4)])multi1.name = [&apos;index1&apos;,&apos;index2&apos;]print multi1 输出结果： 1234MultiIndex(levels=[[u&apos;Row_1&apos;, u&apos;Row_2&apos;, u&apos;Row_3&apos;, u&apos;Row_4&apos;], [u&apos;Col_1&apos;, u&apos;Col_2&apos;, u&apos;Col_3&apos;, u&apos;Col_4&apos;]], labels=[[0, 0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3], [0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3]]) 对于Series来说，如果拥有了多重Index，数据，变形！下列代码说明： 二重MultiIndex的Series可以unstack()成DataFrame DataFrame可以stack成拥有⼆重MultiIndex的Series 1234data_for_multi1 = pd.Series(xrange(0,16),index=multi1)data_for_multi1 输出结果： 1234567891011121314151617181920212223242526272829Row_1 Col_1 0 Col_2 1 Col_3 2 Col_4 3Row_2 Col_1 4 Col_2 5 Col_3 6 Col_4 7Row_3 Col_1 8 Col_2 9 Col_3 10 Col_4 11Row_4 Col_1 12 Col_2 13 Col_3 14 Col_4 15dtype: int32 看到输出结果，好像明白了点，有点类似Excel汇总一样。不过，日后还得查点资料 二重MultiIndex的Series可以unstack()成DataFrame12data_for_multi1.unstack() DataFrame可以stack成拥有⼆重MultiIndex的Series12data_for_multi1.unstack().stack() 输出结果： 12345678910111213141516171819202122232425262728293031323334Row_1 Col_1 0 Col_2 1 Col_3 2 Col_4 3Row_2 Col_1 4 Col_2 5 Col_3 6 Col_4 7Row_3 Col_1 8 Col_2 9 Col_3 10 Col_4 11Row_4 Col_1 12 Col_2 13 Col_3 14 Col_4 15dtype: int32 非平衡数据的例子：1234multi2 = pd.Index([(&apos;Row_&apos;+str(x+1),&apos;Col_&apos;+str(y+1)) for x in xrange(5) for y in xrange(x)])multi2 输出结果： 1234MultiIndex(levels=[[u&apos;Row_2&apos;, u&apos;Row_3&apos;, u&apos;Row_4&apos;, u&apos;Row_5&apos;], [u&apos;Col_1&apos;, u&apos;Col_2&apos;, u&apos;Col_3&apos;, u&apos;Col_4&apos;]], labels=[[0, 1, 1, 2, 2, 2, 3, 3, 3, 3], [0, 0, 1, 0, 1, 2, 0, 1, 2, 3]]) 12data_for_multi2 = pd.Series(np.arange(10),index = multi2) data_for_multi2 输出结果： 12345678910111213141516171819202122Row_2 Col_1 0Row_3 Col_1 1 Col_2 2Row_4 Col_1 3 Col_2 4 Col_3 5Row_5 Col_1 6 Col_2 7 Col_3 8 Col_4 9dtype: int32 DateTime标准库如此好⽤，你值得拥有123456import datetimedates = [datetime.datetime(2015,1,1),datetime.datetime(2015,1,8),datetime.datetime(2015,1,30)]pd.DatetimeIndex(dates) 输出结果： 12DatetimeIndex([&apos;2015-01-01&apos;, &apos;2015-01-08&apos;, &apos;2015-01-30&apos;], dtype=&apos;datetime64[ns]&apos;, freq=None, tz=None) 如果你不仅需要时间格式统一，时间频率也要统一的话1234periodindex1 = pd.period_range(&apos;2015-01&apos;,&apos;2015-04&apos;,freq=&apos;M&apos;)print periodindex1 输出结果： 12PeriodIndex([&apos;2015-01&apos;, &apos;2015-02&apos;, &apos;2015-03&apos;, &apos;2015-04&apos;], dtype=&apos;int64&apos;, freq=&apos;M&apos;) 月级精度和日级精度如何转换？有的公司统⼀以1号代表当月，有的公司统一以最后1天代表当⽉，转化起来很麻烦，可以asfreq 1234print periodindex1.asfreq(&apos;D&apos;,how=&apos;start&apos;)print periodindex1.asfreq(&apos;D&apos;,how=&apos;end&apos;) 输出结果： 1234PeriodIndex([&apos;2015-01-01&apos;, &apos;2015-02-01&apos;, &apos;2015-03-01&apos;, &apos;2015-04-01&apos;], dtype=&apos;int64&apos;, freq=&apos;D&apos;)PeriodIndex([&apos;2015-01-31&apos;, &apos;2015-02-28&apos;, &apos;2015-03-31&apos;, &apos;2015-04-30&apos;], dtype=&apos;int64&apos;, freq=&apos;D&apos;) 最后的最后，我要真正把两种频率的时间精度匹配上？12345678periodindex_mon = pd.period_range(&apos;2015-01&apos;,&apos;2015-03&apos;,freq=&apos;M&apos;).asfreq(&apos;D&apos;,how=&apos;start&apos;)periodindex_day = pd.period_range(&apos;2015-01-01&apos;,&apos;2015-03-31&apos;,freq=&apos;D&apos;)print periodindex_monprint periodindex_day 输出结果： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950PeriodIndex([&apos;2015-01-01&apos;, &apos;2015-02-01&apos;, &apos;2015-03-01&apos;], dtype=&apos;int64&apos;, freq=&apos;D&apos;)PeriodIndex([&apos;2015-01-01&apos;, &apos;2015-01-02&apos;, &apos;2015-01-03&apos;, &apos;2015-01-04&apos;, &apos;2015-01-05&apos;, &apos;2015-01-06&apos;, &apos;2015-01-07&apos;, &apos;2015-01-08&apos;, &apos;2015-01-09&apos;, &apos;2015-01-10&apos;, &apos;2015-01-11&apos;, &apos;2015-01-12&apos;, &apos;2015-01-13&apos;, &apos;2015-01-14&apos;, &apos;2015-01-15&apos;, &apos;2015-01-16&apos;, &apos;2015-01-17&apos;, &apos;2015-01-18&apos;, &apos;2015-01-19&apos;, &apos;2015-01-20&apos;, &apos;2015-01-21&apos;, &apos;2015-01-22&apos;, &apos;2015-01-23&apos;, &apos;2015-01-24&apos;, &apos;2015-01-25&apos;, &apos;2015-01-26&apos;, &apos;2015-01-27&apos;, &apos;2015-01-28&apos;, &apos;2015-01-29&apos;, &apos;2015-01-30&apos;, &apos;2015-01-31&apos;, &apos;2015-02-01&apos;, &apos;2015-02-02&apos;, &apos;2015-02-03&apos;, &apos;2015-02-04&apos;, &apos;2015-02-05&apos;, &apos;2015-02-06&apos;, &apos;2015-02-07&apos;, &apos;2015-02-08&apos;, &apos;2015-02-09&apos;, &apos;2015-02-10&apos;, &apos;2015-02-11&apos;, &apos;2015-02-12&apos;, &apos;2015-02-13&apos;, &apos;2015-02-14&apos;, &apos;2015-02-15&apos;, &apos;2015-02-16&apos;, &apos;2015-02-17&apos;, &apos;2015-02-18&apos;, &apos;2015-02-19&apos;, &apos;2015-02-20&apos;, &apos;2015-02-21&apos;, &apos;2015-02-22&apos;, &apos;2015-02-23&apos;, &apos;2015-02-24&apos;, &apos;2015-02-25&apos;, &apos;2015-02-26&apos;, &apos;2015-02-27&apos;, &apos;2015-02-28&apos;, &apos;2015-03-01&apos;, &apos;2015-03-02&apos;, &apos;2015-03-03&apos;, &apos;2015-03-04&apos;, &apos;2015-03-05&apos;, &apos;2015-03-06&apos;, &apos;2015-03-07&apos;, &apos;2015-03-08&apos;, &apos;2015-03-09&apos;, &apos;2015-03-10&apos;, &apos;2015-03-11&apos;, &apos;2015-03-12&apos;, &apos;2015-03-13&apos;, &apos;2015-03-14&apos;, &apos;2015-03-15&apos;, &apos;2015-03-16&apos;, &apos;2015-03-17&apos;, &apos;2015-03-18&apos;, &apos;2015-03-19&apos;, &apos;2015-03-20&apos;, &apos;2015-03-21&apos;, &apos;2015-03-22&apos;, &apos;2015-03-23&apos;, &apos;2015-03-24&apos;, &apos;2015-03-25&apos;, &apos;2015-03-26&apos;, &apos;2015-03-27&apos;, &apos;2015-03-28&apos;, &apos;2015-03-29&apos;, &apos;2015-03-30&apos;, &apos;2015-03-31&apos;], dtype=&apos;int64&apos;, freq=&apos;D&apos;) 粗粒度数据＋reindex＋ffill/bfill1234full_ts = pd.Series(periodindex_mon,index=periodindex_mon).reindex(periodindex_day,method=&apos;ffill&apos;)full_ts 关于索引，⽅便的操作有？前⾯描述过了，索引有序，重复，但⼀定程度上⼜能通过key来访问，也就是说，某些集合操作都是可以⽀持的。 1234567891011121314151617181920212223242526index1 = pd.Index([&apos;A&apos;,&apos;B&apos;,&apos;B&apos;,&apos;C&apos;,&apos;C&apos;])index2 = pd.Index([&apos;C&apos;,&apos;D&apos;,&apos;E&apos;,&apos;E&apos;,&apos;F&apos;])index3 = pd.Index([&apos;B&apos;,&apos;C&apos;,&apos;A&apos;])print index1.append(index2)print index1.difference(index2)print index1.intersection(index2)print index1.union(index2) # Support unique-value Index wellprint index1.isin(index2)print index1.delete(2)print index1.insert(0,&apos;K&apos;) # Not suggestedprint index3.drop(&apos;A&apos;) # Support unique-value Index wellprint index1.is_monotonic,index2.is_monotonic,index3.is_monotonicprint index1.is_unique,index2.is_unique,index3.is_unique 输出结果： 1234567891011121314151617181920Index([u&apos;A&apos;, u&apos;B&apos;, u&apos;B&apos;, u&apos;C&apos;, u&apos;C&apos;, u&apos;C&apos;, u&apos;D&apos;, u&apos;E&apos;, u&apos;E&apos;, u&apos;F&apos;], dtype=&apos;object&apos;)Index([u&apos;A&apos;, u&apos;B&apos;], dtype=&apos;object&apos;)Index([u&apos;C&apos;, u&apos;C&apos;], dtype=&apos;object&apos;)Index([u&apos;A&apos;, u&apos;B&apos;, u&apos;B&apos;, u&apos;C&apos;, u&apos;C&apos;, u&apos;D&apos;, u&apos;E&apos;, u&apos;E&apos;, u&apos;F&apos;], dtype=&apos;object&apos;)[False False False True True]Index([u&apos;A&apos;, u&apos;B&apos;, u&apos;C&apos;, u&apos;C&apos;], dtype=&apos;object&apos;)Index([u&apos;K&apos;, u&apos;A&apos;, u&apos;B&apos;, u&apos;B&apos;, u&apos;C&apos;, u&apos;C&apos;], dtype=&apos;object&apos;)Index([u&apos;B&apos;, u&apos;C&apos;], dtype=&apos;object&apos;)True True FalseFalse False True 大熊猫世界来去自如：Pandas的I/O老生常谈，从基础来看，我们仍然关心pandas对于与外部数据是如何交互的。 结构化数据输入输出 read_csv与to_csv 是⼀对输⼊输出的⼯具，read_csv直接返回pandas.DataFrame，⽽to_csv只要执行命令即可写文件 read_table：功能类似 read_fwf：操作fixed width file read_excel与to_excel方便的与excel交互 header 表⽰数据中是否存在列名，如果在第0行就写就写0，并且开始读数据时跳过相应的行数，不存在可以写none names 表示要用给定的列名来作为最终的列名 encoding 表⽰数据集的字符编码，通常而言一份数据为了⽅便的进⾏⽂件传输都以utf-8作为标准 这里用的是自己的一个csv数据，因为找不到参考的这个pdf中的数据。 123456cnames=[&apos;经度&apos;,&apos;纬度&apos;]taxidata2 = pd.read_csv(&apos;20140401.csv&apos;,header = 4,names=cnames,encoding=&apos;utf-8&apos;)taxidata2 全部参数的请移步API： http://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html#pandas.read_csv 这里介绍一些常用的参数： 读取处理： skiprows：跳过⼀定的⾏数 nrows：仅读取⼀定的⾏数 skipfooter：尾部有固定的⾏数永不读取 skip_blank_lines：空⾏跳过 内容处理： sep/delimiter：分隔符很重要，常⻅的有逗号，空格和Tab(‘\t’) na_values：指定应该被当作na_values的数值 thousands：处理数值类型时，每千位分隔符并不统⼀ (1.234.567,89或者1,234,567.89都可能)，此时要把字符串转化为 数字需要指明千位分隔符 收尾处理： index_col：将真实的某列（列的数⺫，甚⾄列名）当作index squeeze：仅读到⼀列时，不再保存为pandas.DataFrame⽽是pandas.Series Excel … ?对于存储着极为规整数据的Excel而言，其实是没必要一定用Excel来存，尽管Pandas也十分友好的提供了I/O接口。 123456taxidata.to_excel(&apos;t0401.xlsx&apos;,encoding=&apos;utf-8&apos;)taxidata_from_excel = pd.read_excel(&apos;t0401.xlsx&apos;,header=0, encoding=&apos;utf-8&apos;)taxidata_from_excel 注意：当你的xls文件行数很多超过65536时，就会遇到错误，解决办法是将写入的格式变为xlsx。excel函数受限制问题 唯一重要的参数：sheetname=k，标志着一个excel的第k个sheet页将会被取出。（从0开始） 半结构化数据JSON：网络传输中常⽤的⼀种数据格式。 仔细看一下，实际上这就是我们平时收集到异源数据的风格是一致的： 列名不能完全匹配 key可能并不唯一 元数据被保存在数据里 1234567891011121314import jsonjson_data = [&#123;&apos;name&apos;:&apos;Wang&apos;,&apos;sal&apos;:50000,&apos;job&apos;:&apos;VP&apos;&#125;,\ &#123;&apos;name&apos;:&apos;Zhang&apos;,&apos;job&apos;:&apos;Manager&apos;,&apos;report&apos;:&apos;VP&apos;&#125;,\ &#123;&apos;name&apos;:&apos;Li&apos;,&apos;sal&apos;:5000,&apos;report&apos;:&apos;IT&apos;&#125;]data_employee = pd.read_json(json.dumps(json_data))data_employee_ri = data_employee.reindex(columns=[&apos;name&apos;,&apos;job&apos;,&apos;sal&apos;,&apos;report&apos;])data_employee_ri 输出结果： 深入Pandas数据操纵在前面部分的基础上，数据会有更多种操纵方式： 通过列名、行index来取数据，结合ix、iloc灵活的获取数据的一个子集（第一部分已经介绍） 按记录拼接（就像Union All）或者关联（join） 方便的统计函数与⾃定义函数映射 排序 缺失值处理 与Excel一样灵活的数据透视表（在第四部分更详细介绍） 数据集整合横向拼接：直接DataFrame12pd.DataFrame([np.random.rand(2),np.random.rand(2),np.random.rand(2)],columns=[&apos;C1&apos;,&apos;C2&apos;]) 横向拼接：Concatenate12pd.concat([data_employee_ri,data_employee_ri,data_employee_ri]) 输出结果 纵向拼接：Merge根据数据列关联，使用on关键字 可以指定一列或多列 可以使⽤left_on和right_on 12pd.merge(data_employee_ri,data_employee_ri,on=&apos;name&apos;) 根据index关联，可以直接使用left_index和right_index TIPS: 增加how关键字，并指定 how = ‘inner’ how = ‘left’ how = ‘right’ how = ‘outer’ 结合how，可以看到merge基本再现了SQL应有的功能，并保持代码整洁 自定义函数映射123456dataNumPy32 = np.asarray([(&apos;Japan&apos;,&apos;Tokyo&apos;,4000),(&apos;S.Korea&apos;,&apos;Seoul&apos;,1300),(&apos;China&apos;,&apos;Beijing&apos;,9100)])DF32 = pd.DataFrame(dataNumPy32,columns=[&apos;nation&apos;,&apos;capital&apos;,&apos;GDP&apos;])DF32 map: 以相同规则将1列数据作1个映射，也就是进行相同函数的处理123456789101112131415161718192021222324def GDP_Factorize(v): fv = np.float64(v) if fv &gt; 6000.0: return &apos;High&apos; elif fv &lt; 2000.0: return &apos;Low&apos; else: return &apos;Medium&apos;DF32[&apos;GDP_Level&apos;] = DF32[&apos;GDP&apos;].map(GDP_Factorize)DF32[&apos;NATION&apos;] = DF32.nation.map(str.upper)DF32 排序 sort: 按⼀列或者多列的值进行行级排序 sort_index: 根据index⾥的取值进行排序，而且可以根据axis决定是重排行还是列 sort123456dataNumPy33 = np.asarray([(&apos;Japan&apos;,&apos;Tokyo&apos;,4000),(&apos;S.Korea&apos;,&apos;Seoul&apos;,1300),(&apos;China&apos;,&apos;Beijing&apos;,9100)])DF33 = pd.DataFrame(dataNumPy33,columns=[&apos;nation&apos;,&apos;capital&apos;,&apos;GDP&apos;])DF33 12DF33.sort([&apos;capital&apos;,&apos;nation&apos;],ascending=False) ascending是降序的意思。 sort_index12DF33.sort_index(axis=1,ascending=True) 一个好用的功能：Rank12DF33.rank() 缺失数据处理 忽略缺失值：12DF34.mean(skipna=True) 不忽略缺失值的话，估计就不能计算均值了吧。 如果不想忽略缺失值的话，就需要祭出fillna了： 注：这里我在猜想，axis=1是不是就代表从行的角度呢？还是得多读书查资料呀。 “一组”大熊猫：Pandas的groupbygroupby的功能类似SQL的group by关键字： Split-Apply-Combine Split，就是按照规则分组 Apply，通过⼀定的agg函数来获得输⼊pd.Series返回⼀个值的效果 Combine，把结果收集起来 Pandas的groupby的灵活性： 分组的关键字可以来⾃于index，也可以来⾃于真实的列数据 分组规则可以通过⼀列或者多列 没有具体数据，截图看一下吧，方便日后回忆。 分组可以快速实现MapReduce的逻辑 Map: 指定分组的列标签，不同的值就会被扔到不同的分组处理 Reduce: 输入多个值，返回1个值，一般可以通过agg实现，agg能接受1个函数 参考： S1EP3_Pandas.pdf 不知道什么时候存到电脑里的资料，今天发现了它。感谢作者的资料。]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>Pandas</tag>
        <tag>数据分析</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[杂文-2015/12/20]]></title>
    <url>%2F2015%2F12%2F20%2Flife-20151220%2F</url>
    <content type="text"><![CDATA[今天在朋友圈，发现高中同桌q诚当上爸爸了，恭喜。虽然许久都未曾联系，但是还是由衷的内心给予祝福……回想起高中那段时光，真是记忆犹新。 那时为了一道数学难题，可以熬夜到很晚，想解法。那时为了第二天的考试，可以五点多就起床去河边晨读复习古文。那时有很多让自己感觉很用功的例子…… 可是，一切从大学就变了。虽然自己内心一直想努力，可是行动上却没有。事实很残酷，和大多数的人一样，我成为了随波逐流的人群中的一员。回想在海大的四年，多多少少有遗憾。可没有后悔药的。感慨幸运的是，遇到了一群可爱的室友。我们来自五湖四海。重庆娃娃，君。陕西娃娃，贱贱。山东娃娃，全。安徽娃娃，路路。海南娃娃，阿克。江西娃娃，耐克。 可爱的室友们，尽管现在各自奔天涯，不知道彼此都在做些什么……希望一切安好。期待重逢的那天。 上面这些书，本可以在四年里读完，可以读很多倍的数量……原本有很多时间可以自己去折腾感兴趣的技术的…… 时光易逝。 只能说过去的已经过去了。失去的都是人生。珍惜当下，努力创造未来！ 竟然从老同桌晋级为爸爸，想了这么多，其实，归结到内心，还是对自己未来的深深担忧。毕竟，不是自己一个人的人生。女朋友和我一起快五年了。我必须要加油！是的，不能让她，也不能让自己，让家人失望。 眼下的目标就是： 学好python 搞好论文 come on michael！ 晚安，世界]]></content>
      <categories>
        <category>Life</category>
      </categories>
      <tags>
        <tag>Life</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python机器学习入门资料梳理]]></title>
    <url>%2F2015%2F12%2F16%2Fpython-machine-learning-list%2F</url>
    <content type="text"><![CDATA[在python基本语法入门之后，就要准备选一个研究方向了。Web是自己比较感兴趣的方向，可是，导师这边的数据处理肯定不能由我做主了。paper、peper、paper……真的挺愁人的 还有几个月就要进行春季实习招聘了，加油！总结一下python机器学习方面的资料吧。 1、数据处理1.1 综合 Scipy SciPy is a Python-based ecosystem of open-source software for mathematics, science, and engineering. In particular, these are some of the core packages这里集合着python科学计算的几乎所有核心库，也是一个导航。 Scipy Lecture Notes 极力推荐的一个学习笔记！ Scipy Tutorial scientific-python-lectures Jupyter 1.2 Numpy Numpy Tutorial Index Numpy 遇到Numpy陌生函数，查询用法，推荐！ 1.3 Pandas pandas主页 pandas主页，可以进入它的相关文档教程 pandas documents pandas史上最强参考文档集合 10 Minutes to pandas 十分钟搞定pandas 翻译版 API Reference Index Pandas 遇到陌生函数，查询用法，推荐！ pandas教程-百度经验 1.4 Matplotlib Matplotlib Gallery 提供一些图像例子 Matplotlib Tutorial(译) 翻译原文 matplotlib - 2D and 3D plotting in Python 2、数据可视化2.1 SeabornSeaborn is a Python data visualization library with an emphasis on statistical plots. The library is an excellent resource for common regression and distribution plots 2.2 Plotly Python Library 印刷品质的图片质量啊！ 3、机器算法3.1综合 用python做科学计算 五星推荐的中文学习资料！！！ scikit-learn 3.2 Cluster-聚类算法 Comparing Python Clustering Algorithms 3.3 GA(Genetic Algorithm) Pyevolve documentation]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>整理</tag>
        <tag>ML</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python入门资料大全(更新ing)]]></title>
    <url>%2F2015%2F12%2F02%2Fpython-files-list%2F</url>
    <content type="text"><![CDATA[一、说明面对网络上纷繁复杂的资料，自己真是眼花缭乱，学的毫无章法，东一榔头西一棒子，这样不仅知识不能成为体系，自己的学习进度也不容易掌握，收效甚微。突然有个想法，就是把自己这几天收藏的资料整理出文章出来，方便自己有章可依…… PS:附上一些python相关的好文： 萧大的编程入门指南知乎获赞无数的编程指南，介绍的不光是一门语言的入门，也是关于编程的入门，谈到了作为一名程序员，应该掌握的一些计算机知识。 Python 编码风格指南中译版（Google SOC）PythonTab中文网二、Python社区Python Tip社区 强烈推荐Python Tip,有刷题挑战赛，同时，也有很多在线教程！练手实操必备！ 啄木鸟社区编程指南社区Co三、入门阶段介绍一些入门的资料，对于有编程经验的同学来讲，入门资料学习并不是很费力。 简明教程 入门教程里，简明教程算是细节介绍相对详细的了，知识面也覆盖的挺全，入门资料的好选择。 笨办法学python坚持看完了，尽管最后几章没去实现（主要是和我现在的需求不一致，不想花精力在那个上面）。有所收获吧，但是，确实是入门的，知识不全面，入门够用，风格特别，采用问答形式，学习过程挺有趣。 Python|Codecademy在线挑战，还没用过，貌似现在对英文资料心里还有种抵触，必须克服！！！ 实验楼python研发工程师包含了Linux/Vim/Git/SQL/Python/Django/Flask等学习课程。 老齐的零基础学Python（第二版）github版本，教程内容覆盖很全，也有实战项目介绍。 廖雪峰python2.7教程现在已经有python3的教程了。 Vamei的的python快速教程话说，我还加入了博主的粉丝群，后来加入了微信群，逗比一枚啊，现在好像去新加坡深造去了！博客文章还是很详细的~ 总结到这儿我已经有乱花渐入迷人眼的感觉了！光是入门就这么多资料，看的过来吗？看完得到猴年马月啊！所以必须痛下决心，选择自己觉得好的就OK！青菜萝卜，各有所爱，别人觉得好的，可能在你这儿就是看着不舒服！好吧，自己就选择简明，笨办法，还有，codecademy!ok,暂时就这样了！ 四、充实阶段入门之后，对于这个语言的细节需要更进一步的了解，那么提升阶段必不可少。同时，对于计算机基础不好的同学，了解计算机及编程相关背景知识也很关键。 《Python基础教程》根据自己学习javascript的经验，一本好的教材真是获益匪浅，它能让你明白很多底层的东西。比如红宝书《js高级程序设计》中关于闭包、原型链的讲解就非常详细！好吧，扯远了，因此，学习python也是一样，光是靠博客，在线文章是不能深入了解它的，选择一门经典教材是你深入了解一门语言的必经之路！当然，也有推荐《Python核心编程（第二版）》的，但是自己只买了《Python基础教程》因此，不做评价了，选中一本经典就可以了！何况自己离吃透它，还有很远的距离的！ MIT计算机科学及编程导论Harvard:计算机科学cs502和3属于计算机入门课，之所以放到这儿，是因为介绍了计算机领域中相关的知识点，了解数据结构相关知识。其中，MIT的导论课老师的知识点是基于Python的，在学习时也能巩固Python。编程入门指南中强烈推荐的的两门公开课。（PS：网易真是良心，这两门课都有中英字幕的视频！） Crossin教室除了python教程之外，还有小程序，练手很好！在第一阶段入门之后，来这里做应用小程序，会找到成就感！除此之外，还有git等其他教程。是个不错的入门练手的地方。 五、升华阶段有了扎实的基础，那么方向的选择显得尤为重要了。是数据分析，是web开发，还是游戏开发。下面暂时分为这三个方面整理一下： 5.1 数据分析利用Python进行数据分析这本书是一本大而全的利用Python数据分析的书，数据分析入门肯定够够的，写的也很详细。书的作者就是开发了用于数据分析的著名开源Python库——pandas的作者！ scientific-python-lectures英文资料，对Python数据分析中要用到的一些库，pandas,numpy,matplotlib等等做了简要介绍。Ipython Notebook形式的资料，示例代码都很全。 Matplotlib Tutorial(译)Python制图的入门资料，强烈推荐！在线版的资料，作者排版也很舒服，示例代码也有，推荐！ 5.2 web开发自强学堂Django基础教程很详细的一个Django教程，作者很详细的介绍了每一步。有问题，作者回复也很详细，推荐！同时，自强学堂上也有很多其他教程，是个不错的网站，收藏！ Django搭建简易博客教程建议和1结合看，1的介绍相对更详细一点。 欢迎进入Flask大型教程项目Flask指南#5.3 游戏开发 用Python和Pygame写游戏-从入门到精通六、 计算机素养《深入理解计算机系统》七、 Python面试题 聊聊Python面试那些事儿 暂时总结到这儿了，和大家分享一下，希望有帮助！ 生命不息，折腾不止！关注 「Coder 魔法院」，祝你 Niubilitiy ！🐂🍺]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>List</tag>
        <tag>Python</tag>
        <tag>整理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo之Next主题优化整理]]></title>
    <url>%2F2015%2F11%2F30%2Fhexo-next-optimize%2F</url>
    <content type="text"><![CDATA[搭建hexo的教程实在太多了，折腾了几天，总算搞定了，现在去看参考文章也是能看懂，不过，官方文档也写的相当详细： Hexo Next Yml语法验证 hexo主题 hexo-theme hexo-github-theme-list 有那些好看的hexo主题？ Next主题添加多说新建站点时会创建多说域名：创建站点完成后在 站点配置文件（不是主题配置文件）中新增 duoshuo_shortname 字段，值设置成上一步中的值。duoshuo_shortname: michael-xox其他主题主题添加多说，参考： http://dev.duoshuo.com/threads/541d3b2b40b5abcd2e4df0e9 http://dev.duoshuo.com/docs/5016427f77cf5fa30500000e hexo命令更新hexo：npm update -g hexo 更新主题：cd 到主题文件夹，执行命令：git pull 更新插件：npm update 因为重装系统的缘故，重新要配置一下环境。简要做个笔记。 Windows下npm安装Hexo失败的解放方案因为国外源网速不好的原因，安装hexo失败，可以采用如下方案：命令搞定HEXO!!!12345678# 添加淘宝源npm install -g cnpm --registry=https://registry.npm.taobao.org# nrm类似包管理器cnpm install nrm -gnrm ls# 使用淘宝nrm use taobaonpm install -g hexo-cli 大功告成！ http://www.codes51.com/itwd/1327882.htmlhttp://www.thinksaas.cn/ask/question/21934/ 安装NEXT1git clone https://github.com/iissnan/hexo-theme-next themes/next 参考：Next配置 优化头像设置编辑 站点配置文件，新增字段 avatar， 值设置成头像的链接地址。avatar: http://i5.tietuku.com/0d972d2b106fc7ea.jpg 网站logo设置 通过网站favicon在线制作制作favicon图片，logo最好设置32*32。 next主题：将图片放在next主题source/images目录下 在next主题配置文件中添加：favicon: images/favicon.ico 添加关于页面hexo new page &quot;about&quot;在source文件夹下就会有about文件夹，编辑index.md，然后进入主题的_config.yml中，menu下的#about注释去掉 添加目录云、标签云页面12hexo new page &quot;tags&quot;hexo new page &quot;categories&quot; 然后设置同上，去掉主题配置文件中的注释，调整菜单顺序 设置侧边栏头像在站点配置文件，不是主题配置文件中，添加：12avatar: url#avatar: /uploads/avatar.jpg 设置网站图标Logo 通过网站favicon在线制作制作favicon图片，logo最好设置32*32。 next主题：将图片放在next主题source/images目录下 在next主题配置文件中添加：favicon: images/favicon.ico或者把favicon.ico放到主题文件夹source文件夹下就可以了-》favicon: /favicon.ico12# Put your favicon.ico into `hexo-site/source/` directory.favicon: /images/favicon.ico 增加打赏功能 hexo博客Next主题添加打赏功能 hexo next 主题添加打赏功能 实现网站的打赏功能 为Hexo博客添加版权说明和打赏功能 设置阅读次数 为NexT主题添加文章阅读量统计功能 为博客文章添加阅读量统计功能-LeanCloud 添加最近访客和多说 动动手指，NexT主题与Hexo更搭哦（基础篇） 动动手指，给你的Hexo站点添加最近访客（多说篇） SEO Hexo NexT 主题SEO优化指南 个人博客SEO实践 Hexo教程(四)-hexo博客被搜索引擎收录 Hexo+nexT主题搭建个人博客 安装sitemap扩展： 12npm install hexo-generator-sitemap --savenpm install hexo-generator-baidu-sitemap --save 在你的hexo站点的_config.yml添加下面的代码: 12345# hexo sitemap网站地图sitemap: path: sitemap.xmlbaidusitemap: path: baidusitemap.xml 注意：这个地方的空格要符合语法规范！ 提交sitemap参考next主题官方解答：添加 Google Webmaster tools 验证 配置成功后，hexo编译时会在hexo站点根目录生成sitemap.xml和baidusitemap.xml其中sitemap.xml适合提交给谷歌搜素引擎，baidusitemap.xml适合提交百度搜索引擎。其次，在robots.txt中添加下面的一段代码： 12Sitemap: http://www.arao.me/sitemap.xmlSitemap: http://www.arao.me/baidusitemap.xml 参考这篇文章hexo干货系列：（六）hexo提交搜索引擎（百度+谷歌） 提交sitemap.xml 添加友链在主题配置文件 _config.yml中Sidebar Settings部分添加字段：123456# Blogrollslinks_title: 友情链接links_layout: inlinelinks_icon: link # 设置图标links: Michael翔: http://michaelxiang.me 添加搜索 安装npm install generarot-search 在站点配置文件，不是主题配置文件中，添加：1234# 添加搜索search: path: search.xml field: all 注意：需要在站点配置文件中设置：url: http://michaelxiang.me/，否则搜索的结果点击链接，会跳转到错误页面。 添加背景 参考hexo引用自定义js文件和css样式，在github资源中找到particle.js，将其下载到本地主题文件夹D:\03TBP\TBP\BLOG\themes\next\source\js\src类似这样的文件夹下。 然后在主题layout/_layout.swig中的最后body标签上添加&lt;script type=&quot;text/javascript&quot; src=&quot;/js/src/particle.js&quot;&gt;&lt;/script&gt; 参考 Hexo博客优化 - Next主题个性化定制-推荐！！！ hexo下新建页面下如何放多个文章？ 玩转Hexo博客之Next 动动手指，不限于NexT主题的Hexo优化（SEO篇） 博客推广——提交搜索引擎SEO Next主题常见问题 主题配置 2017-05-25更新： Hexo搭建个人博客-资料整理标签（空格分隔）： 软件 安装准备Git配置SSH git下载 安装完成之后，配置git环境[^1] [^2]：12git config --global user.name &quot;username&quot;git config --global user.email &quot;username@example.com&quot; [^1]:Hexo 3.1.1 静态博客搭建指南 [^2]:GitHub Pages + Hexo搭建博客 生成公钥：12# C:\Users\xiang\.sshssh-keygen -t rsa -C &quot;username@example.com&quot; 然后在C:\Users\michael\.ssh文件夹下查看id_rsa.pub,复制全部内容，添加到github账户中： 验证成功1ssh -T git@github.com 设置，下次部属时不用密码：12git initgit remote set-url origin SSH对应的url（去github对应博客的download查看） 在github创建博客项目：创建Github Repository：Repository名字必须是你的Github名.github.io，比如我是michael728.github.io Node下载安装 Node官方地址 部署Hexo Hexo官方文档 新建一个文件夹，比如，Blog，然后进入该文件夹下： 12npm install hexo-cli -ghexo version 安装依赖包1npm install 配置站点文件为了能够使Hexo部署到GitHub上，需要安装一个插件：1npm install hexo-deployer-git --save 部署博客的配置：12345678910# Deployment## Docs: http://hexo.io/docs/deployment.html# deploy:# type: git# repo: git@github.com:michael728/michael728.github.io.git # branch: masterdeploy: type: git repo: git@github.com:Michael728/michael728.github.io.git #从github博客项目复制，切换为ssh地址 branch: master Front-matterFront-matter 是文件最上方以 — 分隔的区域，用于指定个别文件的变量，举例来说：123title: Hello Worlddate: 2013/7/13 20:46:25--- 比如，在material主题中，在这儿可以通过关键字thumbnail:，填上图片的url地址，设置每篇文章的缩略图 Next主题首先区分两个概念： 主题配置文件 站点配置文件 Next主题下的_config.yml就是主题配置文件，而站点目录下的_config.yml则是站点配置文件 安装： Next-github Next文档 Next作者blog 动动手指，NexT主题与Hexo更搭哦（基础篇） 进入theme文件夹下,执行：1git clone https://github.com/iissnan/hexo-theme-next.git 执行完成之后，在theme文件夹下则会出现next文件夹。 启用Next主题，在站点配置文件中，设置：1theme: next 评论： disqus 主题配置文件中，设置了：1disqus_shortname: michaelxiang 注意：如果有集成评论服务，页面也会带有评论。 若需要关闭的话，请添加字段 comments 并将值设置为 false，如：1234title: 标签date: 2014-12-22 12:39:04type: &quot;tags&quot;comments: false 搜索http://theme-next.iissnan.com/third-party-services.html#search-system添加百度/谷歌/本地 自定义站点内容搜索 1.安装 hexo-generator-searchdb，在站点的根目录下执行以下命令：1$ npm install hexo-generator-searchdb --save 2.编辑 站点配置文件，新增以下内容到任意位置：12345search: path: search.xml field: post format: html limit: 10000 3.编辑 主题配置文件，启用本地搜索功能：123# Local searchlocal_search: enable: true 新建页面举例，新建一个“工具”页面。先执行命令：1hexo new page &quot;tools&quot; 然后在主题配置文件中的menu添加相应的内容：12345678910menu: home: / categories: /categories archives: /archives tags: /tags books: /categories/books #hexo new page &quot;books&quot;要修改三个地方，去language下面，修改zh-hans中才菜单，添加中文 diary: /diary #如果是上面这种结构，则显示该文件夹下所有文章，这后面的英文，要是new page &quot;xx&quot;保持一致 nav: /nav #导航 别忘了添加图标和中文 tools: /tools about: /about 接着，添加对应的中文名字，在next-languages-zh-Hans文件中：123456789101112menu: home: 首页 archives: 归档 categories: 分类 tags: 标签 about: 关于 search: 搜索 books: 书单 diary: 札记 nav: 书签 tools: 工具 commonweal: 公益404 最后，还要设置相应的图标，主题配置文件中：12345678910111213menu_icons: enable: true #KeyMapsToMenuItemKey: NameOfTheIconFromFontAwesome home: home about: user categories: th tags: tags archives: archive books: book #参考fontawsomehttp://fontawesome.io/icons/网站图标，还要去修改language中zh-Hans.yml,添加中文说明 diary: leaf nav: bookmark #别忘了去添加相应中文 tools: paper-plane commonweal: heartbeat 图标链接： 不蒜子统计http://theme-next.iissnan.com/third-party-services.html#analytics-busuanzi 编辑 主题配置文件 中的busuanzi_count的配置项。 当enable: true时，代表开启全局开关。若site_uv、site_pv、page_pv的值均为false时，不蒜子仅作记录而不会在页面上显示。 分享服务http://theme-next.iissnan.com/third-party-services.html#share-system 主题配置文件中：JiaThis 分享服务1jiathis: true 给next主题添加打赏http://theme-next.iissnan.com/theme-settings.html#reward123reward_comment: 坚持原创技术分享，您的支持将鼓励我继续创作！wechatpay: /path/to/wechat-reward-imagealipay: /path/to/alipay-reward-image 添加文章阅读统计 为NexT主题添加文章阅读量统计功能 设置RSShttps://github.com/hexojs/hexo-generator-feed安装扩展：1npm install hexo-generator-feed --save 然后在站点配置文件中设置：123456feed: type: atom path: atom.xml limit: 20 hub: content: 设置侧边栏头像旋转http://leeyom.top/2016/09/29/hexo%E5%8D%9A%E5%AE%A2%E8%BF%9B%E9%98%B6%E6%95%99%E7%A8%8B/ 主要是修改 Hexo 目录下 \themes\next\source\css\_common\components\sidebar\sidebar-author.styl文件12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576.site-author-image &#123; display: block; margin: 0 auto; padding: $site-author-image-padding; max-width: $site-author-image-width; height: $site-author-image-height; border: $site-author-image-border-width solid $site-author-image-border-color; /* 头像圆形 */ border-radius: 80px; -webkit-border-radius: 80px; -moz-border-radius: 80px; box-shadow: inset 0 -1px 0 #333sf; /* 设置循环动画 [animation: (play)动画名称 (2s)动画播放时长单位秒或微秒 (ase-out)动画播放的速度曲线为以低速结束 (1s)等待1秒然后开始动画 (1)动画播放次数(infinite为循环播放) ]*/ -webkit-animation: play 2s ease-out 1s 1; -moz-animation: play 2s ease-out 1s 1; animation: play 2s ease-out 1s 1; /* 鼠标经过头像旋转360度 */ -webkit-transition: -webkit-transform 1.5s ease-out; -moz-transition: -moz-transform 1.5s ease-out; transition: transform 1.5s ease-out;&#125;img:hover &#123; /* 鼠标经过停止头像旋转 -webkit-animation-play-state:paused; animation-play-state:paused;*/ /* 鼠标经过头像旋转360度 */ -webkit-transform: rotateZ(360deg); -moz-transform: rotateZ(360deg); transform: rotateZ(360deg);&#125;/* Z 轴旋转动画 */@-webkit-keyframes play &#123; 0% &#123; -webkit-transform: rotateZ(0deg); &#125; 100% &#123; -webkit-transform: rotateZ(-360deg); &#125;&#125;@-moz-keyframes play &#123; 0% &#123; -moz-transform: rotateZ(0deg); &#125; 100% &#123; -moz-transform: rotateZ(-360deg); &#125;&#125;@keyframes play &#123; 0% &#123; transform: rotateZ(0deg); &#125; 100% &#123; transform: rotateZ(-360deg); &#125;&#125;.site-author-name &#123; margin: $site-author-name-margin; text-align: $site-author-name-align; color: $site-author-name-color; font-weight: $site-author-name-weight;&#125;.site-description &#123; margin-top: $site-description-margin-top; text-align: $site-description-align; font-size: $site-description-font-size; color: $site-description-color;&#125; 站点建立时间个时间将在站点的底部显示，例如© 2013 - 2015。 编辑 主题配置文件，新增字段 since。1since: 2015 SEO优化给你的hexo站点添加sitemap网站地图安装hexo的sitemap网站地图生成插件 123npm install hexo-generator-sitemap --savenpm install hexo-generator-baidu-sitemap --save在你的hexo站点的_config.yml添加下面的代码 hexo sitemap网站地图1234sitemap:path: sitemap.xmlbaidusitemap:path: baidusitemap.xml 配置成功后，hexo编译时会在hexo站点根目录生成sitemap.xml和baidusitemap.xml其中sitemap.xml适合提交给谷歌搜素引擎，baidusitemap.xml适合提交百度搜索引擎。其次，在robots.txt中添加下面的一段代码：12Sitemap: http://www.arao.me/sitemap.xmlSitemap: http://www.arao.me/baidusitemap.xml 参考： http://www.arao.me/2015/hexo-next-theme-optimize-seo/ 给next主题添加背景图片 给hexo个人博客 next主题添加背景图片 Materail主题安装 hexo-theme-material-github material文档 material作者个人blog 进入theme文件夹下,执行：1git clone https://github.com/viosey/hexo-theme-material.git 下载完成之后，修改文件夹名为：material，同时将主题配置文件_config.template.yml修改为：_config.yml设置站点配置文件中的语言：language: zh-CN，这个和Next主题的zh-Hans是有区别的。 然后测试：123hexo cleanhexo ghexo s 访问地址：http://localhost:4000/ 按照material文档文档，可以设置主题的背景等，按照说明文档一步一步设置即可。 dropdown-侧边栏邮箱https://material.viosey.com/intro/#dropdown下拉菜单这里，如果不去language设置dropdown对应的中文，那么，就会显示undefined。 设置独立页面 Material icons 主题文档-Pages 123456hexo new page &quot;about&quot; #新建关于我的页面，其实这条命令就是在根目录source文件夹下新建了一个about文件夹pages: About: #这里可以把它改为关于我 link: &quot;#about&quot; icon: person divider: false 作为一个单位。Name 是该独立页面的名称，请自行修改。link 的参数为相对路径，对应 hexo 目录下的 source 文件夹内的相应文件夹。icon 的参数为自定义的 Material 图标，可用图标可在 Material icons 查询。divider 设置成 true 后会在该条目底部增加一条分割线 PS:菜单显示中文,只需要将“About”设置为“关于我”，因为它的链接link设置对应的文件夹了，比Next主题添加稍微简单点，那个还需要去主题的language中添加对应的中文 创建友链 设置RSS 说明 插件github地址 123456789$ npm install hexo-generator-feed --save#You can configure this plugin in _config.yml.feed: type: atom path: atom.xml limit: 20 hub: content: Qrcode-设置二维码，手机扫描阅读1npm install hexo-helper-qrcode --save 用于在文章页中显示二维码，扫描二维码即可直接打开文章。qrcode: true topPost置顶文章使用该插件可以将指定文章置顶。如果您需要这个功能，请使用 npm install hexo-helper-post-top --save安装支持插件。之后在您需要置顶文章的 front-matter中，添加 top: true 即可置顶。 Hexo插入音乐/视频 通过 Hexo 插件插入音乐/视频 Maupassant主题-大道至简 Maupassant-github Maupassant-中文文档 命令12345678hexo help #查看帮助hexo init #初始化一个目录hexo new &quot;postName&quot; #新建文章hexo new page &quot;pageName&quot; #新建页面，其实作用就是在根目录source目录下，添加一个about的文件夹hexo generate #生成网页, 可以在 public 目录查看整个网站的文件hexo server #本地预览, &apos;Ctrl+C&apos;关闭hexo deploy #部署.deploy目录hexo clean #清除缓存, 多台机器同步每次上传之前，删除同步文件夹下的.deploy_git文件夹。 参考文章 hexo的next主题个性化配置教程-推荐 SF-自己-Hexo+Github Page部署个人博客资源整理 解决用Hexo和GitHub搭建博客时hexo d命令报错问题 Hexo搭建静态博客 Hexo+nexT主题搭建个人博客 hexo博客进阶教程]]></content>
      <categories>
        <category>ToolsDev</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo之github\gitcafe多线路托管博客，DNS域名设置]]></title>
    <url>%2F2015%2F11%2F30%2Fhexo-gitcafe-github-dns-goddaddy-set%2F</url>
    <content type="text"><![CDATA[上一篇挖坑总结（1）中已经详细讲解了同时部署到gitcafe和github上的方法了，那么，接下来要讲解的就是DNS域名相关的问题： 在goddaddy上购买域名关于goddaddy购买域名及设置的流程，就不再说了，很简单，可以参考：Godaddy优惠码网站 设置github及gitcafegithub要在博客站点source文件夹，如：E:\KP\my_blog\source下新建CNAME文件，编辑加入：michaelxiang.megithub官方参考：Categories / GitHub Pages Basics gitcafe在gitcafe的page设置，添加域名:michaelxiang.megitcafe官方参考：gitcafe关于page说明 Dnspod域名解析设置github相关想要访问michaelxiang.me是通过github访问，我们在dnspod设置完CNAME就够了。 gitcafe相关在dnspod里设置，为了让国内ip访问michaelxiang.me是通过gitcafe，我们需要设置CNAME。 说明： 这里建议用设置CNAME的方式，为了防止github或者gitcafe主机迁移导致A记录的ip也需要更改才能访问的额弊病。 gitcafe的记录值，gitcafe.io，而不是用户名+gitcafe.io,这和github不一样，归功于gitcafe提供的域名绑定功能！ 主机记录是@,没用其他的，这样设置就OK了，因为我自己用的是裸域名。Hexo多Repo部署——使用Github和GitCafe同时托管博客 线路类型，gitcafe对应的是国内,github对应的是默认，这么设置的话，那么国内ip访问就是访问的gitcafe，国外ip就是github。 如下图，可以设置监控，当有问题时，切换解析。 测试1ping michaelxiang.me 我们将会看到，它的实际访问ip，就是gitcafe.io。懂点ping方面的知识也是不错的，也算是这次搭建hexo博客的收获之一。 经过比较，发现，gitcafe的博客访问速度确实要快一点。 听过ping可以发现如果是要增加A记录的话，ip地址该写多少。通过dnspod解析域名 已发送若是大于已接收的话，就代表发生了丢包的现象 通过ping+网址\ip 地址，可以查看主机运行情况 #参考 关于CNAME介绍参考dnspod官方参考]]></content>
      <categories>
        <category>ToolsDaily</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
        <tag>DNS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo之github\gitcafe多线路托管博客deploy及SSH设置问题]]></title>
    <url>%2F2015%2F11%2F30%2Fhexo-gitcafe-github-deploy%2F</url>
    <content type="text"><![CDATA[github时常抽风，访问不了，速度和国内的gitcafe相比，也稍微慢一点。那么通过将博客文件部属同时部署到这两个网站，之后通过DNS域名等设置，国内访问gitcafe，国外访问github，这样就ok啦！ 检查SSH keys的设置github官方参考文档：generating ssh keys检查电脑上现有的SSH，简单点单来说，SSH就是和秘钥有关的文件，可以看这篇《理解git,github和SSH Keys》1cd ~/.ssh 咱们要是配置过，ssh一般都在C:\Users\xiang_000\.ssh这样的文件加下。如果检查到有这样的文件，咱们如果现在是在重新搭建的话，可以把这个备份到别处，防止有用，然后把它们删除，然后重新生成。 双SSH生成通过Git bash窗口，生成新的SSH 生成github的SSH1ssh-keygen -t rsa -C &quot;github的email“ 会看到很多需要确认的，咱们一路Enter到底。 github账户设置中添加SSH在C:\Users\xiang_000\.ssh文件夹下就有了github_rsa、github_ras.pub,用编辑器打开pub文件，将公钥添加到github accounting-&gt;add key 配置账户信息现在你已经可以通过SSH链接到GitHub了，还有一些个人信息需要完善的。Git会根据用户的名字和邮箱来记录提交。GitHub也是用这些信息来做权限的处理，输入下面的代码进行个人信息的设置，把名称和邮箱替换成自己的。 12git config --global user.name &quot;github账户名，不是昵称&quot;git config --global user.email &quot;github邮箱名&quot; 测试1ssh -T git@github.com 看到successfully就代表上述配置就没问题，可以正常连接到github啦！ 生成gitcafe的SSH官方的参考文档就很详细了，参考：如何同时使用多个公秘钥1ssh-keygen -t rsa -C &quot;YOUR_EMAIL@YOUREMAIL.COM&quot; -f ~/.ssh/gitcafe 这样生成的gitcafe的ssh在C:\Users\xiang_000\.ssh目录下就有别名，和github生成就有区分。然后步骤差不多，将gitcafe的pub添加到gitcafe中。 Github\Gitcafe双Deploy部属双部属参考文章：hexo博客搭建时遇到的问题在 SSH 用户配置文件 ~/.ssh/config 中指定对应服务所使用的公秘钥名称(config文件的作用就是告诉git程序在同步认证的时候该使用哪个密钥），如果没有 config 文件的话就新建一个，并输入以下内容：12345678Host github.comUser gitHostname ssh.github.comPreferredAuthentications publickeyIdentityFile ~/.ssh/id_rsaPort 443Host gitcafe.com www.gitcafe.comIdentityFile ~/.ssh/gitcafe 注:新建config的两种方式： 新建txt文件,添加完内容之后，重命名，把txt格式名去掉。 touch config命令新建，再用编辑器打开 hexo站点deploy配置123456deploy:type: gitmessage: &quot;xxxxx&quot;repo:github: git@github.com:michael728/michael728.github.io.git,mastergitcafe: git@gitcafe.com:michael233/michael233.git,gitcafe-pages 注意：repo的格式要这么写，因为我们部属时，是利用的ssh方式，所以千万别写成:repo: https://github.com/michael728/michael728.github.io.git 部属，同步到gitcafe\github上12hexo cleanhexo d 关于之后的DNS域名等设置，看下一篇文章。]]></content>
      <categories>
        <category>ToolsDaily</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Windows上那些值得推荐的良心软件-整理]]></title>
    <url>%2F2015%2F11%2F28%2Ftools-list-win%2F</url>
    <content type="text"><![CDATA[Windows系统挺好用的，并不像有些程序员说的那么不堪，尽管我也一直想体验Mac，哈哈……言归正传，Win10的变化还是挺明显的，很多地方都进行了优化，个人觉得有一条技巧使用起来还是很方便的：不要管桌面有多乱，怎么方便怎么来！（强迫症患者无视……） 做法就是把常用的软件全部固定到“开始”屏幕，这样设置以后的好处就是：比如当你正在浏览器浏览网页时，想打开微信，就只要两步，按一下Win键+点击微信；如果将软件图标放在桌面的话，则需要三步，缩小你正在浏览的网页，然后切换到桌面，打开微信。很明显，你正在做的事情就被打乱了…… 工欲善其事，必先利其器！ 日常工具文件搜索 Listary 小众软件介绍，超级好用的文件搜索工具，按下快捷键，随时搜索 Everything 也是传说中的文档搜索神器！其他功能有待开发…… 火柴 原名火萤酱，是一款类似 Mac 平台上 Alfred 的效率软件，提供了搜索、启动应用等功能 聊天 TIM-QQ QQ最新推出的简洁办公版本，还不错 微信 视频播放 PotPlayer 厌烦了暴风一打开就是广告，发现了这款播放器，没广告！能力出色！ 射手播放器 没有广告，字幕匹配很方便！ QQ影音 没有广告，也很清爽 下载神器 FDM 最近体验过的最棒的下载工具了，开源免费，无广告，虽然IDM也很强大，但是IDM要钱呀，FDM一样用！2017-04-03 EagleGet 这样好的下载神器，竟然这么默默无闻，简直没有道理啊！用它来下载百度云上的资源速度也是杠杠赞！用来替代浏览器自带下载要好很多，速度快很多！缺陷是不支持BT/磁力链接…… 硕鼠 视频下载神器！为了下载PC上的网易公开课发现的工具，很多视频网站都能下载！ 维棠播放器 之前了解过的一个视频下载软件，没有体验过，据说厉害。 浏览器 Chrome 很占内存，但启动速度、标签、扩展同步等真是做的棒！一个账号，走遍天下~安利下自己总结的Chrome扩展 Chrome下载 由于某些原因，你可能无法下载扩展，这里可以帮你下载 crx4chrome FireFox 其实火狐也是不错的，它的同步是可以用的，不像chrome 需要架梯子~ 解压软件 Bandizip 清新简洁，功能很强大，最喜欢它可以设置双击直接解压，无需其他操作 7zip 著名解压软件，也是免费 笔记 印象笔记 很棒！裁剪、搜索、标签等细节功能做的很到位！简洁大气的风格，很喜欢。双十一入手了一年的VIP，hia~hia~ 有道笔记 网易的良心产品之一，推荐 pdf查看 福昕pdf阅读正版 Sumatra PDF 体积小，除了支持 PDF 阅读之外，epub 等电子书格式它也支持 电子书查看器 calibre Ebook-Reader 看图 FastStoneImageViewer 免费软件，好用到爆！没广告！功能齐全！不光能看图，还能修图！ 输入法 搜狗 搜狗输入，跨平台性确实很好，广告什么的其实可以通过设置去除的！ rime rime输入法，跨平台的良心输入法，也没有广告！ 截图 搜狗输入法 哈哈，没看错！就是它！安装截图扩展之后，快捷键就能截图，哪个电脑都ok，多方便！我的技巧总结 snipaste 国人开发的一款截图软件，挺简洁的 picpick 确实很棒的一个截图工具，很强大，界面也很舒服 sharex 一款功能非常强大的开源软件，需要学习使用，功能确实太多了 FastStone Capture 这款需要收费，但是可以很多资源找到免费的,比如这里 togif gif动态图制作软件 邮箱 Foxmail 除了接收邮件，还有RSS订阅功能！ 加密工具 Wise Folder Hider Free 隐私文件怎么保存？这个获奖无数的工具，免费版足够用啦！ 写作工具 typora 韩国的一款 Markdown 写作工具，免费的，简介好用！ marktext 一款开源的 Markdown 编辑工具 1checker 英文写作，语法校对工具 思维导图 Xmind 今天体验了一下思维导图，虽然Freemind是开源免费的，但是，这款付费的显然更胜一筹啊！颜控必备！ ProcessOn 强烈推荐，绘制思维导图、流程图等，真的很方便！看个栗子《大型网站技术架构》读书笔记 文件整理 Q-dir 有时候需要在文件夹之间移动文件，这时候，这个整理神器就能派上用场了！ 快速启动 MaxLauncer 最近发现的一款不错的软件，可以通过快捷键快速启动软件！ Wox 也是一个软件启动神器，值得体验！ 小众工具 Wgesture 用惯浏览器鼠标手势的同志，这个绝对是你们的福利！全局鼠标手势！！！ Ditto 剪贴板工具，效率必备，对于经常文字编辑的人员，那就是神器了！最近一直在使用！ 学术工具 NoteExpress 高校大多都购买了，既然有正版，为何还要千方百计去折腾外国的呢？挺好用~ 同步盘 百度云2016年这一年关了很多免费的网盘，貌似就百度网盘坚挺了，百度云也改名为百度网盘，百度云应该作为百度的云品牌发展了！果然免费的不会一直免费下去的！ OneDrive 买希捷的移动硬盘送的容量，就试试了，结果发现用来同步简直太爽了！！！而且，Windows基本都自带，其实体验挺好的！据说，淘宝可以买扩容量套餐微云腾讯的微云也不失为一种选择，尽管，最新的政策出来了，免费空间也降低了！ FileGee 卸载清理 RevoUninstaller卸载程序必备神器！体验了Iobit家的卸载产品之后，仍然回头来使用这款！有机会写篇文章来介绍一下。 Unlocker下载 当你重命名或删除一个文件/文件夹时,Windows 弹出对话框提示你“无法删除 xxx:它正在被其它用户/程序使用!”,怎么办? ccleaner 免费的系统清理软件 系统优化右键菜单管理 右键菜单-FileMenuTolls 这是一个神器，在右键菜单中方便提供了很多小功能，比如，文件校验功能，就能方便的验证系统镜像文件是否完整，有没有被修改。 屏保 fliqlo 数字时钟，屏幕保护，逼格满满 flux 视力保护，通过根据时间调节屏幕颜色，减少蓝光对视力的影响，效果有点类似iphone开启眼见屏幕保护色。 系统安全 火绒安全 最近发现的比较安静的安全软件，最喜欢它的窗口拦截功能，比如迅雷的那些弹窗，他都给拦截掉了！ 系统修复 PowerTool 查看系统进程等信息，安全修复！ Dism++ 知乎看到的，简洁的系统管理软件，集成了很多小工具，还可以系统备份 Dock 栏 RocketDock 可以在屏幕上添加Dock栏，将常用快捷方式添加到状态栏上！有点Mac效果的感觉 系统相关安装系统准备 MSDN镜像下载 干净的系统镜像！ 清华大学开源软件镜像站 可以下载到很多Linux镜像，速度很快！ easybcd 引导工具 easyuefi 引导工具 ultraiso 制作启动盘 双系统 Windows10+Ubuntu双系统安装[多图] windows10+ubuntu 16.04+双硬盘（SSD+HDD）分区（图文） Ubuntu 16.04与Win10双系统双硬盘安装图解 有这三篇文章，基本是够了，需要注意的点是：要知道你的是UEFI+GPT还是传统的MRB！ 系统检测 AIAD64 硬件检测工具，里边功能很丰富！ 硬盘性能检测-AS SSD Benchmark CrystalDiskMark UWP-CrystalDiskMark 5 资源软件资源 正版中国 filehippo 软件缘 大眼仔 精品绿色便携软件 软矿 殁漂遥 吾乐吧软件站 sourceforge softpedia 反斗软件 参考 Windows 10 上什么软件值得推荐？ Windows 平台有哪些值得推荐的常用软件？ 推荐-Gitbook-Windows绝赞应用 Windows 下的开发工具软件安装 Scoop 参考： 装机软件合集 控制台 cmder 如果厌倦了Windows下控制台丑陋不方便的样子，可以试试这个,强烈安利！这是一篇比较好的介绍文章Win下必备神器之Cmder 编辑器 VScode 微软家的编辑器，最近都在使用，强烈推荐，写作一篇总结打造性感好用的VS Code编辑器 Sublime Text Notepad++ Atom IDE Pycharm 这么棒的软件，学生党免费！前提是要有学校邮箱~下载链接 附上一个我写的使用总结PyCharm/IDEA 使用技巧总结 Redo python调试很方便，界面有点类似R-studio、 PyScripter python开发 WebStorm 最后除了这些软件，还总结了一份利器清单，主要是网页在线版的工具： 利器]]></content>
      <categories>
        <category>ToolsDaily</category>
      </categories>
      <tags>
        <tag>Tools</tag>
        <tag>Windows</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python多版本共存工具-Pyenv及Anaconda科学计算环境的配置]]></title>
    <url>%2F2015%2F11%2F26%2Fpython-pyenv-anaconda%2F</url>
    <content type="text"><![CDATA[为了安装Anaconda科学计算环境，控制好Python版本，今天上午总算折腾好了。 学习python有时希望在python2.7环境下，有时希望在python3.4环境下，该怎么办呢？ Anconda的包也不知道适合在什么环境下工作？ 解决多python环境下，python版本切换的工具–pyenv应运而生。同时，另外一个工具virtualenv则提供了一种功能， 就是将一个目录建立为一个虚拟的python环境， 这样的话， 用户可以建立多个虚拟环境， 每个环境里面的python版本可以是不同的， 也可以是相同的， 而且环境之间相互独立。下面简要介绍一下安装的过程： Unix系统下pyenv安装与使用:安装pyenv12345678$ git clone https://github.com/yyuu/pyenv.git ~/.pyenv #使用 git 把 pyenv 下载到家目录$ echo &apos;export PYENV_ROOT=&quot;$HOME/.pyenv&quot;&apos; &gt;&gt; ~/.bashrc #然后需要修改环境变量，使用 Bash Shell 的输入$ echo &apos;export PATH=&quot;$PYENV_ROOT/bin:$PATH&quot;&apos; &gt;&gt; ~/.bashrc$ echo &apos;eval &quot;$(pyenv init -)&quot;&apos; &gt;&gt; ~/.bashrc #最后添加 pyenv init$ exec $SHELL -l #输入命令重启 Shell,然后就可以重启pyenv 查看pyenv可安装的版本列表1$ pyenv install --list 該命令将列出pyenv可以安装的列表，单单列举几个咱们关心的python和anaconda把： 12345672.7.8 # Python 2最新版本3.4.1 # Python 3最新版本anaconda-2.4.0 # 支持Python 2.6和2.7anaconda3-2.0.1 # 支持Python 3.3和3.4 安装指定的python版本。1$ pyenv install 3.4.1 该命令会从github上下载python的源代码安装，但是，我这里主要是用来进行科学计算的环境安装，因此，最后选择安装anaconda-2.4.0（python2.7环境） 和 anaconda3-2.4.0（python3.4环境）。可以选择都安装，之后可以使用pyenv进行版本的切换。注： 这里利用pyenv命令安装的python版本都安装在~.pyenv/versions文件夹下，当然，如果你从图形界面进入Ubuntu的用户主目录下可能看不见.pyenv文件夹，这时候，你可以使用ls -a看到隐藏的文件夹。 使用pip安装的包完成之后，可能需要对数据库进行更新:1pyenv rehash 卸载指定的python版本1pyenv uninstall x.x.x python版本查看查看当前已经安装了的python版本：1pyenv versions 输出结果如下：1234*system (set by /home/michael/.pyenv/version)2.7.13.4.1anaconda-2.4.0 system是指系统的python版本；*表示当前环境所处于的python版本 python版本切换全局版本切换：1pyenv global anaconda-2.4.0 全局切换为anaconda科学计算环境，因为，我现在也不做其他python开发，所以，无需再安装其他环境了。查看现在的python版本： 12345michael@michael-ThinkCentre-XXXX:~$ pyenv versionssystem2.7.13.4.1* anaconda-2.4.0 (set by /home/michael/.pyenv/version) 有全局版本切换，当然也会有局部环境的切换：在test文件夹下希望切换到python3.4.1:1pyenv local python3.4.1 Anaconda科学计算包的使用：使用conda list查看anaconda安装自带的包：1234567891011michael@michael-ThinkCentre-XXXX:~/test$ conda list# packages in environment at /home/michael/.pyenv/versions/anaconda-2.4.0:#abstract-rendering 0.5.1 np110py27_0alabaster 0.7.6 py27_0anaconda 2.4.0 np110py27_0anaconda-client 1.1.0 py27_0argcomplete 1.0.0 py27_1astropy 1.0.5 np110py27_1babel 2.1.1 py27_0backports.ssl-match-hostname 3.4.0.2 &lt;pip&gt; 注： 使用conda list命令的环境时python版本切换到anaconda版本下，不然，这个命令无法来查询。 看上面列表就能知道，anaconda的环境下，也是能使用系统pip命令安装的包的！ 给anaconda安装包1conda install ×××× 如果需要指定包的版本。1[package-name]=x.x #指定包的版本 多个Python版本并存，尤其是2.x和3.x的并存。这个通过virtualenv可以做到。Anaconda也正是通过其实现的。下面用conda创建一个名叫python2的版本为python2.7的环境。 1conda create -n python2 python=2.7 这样就会在Anaconda安装目录下的envs目录下创建python2这个目录。向其中安装扩展可以： 直接用conda install并用-n指明安装到的环境，这里自然就是python2。像virtualenv那样，先activate，然后在虚拟环境中安装。注： 关于virtualenv的使用，还需了解，可以参考python生态 下面的操作，貌似会安装很多包，谨慎使用。 1conda create -n py34 python=3.4 anaconda 利用Pycharm的版本切换功能~推荐！很方便！可以选择安装anaconda 不同的版本，然后按照下面操作,切换版本。Windows/Linux下都有[Pycharm][1]。 打开pycharm，打开preference –&gt; project –&gt; project interpreter–&gt; Windows系统切换首先当然是安装你需要的两个不同版本的python，我安装的是2.7和3.4的，两个版本安装顺序无所谓，但是后面安装的会变成默认的（因为我是后安装的python 3.4，它就变成了默认的python）。 然后去python27 文件夹下面把python.exe改名python2.exe，然后就可以在命令行下通过python或者py来调用3.x，python2来调用2.x。 另外pip的话直接使用 pip2 或者 pip3 就可以了。 参考：pyenv Python多版本共存之pyenv yyuu/pyenv-github 用pyenv 和 virtualenv 搭建单机多版本python 虚拟开发环境 lixm/pybooklet-github 使用 pyenv 和 Miniconda 管理 Python 科学计算环境 Python 2.X 3.X 多版本共存 一篇文章入门Python生态系统 Anaconda DOWNLOAD ANACONDA NOW P]ython科学计算利器——Anaconda Python科学计算发行版—Anaconda Virtualenv(待续) https://virtualenv.pypa.io/en/latest/installation.html]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>Anaconda</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[那些离不开的 Chrome 扩展插件]]></title>
    <url>%2F2015%2F11%2F26%2Ftools-chrome-extentions%2F</url>
    <content type="text"><![CDATA[虽然Chrome浏览器是个吃内存的怪兽，但是，它却因为启动速度、调试功能等成为了程序猿的必备浏览器！今天有时间，整理一下自己最常用的一些Chrome扩展吧： 常用网页浏览非开发类扩展：Tampermonkey推荐指数：★★★★★最近发现的神器啊，哈哈，很喜欢，利用脚本比安装扩展少用内存啊！速度还快！用法也很简单–20151202更新用法简要记录下： Greasy Fork国内油猴脚本的下载地，常用的百度网盘助手,去除贴吧列表里面的广告，CSDN去广告自动展开文章等脚本都有 当找到脚本之后，点击安装即可，然后在相关网站，就会有效果了。例如，在百度网盘下载页面，就会有百度助手下载按钮出现。 在相应页面点击油猴扩展，可以查看脚本，可以禁用。也可以卸载安装过的脚本。 两个可以发现好用的脚本的网站： https://greasyfork.org/zh-CN https://openuserjs.org/ 下图是我目前在用的几个脚本： 解除B站区域限制解锁B站其他区域的视频 CSDN自动展开+去广告+净化剪贴板+免登陆 EX-百度云盘 MiniblogImgPop - 微博浮图 MoreMovieRatings 豆瓣查看电影时，会有烂番茄的评价 Yet Another Weibo Filter 看真正想看的微博 还你一个清爽的微博 百度网盘直接下载助手 直链加速版 破解VIP会员视频集合 观看 VIP 视频时，左侧会有可播放列表 OneTab推荐指数：★★★★★ Chrome是个吃内存的怪兽啊！有了这个神器，网页打开再多都不怕啦！必装！推荐！ Markdown Here推荐指数：★★★★★ 这个扩展简直是Markdown的福音啊！！！在写邮件、印象|为知笔记（命名不需要.md)在线版编辑文字时,遵循Markdown语法编辑文字，然后点击Markdown Here扩展就可以可以一键渲染！渲染效果可以在该扩展选项里进行设置，多个主题可以选择！没钱入手马克飞象的同志们，可以考虑用这个神器啊！！！从此，邮件也可以回复的有逼格啦! 新浪微博图床推荐指数：★★★★★ 简单好用的新浪微博图床,支持选择/拖拽/粘贴上传图片,并生成图片地址,HTML,UBB和Markdown等格式,支持浏览和删除历史记录。 扩展管理器推荐指数：★★★★★ 对于经常折腾扩展的同志们，就不用担心扩展安装多了，chrome就卡的问题！有了它，轻松管理扩展，暂时不用却又舍不得卸载的扩展，就可以左击一键禁用和启用，右击卸载。必装！这个插件是最新（20190303）发现的，比之前的 SimpleExtManager 好用点 右键搜推荐指数：★★★★ 看到扩展这么多设置选项，就知道它的功能是有多强大了！功能就是如它的扩展名一样，对于浏览网页时的图片，链接等，右键点击，提供很多扩展功能，例如： 对图片右击，可以选择去谷歌搜索相似图片|解析图片的网址|提取图片二维码 对页面右击，可以定制进入浏览器扩展程序菜单|查看内存|生成当前网址二维码更关键的是，它还支持自定义很多功能，例如，你可以设置对选中文字，进行在知乎里搜索！可以通过方法，自定义搜索引擎！必装神器！ 眼不见心不烦（新浪微博）推荐指数：★★★★★ Chrome就是满分评价，可见这扩展真是良心扩展啊！微博党的福音！在浏览器端，自己通过这个插件进行设置，可以将热门微博、会员推广等等内容窗口都给屏蔽了！还我们一个干净、舒服的微博环境！推荐！！！ LastPass: Free Password Manager推荐指数：★★★★★ LastPass,屡获殊荣的密码管理器,保存你的密码,让你安全访问任何计算机和移动设备。多平台同步，离不开的密码神器！安全可靠~ Chrono下载管理器推荐指数：★★★★ 这是个下载扩展，好用！之前在下载百度网盘文件时，点击下载，需要一堆操作，登录网盘，保存到网盘……为啥就不能直接下载呢？！直到我发现了它！点击下载就立马启动Chrome自带的下载器下载了！个人觉得离不开，必装！ 网页截图:注释&amp;批注推荐指数：★★★★ 在安装了一堆截图扩展之后，最后剩下了它，满足了截图所有的需求，截取可见网页，选择区域，整个网页，另外，还有对截图的标记。 印象笔记·剪藏推荐指数：★★★★★ 作为一名大象用户，这个扩展肯定是必装！这里必须稍微介绍一下它的使用： 收藏网页 截图 在百度，google搜索内容时，提供搜索笔记相关内容的功能，出现在搜索结果第一行 uBlock Origin推荐指数：★★★★★ 发现这一款效果也很好！ Save to Pocket推荐指数：★★★★ 看到感兴趣的先收藏着，然后走哪儿都能看，因为它提供了全平台的APP，方便管理。Pocket也是手机端我必装的APP之一。 Imagus推荐指数：★★★★ 图片放大镜的功能！在体验了360浏览器、猎豹浏览器之后，特地去找的扩展！微博党的利器！这个不管能鼠标悬停放大图片，同时，对链接等也有预览。提供很多功能选项进行设置。 crxMouse Chrome Gestures推荐指数：★★★★ 对于国产浏览器自带鼠标手势的功能，真觉得很方便！这款扩展也是必装啊！ 标签页Infinity新标签页推荐指数：★★★★ 功能强大的新建标签页扩展！做的界面很美，每日壁纸质量也很高！有同步笔记、代办事项等，同时，喜欢它的网页图标，提供了很多常用网站的图标，自定义书签时很好看~唯一的缺点，就是感觉启动比较慢~ Momentum推荐指数：★★★★ 现在在用的标签页扩展，挺简洁的，壁纸很美！ RSSHub Radar今天经过公众号的推荐发现的一个 RSS 利器，对于喜欢订阅 RSS 的用户来说，真是方便！可以发现你访问的网站上的 RSS 源地址。 惠惠购物助手推荐指数：★★★ 剁手党的神器！本来想给五星的，但是，双十一期间，竟然对淘宝不能查价了！减了两个★！还有，安装它之后，必须要进入扩展选项设置，不然这货会弹出广告！ 程序猿开发相关扩展：Vimium推荐指数：★★★★★ shift+b 搜索你书签中的链接，所以，保存书签的时候，设置点关键字吧 x 快速关闭标签 shift+x 快速恢复你之前关闭的标签 gg 回到页首 G 回到页尾 VIM党的利器。今天特地录制了一个小视频，介绍它的使用方法： https://www.bilibili.com/video/av56598067 API 测试工具 Restlet Client - REST API Testing 颜值比较高，另外，Postman 已经提供独立的软件了，推荐 Clear Cache推荐指数：★★★★★ 点击图标即可清除缓存、cookie等，开发必备！ JSON Viewer Awesome推荐指数：★★★★★ 看到同事用的，颜值超高的JSON文件渲染，比之前用的JSON Viewer颜值还要高，更方便！ Git这里列几个和 Git 相关的 octotree推荐指数：★★★★★ Web浏览Github项目时必备的插键，快速查看项目结构 sourcegraph推荐指数：★★★★★ sourcegraph配合 Github 使用，真是利器，有点 WebIDE 的感觉 Git History Browser Extension推荐指数：★★★★★ 官网Git History介绍只需要将 GitHub 仓库的 『github.com』网址替换为『github.githistory.xyz』，则可以动态显示文件的提交历史 Isometric Contributions推荐指数：★★★ 3D 展示你 Github 上的提交活动，酷炫的 WhatRuns推荐指数：★★★★★ 查看访问的网页主要采用了什么技术框架，之前有个类似的插键 wappalyzer，没这个全 Code Cola推荐指数：★★★★ Code Cola是一个可视化编辑在线页面css样式的chrome插件。 WEB前端助手(FeHelper)推荐指数：★★★★ FE助手：包括字符串编解码、图片base64编码、代码压缩、美化、JSON格式化、正则表达式、时间转换工具、二维码生成器、编码规范检测、页面性能检测、栅格检测、JS运行效率分析等 二维码(QR码)生成器推荐指数：★★★★ 前端开发调试，生成当前网页的二维码 XPath Helper爬虫好像使用到的一个插键，这里有个教程 XPath Helper：chrome爬虫网页解析工具 Chrome插件图文教程 Changelog20190303 去除了一些不用的插键 补充了工作后用到的一些有用的插键，比如 git 相关的 参考 Chrome插件英雄榜 介绍了一些比较少见的扩展，掘金上发的一篇文章]]></content>
      <categories>
        <category>ToolsDaily</category>
      </categories>
      <tags>
        <tag>Chrome</tag>
        <tag>扩展</tag>
        <tag>效率软件</tag>
      </tags>
  </entry>
</search>
